The number of train datas: 6660
The number of test datas: 1666
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7024178137650361	0.5027027027027027	0.692410011394542	0.5240096038415366
1	0.6982779424827736	0.5112612612612613	0.6882116116252409	0.539015606242497
2	0.6913834483057887	0.5298798798798798	0.6863069411228542	0.56062424969988
3	0.6889965553541442	0.5361861861861862	0.683890121037505	0.5834333733493398
4	0.6844039198872564	0.5522522522522523	0.6818307105805121	0.5882352941176471
5	0.6815433956123329	0.5605105105105105	0.6778069111336322	0.6032412965186075
6	0.680475127947581	0.5672672672672673	0.6743575252977168	0.6128451380552221
7	0.6720031537809171	0.5858858858858859	0.669084494998332	0.6350540216086434
8	0.6690913928879632	0.5945945945945946	0.6619495811725722	0.6554621848739496
9	0.6574389164154236	0.6264264264264264	0.653686117725212	0.6632653061224489
10	0.6519683807461827	0.6237237237237238	0.6439761762716332	0.687875150060024
11	0.6424146456761403	0.6408408408408408	0.6336541471361112	0.6974789915966386
12	0.6312132143043541	0.6490990990990991	0.6218647291394127	0.7118847539015606
13	0.617787083813378	0.672972972972973	0.607798497072932	0.7160864345738295
14	0.6014633457223932	0.686036036036036	0.5909465205054037	0.7250900360144058
15	0.5887959247952825	0.7004504504504504	0.5727315638818088	0.7436974789915967
16	0.5700423137024716	0.7202702702702702	0.5560849634539179	0.7430972388955582
17	0.5451849525755232	0.730930930930931	0.5320486613109905	0.7635054021608644
18	0.5257567659154668	0.748048048048048	0.5114667029941783	0.7737094837935174
19	0.5023850994783121	0.7615615615615615	0.49982156891639634	0.7683073229291717
20	0.48476371013366426	0.778078078078078	0.4773704808156173	0.7869147659063626
21	0.4633735146339949	0.7848348348348348	0.45305322641942825	0.7989195678271308
22	0.4433916889511429	0.8046546546546547	0.43110745236510134	0.8139255702280912
23	0.4247805891631244	0.8162162162162162	0.41355894700962814	0.8241296518607443
24	0.4069794243520445	0.825075075075075	0.40801687075310394	0.8223289315726291
25	0.3931414537959629	0.836036036036036	0.38248585910499455	0.8499399759903962
26	0.36668862623495385	0.8540540540540541	0.3797395085873438	0.84093637454982
27	0.36169996841533764	0.8536036036036037	0.3523117108863084	0.8637454981992797
28	0.3429009706408412	0.8611111111111112	0.34125931766711504	0.8637454981992797
29	0.33611594213021767	0.8660660660660661	0.33102697091085426	0.8721488595438175
30	0.323006980948978	0.8698198198198198	0.32213074952757514	0.8709483793517407
31	0.3076223771627601	0.8798798798798799	0.31346899458841115	0.8739495798319328
32	0.3041532470299317	0.8764264264264264	0.31252061172264395	0.8775510204081632
33	0.2913564071282968	0.8888888888888888	0.29552036098071505	0.8835534213685474
34	0.28394543984541304	0.8944444444444445	0.30014162933697647	0.8805522208883554
35	0.27200940492990855	0.8993993993993994	0.3027396800280476	0.8763505402160864
36	0.2632339644002485	0.9036036036036036	0.31119998675935406	0.8673469387755102
37	0.26828077722777116	0.896996996996997	0.2636615807483462	0.8997599039615847
38	0.2536550792487892	0.9076576576576577	0.26460802290333707	0.897358943577431
39	0.25151330655043547	0.9082582582582582	0.26736833650667985	0.8943577430972389
40	0.24606056725298678	0.9123123123123124	0.24970792505849881	0.9027611044417767
41	0.23343414870557844	0.9187687687687688	0.25403397622443336	0.8961584633853541
42	0.2337498266775687	0.9166666666666666	0.23839505438973493	0.9081632653061225
43	0.22707179555663834	0.9222222222222223	0.23382832052684774	0.9093637454981993
44	0.21932598950268628	0.9255255255255255	0.27560706221971476	0.8907563025210085
45	0.21310220183552922	0.9219219219219219	0.22704176119968097	0.907563025210084
46	0.21297989953029622	0.9294294294294294	0.22819015204834908	0.9105642256902761
47	0.20623099637013656	0.9303303303303303	0.22495792423333583	0.9105642256902761
48	0.19864636724059645	0.9330330330330331	0.2159622241647876	0.9177671068427371
49	0.2023621879092924	0.9325825825825825	0.213492642913689	0.9159663865546218
50	0.19923859729848287	0.9328828828828829	0.21641889108973247	0.9129651860744298
51	0.18666206161539117	0.9361861861861862	0.20774497845772505	0.921968787515006
52	0.1841596612343201	0.94009009009009	0.20819746786091223	0.9213685474189676
53	0.1888319359751077	0.9370870870870871	0.20416589512401412	0.9195678271308524
54	0.17739054860026987	0.9424924924924925	0.20360626221275557	0.9183673469387755
55	0.18136012267780016	0.9405405405405406	0.21772928554721238	0.918967587034814
56	0.17396570294200478	0.9442942942942943	0.2069690425713666	0.9177671068427371
57	0.17275571938346815	0.9430930930930931	0.20251153899627286	0.9201680672268907
58	0.16862544444006486	0.9459459459459459	0.19493496974333138	0.9237695078031213
59	0.1651225534690035	0.9472972972972973	0.198499148543857	0.921968787515006
60	0.1626986834402378	0.9456456456456457	0.19266378545031257	0.9237695078031213
61	0.1654060238653475	0.9474474474474475	0.19246925576394344	0.9255702280912365
62	0.1633655942864604	0.9478978978978979	0.1915986049218195	0.9261704681872749
63	0.15564202782628056	0.9506006006006006	0.18817278043347963	0.9297719087635054
64	0.15780803931725992	0.9495495495495495	0.19590635411664933	0.9285714285714286
65	0.1574777022854344	0.951051051051051	0.19380005967824543	0.9297719087635054
66	0.16234496177786642	0.9462462462462462	0.18725593829927753	0.9255702280912365
67	0.1508198217586712	0.9545045045045045	0.18782024101621392	0.9261704681872749
68	0.15551520173770708	0.9522522522522523	0.19073410821454723	0.9285714285714286
69	0.141485897646294	0.9561561561561561	0.20690451165278848	0.9237695078031213
70	0.1459229697336306	0.956006006006006	0.19119220995316272	0.9303721488595438
71	0.14411505365872884	0.9551051051051052	0.21303842704640288	0.9225690276110444
72	0.14844266842077444	0.9518018018018019	0.18781468269525886	0.9279711884753902
73	0.14809514715506866	0.9537537537537537	0.18890220662053464	0.9309723889555822
74	0.14357366966861146	0.9567567567567568	0.18598845003604317	0.9315726290516206
75	0.1420543449419039	0.9554054054054054	0.19797332766426712	0.9297719087635054
76	0.1400204647186998	0.9585585585585585	0.19166821655945904	0.9315726290516206
77	0.1384374439716339	0.9567567567567568	0.19336567720731482	0.9303721488595438
78	0.13495193231772554	0.9576576576576576	0.18591368848643527	0.9357743097238895
79	0.13084343594831746	0.9579579579579579	0.1902942259808262	0.9327731092436975
80	0.13199706237998093	0.9587087087087087	0.18462035269224916	0.9345738295318127
81	0.13274994759230285	0.9572072072072072	0.2117805325416099	0.9255702280912365
82	0.136462583721758	0.9591591591591592	0.18336232938543232	0.9357743097238895
83	0.1303229257061675	0.9579579579579579	0.18224139035749837	0.9375750300120048
84	0.12459145110134069	0.9626126126126127	0.18877882864616927	0.9333733493397359
85	0.1272978578618652	0.9612612612612612	0.1880665949555863	0.9339735894357744
86	0.1258092567816869	0.962012012012012	0.19297479770156373	0.9333733493397359
87	0.12873957523175547	0.9605105105105105	0.18426478268647967	0.9357743097238895
88	0.11953671307893128	0.9629129129129129	0.1852667238853988	0.9297719087635054
89	0.13174889365116038	0.9587087087087087	0.18435672143785034	0.9351740696278511
90	0.12229767323949853	0.9621621621621622	0.19251525334092606	0.9333733493397359
91	0.1175374876271497	0.9629129129129129	0.18562463077963615	0.93937575030012
92	0.1215229560036559	0.9602102102102102	0.18419053039702477	0.9399759903961584
93	0.11596110374988379	0.9644144144144144	0.1905591180648695	0.9345738295318127
94	0.11801642536132544	0.965015015015015	0.1839109365196646	0.93937575030012
95	0.11497211293639005	0.9647147147147147	0.18908833189546562	0.9351740696278511
96	0.11674281526748483	0.9642642642642643	0.18291348404958754	0.9381752701080432
97	0.11491101500284565	0.9654654654654654	0.18472191267440013	0.93937575030012
98	0.10710067276482109	0.9683183183183183	0.18694950539131266	0.93937575030012
99	0.11226581509138371	0.9654654654654654	0.1846990956961751	0.936374549819928

The optimal condition:
	epoch: 92
	train_acc: 0.9602102102102102
	val_acc: 0.939975990396
	using time: 466.86769104
