The number of train datas: 6660
The number of test datas: 1666
epoch	train_loss	train_acc	val_loss	val_acc
0	0.700981395380633	0.5097597597597597	0.6942721462192513	0.507202881152461
1	0.6974644340194381	0.5154654654654655	0.6901473770050012	0.5348139255702281
2	0.6889470196701026	0.5321321321321322	0.6888379451035023	0.5462184873949579
3	0.6874844379611201	0.5333333333333333	0.6862089279032841	0.563625450180072
4	0.6828363264645184	0.5624624624624625	0.6838347146204826	0.5726290516206483
5	0.6803030147924796	0.5638138138138138	0.6793921852455277	0.5930372148859544
6	0.6765721628973792	0.571021021021021	0.6743106169431579	0.6176470588235294
7	0.6710020129745071	0.5848348348348348	0.6684280912987753	0.6188475390156063
8	0.6650908933387504	0.6022522522522522	0.6599327058208232	0.6518607442977191
9	0.6516382202013835	0.6337837837837837	0.6522568819903526	0.6356542617046819
10	0.645455475326057	0.6303303303303304	0.6397228965095254	0.673469387755102
11	0.6355445984605554	0.6451951951951952	0.628113613910034	0.6902761104441777
12	0.6276787773624912	0.6587087087087087	0.616598608971787	0.6968787515006002
13	0.6164400750810319	0.6666666666666666	0.6045471268112348	0.6974789915966386
14	0.5937580456604828	0.696996996996997	0.587281233551694	0.7214885954381752
15	0.5870891694192056	0.6941441441441442	0.5740418295327927	0.726890756302521
16	0.5674279440630664	0.7171171171171171	0.5584805688651956	0.734093637454982
17	0.5502508890700412	0.7262762762762762	0.5388256939662461	0.7575030012004802
18	0.5286535712870749	0.7453453453453454	0.5177294674182997	0.7773109243697479
19	0.5088638166049579	0.7632132132132132	0.5062347528885822	0.7665066026410564
20	0.485380806937232	0.7774774774774775	0.48056523439263094	0.7839135654261705
21	0.4667042693397304	0.7894894894894895	0.45627739506752407	0.804921968787515
22	0.4441102078369072	0.806006006006006	0.4323580893291002	0.8283313325330132
23	0.42057786546311937	0.8183183183183184	0.4059548747925913	0.8301320528211285
24	0.4024230175190144	0.8259759759759759	0.4084236430449217	0.8211284513805522
25	0.3833978905155136	0.8387387387387387	0.3713538772633382	0.843937575030012
26	0.3593774680976753	0.8493993993993993	0.37301034114512505	0.8349339735894358
27	0.34786183322156156	0.860960960960961	0.33416451404647096	0.8697478991596639
28	0.3323079553810326	0.8678678678678678	0.31787848028959204	0.8757503001200481
29	0.321947497845412	0.8767267267267267	0.30643275186938257	0.8787515006002401
30	0.3003269431290326	0.8851351351351351	0.29036236360293477	0.8895558223289316
31	0.29251883429539455	0.8933933933933934	0.2939529801402487	0.8709483793517407
32	0.28159608218046994	0.895045045045045	0.2752874865680754	0.8871548619447779
33	0.27499100130957527	0.898048048048048	0.2725129195836698	0.8847539015606243
34	0.26737051966849035	0.9007507507507507	0.2711197491131481	0.8841536614645858
35	0.25664192035391525	0.906006006006006	0.25559620020770224	0.8979591836734694
36	0.24455912867644886	0.9124624624624624	0.25616332219571486	0.8913565426170468
37	0.24520820694284753	0.9151651651651652	0.2317963362026329	0.9153661464585834
38	0.2364174271131063	0.9174174174174174	0.228885817749589	0.9141656662665066
39	0.23305378731888335	0.9196696696696697	0.24079129670490595	0.9015606242496998
40	0.22729295334658464	0.9240240240240241	0.22415199521638338	0.9159663865546218
41	0.22012141097236324	0.9304804804804805	0.21460833583845526	0.9231692677070829
42	0.21499507075494473	0.9265765765765765	0.21016142491389866	0.9237695078031213
43	0.2080364733263179	0.9291291291291291	0.2045897456491981	0.9273709483793517
44	0.2013948112994701	0.9331831831831832	0.2711338125714878	0.8865546218487395
45	0.20256294989371085	0.9303303303303303	0.19857310400862083	0.9285714285714286
46	0.19762957248243843	0.936036036036036	0.19600595832586576	0.9297719087635054
47	0.19352495674345943	0.9348348348348349	0.20264531906340874	0.9201680672268907
48	0.18706481426327795	0.9403903903903904	0.18931823546717577	0.9303721488595438
49	0.19167454558628816	0.9432432432432433	0.1934062921557249	0.9279711884753902
50	0.1831213050060444	0.9427927927927928	0.19020486146318955	0.9309723889555822
51	0.17869403319315869	0.9429429429429429	0.18430433850757785	0.9339735894357744
52	0.1768553918456888	0.9435435435435435	0.18291393716652998	0.9345738295318127
53	0.17714143915622085	0.9429429429429429	0.183498972711586	0.9327731092436975
54	0.16684462817402573	0.9478978978978979	0.1845604631365562	0.9309723889555822
55	0.17167398934518252	0.945045045045045	0.19469287088152026	0.9279711884753902
56	0.1658901869691349	0.9486486486486486	0.18290084953747449	0.9327731092436975
57	0.16309235454970472	0.9480480480480481	0.1816678236619908	0.9339735894357744
58	0.16004711002021937	0.9521021021021021	0.1756815607307338	0.9375750300120048
59	0.15728891750982216	0.9498498498498499	0.18982909464177822	0.9297719087635054
60	0.15329824302110587	0.951051051051051	0.1749077994210952	0.93937575030012
61	0.1576417524199765	0.9521021021021021	0.17361982520960387	0.9399759903961584
62	0.15277345320125957	0.9521021021021021	0.1775148977645162	0.9381752701080432
63	0.14906829788878156	0.9548048048048048	0.16904003425341407	0.9399759903961584
64	0.14926151944710328	0.951051051051051	0.17144720140053016	0.9411764705882353
65	0.1447449940818924	0.9551051051051052	0.17121032771228456	0.9399759903961584
66	0.15333273424948748	0.9501501501501501	0.16840299461282887	0.9423769507803121
67	0.14555170009578314	0.954954954954955	0.1720367266493542	0.9381752701080432
68	0.14724486746766546	0.956006006006006	0.17386497859479713	0.9369747899159664
69	0.13918816014878205	0.9581081081081081	0.17328496459795503	0.9387755102040817
70	0.13881435853292098	0.9573573573573574	0.1716251914240733	0.9411764705882353
71	0.14102797241987766	0.9573573573573574	0.1706425610030828	0.9429771908763506
72	0.1372175520604795	0.960960960960961	0.17231720265577966	0.93937575030012
73	0.14183855674959517	0.9569069069069069	0.1683609636963344	0.9447779111644657
74	0.1316076407740424	0.9608108108108108	0.17243064480240033	0.9405762304921969
75	0.13605257845497704	0.9581081081081081	0.18757598721036534	0.9309723889555822
76	0.13588230662025488	0.9606606606606607	0.17459765030127042	0.9357743097238895
77	0.13067340849935113	0.9608108108108108	0.1732117262582819	0.9381752701080432
78	0.1307159924337098	0.9605105105105105	0.16541700236866025	0.9459783913565426
79	0.12725978753230235	0.9612612612612612	0.1932550627885818	0.9309723889555822
80	0.12932892002098195	0.9617117117117117	0.16317256863842777	0.943577430972389
81	0.12509072072155125	0.9642642642642643	0.20909164770811545	0.9267707082833133
82	0.13519427900736755	0.959009009009009	0.1647391754145525	0.9429771908763506
83	0.12580753784995896	0.9629129129129129	0.16433711314187044	0.9447779111644657
84	0.12046996315678318	0.9630630630630631	0.17460294404164367	0.936374549819928
85	0.12096969338061216	0.9641141141141141	0.16953363189963447	0.9411764705882353
86	0.12272083127127216	0.9644144144144144	0.16722144007611245	0.943577430972389
87	0.11863831966757417	0.966066066066066	0.16862763773922732	0.9423769507803121
88	0.11517977747652265	0.965915915915916	0.16327158020002072	0.9447779111644657
89	0.11972822453435118	0.9656156156156156	0.16752037076818413	0.943577430972389
90	0.11374966919243157	0.9678678678678678	0.16841610239333465	0.9447779111644657
91	0.11408039375513165	0.9668168168168169	0.16264927140375574	0.9453781512605042
92	0.11202908687897631	0.9662162162162162	0.16584934576862856	0.9459783913565426
93	0.11368922593782435	0.9644144144144144	0.16955883074708344	0.9423769507803121
94	0.11010751192857911	0.9671171171171171	0.1639020636516745	0.9453781512605042
95	0.10724730141651076	0.9677177177177178	0.16682655556576878	0.9447779111644657
96	0.11322642421914829	0.963963963963964	0.16431778172055642	0.9453781512605042
97	0.10976756062727791	0.9671171171171171	0.16723171987381874	0.9447779111644657
98	0.10196132019117429	0.9692192192192193	0.17126046011105878	0.943577430972389
99	0.10679810981213061	0.9675675675675676	0.16591596919126442	0.9477791116446579

The optimal condition:
	epoch: 99
	train_acc: 0.9675675675675676
	val_acc: 0.947779111645
	using time: 518.889090061
