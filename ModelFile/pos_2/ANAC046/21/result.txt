The number of train datas: 6660
The number of test datas: 1666
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7061156725024318	0.49234234234234237	0.6970540277239512	0.5054021608643458
1	0.7010125496008016	0.4987987987987988	0.6934003175235167	0.5162064825930373
2	0.6946313548016476	0.5103603603603604	0.6921185880434327	0.5234093637454982
3	0.6921900394084576	0.5193693693693694	0.6901428240115474	0.539015606242497
4	0.690373698011175	0.5328828828828829	0.6888567983460169	0.5462184873949579
5	0.6883539996705613	0.5351351351351351	0.6868302352717516	0.5642256902761105
6	0.6868195322540788	0.5504504504504505	0.6845575952444042	0.5768307322929171
7	0.6833138230326655	0.5585585585585585	0.6808572179701577	0.5888355342136855
8	0.6769694830204274	0.571021021021021	0.6761575459289093	0.6080432172869148
9	0.6713240265488266	0.5926426426426427	0.671636819267044	0.6074429771908764
10	0.6662618387926806	0.6027027027027027	0.6624996998444611	0.6332533013205283
11	0.6600555912868397	0.6064564564564564	0.6545712545710881	0.6524609843937575
12	0.6540549349498462	0.6237237237237238	0.6458129563680789	0.6554621848739496
13	0.6401529060648726	0.6382882882882883	0.6350346324252052	0.6644657863145258
14	0.6288674922497781	0.6507507507507507	0.6218761489027832	0.6746698679471789
15	0.6179100346278857	0.6621621621621622	0.6109746707444574	0.6800720288115246
16	0.6071505276111511	0.6764264264264265	0.5983831546172088	0.6836734693877551
17	0.5899939368973981	0.6912912912912913	0.5826511434575661	0.6992797118847539
18	0.5705780088006556	0.7100600600600601	0.5679742689607811	0.7130852340936374
19	0.5559106735853819	0.7205705705705706	0.5643716176875643	0.709483793517407
20	0.5352812622939502	0.7415915915915916	0.5431756246275976	0.7214885954381752
21	0.5222562564206911	0.7493993993993994	0.5234693759629706	0.7448979591836735
22	0.49497393294497655	0.7707207207207207	0.49266454881551314	0.7737094837935174
23	0.47806353758763265	0.7827327327327327	0.47252832097308833	0.7857142857142857
24	0.45752238894368075	0.7920420420420421	0.4623449026894312	0.7845138055222088
25	0.4371158486550993	0.8094594594594594	0.43253827177319065	0.8169267707082833
26	0.4100619370514924	0.824024024024024	0.4498840776347026	0.7767106842737095
27	0.4055109662157637	0.8262762762762763	0.39597168332245314	0.8307322929171669
28	0.3761580544012087	0.842042042042042	0.37770603069451963	0.8397358943577431
29	0.3690191378822556	0.8438438438438438	0.36561543837028676	0.8457382953181273
30	0.3419750953758801	0.862012012012012	0.3477693121759545	0.8547418967587035
31	0.334187983446293	0.8642642642642643	0.3567462854382514	0.8355342136854742
32	0.3226510445992868	0.8696696696696696	0.3244078909578014	0.8607442977190877
33	0.31341825353132713	0.8743243243243243	0.3273733312270793	0.8571428571428571
34	0.30150010481969014	0.8840840840840841	0.3455240628799471	0.8463385354141657
35	0.2904758626813287	0.8903903903903904	0.2970592650402637	0.8721488595438175
36	0.27626230852739947	0.895045045045045	0.322832398715855	0.8613445378151261
37	0.2745840828518968	0.8987987987987988	0.2761349925974838	0.8775510204081632
38	0.2603570634538347	0.9043543543543544	0.27461195242505115	0.89015606242497
39	0.2640957708607565	0.9001501501501501	0.27784102387717363	0.8835534213685474
40	0.2503380145933535	0.9108108108108108	0.26733808593303504	0.8883553421368547
41	0.24195955534418065	0.9126126126126126	0.26480686767440453	0.8895558223289316
42	0.23754536982950147	0.9127627627627628	0.24758361319319255	0.8979591836734694
43	0.23001805517050597	0.9183183183183183	0.23991271753271087	0.904561824729892
44	0.22366454551169823	0.9204204204204204	0.30730853464101116	0.8757503001200481
45	0.22302408886027408	0.9223723723723724	0.2367512934169277	0.9069627851140456
46	0.21976288549892894	0.9240240240240241	0.22597557970849264	0.9093637454981993
47	0.2108522121187624	0.9256756756756757	0.239476222951873	0.907563025210084
48	0.1998453581476355	0.9325825825825825	0.21456099885637733	0.9159663865546218
49	0.2049890250325561	0.9343843843843844	0.2209301019380359	0.9141656662665066
50	0.1936508965809961	0.9354354354354354	0.2165461457899066	0.9171668667466987
51	0.19136495676126566	0.9327327327327327	0.2071242575206104	0.9237695078031213
52	0.1925689182839952	0.9351351351351351	0.20717560343381738	0.9195678271308524
53	0.18958338916570217	0.9363363363363363	0.21030497275480703	0.921968787515006
54	0.18007774696693765	0.9384384384384384	0.19845160951061983	0.9297719087635054
55	0.1826289693335513	0.937987987987988	0.22019676459865983	0.9147659063625451
56	0.17767122769029112	0.9414414414414415	0.20503260978773719	0.921968787515006
57	0.16872039400376715	0.9453453453453453	0.20673907810256403	0.9195678271308524
58	0.16475543413792287	0.943993993993994	0.19131700383300254	0.9315726290516206
59	0.16227854133189262	0.9463963963963964	0.19575988800049116	0.9279711884753902
60	0.15710677926515315	0.9487987987987988	0.18604728677908197	0.9333733493397359
61	0.16284104767325405	0.9480480480480481	0.19011435274030267	0.9309723889555822
62	0.1596091802950736	0.9509009009009008	0.19278032711001575	0.929171668667467
63	0.15078154956256304	0.9518018018018019	0.18087746288810744	0.9381752701080432
64	0.15464114142251803	0.9480480480480481	0.18770278145034774	0.9297719087635054
65	0.14872053825819456	0.9518018018018019	0.1948379982991808	0.9213685474189676
66	0.1588943888441668	0.9471471471471471	0.17927564736925253	0.9357743097238895
67	0.145565288270021	0.9540540540540541	0.18834187458900986	0.9303721488595438
68	0.14466226591809733	0.954954954954955	0.19455647611675286	0.9261704681872749
69	0.13877599960690862	0.9575075075075075	0.1923541031232258	0.9267707082833133
70	0.13895562937869144	0.9563063063063063	0.18904931369234249	0.9297719087635054
71	0.14134730684148658	0.9561561561561561	0.18369305349376594	0.9309723889555822
72	0.13863522477515108	0.9566066066066066	0.17290923181845216	0.9405762304921969
73	0.13752416777718174	0.9551051051051052	0.17486175768622975	0.9369747899159664
74	0.13931250633062184	0.9551051051051052	0.18066554497770904	0.9309723889555822
75	0.1312073354606514	0.9587087087087087	0.2041995394058159	0.9243697478991597
76	0.13963770661670882	0.9587087087087087	0.18363523350901106	0.9315726290516206
77	0.12828674846225316	0.960960960960961	0.1947609777746796	0.9267707082833133
78	0.12860889976268058	0.9597597597597598	0.17738653773985275	0.9339735894357744
79	0.1252747221393986	0.9621621621621622	0.18881528254817515	0.9285714285714286
80	0.12719884003000753	0.9593093093093094	0.17419950612166635	0.9357743097238895
81	0.12376805815968786	0.9608108108108108	0.20492551827273306	0.921968787515006
82	0.12661642193257272	0.9605105105105105	0.1730227194198755	0.9351740696278511
83	0.12432406459439982	0.9629129129129129	0.17036209598022634	0.9351740696278511
84	0.11346049971274427	0.9644144144144144	0.17588230787741752	0.9369747899159664
85	0.11803033524989948	0.965015015015015	0.17887328653669013	0.9339735894357744
86	0.11853443437644669	0.9633633633633634	0.1743549496686759	0.9357743097238895
87	0.111628222576267	0.9669669669669669	0.17634592669493868	0.9345738295318127
88	0.11323127488832216	0.9642642642642643	0.16771799758845876	0.93937575030012
89	0.11345772722193428	0.9633633633633634	0.18102703506455703	0.9333733493397359
90	0.11005332424968213	0.9669669669669669	0.19287625049986615	0.9285714285714286
91	0.10900707500553257	0.965915915915916	0.1673536034119802	0.93937575030012
92	0.10798625914273677	0.9677177177177178	0.1729073866146381	0.9375750300120048
93	0.10765543645387655	0.9657657657657658	0.18455485861842372	0.9321728691476591
94	0.10501285857121061	0.9684684684684685	0.16825633471896526	0.9399759903961584
95	0.10196077682737921	0.9693693693693693	0.17106148024567036	0.9381752701080432
96	0.10740410389305952	0.9678678678678678	0.16882414255394082	0.9375750300120048
97	0.10192535952091575	0.9714714714714715	0.17833924826596823	0.9345738295318127
98	0.09701166059765909	0.9686186186186186	0.17255983007054368	0.9381752701080432
99	0.09944082645324616	0.9698198198198198	0.17221940722929185	0.9387755102040817

The optimal condition:
	epoch: 72
	train_acc: 0.9566066066066066
	val_acc: 0.940576230492
	using time: 610.103703976
