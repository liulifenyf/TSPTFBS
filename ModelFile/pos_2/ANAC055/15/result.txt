The number of train datas: 5248
The number of test datas: 1312
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7239407402713124	0.5043826219512195	0.6872460987509751	0.5609756097560976
1	0.6929210860554765	0.518483231707317	0.684938009192304	0.5777439024390244
2	0.6920538224825045	0.5268673780487805	0.6826044350135617	0.5838414634146342
3	0.6901093692314334	0.5266768292682927	0.6804810006444048	0.5945121951219512
4	0.6845100827333404	0.5524009146341463	0.6774464293224055	0.6089939024390244
5	0.6785615595375619	0.5672637195121951	0.6733956860332955	0.618140243902439
6	0.676662719831234	0.5705030487804879	0.6686388283241086	0.6272865853658537
7	0.6738275871044253	0.583079268292683	0.6636301729737258	0.6387195121951219
8	0.6687331156032842	0.6000381097560976	0.657493011253636	0.65625
9	0.664172887802124	0.6114710365853658	0.6508814241827988	0.6707317073170732
10	0.6552937379697474	0.6177591463414634	0.6424226833552849	0.6882621951219512
11	0.6463505000602908	0.6293826219512195	0.6328140555358515	0.7096036585365854
12	0.6354018507934198	0.6518673780487805	0.6212969800321068	0.7225609756097561
13	0.6219119458663754	0.671875	0.6083092747665033	0.7301829268292683
14	0.6097487676434401	0.6804496951219512	0.5947143857072039	0.7416158536585366
15	0.5946644341073385	0.700266768292683	0.5805727345187489	0.743140243902439
16	0.5763302125581881	0.7172256097560976	0.5631258385937389	0.7507621951219512
17	0.5603763170358611	0.7322789634146342	0.5447269728997859	0.7644817073170732
18	0.5425860067693199	0.7408536585365854	0.525409765359832	0.7682926829268293
19	0.5203760629746972	0.7621951219512195	0.5052957731049236	0.7827743902439024
20	0.49909690531288703	0.7820121951219512	0.4857954470122733	0.7964939024390244
21	0.4704999858286323	0.7982088414634146	0.4619333235228934	0.8071646341463414
22	0.45584695804409864	0.7983993902439024	0.4443279170408482	0.8224085365853658
23	0.4327062608265295	0.8201219512195121	0.42396928769786185	0.8300304878048781
24	0.41058196599890545	0.8298399390243902	0.40608710486714433	0.8391768292682927
25	0.3892384367745097	0.8435594512195121	0.3886297505076339	0.8498475609756098
26	0.371195037917393	0.8532774390243902	0.36988087689004295	0.8536585365853658
27	0.3519737109905336	0.8673780487804879	0.3560353052325365	0.8635670731707317
28	0.3400255387149206	0.8725228658536586	0.34642513496119803	0.8704268292682927
29	0.32421186130221297	0.8774771341463414	0.3346032918226428	0.8788109756097561
30	0.3182496108659884	0.8841463414634146	0.32482617148538917	0.8841463414634146
31	0.3058118816556	0.8923399390243902	0.31675358661791175	0.885670731707317
32	0.2953205264923049	0.8967225609756098	0.310069674035398	0.8902439024390244
33	0.286918604882752	0.8976753048780488	0.3033516367034214	0.895579268292683
34	0.27740926459068205	0.9032012195121951	0.29872207888742774	0.8948170731707317
35	0.2771645188331604	0.9045350609756098	0.29512207355441117	0.9024390243902439
36	0.26808245007584736	0.9098704268292683	0.29827590904584744	0.8925304878048781
37	0.2576461688774388	0.9110137195121951	0.28670480738325815	0.9032012195121951
38	0.26217113907744244	0.9079649390243902	0.28355728271530894	0.9054878048780488
39	0.2495673128017565	0.9173018292682927	0.2806230896129841	0.90625
40	0.24883097919022165	0.9144435975609756	0.2785687613777998	0.9085365853658537
41	0.23848417110559417	0.9193978658536586	0.2765785023206618	0.9070121951219512
42	0.23824462403611438	0.9201600609756098	0.27418400528954295	0.9123475609756098
43	0.2372318059206009	0.921875	0.2716278484681757	0.9115853658536586
44	0.23224900045045993	0.922827743902439	0.27044854076897223	0.9123475609756098
45	0.2302096086304362	0.9235899390243902	0.26874670531691575	0.913109756097561
46	0.22358044691202117	0.928734756097561	0.267439785163577	0.9138719512195121
47	0.22431101777204654	0.9283536585365854	0.2662049066729662	0.9138719512195121
48	0.22373908794507746	0.9274009146341463	0.2688837254919657	0.913109756097561
49	0.22132687343329918	0.9308307926829268	0.2754267744901704	0.9047256097560976
50	0.21720929661901986	0.930640243902439	0.26520661101108645	0.9146341463414634
51	0.2181915233774883	0.9272103658536586	0.26206336806460123	0.916920731707317
52	0.20739027948641195	0.9333079268292683	0.262776601968742	0.916920731707317
53	0.20994306700985607	0.9304496951219512	0.2611974208820157	0.9192073170731707
54	0.20574809719876544	0.9348323170731707	0.2609135468558567	0.9184451219512195
55	0.20621324748527714	0.9361661585365854	0.26007385697306656	0.9184451219512195
56	0.20346512518277982	0.934641768292683	0.25937096665545206	0.916920731707317
57	0.20175486984776286	0.9327362804878049	0.2624411502989327	0.916920731707317
58	0.2023177643011256	0.9348323170731707	0.25902824576308087	0.9192073170731707
59	0.19969136940269935	0.9344512195121951	0.26130312971952485	0.9153963414634146
60	0.1977773056161113	0.9375	0.25848210076006445	0.9207317073170732
61	0.1912241327326472	0.9392149390243902	0.26077788232303245	0.9176829268292683
62	0.18678847464119516	0.9411204268292683	0.2614021032321744	0.9161585365853658
63	0.18692600254605457	0.9373094512195121	0.2576367851437592	0.9207317073170732
64	0.19073174130625842	0.9369283536585366	0.2579803550388755	0.9184451219512195
65	0.18324458526401985	0.9388338414634146	0.260257214671228	0.916920731707317
66	0.1834259569281485	0.9434070121951219	0.25729321488519996	0.9199695121951219
67	0.18065982511857662	0.9426448170731707	0.2584112388331716	0.9192073170731707
68	0.18537898779642292	0.9392149390243902	0.25716122948541875	0.9184451219512195
69	0.17755250214803509	0.9405487804878049	0.26056020361621207	0.916920731707317
70	0.17947604525380018	0.9420731707317073	0.2592896488381595	0.916920731707317
71	0.17683442881921443	0.9437881097560976	0.2590339838004694	0.9176829268292683
72	0.17681521849661339	0.9445503048780488	0.2574372854901523	0.9184451219512195
73	0.17228278753961004	0.9449314024390244	0.25763522633692115	0.9184451219512195
74	0.18058127382906472	0.9434070121951219	0.25919256813642455	0.9161585365853658
75	0.17717597542739497	0.9449314024390244	0.2624666392803192	0.913109756097561
76	0.16379724479303126	0.9468368902439024	0.2634206028973184	0.9146341463414634
77	0.1690851379095054	0.9479801829268293	0.2660903836168894	0.9077743902439024
78	0.1671247093415842	0.9477896341463414	0.25949856311809727	0.9153963414634146
79	0.16589035747981654	0.948170731707317	0.25807730017638786	0.916920731707317
80	0.16484894894245194	0.9470274390243902	0.2605322323194364	0.916920731707317
81	0.16621438413858414	0.9447408536585366	0.2597448647749133	0.9161585365853658
82	0.1640397277547092	0.9479801829268293	0.2628028418232755	0.9146341463414634
83	0.16163181949679445	0.9491234756097561	0.2657775788045511	0.9085365853658537
84	0.1589346896947884	0.9464557926829268	0.261833362099601	0.9161585365853658
85	0.16168088138830372	0.9475990853658537	0.26407174584342213	0.9123475609756098
86	0.16276267988652718	0.9485518292682927	0.26146938560939414	0.9146341463414634
87	0.15403610649632243	0.9496951219512195	0.26163262710338686	0.9161585365853658
88	0.15359512280400206	0.9508384146341463	0.26701763308629756	0.9092987804878049
89	0.1514508564297746	0.9523628048780488	0.2693365514278412	0.9108231707317073
90	0.15025548891323368	0.9506478658536586	0.266178994280536	0.9138719512195121
91	0.15361643073762335	0.9514100609756098	0.26297255659975655	0.9184451219512195
92	0.14746500151913342	0.9554115853658537	0.26628280412860034	0.9138719512195121
93	0.15025708388264586	0.9517911585365854	0.26844094948070807	0.9077743902439024
94	0.15277754260999402	0.9535060975609756	0.26463208184009646	0.9146341463414634
95	0.14856884065197734	0.9544588414634146	0.2692010340894141	0.9115853658536586
96	0.14646303762749927	0.9529344512195121	0.2637654564729551	0.9176829268292683
97	0.14660114249805126	0.9538871951219512	0.2722668600518529	0.9085365853658537
98	0.142397350109205	0.955983231707317	0.2680412948858447	0.913109756097561
99	0.14162138413365294	0.9533155487804879	0.2722578510278609	0.9108231707317073

The optimal condition:
	epoch: 63
	train_acc: 0.9373094512195121
	val_acc: 0.920731707317
	using time: 414.12894702
