The number of train datas: 3160
The number of test datas: 792
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7016426852986782	0.5322784816162496	0.6935985473671344	0.5391414141414141
1	0.6963220277919046	0.5414556957498381	0.6875895057061706	0.5732323235333568
2	0.693344661253917	0.5386075953894024	0.6820978877520321	0.6010101013111345
3	0.6894503961635541	0.5313291143767441	0.6779833056709983	0.6111111114121447
4	0.6828632603717756	0.5566455703747424	0.6753667773622455	0.6287878787878788
5	0.6788676397709907	0.5689873414703562	0.6729750109441353	0.6351010097999765
6	0.6728448608253575	0.5806962029843391	0.6694813256311898	0.6439393936383604
7	0.671403519714935	0.5844936707351781	0.6651708724522831	0.6452020202020202
8	0.6683515942549404	0.5841772159443626	0.6616737005686519	0.6540404037393704
9	0.6570622584487819	0.6094936702824846	0.6560396383507083	0.6691919194929528
10	0.6527480552468119	0.6262658227848101	0.6496518362652172	0.678030303030303
11	0.648145912116087	0.621835442736179	0.6429336630936825	0.675505050204017
12	0.637119658385651	0.6427215192891375	0.6361016570919692	0.6893939399960065
13	0.629292632960066	0.6563291133204593	0.6284590676577404	0.7045454551475216
14	0.6207516638538505	0.6705696202531646	0.6200215575670955	0.7121212124222457
15	0.6113905938365791	0.6838607599463644	0.6105783852663907	0.7171717177737843
16	0.6031868650943418	0.6936708862268472	0.6008775571379998	0.7146464640443976
17	0.5861254974256588	0.7069620253164557	0.5900442768829037	0.7222222216201551
18	0.5742289244374142	0.7142405061782161	0.5794360902574327	0.7411616161616161
19	0.5580254441575159	0.7294303794450397	0.5677782483775207	0.7373737379758045
20	0.5535112328167203	0.727215189571622	0.5572580863731076	0.7537878787878788
21	0.5397315141520923	0.7348101258277893	0.5469271402166347	0.746212120610054
22	0.5247257148163228	0.7547468360466293	0.5364042496440387	0.7487373731353066
23	0.5095809735829318	0.7613924050632911	0.5275507786057212	0.7512626268646934
24	0.5026407614538941	0.7658227855646158	0.5169250694188204	0.7563131319151984
25	0.4938935473749909	0.7721518991868708	0.5048651665148108	0.7727272727272727
26	0.474360686163359	0.7879746835443038	0.4927272314977164	0.7790404034383369
27	0.4606855811952036	0.7924050634420371	0.482215449665532	0.7866161616161617
28	0.459782446034347	0.7962025317964675	0.47173051460824833	0.7967171717171717
29	0.4448383593861061	0.8044303805013246	0.46363654823014233	0.7929292929292929
30	0.4345470752142653	0.8104430372201944	0.4534572790367435	0.8080808080808081
31	0.41346062851857535	0.8234177215189873	0.44299737672613126	0.8131313131313131
32	0.4053226857245723	0.8294303795959376	0.43429904393475466	0.8156565662586328
33	0.39761905534357966	0.8306962026825434	0.42498802897906063	0.8156565662586328
34	0.3851154017297527	0.8414556965043273	0.4191515996600642	0.8181818187838853
35	0.3739776304251031	0.842721519741831	0.40965679408323885	0.8232323238343904
36	0.36824274538438534	0.8525316451169267	0.4050656400545679	0.8244949500970166
37	0.36880429719067825	0.8509493673904033	0.3981493016084035	0.8232323238343904
38	0.35217043002949483	0.859493670886076	0.3923095163672861	0.8244949500970166
39	0.33881743965269645	0.863924050934707	0.38739768904869004	0.8282828288848954
40	0.3421471059699602	0.8670886080476302	0.3820599422912405	0.8257575763596429
41	0.3368228985538966	0.8670886080476302	0.3803581110756807	0.8333333339354004
42	0.32718073382407803	0.8702531647078598	0.37327757507863674	0.8282828288848954
43	0.31759301748456836	0.8756329106379159	0.3713212518981009	0.8345959601980267
44	0.3275896933259843	0.8661392411099205	0.36789870262145996	0.8345959601980267
45	0.3153619953348667	0.8797468346885488	0.36328183912267586	0.8383838389859055
46	0.3093280070190188	0.8810126589823373	0.35921905287588485	0.8472222228242894
47	0.3076402567609956	0.8819620253164557	0.3598847410293541	0.8484848490869156
48	0.2942517874361594	0.892088607293141	0.3538936608367496	0.8434343440364106
49	0.29360288283492947	0.8901898734177215	0.35348804039184495	0.8472222228242894
50	0.28939333708980414	0.8930379743817486	0.34919535361155113	0.8510101016121682
51	0.2917567628848402	0.8917721515969385	0.35138219293921885	0.8535353541374207
52	0.2846945700011676	0.9000000007544892	0.3457040497750947	0.8535353541374207
53	0.277610460074642	0.8946202536172505	0.3470976376774335	0.8547979791959127
54	0.28495872926108445	0.893354431134236	0.33965886000430945	0.8598484854505519
55	0.2692523228971264	0.8974683551848689	0.3399118823234481	0.8636363642384307
56	0.27105884469008146	0.9	0.3400282236662778	0.8661616155595491
57	0.27107769831826417	0.9012658227848102	0.33417400175874884	0.8674242430263095
58	0.27076363654076296	0.8981012655209891	0.3328767918577098	0.8661616167636833
59	0.26098405488684207	0.9015822780283191	0.3363690779666708	0.8674242418221753
60	0.27338415127766286	0.9	0.33008998090570624	0.8636363642384307
61	0.25688651283330555	0.9066455694693554	0.32912882169087726	0.8674242430263095
62	0.25535700419281104	0.9079113931595525	0.32940474905148903	0.8623737379758045
63	0.2612345861483224	0.9069620245619665	0.32872441531431795	0.8611111117131782
64	0.2525319265413888	0.9047468346885488	0.32764731031475647	0.8686868680848016
65	0.24527799049510232	0.9177215197418309	0.3257596525881026	0.8699494943474279
66	0.2410628240319747	0.9148734175706211	0.32946583417930986	0.8737373737373737
67	0.23990070676501793	0.9142405067818075	0.32660429856993933	0.8737373731353066
68	0.2372048860109305	0.9113924049123933	0.32514893647396204	0.8699494943474279
69	0.23282760438285297	0.9155063289630262	0.3248492587696422	0.875
70	0.2377415643462652	0.9148734184760081	0.32303820746113554	0.8686868692889358
71	0.24021015672744075	0.91265822724451	0.32088633257933336	0.8724747468726803
72	0.23530881333200238	0.9155063292648219	0.31936355341564526	0.8737373731353066
73	0.23076635550094557	0.9158227849610244	0.3203862821212923	0.8737373731353066
74	0.23258875940419452	0.9170886069913454	0.3184834799983285	0.8724747468726803
75	0.2287623510330538	0.9202531653114512	0.3190176405689933	0.8737373737373737
76	0.22244904859911038	0.9177215197418309	0.3167733974529035	0.8724747468726803
77	0.22430210264423225	0.9212025319473653	0.3172811549721342	0.8762626262626263
78	0.2179567530562606	0.9208860754966736	0.3160830383951014	0.8724747468726803
79	0.21825946792017056	0.9218354425852812	0.3165512503397585	0.8762626256605591
80	0.21591644513456126	0.9256329115433028	0.31580754994141935	0.8762626256605591
81	0.2200395953428896	0.9208860753457757	0.31830269309005355	0.8724747480768146
82	0.21557718187193328	0.9272151894207242	0.31684950174707355	0.8724747480768146
83	0.2081004539999781	0.9253164555453047	0.3143200564264047	0.875
84	0.20796438300911385	0.925316455243509	0.3142150818097471	0.8775252531273197
85	0.20527604180800763	0.9262658233884015	0.3132813482573538	0.8762626256605591
86	0.2057310504626624	0.9303797469863408	0.3147665223087927	0.8775252531273197
87	0.20246530431735366	0.9313291140749484	0.31220788907523106	0.871212120610054
88	0.20461565814440763	0.9303797475899322	0.3088847811173911	0.8762626256605591
89	0.19770121559312073	0.9294303795959377	0.31136852051272534	0.875
90	0.20008934615533563	0.929430380199529	0.31163800635723155	0.8762626268646934
91	0.20107358935513073	0.9338607591918752	0.31067712589947866	0.875
92	0.19369218587120876	0.9262658235392993	0.31009793311658534	0.878787879389946
93	0.19859646841695036	0.9329113928577568	0.31158012934405394	0.878787879389946
94	0.19237897033932844	0.9332278487048572	0.3152302831712395	0.875
95	0.1890352438145046	0.9351265815239919	0.31229319716944837	0.8775252525252525
96	0.18823331217222575	0.9316455690166618	0.31330219151997807	0.875
97	0.1856863162562817	0.9376582273954077	0.3122951282997324	0.878787879389946
98	0.1956205092276199	0.9335443033447749	0.3078157200355722	0.8724747468726803
99	0.19650186786923227	0.9338607602481601	0.3078008300126201	0.8712121212121212

The optimal condition:
	epoch: 97
	train_acc: 0.9376582273954077
	val_acc: 0.87878787939
	using time: 171.608229876
