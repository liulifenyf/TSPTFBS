The number of train datas: 8716
The number of test datas: 2180
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7038184074482386	0.5042450665169322	0.6908487011533264	0.5284403669724771
1	0.6957578117172343	0.5108994951812759	0.687945481615329	0.5490825688073394
2	0.6917203272247927	0.5263882514915099	0.6850744108541296	0.5779816513761468
3	0.6887422923157662	0.5379761358558065	0.6822956478923833	0.5926605504587156
4	0.680914578278057	0.5582836163104155	0.6781835781324894	0.6142201834862385
5	0.6816879199589541	0.5592014685635612	0.6743758086764484	0.6330275229357798
6	0.6738989629183082	0.5882285452315762	0.6687828956394021	0.6458715596330276
7	0.6680571514567742	0.6002753556403834	0.6620531122618859	0.6637614678899083
8	0.6636095251879488	0.6052088113540135	0.6539095668617738	0.6729357798165138
9	0.6521644917525737	0.6280403854705807	0.6417682206958806	0.7
10	0.6412414536392979	0.6441027994492886	0.6259325639917216	0.7293577981651376
11	0.628294908053944	0.6602799449562206	0.6074816523341957	0.75
12	0.6034586039252542	0.6921753097477721	0.5841355129119453	0.7582568807339449
13	0.5787551533251303	0.7282010096237713	0.5578118695031612	0.7674311926605505
14	0.5577687889870945	0.7357732905002294	0.5249491540663833	0.805045871559633
15	0.5189171778521116	0.7667508030933434	0.48895194596106856	0.8155963302752294
16	0.4885623217340236	0.786140431363192	0.45381084286838497	0.8344036697247706
17	0.45739435999149464	0.8047269389354729	0.42882024831728105	0.8321100917431192
18	0.4241592265518503	0.8235429096189099	0.39371633185159177	0.8541284403669724
19	0.3939765728274963	0.841670491078295	0.3689329396694078	0.8669724770642202
20	0.3698224012542066	0.8499311610830657	0.3443763241581961	0.8733944954128441
21	0.3460651187926271	0.8653051858924299	0.32316326225569486	0.881651376146789
22	0.3258777228092152	0.8745984396512162	0.30866558360397267	0.8853211009174312
23	0.30952999709723683	0.8811381367873358	0.2965065605870081	0.8912844036697247
24	0.2869348720899138	0.8896282698759085	0.2793648182798963	0.9
25	0.2660602372261076	0.9022487379805436	0.2695518821751306	0.9045871559633027
26	0.2611821296908211	0.9090178981457571	0.2651862144060091	0.9018348623853211
27	0.24450303757064876	0.9125745755206996	0.24880186765018952	0.9142201834862386
28	0.23395956824984557	0.918999541046533	0.24264934062957763	0.9155963302752294
29	0.22700638891962374	0.9191142726021111	0.23356184724274032	0.9206422018348623
30	0.21109257393634992	0.9292106470858191	0.2312283554345096	0.9201834862385321
31	0.20493644538851383	0.9311610830382723	0.21943244318896477	0.9252293577981652
32	0.19659344164014356	0.9340293712985794	0.2138528424118637	0.9261467889908257
33	0.18571836478450857	0.9404543368244127	0.2073447969801929	0.9325688073394496
34	0.17774510941630167	0.9406837999355689	0.20352295654902763	0.9357798165137615
35	0.16803243222888756	0.945846718705647	0.20086860986204322	0.9344036697247706
36	0.16686775628007186	0.9482560807709959	0.195173544122265	0.936697247706422
37	0.16244531662885942	0.9484855438547979	0.190005130382306	0.9408256880733945
38	0.1575303628062808	0.9492886645250115	0.18689584010237947	0.9422018348623853
39	0.1463948109859499	0.9543368517942197	0.1859258637105653	0.9408256880733945
40	0.14800889779458412	0.9537631941257457	0.18522932785093238	0.9412844036697248
41	0.14319525442302855	0.9547957778524072	0.17977643496946458	0.9458715596330275
42	0.1447459627259155	0.9561725562184489	0.19720098605601613	0.9334862385321101
43	0.1355034777088524	0.9607618173474071	0.17288365349720378	0.9495412844036697
44	0.13088112717007977	0.9627122533272143	0.1700069388118359	0.9518348623853211
45	0.13085740018241063	0.9627122533272143	0.16736518968956185	0.9509174311926606
46	0.12321544046068804	0.9634006425239122	0.1660940092979768	0.9536697247706422
47	0.12114726397977776	0.966154199173933	0.17221068808245002	0.9486238532110092
48	0.11583641979769864	0.9674162459843965	0.1625626966630647	0.9522935779816514
49	0.11451387950469248	0.9668425883432767	0.15976156265637195	0.9536697247706422
50	0.11107319616680573	0.9691372189077558	0.16202289903314288	0.9522935779816514
51	0.1110930724437902	0.9715465810004589	0.15686526921227437	0.9568807339449541
52	0.10652824442025005	0.9709729233593392	0.15947004767186052	0.9559633027522936
53	0.103565087592372	0.9690224873795319	0.15489147427158617	0.9564220183486238
54	0.10212132720060445	0.9725791647544745	0.15553160667966265	0.958256880733945
55	0.10294376331210109	0.9737264800367141	0.1529527701710889	0.9564220183486238
56	0.10081123933537994	0.9716613125286829	0.15264551308723764	0.958256880733945
57	0.09594202760697615	0.9732675539238183	0.15500344645676262	0.9596330275229358
58	0.09564076419432484	0.9746443322898599	0.157684357074696	0.958256880733945
59	0.09526025590381254	0.9745296007616359	0.16552233613959147	0.9541284403669725
60	0.09286998516652167	0.9757916475720995	0.14946531093585383	0.960091743119266
61	0.0885276706203709	0.9778568150527766	0.15097517285393466	0.9605504587155963
62	0.0880465962680013	0.979233593391464	0.14887067458908493	0.9577981651376147
63	0.0850083685525791	0.9771684258834328	0.15048753746674148	0.960091743119266
64	0.08225021346165752	0.9795777880034899	0.14840937013472985	0.9559633027522936
65	0.08326860581075464	0.9804956402019275	0.1490287810734926	0.9596330275229358
66	0.082613527256792	0.9779715465810005	0.1488801493198363	0.9591743119266055
67	0.07941493892827647	0.979233593391464	0.15060057600772161	0.960091743119266
68	0.08133482321765156	0.9793483249196879	0.15002026447188962	0.955045871559633
69	0.07873466020679087	0.981642955484167	0.14879449505119696	0.9573394495412844
70	0.07582381614554415	0.9810692978156932	0.15019373323324076	0.9610091743119266
71	0.07651030073244126	0.9801514456446098	0.16038257219922653	0.9587155963302753
72	0.07203473600278129	0.9824460761817347	0.14791598155274305	0.9596330275229358
73	0.07302128381432196	0.9839375860486461	0.14850828358134546	0.9610091743119266
74	0.06979282854100113	0.9832491969066566	0.14854472111910583	0.9605504587155963
75	0.0715036374072708	0.9827902707664066	0.15316599065079053	0.9614678899082569
76	0.07294329757425641	0.9830197338228546	0.15065770499203182	0.9610091743119266
77	0.07316451786088528	0.9817576870397451	0.15168341092696977	0.9610091743119266
78	0.06853083508476417	0.9845112437171201	0.14886820916120613	0.9619266055045872
79	0.07096126457798531	0.9847407067462138	0.14794287594086533	0.9596330275229358
80	0.06461909165825591	0.9856585589720055	0.14814320974598785	0.9605504587155963
81	0.06583583332799518	0.9849701698026617	0.14803230453863603	0.960091743119266
82	0.0645740232975344	0.984740706773568	0.14817557410431018	0.9555045871559633
83	0.06134059868740989	0.9863469481413493	0.147040110682949	0.9587155963302753
84	0.06269667239132251	0.984511243689766	0.14715571562597238	0.9623853211009175
85	0.06035595920417516	0.987150068838917	0.14746078255355632	0.9605504587155963
86	0.06328006614360338	0.9865764111977972	0.14916474592931775	0.9623853211009175
87	0.059976798834851054	0.9878384580356148	0.1490346582538081	0.9564220183486238
88	0.06291316987214907	0.9850849013308858	0.1461477502308991	0.9610091743119266
89	0.057271793274402946	0.9864616796695732	0.14751982036978006	0.9577981651376147
90	0.05844869221013147	0.9870353373106929	0.14481499708607928	0.960091743119266
91	0.05639427179874987	0.9864616796969273	0.14589228037437169	0.960091743119266
92	0.05632955560220483	0.9888710417622762	0.14718054841622846	0.9623853211009175
93	0.05245002461473375	0.9870353373106929	0.15241919495848888	0.9614678899082569
94	0.0549045662785025	0.9865764111977972	0.14830112792722402	0.9623853211009175
95	0.053513573049240676	0.9881826525655784	0.1462176862506008	0.9619266055045872
96	0.05601011525058265	0.9885268471502503	0.15853593228470295	0.9605504587155963
97	0.052733131948073775	0.9874942634235888	0.14752894896125301	0.9605504587155963
98	0.053822510235076546	0.9865764111977972	0.1465148448388716	0.9610091743119266
99	0.04983886235601732	0.9893299678751721	0.14776760006682316	0.960091743119266

The optimal condition:
	epoch: 94
	train_acc: 0.9865764111977972
	val_acc: 0.962385321101
	using time: 867.578886032
