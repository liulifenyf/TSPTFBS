The number of train datas: 9928
The number of test datas: 2484
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7050508496071618	0.4922441578891179	0.6929066668769972	0.5100644122863162
1	0.6958300324815786	0.5137993551664637	0.6907403222412687	0.5185185185185185
2	0.690574735090869	0.5353545529241047	0.6879578022565243	0.539855072175823
3	0.6911639599527302	0.5300161160354553	0.685660575227077	0.5503220609036813
4	0.6892455804261539	0.5422038676563912	0.6828385898648445	0.5628019324151406
5	0.6866862025595211	0.5458299758739763	0.6794170721909466	0.5789049919484702
6	0.6803340407555186	0.5638597906836572	0.6738803514343913	0.6062801930447516
7	0.6785288002585135	0.5715149075249143	0.6678842627675828	0.62318840627701
8	0.6681511945344093	0.5934730056406124	0.6590373504564958	0.6485507251175897
9	0.6627026780971493	0.6032433521353747	0.6475922861728883	0.6747181963613452
10	0.6517916181027937	0.6251007254137136	0.632953833842623	0.6992753627987491
11	0.6426833662460352	0.6334609185659914	0.6147420744197188	0.7258454101481108
12	0.6242566734048073	0.6619661563735735	0.5902397778491083	0.7487922703394375
13	0.6004695432691397	0.6946011281224819	0.557857220299578	0.7850241547813354
14	0.564171168181706	0.7285455279442498	0.5132375127259468	0.8172302731761226
15	0.5285849562582712	0.7589645448180574	0.46429423673525333	0.8546698873745646
16	0.4745023322624127	0.7969379531194086	0.40106819668445803	0.8804347820328053
17	0.4107940029127765	0.8426672037717895	0.3378919351504045	0.9049919481822642
18	0.3603770968464476	0.8679492343442273	0.28746525412980295	0.9239130434782609
19	0.31308953760613556	0.8861804997892172	0.25059213574477823	0.9367954908553721
20	0.27343222694614067	0.9065269945515056	0.219958645194145	0.9436392911774333
21	0.24739092960653528	0.919016921837228	0.19934143619116954	0.9484702090518294
22	0.22764598074504966	0.9272763899600285	0.18433037203483152	0.9484702090518294
23	0.20446335534526877	0.9353344075916085	0.1766692678205633	0.9541062799052916
24	0.19478548016162	0.9403706686713829	0.16713455738124833	0.9524959739471596
25	0.18508398740595142	0.9446011279783932	0.16117917965863637	0.9569243153320226
26	0.17483572718311374	0.9490330376805652	0.15731811182702413	0.9569243153320226
27	0.17377010466325293	0.9512489927477841	0.15369402887164682	0.9609500802273527
28	0.16819761260011137	0.9505439160525271	0.15017635161701992	0.9605475037378197
29	0.1571969198157574	0.9550765510723536	0.14991309942494652	0.9609500802273527
30	0.152352668218897	0.9569903302346382	0.14488356986387532	0.9601449272482867
31	0.15036275376483954	0.9572925059954838	0.14345843259743063	0.9597423507587537
32	0.14925082781975735	0.9575946815161817	0.14149134777690286	0.9617552332064188
33	0.1429116780915441	0.9612207898298258	0.14281435007298435	0.961755233494364
34	0.1404771990323624	0.9606164381640463	0.1432242501023167	0.9629629629629629
35	0.13775609906741826	0.9621273166320672	0.13749271036154215	0.9589371977796877
36	0.13212482514734905	0.963436744464779	0.1385131366101008	0.9637681159420289
37	0.13117170004860035	0.9632352943097652	0.13499165666492088	0.964170692431562
38	0.13072811861993036	0.9613215147152147	0.13373343436866278	0.9637681159420289
39	0.12453427408595992	0.9655519742143432	0.13221285754331835	0.964170692431562
40	0.12540366983913204	0.9646454471239249	0.13255087064876073	0.964975845410628
41	0.12349277315098466	0.9663577758430186	0.13040609424408892	0.961755233494364
42	0.12114192195999152	0.9656526992438207	0.12924420728307703	0.964170692431562
43	0.11819023419828976	0.9664585010165846	0.12881894329871724	0.961755233494364
44	0.11359762726989511	0.9681708299758259	0.12958749687230145	0.9601449275362319
45	0.11567799401177599	0.9682715550533328	0.12859818712776697	0.964573268921095
46	0.11196739566688764	0.9678686542630099	0.12896471369513662	0.9637681159420289
47	0.11130099841464824	0.9695809830301333	0.12716321591377835	0.961352657004831
48	0.110065495458752	0.9681708301199146	0.12558871114719508	0.964170692431562
49	0.10643918665784871	0.9686744559397148	0.12504789870286334	0.964975845410628
50	0.10843432519365759	0.9705882352460882	0.12397665486951477	0.964975845410628
51	0.10615132348034095	0.9690773569221558	0.12605724472630522	0.964975845410628
52	0.10500750292053537	0.9692788072692877	0.12281351763269176	0.9637681159420289
53	0.09977073253017582	0.9711925864796019	0.12256213318670525	0.9633655394524959
54	0.10019631758272216	0.9712933117011975	0.12231632211094125	0.964573268921095
55	0.10034070721107755	0.9720991135219909	0.12291801881027106	0.965780998389694
56	0.09500805568025056	0.9712933117972565	0.12116736326000732	0.9637681159420289
57	0.09873890377563109	0.9716962126836385	0.12041531190660072	0.9637681159420289
58	0.0927927352602111	0.9732070909595413	0.12202145306216537	0.966183574879227
59	0.09804667382351724	0.9723005639171524	0.12228112358257966	0.961352657004831
60	0.09288614300304032	0.9732070909595413	0.12036237825494074	0.966183574879227
61	0.09222243291136001	0.9736099919419823	0.12116663802967027	0.965780998389694
62	0.09075177986231857	0.9732070909595413	0.11874289529611043	0.964170692431562
63	0.09141486597387757	0.9746172441099076	0.11830113067827075	0.964975845410628
64	0.08457982958587881	0.9733078161331072	0.11928925008457544	0.964170692431562
65	0.08499099648018021	0.9752215954394805	0.11928829383674931	0.962157809983897
66	0.08621034634920208	0.9744157935226281	0.11847810035694432	0.964975845410628
67	0.0862277849163863	0.9758259466249649	0.1189584186339628	0.9629629629629629
68	0.08373416121073493	0.9748186946011281	0.11796335549050291	0.9637681159420289
69	0.08342843433117117	0.975926671990649	0.11752751967517266	0.964573268921095
70	0.08367636523792621	0.976228847703465	0.11861985543631796	0.964573268921095
71	0.07741172891635505	0.9774375503626108	0.11752262326398334	0.964573268921095
72	0.0803757733864279	0.9758259467690534	0.1175279385558721	0.964573268921095
73	0.0781905648901182	0.9769339242546333	0.11679485217696611	0.964573268921095
74	0.07897422148708755	0.9769339241105448	0.11698345113515662	0.964573268921095
75	0.07811919545137912	0.9766317484457583	0.11620663882693615	0.9637681159420289
76	0.07698842431632479	0.9776390006136837	0.11654093732304523	0.9637681159420289
77	0.07608063914344063	0.9780419016441542	0.11617736432599368	0.964975845410628
78	0.07407460920062399	0.9789484286385136	0.11686429995653518	0.9637681159420289
79	0.07219781797442294	0.9786462530217567	0.11726505154722795	0.964573268921095
80	0.0719468661829361	0.9781426268177201	0.11674854323123963	0.964573268921095
81	0.07309202330845868	0.979552780016116	0.11801846553803978	0.9633655394524959
82	0.071320571790327	0.9790491539081386	0.11572269891237243	0.9637681159420289
83	0.07168268658502941	0.9785455277521317	0.11625190562720077	0.9637681159420289
84	0.06830590633761009	0.9792506042552706	0.11908236859237323	0.964170692431562
85	0.06822850840657013	0.9806607574536664	0.11700849233258173	0.965378421900161
86	0.06743040336273448	0.9796535051416525	0.1162943305918608	0.9637681159420289
87	0.06816018449021001	0.9807614825792028	0.1167815128872216	0.965378421900161
88	0.06676719220029453	0.9807614825792028	0.11766300619476372	0.964170692431562
89	0.065586476617528	0.9802578565192549	0.11584577565763787	0.964975845410628
90	0.06573427141036937	0.9805600321840414	0.11569096493848184	0.964573268921095
91	0.0632762631024688	0.9807614826272324	0.11595249942379393	0.965378421900161
92	0.0612719412968103	0.9805600320399528	0.11718938624465332	0.966183574879227
93	0.06146613632138941	0.9818694600647827	0.11624603325894009	0.964170692431562
94	0.06045724586775041	0.9822723609991942	0.11706982176876875	0.964170692431562
95	0.06056314676483728	0.9807614826752619	0.11868757326395855	0.9633655394524959
96	0.06039461008393889	0.9812651087352098	0.11764561562182535	0.9625603864734299
97	0.05815633712373944	0.9828767122807376	0.11697225269956002	0.964573268921095
98	0.05908245918109088	0.9815672843039372	0.11663403332941294	0.96658615136876
99	0.05956473381023653	0.9820709104119146	0.11662820453385128	0.964170692431562

The optimal condition:
	epoch: 98
	train_acc: 0.9815672843039372
	val_acc: 0.966586151369
	using time: 712.348594189
