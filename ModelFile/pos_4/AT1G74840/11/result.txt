The number of train datas: 5296
The number of test datas: 1326
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7064073078581934	0.5022658611172276	0.6926390537669036	0.5082956263472411
1	0.6997868539343428	0.5069864046537624	0.6900320853223268	0.5248868773785472
2	0.6952899705247216	0.5168051357715872	0.6876524642761657	0.5316742080099442
3	0.6910726161521727	0.5271903322362468	0.6852577379925758	0.5610859723562209
4	0.6878816514216881	0.5358761329305136	0.6830515338284937	0.5739064851767337
5	0.6849586005657461	0.5453172203637322	0.6807025959588823	0.5791855207665474
6	0.6842431645739114	0.5538141995758449	0.6780386728938349	0.5882352936231893
7	0.6801840346025196	0.5649546825993818	0.6746401384944829	0.6146304670771862
8	0.6750449487810048	0.584969788699712	0.6703711672605972	0.6289592761979024
9	0.6684346670830718	0.5949773412096536	0.6653588085152984	0.6523378580404083
10	0.667640810826754	0.5970543804845782	0.6596741733867478	0.6674208141200323
11	0.6639076892702961	0.6023413897280967	0.6535777988117385	0.6832579178328247
12	0.656066872021943	0.6244335347432024	0.6466126103926209	0.7239819007221929
13	0.6533313242330292	0.6200906342610132	0.6384170537261042	0.7096530912868217
14	0.6451188561779495	0.6363293053160262	0.6301559308715176	0.7217194562943633
15	0.6362804615605634	0.6514350451371461	0.6171582261181885	0.7541478134208495
16	0.6260321167300475	0.6612537764350453	0.6035721853128206	0.7745098041912729
17	0.6117251162442556	0.6867447129909365	0.5867213288583367	0.789592760091094
18	0.5936544919302096	0.707137462055575	0.5659590410251244	0.8061840117966608
19	0.5765687157020107	0.7224320239891099	0.5437736476168913	0.8076923077822091
20	0.560065595675091	0.7356495468277946	0.5171677980847308	0.8288084458261953
21	0.5303496277224261	0.760196374442282	0.48917058483328035	0.8416289586467082
22	0.5082950468690014	0.773602719213307	0.458534085193191	0.8491704367764216
23	0.4831496330366394	0.7945619335347432	0.4284008015424777	0.8619909495969343
24	0.4557624517790861	0.816654078549849	0.4004192079444097	0.8725490189785332
25	0.43645071335069363	0.8274169182489286	0.37364030225963796	0.883107088360132
26	0.413896315047388	0.8440332324483243	0.34875481534148056	0.8929110099287594
27	0.39251839430310576	0.844410875952856	0.32492928910399277	0.9027149314973869
28	0.3667882923093087	0.8598942599988055	0.30350165251153627	0.9102564092674946
29	0.34877882839329655	0.8712235651347572	0.2850834527706129	0.9140271483323513
30	0.33980550452661656	0.8746223566755428	0.2732275545507175	0.9238310699009787
31	0.3221529441297595	0.8878398789740041	0.25942613676662357	0.9245852177139501
32	0.30616051480849343	0.8921827794561934	0.24893267751639064	0.9245852177139501
33	0.30637691199239286	0.8916163141993958	0.2408688174024067	0.9298642524047495
34	0.2856485860765521	0.901623866889412	0.23023894011165222	0.9328808436566348
35	0.2801526321205128	0.9059667673716012	0.22334926511367523	0.9336349914696062
36	0.27140109173480836	0.9112537766151197	0.2176688018607518	0.9351432870955488
37	0.2689745469846034	0.9082326283987915	0.2132671556771251	0.9381598802353642
38	0.26093787427575205	0.9127643502730978	0.20856862959099393	0.9351432870955488
39	0.2573574458184199	0.9169184288229467	0.20305256444404568	0.9389140280483356
40	0.2476954515967124	0.9171072509353615	0.2022787247802697	0.9434389145665578
41	0.24547291819422626	0.923149547007869	0.1955264031797153	0.9396681758613069
42	0.23353083251646278	0.923904833836858	0.19718007489387088	0.9336349914696062
43	0.23837415543117552	0.9256042297873253	0.19004567835036087	0.9449472103723034
44	0.23291821224091636	0.925226586102719	0.18890940288972352	0.9389140280483356
45	0.2292917219983847	0.9242824773413897	0.1859421854330224	0.9449472101925006
46	0.22967662052265467	0.9314577041075669	0.18418137508909446	0.9434389145665578
47	0.22350785843015078	0.9307024170985034	0.18741241425590457	0.9366515829012945
48	0.2183430463615861	0.9342900300314059	0.18059518870365207	0.9441930623795293
49	0.2204707834385673	0.9314577041075669	0.17926796983090282	0.9449472101925006
50	0.210875531292754	0.933912386887023	0.17836809738189385	0.9434389145665578
51	0.20740352503482667	0.9373111782477341	0.17573378503682208	0.9472096536314146
52	0.20953349553026102	0.9324018126888217	0.1743464966165534	0.9464555058184433
53	0.20542834384023603	0.9354229607250756	0.17330507855429728	0.9441930623795293
54	0.20315040679496582	0.9344788519637462	0.173284686820899	0.9441930623795293
55	0.1957554051207992	0.938066465436872	0.17114406482486524	0.9449472101925006
56	0.1990400933607107	0.9369335349232769	0.17018477638922125	0.9464555058184433
57	0.19263516177403603	0.9382552870090635	0.16808558279033162	0.945701358005472
58	0.19489140250351494	0.9390105740181269	0.16875611537811802	0.9509803926962713
59	0.19033484716879998	0.9401435047117965	0.16757193679723265	0.9472096536314146
60	0.1873537594638202	0.9435422958924331	0.1690763386126557	0.9434389147463608
61	0.18724833870042126	0.9425981873111783	0.1670621267181356	0.947963801444386
62	0.18442048548841763	0.942220543986721	0.1714880265981004	0.9426847652252623
63	0.1791515496652292	0.9431646523879014	0.16539987364325948	0.9464555059982461
64	0.17423589694175837	0.9424093657389868	0.16440537169598166	0.9472096536314146
65	0.18200930820220906	0.9418429004821892	0.16481378625061358	0.9434389147463608
66	0.17677104774738728	0.943731117644699	0.16217473122329193	0.9487179492573573
67	0.17496702090761093	0.9424093657389868	0.16196661153709907	0.947963801444386
68	0.17381199970391223	0.947129909365559	0.1616400267428762	0.9494720970703286
69	0.1717087921329135	0.945619335347432	0.1637313361890715	0.9441930625593321
70	0.16924478698893256	0.9454305134150917	0.16032733733387913	0.9457013581852748
71	0.16171729368835777	0.9458081572797723	0.1627546700327285	0.9441930625593321
72	0.1635554051561298	0.948262839879154	0.16317883781178505	0.9509803926962713
73	0.1621402912179509	0.9488293049558773	0.1591256914904754	0.9457013581852748
74	0.16113997262050017	0.9471299091854845	0.15859955690834857	0.9509803926962713
75	0.15881636351617082	0.9493957702126747	0.1606087741493999	0.9449472103723034
76	0.15575978299462184	0.9509063442308017	0.16235839392354945	0.9434389147463608
77	0.15577825732821785	0.9469410874332186	0.1571665480620541	0.9472096538112175
78	0.15348473663956738	0.9484516618114944	0.15755157282809146	0.9517345406890455
79	0.14985878360415514	0.9505287009063444	0.1568058829411842	0.9472096538112175
80	0.15383049674624763	0.9510951663432164	0.15652280061493093	0.9457013581852748
81	0.15619413646956584	0.9495845921450151	0.1583546497388483	0.9517345405092427
82	0.15009011100876368	0.9518504533522799	0.15785972189669514	0.9434389147463608
83	0.1452680210332496	0.949773413897281	0.15500503443574834	0.9494720972501315
84	0.1447163555107088	0.9507175226586103	0.15744516010737528	0.9532428361351853
85	0.14308175251022925	0.9492069486404834	0.15707820633687586	0.9441930625593321
86	0.14185663341935667	0.9503398791540786	0.15642257178620875	0.9434389147463608
87	0.14155469096499268	0.9514728096676737	0.1537840289497807	0.9487179494371601
88	0.1408876920979909	0.9527945621136092	0.15504580765378242	0.9457013581852748
89	0.13509382294023864	0.9556268883975971	0.15231348567418923	0.9502262450631028
90	0.13695919858094788	0.9535498487625237	0.15314734004561537	0.9479638016241888
91	0.13582909215252925	0.9548716013885337	0.1522817634843953	0.9509803928760742
92	0.13255238017556892	0.9558157099697885	0.15185704164285646	0.9494720972501315
93	0.13341870696883187	0.9550604229607251	0.1525891163185531	0.9479638016241888
94	0.12916133032824698	0.9594033232628398	0.15193249694272584	0.9517345406890455
95	0.12612721866441276	0.955815710149863	0.15140726930864976	0.9524886885020168
96	0.12414246345124576	0.9592145013304996	0.15125025808811188	0.9502262450631028
97	0.12326662980717834	0.9607250753486265	0.15453579920719113	0.9472096538112175
98	0.125211824733325	0.9580815711770533	0.1508372503123492	0.9487179494371601
99	0.12846698987880142	0.9578927490646385	0.15198536504897237	0.9464555059982461

The optimal condition:
	epoch: 84
	train_acc: 0.9507175226586103
	val_acc: 0.953242836135
	using time: 330.294936895
