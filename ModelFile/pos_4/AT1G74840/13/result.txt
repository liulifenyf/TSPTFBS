The number of train datas: 5296
The number of test datas: 1326
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7052307199135288	0.5009441088513665	0.6919221434837732	0.5135746608582378
1	0.6987828358422593	0.5060422958924331	0.6897596987484088	0.5188536951894315
2	0.6956233819805964	0.5202039276725215	0.6877556620320224	0.5444947207855063
3	0.6891459671392182	0.5317220542005902	0.6860197167590733	0.5618401203040444
4	0.6865190768169852	0.5473942596386566	0.6842149681275427	0.5588235295915676
5	0.6854713631180478	0.5477719033232629	0.6826174948729721	0.5663650072268231
6	0.6841269265128767	0.5568353476120986	0.6804672769112106	0.5844645543335789
7	0.6802816925812344	0.5536253774634301	0.6777709054551333	0.5904977373767583
8	0.6768540786832481	0.5753398791540786	0.6742005608919699	0.5995475111324143
9	0.6697339455166612	0.601397280786693	0.6701387709082521	0.6184012057374865
10	0.6695840119235105	0.5949773412096536	0.6648065156526695	0.6357466056156302
11	0.6652886628024167	0.5989425980072367	0.658912475652105	0.6553544485730822
12	0.6566393658113624	0.6197129907564815	0.6521312258182428	0.6576168937201233
13	0.6556438735244497	0.6199018125087473	0.6435787568984168	0.6915535437755096
14	0.6442740602795811	0.6334969786718893	0.6338836180318714	0.6907993963221439
15	0.6360715038826819	0.6510574018126888	0.6209114599371748	0.7247360488947701
16	0.6240853811318781	0.664463746223565	0.6071767700923154	0.7443438914926164
17	0.6092820927455707	0.6842900303915548	0.5904675124277716	0.7601809955650145
18	0.5947802882540262	0.7035498487625237	0.5704392753035774	0.7911010558968395
19	0.576665651582159	0.7163897279166023	0.5488234191099084	0.8009049778250728
20	0.560313680831039	0.726397280786693	0.5236762635308693	0.8235294118546073
21	0.5341017183220278	0.7560422960725075	0.4956403654265368	0.8325791856102635
22	0.5113202628772424	0.772469788339563	0.46808326765782515	0.8461538462437476
23	0.48748161614481417	0.7949395770392749	0.4371632124503813	0.8582202108916833
24	0.46259020309433835	0.8068353472519497	0.41062881063731727	0.8710407235323934
25	0.4416419306370427	0.8198640483383686	0.3851604387051739	0.8785822018419096
26	0.4169394365790387	0.832892749244713	0.3607633397949587	0.8898944188566769
27	0.3968337344799157	0.8462990934755147	0.3368094010140921	0.9019607835046126
28	0.37495555798452784	0.8581948640483383	0.3160230430183008	0.9057315225694694
29	0.3563101248438625	0.8734894261619476	0.2981184225186683	0.9095022616343261
30	0.3458478497594505	0.8746223564954683	0.285343704045628	0.9155354441380968
31	0.324659236968464	0.8876510572217382	0.2734255908481316	0.9155354441380968
32	0.316626710113802	0.8834969788519638	0.2621890198141561	0.9215686266418676
33	0.3117979880186006	0.8940709971589265	0.25696882034678625	0.9276018089658354
34	0.29327230646170876	0.900113292871285	0.24466074839077023	0.9253393655269214
35	0.2927164624464836	0.9016238670694864	0.2396830279902635	0.9245852177139501
36	0.28030213785675717	0.9076661629619195	0.23108993704412498	0.9276018089658354
37	0.2751607593722934	0.9063444108761329	0.226339137257494	0.9298642524047495
38	0.265397296616318	0.9127643502730978	0.22273864649899225	0.9276018089658354
39	0.26435643596591546	0.9163519635661491	0.21756125404464352	0.9291101045917781
40	0.25808961937074576	0.9142749242912246	0.213237847250691	0.9374057320627871
41	0.25167887799689415	0.9199395768592005	0.21097620418168841	0.9328808453647619
42	0.24603473748505295	0.9218277943818591	0.21327055628842717	0.9276018089658354
43	0.24518865065542234	0.9233383685800605	0.20263761924762352	0.9389140276887298
44	0.23897804355873442	0.9227719031431884	0.20173101960983392	0.9366515844296186
45	0.23458933240517388	0.9239048340169325	0.19680625550887165	0.9396681755017011
46	0.23252055039938843	0.9254154078549849	0.19473905856882645	0.9404223233146725
47	0.2282536429580965	0.929947129729291	0.19836255107889708	0.9343891409907046
48	0.22645899599412417	0.927870090634441	0.1903803891545867	0.9411764711276438
49	0.22299857815766982	0.9308912386706949	0.1882863981961125	0.9411764711276438
50	0.215712883681329	0.9308912384906204	0.18757716684319856	0.9411764711276438
51	0.21224991459500753	0.9346676738960865	0.18434536284001524	0.9419306187608123
52	0.21646031179096764	0.9346676738960865	0.1835761310063516	0.9434389145665578
53	0.21260024269541944	0.9346676738960865	0.18328127919009368	0.9434389145665578
54	0.21041753329899376	0.9350453172205438	0.18186380423122223	0.9426847667535865
55	0.20420832542584383	0.9369335347432024	0.17960186626307026	0.9441930623795293
56	0.20598314725020142	0.9367447128108621	0.1783652904796025	0.9441930623795293
57	0.19834773201956848	0.9393882173425842	0.17687002098578314	0.9449472100126977
58	0.19793092088036668	0.9376888217522659	0.17778163862893664	0.9494720968905258
59	0.1953039278031476	0.9384441087613293	0.17504200620259275	0.9464555056386403
60	0.1926686508057701	0.9403323262839879	0.17384761900024356	0.945701357825669
61	0.191784382226604	0.9393882173425842	0.1732382667595085	0.9472096534516118
62	0.18878566169846814	0.9412764348652428	0.17611852083720414	0.9419306189406151
63	0.18210433630604758	0.9442975829014966	0.1720167517572147	0.9441930623795293
64	0.17979904716648723	0.94089879172086	0.17102735827860968	0.9464555056386403
65	0.18329794304248428	0.943542296252582	0.171452702709992	0.9441930623795293
66	0.18201817770198753	0.9425981871311038	0.16950044829291636	0.9479638012645831
67	0.17847729373014226	0.9418429001220403	0.16852255720718234	0.9479638012645831
68	0.17967708572025026	0.9431646525679759	0.1687138487850379	0.9502262447034971
69	0.1788775683619825	0.9439199395770392	0.16804103193689435	0.9479638012645831
70	0.17365115192181393	0.9446752267661772	0.1685460173661173	0.9434389145665578
71	0.1651478861078755	0.9446752265861027	0.16992372616024218	0.9426847669333894
72	0.1680849404763599	0.946374622176421	0.16852615047723818	0.9502262447034971
73	0.16949079129450992	0.9441087611492307	0.16612721570566588	0.9449472101925006
74	0.1639545035416266	0.9473187312978992	0.16579298360405284	0.9517345403294398
75	0.15964444665930422	0.9473187311178247	0.1685768228985066	0.9426847669333894
76	0.15866612325622237	0.9499622354694723	0.16750220311622993	0.9434389145665578
77	0.15969602164905236	0.948262839879154	0.16463429124556694	0.9464555058184433
78	0.15703657535087667	0.950339879334153	0.1636612150554024	0.9517345403294398
79	0.16089756012503115	0.947696374802431	0.16255878595295356	0.9502262448833
80	0.1581312295083193	0.9501510575818871	0.1649289469643416	0.9426847669333894
81	0.16107951617853158	0.9488293053160262	0.16508171510732372	0.9524886881424112
82	0.15405158129073343	0.9507175228386847	0.16311104723770695	0.9472096536314146
83	0.15477005817738904	0.947696374802431	0.1621889522127796	0.9509803925164685
84	0.15149574026780546	0.9514728096676737	0.16576965901646679	0.9524886881424112
85	0.1412756057664347	0.9537386708749385	0.1693922836406558	0.9434389147463608
86	0.1463969518230761	0.952416918429003	0.16136222237195724	0.947963801444386
87	0.14209920555083053	0.9563821752265861	0.16246392520574424	0.9472096538112175
88	0.1433824261149611	0.9529833838658751	0.16314415172933633	0.9464555059982461
89	0.14154458027952027	0.9522280964966627	0.16171927639981382	0.9472096538112175
90	0.14374517919523838	0.950339879334153	0.16482172463634254	0.9426847669333894
91	0.14024852765470833	0.9524169182489286	0.16186866559773727	0.9472096538112175
92	0.13915975063228894	0.9552492447129909	0.16076604642120063	0.9494720970703286
93	0.13289250273628897	0.9595921451951802	0.16278703780465537	0.9457013581852748
94	0.1313074925334792	0.9569486403033093	0.16150820351923573	0.9487179490775545
95	0.1329987071161904	0.9561933532942458	0.16233422325117736	0.9479638016241888
96	0.12617871226050703	0.957137462055575	0.16141350050407657	0.9502262447034971
97	0.12882812832147333	0.9595921451951802	0.16692937171117572	0.9434389147463608
98	0.12756491065295442	0.9594033230827654	0.16053860676144763	0.9487179494371601
99	0.133337795036617	0.9569486403033093	0.16851789662740888	0.9449472103723034

The optimal condition:
	epoch: 84
	train_acc: 0.9514728096676737
	val_acc: 0.952488688142
	using time: 376.583631039
