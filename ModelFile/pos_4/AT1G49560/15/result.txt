The number of train datas: 4320
The number of test datas: 1082
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7052903647776003	0.507175925925926	0.6898925305514592	0.5295748600457381
1	0.6917826347880893	0.5331018520726098	0.6797125316371319	0.567467652385204
2	0.6847598499721951	0.551388888447373	0.6707468963815192	0.6284658025240942
3	0.6782645750928809	0.5662037041452196	0.6621323540779227	0.6552680227320208
4	0.6689717005800317	0.5956018522933677	0.6530002702626636	0.6682070248007995
5	0.6547874243171127	0.6240740736325582	0.640795709024736	0.6866913129353479
6	0.6447731428676181	0.639351851410336	0.6257708564042604	0.714417744365946
7	0.6287603934605916	0.6638888893304048	0.6093927838886071	0.71903881755642
8	0.6117673454461274	0.6805555559970714	0.5925848652606971	0.7107208858135667
9	0.6027153655334755	0.6840277773362619	0.5752468997140909	0.7218114597079053
10	0.5821779917787623	0.7122685189600344	0.5564590532766472	0.7301293894676095
11	0.5725760296539024	0.7085648148148148	0.5413156238809751	0.7402957480628036
12	0.5540729332853247	0.7347222222222223	0.5265720677243584	0.7458410355608477
13	0.5450107777560199	0.7333333328918175	0.512939214486071	0.746765248987018
14	0.5299371763511941	0.75	0.49949759377128755	0.7523105354934876
15	0.5154769056373172	0.7537037041452196	0.48501395286782173	0.7735674690847697
16	0.49767838848961726	0.7699074074074074	0.46810933743739525	0.7791127544894897
17	0.4879776265886095	0.7724537037037037	0.4552683913994188	0.7892791120931093
18	0.4750410400055073	0.7756944444444445	0.4362879992082247	0.8012939005153678
19	0.45873111177373815	0.79375	0.4199367632707254	0.8049907581863474
20	0.4466363641950819	0.7983796300711455	0.39943293144654435	0.830868761883205
21	0.4250948969964628	0.8159722217807064	0.37790803933540246	0.8465804069848687
22	0.40468619487903734	0.8206018514103359	0.3529724101372435	0.8576709799978076
23	0.38177717239768416	0.8391203703703703	0.3291281515701421	0.8743068395172161
24	0.35908646561481333	0.8543981481481482	0.30793007189156607	0.8881700567749644
25	0.3417008541248463	0.8671296291881138	0.28548424736409	0.8946395565974293
26	0.32590073192561114	0.873148148589664	0.2605904200270965	0.9149722726860681
27	0.297961496203034	0.8854166666666666	0.23928901586206475	0.9232902024457723
28	0.285918194938589	0.8949074078489233	0.22044337247524157	0.9306839188894811
29	0.2748660537931654	0.9020833328918174	0.2054391798052021	0.9380776342314404
30	0.26067043134459744	0.9094907411822566	0.19119598354297293	0.9436229217294845
31	0.24976008931795757	0.9122685185185185	0.17907442965040365	0.9473197794004641
32	0.22751404720324056	0.9215277777777777	0.16638212324621057	0.9537892803246786
33	0.21833767294883727	0.9249999995584841	0.15946480910020042	0.9519408493958648
34	0.21270190642939674	0.9280092588177433	0.15084316783934115	0.9565619235779133
35	0.21152957600575906	0.9340277773362619	0.14949371143762374	0.9547134926490995
36	0.20444641002902278	0.9335648152563307	0.14273627540320433	0.9574861379956582
37	0.19294059265542912	0.9395833337748493	0.13735341502425852	0.9584103524134031
38	0.18986056844393412	0.9391203703703703	0.13333305184920483	0.9621072089826334
39	0.18621799068318473	0.9439814819229974	0.13009676235330303	0.9630314234003783
40	0.1808067003885905	0.9421296291881137	0.12823456068576594	0.9648798522358681
41	0.18575944183049378	0.9402777773362619	0.12446766149755327	0.9667282810713579
42	0.17541823056009082	0.9474537037037037	0.1231553367237507	0.9676524954891028
43	0.16843889123863645	0.9481481477066322	0.12002156991614872	0.9676524954891028
44	0.16587627099619973	0.9497685180770026	0.11836529466669572	0.9685767099068477
45	0.16486785930615885	0.9476851856267011	0.11625413869313084	0.9685767099068477
46	0.15913927080454648	0.9467592588177434	0.11439145156724616	0.9695009243245927
47	0.15836028787824843	0.9534722217807063	0.11511436203931925	0.9695009243245927
48	0.15699268965809435	0.9541666662251508	0.11221709390224238	0.9695009243245927
49	0.15207430687215592	0.9493055555555555	0.11341650048597904	0.9695009243245927
50	0.15152495150212889	0.9532407411822567	0.10946035809305371	0.9695009243245927
51	0.14728126890129514	0.9560185185185185	0.11114211672445322	0.9695009243245927
52	0.1438449243704478	0.9546296296296296	0.10756105506816765	0.972273566476078
53	0.14324471166840305	0.95717592548441	0.10748566307003529	0.9695009243245927
54	0.14025651492454388	0.955787037037037	0.10909749848454806	0.9704251387423376
55	0.1380002063181665	0.9560185185185185	0.10632250770623494	0.9704251387423376
56	0.13891532939893228	0.9576388893304048	0.10415473544553555	0.972273566476078
57	0.13556131952338749	0.9555555551140397	0.10365394113134324	0.9713493531600825
58	0.1389197320849807	0.9534722217807063	0.10341094194630819	0.972273566476078
59	0.1343820379840003	0.9567129629629629	0.10598082402497254	0.9704251387423376
60	0.1297765615913603	0.9597222226637381	0.10283417035713655	0.9704251387423376
61	0.1274476407578698	0.9604166662251508	0.10132225695136735	0.9713493520583331
62	0.13432076120818104	0.9599537032621878	0.10641539005937946	0.9695009243245927
63	0.12421239824206741	0.9608796296296296	0.09947448847694891	0.9713493531600825
64	0.12268851587065945	0.9615740736325582	0.09895421176212332	0.9713493531600825
65	0.11780243438703042	0.9655092588177434	0.10238241579197692	0.9685767099068477
66	0.12175242415180913	0.9629629629629629	0.0980871473051704	0.9731977808938229
67	0.11393066699858065	0.9664351847436693	0.10030693845916368	0.9704251387423376
68	0.11720855997668372	0.9622685189600344	0.09873512315661982	0.9713493531600825
69	0.11550095235859906	0.9636574078489233	0.09825512651154382	0.9704251387423376
70	0.11824644649470294	0.9636574078489233	0.097730724213304	0.9704251387423376
71	0.11135646226229491	0.9634259254844101	0.096117833267739	0.972273566476078
72	0.10933338900407155	0.9657407411822566	0.09593026777953186	0.9704251387423376
73	0.1118335837567294	0.9671296291881137	0.09861392898281929	0.9695009243245927
74	0.1097959745813299	0.9615740736325582	0.09477173731199254	0.9731977808938229
75	0.10405084419029731	0.9650462967378122	0.09528893974649268	0.9704251387423376
76	0.11082458678219054	0.9664351847436693	0.09478740431299491	0.9722735675778275
77	0.10294848421105632	0.9699074069658915	0.09760395796924774	0.9695009243245927
78	0.10065298069406439	0.96875	0.10363622960013075	0.9704251387423376
79	0.09654593451155556	0.9722222222222222	0.09470739884925197	0.9704251387423376
80	0.10027592011072017	0.9685185180770026	0.09490057265527146	0.9704251387423376
81	0.09772516301384679	0.9694444440029285	0.0939826422031838	0.9704251387423376
82	0.09263232631815804	0.9717592592592592	0.09363077783375262	0.972273566476078
83	0.0974879014271277	0.9696759254844101	0.09363505959015016	0.9713493531600825
84	0.09254975884600922	0.9715277773362619	0.09309988325657995	0.9713493531600825
85	0.09085346283736052	0.9715277773362619	0.09217164248172986	0.9713493531600825
86	0.09055037746826808	0.9733796291881137	0.09206078054173376	0.9713493520583331
87	0.08837366777437705	0.9733796296296297	0.09663923838057051	0.9704251387423376
88	0.0886753406237673	0.9747685189600344	0.09240704560015427	0.972273566476078
89	0.09329261062321839	0.9712962958547804	0.09422882454893285	0.9713493531600825
90	0.08896889565167604	0.9740740745155899	0.0927174564265059	0.9713493520583331
91	0.0834339091071376	0.9715277773362619	0.09369893779706162	0.9713493531600825
92	0.08286437204590551	0.9729166671081826	0.09785134083627553	0.9704251387423376
93	0.08442446804708904	0.9745370374785529	0.09374522540353362	0.9731977808938229
94	0.0841413465363008	0.9740740740740741	0.09225151099801725	0.9713493520583331
95	0.08161713207761447	0.9731481477066323	0.09273973995623438	0.9731977808938229
96	0.08684963586705702	0.9743055551140397	0.09349653783104556	0.9713493531600825
97	0.08215515166521073	0.975925925925926	0.09219070865519606	0.972273566476078
98	0.08405912441236002	0.975925925925926	0.09254695997055269	0.972273566476078
99	0.08213814673600374	0.9775462962962963	0.09202430747077557	0.9713493520583331

The optimal condition:
	epoch: 95
	train_acc: 0.9731481477066323
	val_acc: 0.973197780894
	using time: 337.149544954
