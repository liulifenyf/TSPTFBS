The number of train datas: 4320
The number of test datas: 1082
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7062368428265607	0.5057870374785529	0.6899771252974124	0.5184842880243735
1	0.6939209907143205	0.5275462962962963	0.6835072750084501	0.5804066551150324
2	0.6860421463295265	0.5400462962962963	0.6775287270766309	0.5998151566757512
3	0.6820873737335205	0.5583333337748492	0.6699883613921358	0.6469500908789926
4	0.6733968430095248	0.5817129629629629	0.6614008253911947	0.675600737829085
5	0.6606493866002118	0.607638888447373	0.6493637744688503	0.6903881706063276
6	0.6520105101444104	0.6349537037037037	0.6351226009635079	0.7014787433989167
7	0.6385200363618356	0.6453703703703704	0.6190638520140305	0.713493529948201
8	0.6240094719109712	0.6682870374785529	0.6005319882452819	0.724584103071315
9	0.6095160356274357	0.6745370365955211	0.5825018575363371	0.7338262482403387
10	0.592949159057052	0.6928240736325582	0.5614509927367106	0.7421441788814425
11	0.576971917240708	0.712037037037037	0.5448633090845979	0.7532347518943815
12	0.5590563796184681	0.720601851410336	0.5283920352868805	0.7550831796281219
13	0.5504419132515236	0.7233796300711455	0.5154002011373171	0.7532347499112325
14	0.5341403477721745	0.7446759254844101	0.5002188895193794	0.7615526795607618
15	0.5208820000842765	0.7546296296296297	0.48722172725443036	0.7680221804849762
16	0.504820395178265	0.7597222222222222	0.47346338866598725	0.7744916814091907
17	0.4914331497969451	0.7726851847436693	0.45899469233264323	0.7846580400043848
18	0.4810725324683719	0.776388888447373	0.4440328692552563	0.7994454727816274
19	0.4647780539812865	0.7932870370370371	0.4305008355658949	0.8059149726040923
20	0.4536706445393739	0.7951388888888888	0.41219836589148656	0.8188539744525212
21	0.4309555142014115	0.8122685180770026	0.39126969121961186	0.8271719042122254
22	0.41787131627400714	0.8178240745155899	0.36979888707344283	0.8410351193766497
23	0.39362633691893684	0.8342592592592593	0.34768271214860647	0.858595195407127
24	0.3710509271533401	0.8453703703703703	0.32827663465700835	0.8641404819135966
25	0.35408475553547897	0.8636574074074074	0.3069244563689734	0.8752310549265355
26	0.3375724929350394	0.8671296296296296	0.2854865534909331	0.88724584125547
27	0.3163226118794194	0.875	0.2647443629677326	0.9048059142010489
28	0.303588761444445	0.8870370365955211	0.2462092192358098	0.9140480583784981
29	0.28908134676792	0.8935185189600344	0.228369454138821	0.9214417748222069
30	0.2775203382527387	0.8956018522933678	0.2163092569480762	0.9288354890624168
31	0.2601937967318076	0.9115740740740741	0.202379673939756	0.9325323466232215
32	0.24270001020696427	0.9148148152563307	0.18899550469327106	0.9371534198136956
33	0.23378763927353752	0.9201388893304048	0.18037489814039961	0.9417744919024201
34	0.22069302366839516	0.9287037037037037	0.17228679708764646	0.94362292073791
35	0.22101102537579007	0.9305555559970714	0.16773356263165995	0.9482439928266345
36	0.20646961485898052	0.9331018518518519	0.15997332450202123	0.9500924216621244
37	0.20292234509079546	0.9351851847436693	0.15482811459001022	0.9528650649153592
38	0.19842113808349326	0.9356481477066323	0.15082244310603785	0.954713493750849
39	0.19059204619239878	0.9439814810399656	0.15000811227478514	0.9537892793331041
40	0.18610361604778855	0.941435185626701	0.14318632961090744	0.9565619235779133
41	0.18877375412870337	0.9414351851851852	0.14067726137457406	0.9556377091601683
42	0.18340789874394733	0.9444444448859604	0.13894387589364748	0.9565619214845894
43	0.17709574302037556	0.9458333328918175	0.13572097097328983	0.9574861379956582
44	0.17057613686279013	0.9490740736325581	0.13543476745513802	0.9574861359023342
45	0.1700655303619526	0.948148148589664	0.13128637096908308	0.9621072089826334
46	0.17095177328145061	0.9465277773362619	0.13201794726515875	0.9648798511341187
47	0.16634578384734966	0.9495370365955211	0.12894911257044003	0.9602587801471435
48	0.15792962389963644	0.9546296291881138	0.1259004828174101	0.9639556378181232
49	0.16235088419031213	0.9483796296296296	0.12541459175773556	0.9630314234003783
50	0.15937746095436592	0.9511574074074074	0.12396027037594984	0.9667282799696085
51	0.1539548835268727	0.9539351851851852	0.1259411276763997	0.9621072089826334
52	0.14548002553206904	0.9562500004415159	0.1223038318196859	0.9685767088050984
53	0.14356738251668436	0.9597222226637381	0.11990031535270694	0.9658040666536131
54	0.14397803567073963	0.9567129629629629	0.1226529135556406	0.9658040677553624
55	0.14353552366848346	0.9574074069658915	0.11914567283032783	0.9667282810713579
56	0.14186878237459394	0.9581018518518518	0.1194892564234143	0.9704251397339121
57	0.14277391659992714	0.9569444440029286	0.11636414793414682	0.9695009243245927
58	0.14213937316779737	0.9562499995584841	0.11707743769597655	0.9695009232228432
59	0.13597108523050944	0.9585648143732989	0.11781978348266615	0.9685767110085972
60	0.13589822274667246	0.9590277777777778	0.1161633051532474	0.9704251387423376
61	0.13186275401601086	0.9613425930341085	0.1169114089992703	0.9695009253161672
62	0.1380683335993025	0.9583333337748492	0.11675343881473083	0.9685767110085972
63	0.129748621251848	0.9606481485896641	0.11224602250977937	0.9695009243245927
64	0.12792785548501545	0.9608796300711455	0.11203889579076644	0.972273568569402
65	0.12197420997200188	0.9618055551140396	0.11181646520736697	0.9713493531600825
66	0.12794026892494273	0.9636574078489233	0.11129799321321375	0.9704251376405881
67	0.11852413846386803	0.9652777782192936	0.11090273079557031	0.9713493531600825
68	0.12035269439220428	0.9629629625214471	0.11124010791730088	0.9704251387423376
69	0.12469420896636116	0.962037037478553	0.11022184045499883	0.9704251376405881
70	0.12471425433953603	0.9636574074074075	0.11089437581640074	0.9704251398440871
71	0.11968648019764158	0.9608796291881138	0.10948877174290182	0.9731977829871469
72	0.11633051037788392	0.9655092588177434	0.10911330383773653	0.9704251398440871
73	0.11183213379096102	0.9675925921510767	0.11008068138316907	0.971349354261832
74	0.11547401817860427	0.9631944440029285	0.10729889051090107	0.9731977808938229
75	0.10488514916764366	0.9680555559970715	0.10691357567878836	0.9731977808938229
76	0.11536257106948782	0.9666666662251507	0.108026866758046	0.972273568569402
77	0.10738155935649518	0.9699074069658915	0.11159127697265964	0.9685767110085972
78	0.10679879955671452	0.9685185180770026	0.114276865025545	0.9667282821731074
79	0.1002473094397121	0.9689814819229974	0.10600882124107558	0.9731977808938229
80	0.10957501801075759	0.9655092592592592	0.10619915464063229	0.9731977819955724
81	0.10374399925823564	0.9680555551140396	0.10955547403661249	0.9695009254263421
82	0.09892636278161296	0.9675925925925926	0.10855106654785257	0.9713493530499075
83	0.10034959835034829	0.969212962962963	0.10569781938123615	0.9731977808938229
84	0.0975678155819575	0.9699074078489233	0.1054489871215027	0.9731977808938229
85	0.0958613118087804	0.9717592588177434	0.10513632139965699	0.9731977808938229
86	0.09558093299468358	0.9715277782192937	0.10450551263616177	0.9731977808938229
87	0.09492504668456536	0.9701388888888889	0.10831756210867005	0.9685767110085972
88	0.09629096546106869	0.9719907402992248	0.10457255522584519	0.9704251397339121
89	0.09491140676869286	0.9717592588177434	0.10297470582501064	0.9731977808938229
90	0.09113961805899938	0.9722222226637381	0.10671343166870022	0.9713493530499075
91	0.08852369056807624	0.9717592588177434	0.10378093861883537	0.9741219953115678
92	0.08673941399212237	0.973148148589664	0.10544830851270619	0.9722735675778275
93	0.08653091032195974	0.9752314814814815	0.10415832433925318	0.972273566476078
94	0.09021512888095996	0.9717592588177434	0.10432789832794291	0.9731977829871469
95	0.08601527390656648	0.9738425921510767	0.10427010402276203	0.972273566476078
96	0.09094652224470068	0.9719907411822566	0.10371763107681892	0.9731977808938229
97	0.0874580106249562	0.9747685185185185	0.1031412311215057	0.972273566476078
98	0.08461952867607275	0.975	0.10422811315647997	0.972273566476078
99	0.0865024492972427	0.976388888447373	0.10370923764659384	0.9731977829871469

The optimal condition:
	epoch: 91
	train_acc: 0.9717592588177434
	val_acc: 0.974121995312
	using time: 378.897219896
