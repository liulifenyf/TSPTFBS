The number of train datas: 6486
The number of test datas: 1622
epoch	train_loss	train_acc	val_loss	val_acc
0	0.705878078919151	0.5020043170639589	0.6937957071640636	0.5086313203142545
1	0.6944839501505901	0.5097132287862085	0.6927408142389704	0.502466090473676
2	0.6930400874928637	0.516651248641489	0.6909135105283575	0.5166461163105124
3	0.6906044863272405	0.5303731111145078	0.6892260673895717	0.5363748458692972
4	0.6902445179791941	0.5306814675010577	0.6875336556046576	0.5419235511713933
5	0.6901102031486622	0.5252852297990807	0.6863514719997176	0.5480887789908525
6	0.6872608810525377	0.5374653096960681	0.6851461634829953	0.5554870537191666
7	0.6841773678592572	0.5556583411157627	0.6835659172767188	0.5678175086598802
8	0.6845399465158035	0.5479494292097182	0.6817726329722328	0.5807644879920856
9	0.6816701951895898	0.5618254706111911	0.6797090579931304	0.594327990723597
10	0.6805562717915317	0.5667591738987586	0.6774437507630571	0.6066584475384393
11	0.6770839088866639	0.5827937093995583	0.6746846388212409	0.6257706527057323
12	0.6751595075359104	0.5912735122719776	0.6718879602252334	0.6356350196716083
13	0.6704534350667807	0.5880357692207115	0.667871591709692	0.6510480885587991
14	0.6677139899335891	0.602682701349626	0.6637850916782525	0.6596794067416915
15	0.6642330107665378	0.6114708599653135	0.6583499476295217	0.6763255255877898
16	0.6602982578364339	0.6077705825363968	0.6537196322375249	0.678791614187337
17	0.6548556526832804	0.6325932775534784	0.6469020248929317	0.6929716403181544
18	0.6494531797620201	0.6339808819178553	0.6400315685131106	0.7053020965450348
19	0.641684606436995	0.6432315758669263	0.630710915484352	0.7194821217939092
20	0.6327593872622873	0.6672833796051818	0.6207913022153033	0.7281134388743729
21	0.6254028399123699	0.6643539928669479	0.609122342451874	0.7330456222470679
22	0.6139665054679468	0.6745297566373297	0.5958274244233213	0.7466091243906174
23	0.6046826903591397	0.6917977182724724	0.5836098823976575	0.7638717630347547
24	0.593333120960679	0.701819303298195	0.5663739104747184	0.765104809024919
25	0.5698780660051421	0.7220166511937053	0.5475998487043322	0.7879161538530954
26	0.5613290194262335	0.7283379584229217	0.5284827003202662	0.7977805194225617
27	0.5401027050975514	0.7493061977810526	0.505467476885945	0.8113440195817395
28	0.5255372824490235	0.7523897628963563	0.48436108804807415	0.8144266325360309
29	0.503484883096679	0.7727412889667621	0.4604662200378578	0.8360049326234622
30	0.4851820215173904	0.7792167747017046	0.4381009423703359	0.8452527753815845
31	0.4630424120049031	0.7935553503154128	0.4143800237543339	0.857583231608465
32	0.43759729944553194	0.8149861236468459	0.3898690924250536	0.8637484571495715
33	0.4140307983700008	0.8283996302295606	0.366594631633688	0.8723797770963497
34	0.4007020476071731	0.835029293771809	0.34762699345331155	0.881627619854472
35	0.3815629273846015	0.8428923836505747	0.32749403618119943	0.8951911219980214
36	0.3631731286447356	0.8572309586761397	0.3088061183360296	0.9050554875674877
37	0.35284615101506966	0.859235276181206	0.29557591489299156	0.915536375066355
38	0.3369428940643472	0.8695652173729249	0.2836248800434108	0.91368680575038
39	0.3204109399288553	0.8729571382866352	0.26667481624095274	0.9198520344517822
40	0.3072598614315541	0.8818994761248484	0.2564607893751817	0.916152898759642
41	0.2978100601791637	0.8851372184593149	0.2476200517978974	0.9229346485085023
42	0.28618865993851467	0.8922294168387009	0.23856550930975104	0.9254007406358213
43	0.2782848028996239	0.8970089422454446	0.22932819584809455	0.9272503093638343
44	0.2656754793353997	0.9039469626704889	0.2217318715869866	0.9297164003152295
45	0.2629169396989477	0.9034844282009408	0.21504503769659966	0.9309494456439366
46	0.2605367633633286	0.9073388838782709	0.21068057812906518	0.9290998772099045
47	0.2409569606658231	0.9128893000859741	0.20431096056239673	0.9290998772099045
48	0.24242682957167688	0.9155103301435865	0.19928858793913656	0.9364981515339946
49	0.23810241821001166	0.9127351220764939	0.19508608203707434	0.9371146743453387
50	0.22527424351984507	0.9216774589957332	0.19561360616572246	0.9284833538105984
51	0.22662837540077788	0.9178230033735416	0.19140162654266993	0.9371146717730051
52	0.2238660210946295	0.919827320731572	0.18543299477726552	0.9414303314524132
53	0.2158462505372924	0.9212149247283594	0.18304429040663633	0.9327990146659305
54	0.214279618756366	0.925994449436683	0.1858314461317074	0.9309494456439366
55	0.20781976098066637	0.9275362316635043	0.17687479253173904	0.9401972886960398
56	0.20365316206902367	0.9296947272331891	0.1748139530640789	0.9395807658846957
57	0.20369998683835341	0.9270736973961304	0.172399070293042	0.9364981518279757
58	0.19103070634072333	0.9330866481468996	0.1681949099762372	0.9395807658846957
59	0.19506588440378103	0.9306197962641827	0.16884271337497983	0.9383477202620077
60	0.1913508086514407	0.9313906874878701	0.16672980934197748	0.9420468542637572
61	0.1818859212254434	0.9397163117626659	0.16483687795928315	0.9364981518279757
62	0.1864055532145346	0.9350909652843764	0.16223607650520475	0.9377311974506637
63	0.17756716785719834	0.9403330246828017	0.17093027780882086	0.9371146740513577
64	0.1748043899270733	0.9407955599426672	0.16877158667832504	0.9383477196740457
65	0.16929005040013786	0.9394079556518082	0.15876322922224476	0.9364981515339946
66	0.17067352415160414	0.9415664506701088	0.15706495084465652	0.9371146743453387
67	0.1642051357758696	0.9431082334666939	0.16261539188398533	0.9401972878140968
68	0.15914898126343316	0.9477335798714656	0.16064768160536022	0.9408138109194218
69	0.16177182067719795	0.9444958373899633	0.15470295071454876	0.9401972884020587
70	0.15709883097307645	0.9472710451813638	0.1589523395649749	0.9408138109194218
71	0.15893363114532555	0.9471168667307762	0.15379376920760046	0.9432799021647978
72	0.15540285478798357	0.9474252238341258	0.15446664543613406	0.943896424682161
73	0.15630712171524275	0.9475794020641596	0.14977683597296	0.9445129480814669
74	0.15355932060083488	0.9486586490311154	0.1524205840986254	0.9463625139431654
75	0.15067891584036713	0.9502004319012184	0.14823241269103402	0.9457459937041549
76	0.14700669795963964	0.9498920748713867	0.17466913444781274	0.9315659681612996
77	0.14807204283243192	0.9478877585242275	0.1462098564194692	0.948828608054856
78	0.14211534616611196	0.9537465306222347	0.14517816849760298	0.948212085243512
79	0.14575297331464462	0.9500462532484565	0.1451117321205786	0.946362516515499
80	0.1380024133017502	0.9523589272687291	0.1440651493764835	0.948828608054856
81	0.1387220563259604	0.9531298179226527	0.15200756629871529	0.945745993116193
82	0.13543708332059856	0.954825778802236	0.14445347165282352	0.9482120823771975
83	0.13665440423351505	0.9528214613155491	0.1424335953486686	0.9512946993002321
84	0.1358954027947584	0.954979956536024	0.14597731292174276	0.9463625142371463
85	0.12783650241073105	0.9571384519770525	0.1461665568237093	0.9445129474935049
86	0.12723595279117003	0.9572926300600506	0.14206328479120675	0.9500616533835631
87	0.12823966987295501	0.9574468082900846	0.14114519498057196	0.9494451305722191
88	0.13102369556778418	0.9577551648236703	0.14238516177922378	0.9488286074668941
89	0.12442120617916655	0.9577551648236703	0.13973422743536248	0.9512946967278985
90	0.12167235151176793	0.9588344123603898	0.13839141793007034	0.9525277423505866
91	0.12421372827835153	0.960222017000459	0.14445244354619638	0.945129470304849
92	0.12224455494140718	0.9599136600441451	0.13896464513277154	0.9519112218175951
93	0.11910192151055672	0.9583718776702881	0.13774340773407834	0.9531442677342642
94	0.11457966576378323	0.962380511577652	0.14823088253837918	0.9414303334367848
95	0.11404765850364372	0.9629972246448236	0.13867968589104207	0.9512946990062512
96	0.11585942543457219	0.9611470858844166	0.1380098207994983	0.9506781761949071
97	0.11191497118916734	0.9616096205010004	0.14851106379902318	0.9414303334367848
98	0.10945245467133262	0.9631514028748575	0.13625122200693068	0.9512946964339175
99	0.10994956996768593	0.9629972246448236	0.14737523090824686	0.9420468562481289

The optimal condition:
	epoch: 93
	train_acc: 0.9583718776702881
	val_acc: 0.953144267734
	using time: 466.178251982
