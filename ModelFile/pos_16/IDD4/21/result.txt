The number of train datas: 9796
The number of test datas: 2450
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7015511008514196	0.5159248671467423	0.6872735962089227	0.5334693877064451
1	0.6919984478228138	0.5305226623111474	0.6839714640014025	0.5591836736640151
2	0.6889106513237944	0.5391996732143637	0.6805825645096448	0.5800000001459705
3	0.6855018804052889	0.5408329929366994	0.67650566042686	0.6028571430031134
4	0.6794770088863645	0.5729889752622428	0.671289115098058	0.6044897960156811
5	0.6765550577966667	0.5769701920854359	0.6642780943792693	0.648163265452093
6	0.671453781447249	0.587382605339664	0.6572188650831884	0.6693877551993546
7	0.6632708279684447	0.610657411115225	0.6472279390996816	0.6926530613218035
8	0.65483852131798	0.6228052266474499	0.636462208202907	0.7040816327503749
9	0.6441962146282001	0.63587178435312	0.6226436560007991	0.7191836735667014
10	0.6324499213924307	0.6544507963893949	0.6080868861140037	0.7253061223030091
11	0.6195650182484899	0.6698652509282004	0.5900666013055919	0.7432653059764784
12	0.6028850467022997	0.683646386255776	0.570872420096884	0.7538775511177219
13	0.5829741952126247	0.7105961617229909	0.5485761436150999	0.7640816327503749
14	0.5636404201954226	0.7233564721267532	0.5262326423975886	0.7791836735667015
15	0.5459950492303193	0.7348917924467034	0.5045947202371092	0.7897959184646607
16	0.5152032052609034	0.7595957534660753	0.4796638352530343	0.8061224491255624
17	0.49155338727342396	0.7771539404568453	0.4545815913044676	0.8179591837707831
18	0.4749093225850237	0.7890975910237781	0.43067297940351523	0.8326530611271761
19	0.44704379173579045	0.8082890976395302	0.40817563879246616	0.8432653062197627
20	0.41506700619915254	0.8307472436512767	0.3835610055923462	0.8551020407190129
21	0.3920479619342388	0.8424867293502711	0.36322976482157804	0.8685714287173991
22	0.37335361145427637	0.8517762352467168	0.3494749076269111	0.8677551020894732
23	0.3562605163061945	0.8630053081187291	0.34577260715620856	0.867346938824167
24	0.33388194082804534	0.872396896522159	0.3152668240362284	0.8889795916907641
25	0.3140239956891016	0.8871988568222245	0.2994438512957826	0.8971428572401708
26	0.29836856879570767	0.8940383830378132	0.2880694443838937	0.9024489794458662
27	0.2898364358164428	0.8972029401458688	0.28104252525738305	0.9032653059764785
28	0.28380481456434936	0.8985300123959281	0.27466457109062037	0.9065306120989274
29	0.2701056785075311	0.9005716620488476	0.26482826464030207	0.9130612243438253
30	0.2598724267150782	0.9093507555564018	0.26335816417421615	0.9130612243438253
31	0.25103036823833463	0.915475704490822	0.2564012211682845	0.9138775508744376
32	0.2505933185069597	0.9151694567751621	0.2510578995334859	0.9138775511663787
33	0.24384817640457215	0.9154757041987618	0.24867671506745476	0.9163265307095586
34	0.2379252941280348	0.9196610862793072	0.2458181802593932	0.9183673470360892
35	0.23337280303665744	0.922519395623026	0.24247855597612808	0.9208163264332986
36	0.22889697016283364	0.9209881584563514	0.2463896660902062	0.9167346937315805
37	0.22616290656120352	0.9227235606613331	0.24132180535063452	0.9179591835274988
38	0.22456409797078494	0.9260922824912969	0.24040577793607906	0.918367346792805
39	0.21707542531463067	0.929563087095967	0.23540605301759682	0.918775510106768
40	0.21509879461815523	0.9296651693839061	0.23405744742374032	0.9191836733720741
41	0.2106014897916793	0.9296651694082445	0.2336118850902635	0.9204081631679925
42	0.20542668645821965	0.9356880359573723	0.23475866772690598	0.9208163263846417
43	0.20752862718894852	0.931400571807933	0.23094760705013664	0.9199999999026863
44	0.202013669451094	0.9347692935405434	0.2317163701446689	0.921224489893232
45	0.2017338327506748	0.9343609635856212	0.23237939017159598	0.9228571427111723
46	0.1969237344004077	0.9335443037487916	0.22881627664274098	0.9232653060251352
47	0.19861182977516537	0.935994283186265	0.22838271975517274	0.9228571427598291
48	0.19269790156927338	0.9369130256274322	0.22749644714958814	0.9228571427598291
49	0.1912484043085755	0.9384442628671219	0.23287263634253522	0.9208163263846417
50	0.19011927185836447	0.9369130255300787	0.22892702299721387	0.924489796015681
51	0.1874653616393036	0.9388525927246907	0.2268770549248676	0.9220408162292169
52	0.1850945163607938	0.9392609227526281	0.22927530415204106	0.9236734692417845
53	0.18233179404157285	0.9397713353605648	0.2255391604316478	0.9220408162292169
54	0.18198637480563462	0.9425275623920062	0.2257503586399312	0.9216326529639108
55	0.18221849519508426	0.9416088197561321	0.22574566434840768	0.9220408162292169
56	0.17878901657886825	0.9423233973293608	0.22524976056449267	0.9248979592809872
57	0.17273352700698225	0.9445692120449257	0.2258797553120827	0.9232653060251352
58	0.17320188855932606	0.9429358922252367	0.2284249241498052	0.9228571427111723
59	0.17487132768331132	0.943854634666404	0.225257579939706	0.9228571429544565
60	0.17167964471803	0.9466108616978454	0.2280182297132453	0.9240816327503749
61	0.16808815465357022	0.9445692118502189	0.22760520088429353	0.9195918366373802
62	0.17300837088137463	0.9450796242634488	0.22491908039365496	0.9220408164238443
63	0.16863891793884225	0.9456921190376328	0.22723369527836235	0.9220408164238443
64	0.16875558570727078	0.9465087792395377	0.23079268455505372	0.9224489796891504
65	0.16516632149539806	0.9468150263467386	0.22704701411480807	0.9228571429544565
66	0.1625480349573032	0.9490608409892884	0.22745819476186013	0.9224489796891504
67	0.16518556704176549	0.948448346190766	0.2281175398583315	0.921224489893232
68	0.160358035306436	0.9477337689095976	0.22845829625518954	0.921224489893232
69	0.16033439022417018	0.9484483462637812	0.23123058859182863	0.9208163266279259
70	0.15778011330637265	0.9501837484931012	0.23050435316805937	0.9216326531585382
71	0.15324057027752325	0.9488566759996582	0.2291428160180851	0.921224489893232
72	0.15570197284538048	0.9488566762187034	0.23528907384191242	0.9220408164238443
73	0.15196502012785915	0.9500816661078085	0.23022139673330347	0.9228571429544565
74	0.15052417128754908	0.9515108208648523	0.22833247856217986	0.9216326531585382
75	0.1503805777658098	0.9528378928228513	0.23118337582568732	0.9236734694850688
76	0.15096820760084786	0.9522253980243289	0.23036263833240586	0.9216326531585382
77	0.14844453652423953	0.9537566353857103	0.23565491386822293	0.9204081633626199
78	0.14543867708104344	0.9535524704204184	0.23559887905510105	0.9216326531585382
79	0.1476335062901309	0.9517149858301442	0.234600150439204	0.9216326531585382
80	0.1456555649729445	0.9543691303789397	0.2298760180084073	0.9232653062197627
81	0.1456429008706315	0.9532462228507886	0.23228591091778814	0.9228571429544565
82	0.13921880623475538	0.9550837077574615	0.2350137957991386	0.9216326531585382
83	0.1425831614768763	0.9551857899237088	0.2331683471008223	0.9224489796891504
84	0.1397501502342738	0.9562066150909057	0.2333213289416566	0.9204081633626199
85	0.1390173477559929	0.9564107799345057	0.23489493691191382	0.9228571429544565
86	0.13757792294098437	0.9542670476042333	0.2360901041663423	0.9216326531585382
87	0.13696972361970017	0.9565128625388436	0.23712401886375584	0.9195918366373802
88	0.14024084454752953	0.954573295027833	0.23246068565212952	0.921224489893232
89	0.1331977710681528	0.9589628419033018	0.2354212945821334	0.9208163266279259
90	0.13528612122797587	0.9572274396009667	0.2350073175770896	0.9224489796891504
91	0.13543406201898442	0.955696202555984	0.2397435669509732	0.9208163266279259
92	0.13548760285556147	0.9569211921286904	0.24463228415469734	0.9167346937802373
93	0.12840473652190215	0.9580440994377962	0.23961246685105927	0.9167346937802373
94	0.13059655474419007	0.9592690894242548	0.24060779459622442	0.921224489893232
95	0.12901978909044473	0.9606982442056369	0.24018871764747463	0.9195918368320076
96	0.12570649260109715	0.9592690895459466	0.24014548795563834	0.9200000000973138
97	0.12812346240399855	0.9578399344725043	0.24065439328855398	0.9208163266279259
98	0.12618095731676818	0.9576357695072123	0.2438147442924733	0.921224489893232
99	0.1225811516346616	0.960800326566591	0.24653702280959305	0.9204081633626199

The optimal condition:
	epoch: 56
	train_acc: 0.9423233973293608
	val_acc: 0.924897959281
	using time: 884.64131093
