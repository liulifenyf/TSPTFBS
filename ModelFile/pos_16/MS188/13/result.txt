The number of train datas: 5016
The number of test datas: 1256
epoch	train_loss	train_acc	val_loss	val_acc
0	0.706642877922484	0.5007974482609324	0.6955539253866596	0.5071656039565992
1	0.7028300523567809	0.4992025518816624	0.6922810324438059	0.5222929926814547
2	0.6960028895730987	0.5237240830296724	0.6899229633580347	0.5286624215211079
3	0.6932673584521292	0.5193381180698602	0.6876645107178172	0.5366242047707745
4	0.6926754711157207	0.523524720893142	0.6858670278719277	0.556528663179677
5	0.6885845733411384	0.5428628390105337	0.6841909369086004	0.5700636936980448
6	0.6852456644961709	0.5516347686449686	0.6823614380162233	0.5780254771375353
7	0.684080656540641	0.556020733604781	0.6800294476709549	0.593949043447045
8	0.6809463030413577	0.5663875599036756	0.6776673926669321	0.609872612224263
9	0.6806049711015997	0.5622009568902674	0.6753241283119105	0.6202229284177161
10	0.6752608278721713	0.5771531099527837	0.6721670866771868	0.6393312082928457
11	0.6689173525029962	0.6030701754385965	0.6682786713739869	0.6464968133883872
12	0.668268535981338	0.59688995215311	0.6636623990763525	0.6576433117222634
13	0.6645678499478853	0.6124401913875598	0.6590796059863583	0.6711783454676342
14	0.6588986275488871	0.630382775024554	0.6532102876408085	0.6759554124941491
15	0.6550631704703093	0.6218102072414599	0.6462208305954174	0.6871019123466151
16	0.6453121099175448	0.6423444977027187	0.6384823751297726	0.7101910805246633
17	0.6388954204615603	0.6547049440835652	0.6291013470121251	0.727707007508369
18	0.6285285620788258	0.6632775120567858	0.6171116752988973	0.740445862150496
19	0.6228433422494734	0.671451355661882	0.6042307045809023	0.7563694252330027
20	0.6070957846428598	0.6905901116427432	0.5897629082582558	0.7659235680179232
21	0.5971905148010315	0.6975677831891621	0.573349458017167	0.7754777089046065
22	0.580274657104194	0.716108452855495	0.5524269965044253	0.7945859861222042
23	0.5663986051101624	0.729066985645933	0.530915896983663	0.8105095541401274
24	0.5380725601073088	0.754585326953748	0.5056450788382512	0.8232484072636647
25	0.5206110070576888	0.7673444975125923	0.480383544211175	0.8399681532458895
26	0.49272945171528076	0.793859649122807	0.45132933338736275	0.8558917212638126
27	0.4734032520076685	0.7932615629033418	0.42672717020769785	0.8638535016661237
28	0.45530345014027623	0.8028309408937725	0.4000500683571882	0.8742038224153458
29	0.4200438072331594	0.8333333333333334	0.3729544361685492	0.8805732484076433
30	0.40411955127685645	0.8313397130137236	0.34895153732816125	0.89171974522293
31	0.3707701979736772	0.8536682614679352	0.32827609587626855	0.8837579598852024
32	0.3563469902893002	0.86662679416331	0.307536058175336	0.8996815286624203
33	0.33300679413515605	0.8740031897926634	0.2917227832375059	0.8957006380816174
34	0.3106155784554078	0.8845693778953674	0.2807134399368505	0.8980891712152275
35	0.301891109922476	0.8875598085173769	0.26418124300659085	0.904458599865057
36	0.2872091343766004	0.8933413077199288	0.25214294899421136	0.9116242049605983
37	0.2741494331348456	0.9033094099834205	0.24270089891306154	0.9132165597502593
38	0.26454596680127074	0.9013157894736842	0.23197069346525107	0.9148089164381574
39	0.24870104976057816	0.9146730461569303	0.22536776153145321	0.9156050947821064
40	0.24328634387663486	0.9160685804472015	0.2172640449112388	0.9187898081579026
41	0.22876463628461677	0.9162679424886688	0.21425463192781824	0.9187898081579026
42	0.22897367914945504	0.9220494416912207	0.20628973651843466	0.924363056565546
43	0.22304639234497217	0.91766347677894	0.2013071048411594	0.925955413253444
44	0.21315788348135575	0.9264354066035013	0.19681891191537212	0.925955413253444
45	0.20495595489487503	0.9322169059961797	0.1944689745925794	0.9299363080103686
46	0.20777636697512875	0.926236044562034	0.19342786946873755	0.9323248430422157
47	0.2014224696815299	0.9304226474328474	0.19552101394173446	0.9275477710802844
48	0.19768991657611476	0.93122009569378	0.18557973766023186	0.9315286616610873
49	0.19345256700470118	0.9334130780548571	0.1865127403644999	0.9347133761758257
50	0.18929838250128275	0.9393939394890026	0.18029894769951038	0.9363057328637239
51	0.17695838420917734	0.9417862838915471	0.18160309951016856	0.9378980895516219
52	0.17923423690659007	0.9399920254232781	0.17469437705103757	0.9371019100687307
53	0.17588967844202189	0.9417862838915471	0.1750952748546175	0.9402866245834691
54	0.1738156519200433	0.9407894736842105	0.17213566269084907	0.93710191310591
55	0.1692189446856911	0.9459728867623605	0.17355828518700447	0.9418789812713672
56	0.16319398433445362	0.9463716109403583	0.1704765749015626	0.937898091449859
57	0.16391758924941316	0.9521531101429102	0.17099492251873016	0.9418789812713672
58	0.15550986135547812	0.9495614034137086	0.176350986596885	0.9418789824103094
59	0.1593854713834454	0.9499601275917066	0.16852403190105583	0.9418789812713672
60	0.1587885647204124	0.9503588517697044	0.1654090475124918	0.9450636946471633
61	0.15338171894945787	0.9521531099527837	0.16511463388136238	0.9410828048256552
62	0.15195538405406228	0.9539473684210527	0.16695386456076505	0.9426751607542585
63	0.14750244590844455	0.9549441786283892	0.16371807114333864	0.9426751577170791
64	0.14240406881394	0.9603269536529432	0.17053435239822243	0.9418789824103094
65	0.14408168077849126	0.9559409888357256	0.16734210283133635	0.9426751607542585
66	0.1442710236784374	0.9559409887406625	0.16592052901626392	0.9426751588560214
67	0.14312345244620214	0.9557416267942583	0.15871338821520473	0.9490445875058509
68	0.13659509697385383	0.9617224880382775	0.15603438892941565	0.9474522315772476
69	0.14481500998448338	0.9559409887406625	0.15973031264581497	0.9474522308179527
70	0.1336590090745754	0.9597288675285413	0.16646658880695417	0.9402866219259371
71	0.1346196585484859	0.9597288677186677	0.16468510401856368	0.9410828002698862
72	0.13195066882425138	0.9603269536529432	0.15342138081219545	0.9522292997427048
73	0.13061091735174782	0.9615231259017469	0.1632245067198565	0.9418789786138352
74	0.13454528300290663	0.9585326952797374	0.16144458133323936	0.9418789786138352
75	0.12623930569185596	0.9645135565237566	0.1521292162738788	0.9514331213987557
76	0.12183482971107751	0.965311004784689	0.15035839350360214	0.9538216564306028
77	0.12382641686587052	0.9629186601920181	0.1523097586479916	0.9522292989834099
78	0.12265445627093885	0.9619218500797448	0.15396903521695715	0.9498407639515628
79	0.11736423688594615	0.9671052630628315	0.17301184812169165	0.9331210168303957
80	0.12086156432470826	0.9663078148969623	0.15744266673258156	0.9442675136456824
81	0.12473318126926011	0.9645135566188198	0.1558645085734167	0.9458598703335804
82	0.12074489208856268	0.9683014353116354	0.14851725822801043	0.9554140142574432
83	0.11455642357112118	0.9700956937799043	0.15571527752527006	0.9450636919896314
84	0.11579691403006252	0.967304625199362	0.14868489705073606	0.9538216575695451
85	0.10390146473568213	0.9704944177677757	0.14795805846050286	0.9538216575695451
86	0.11260245410068943	0.9671052630628315	0.1484565320098476	0.9538216575695451
87	0.11176346827363759	0.9702950558213717	0.1524139817353267	0.9474522270214786
88	0.10772435009431991	0.9694976075604391	0.15075525404161708	0.9530254754291219
89	0.10529742408038802	0.9706937799043063	0.156230952566976	0.9418789786138352
90	0.10522258571650613	0.9732854864433812	0.1513290987083107	0.9514331206394608
91	0.10346102597491973	0.9706937799043063	0.14857563338461954	0.9546178359134941
92	0.10821879135839867	0.970693779809243	0.15111421333376768	0.9498407620533257
93	0.10630687909643426	0.9732854863483179	0.14702108208161252	0.9554140142574432
94	0.10266984245803748	0.9722886761409815	0.1459874134914131	0.9554140142574432
95	0.10241293100316369	0.9730861244019139	0.14860559867066184	0.9538216537730709
96	0.10468647235698487	0.9694976075604391	0.15246092912497794	0.9474522270214786
97	0.10056034246224917	0.9710925038921776	0.14592687918502054	0.954617834015257
98	0.09611249212294437	0.972488038277512	0.15180491708266508	0.9498407620533257
99	0.09836448902825705	0.9720893141945773	0.14441960366668216	0.9546178359134941

The optimal condition:
	epoch: 94
	train_acc: 0.9722886761409815
	val_acc: 0.955414014257
	using time: 283.968317986
