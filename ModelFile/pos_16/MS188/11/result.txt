The number of train datas: 5016
The number of test datas: 1256
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7003624054233423	0.5123604464759096	0.6915775757686348	0.5254777077656643
1	0.6982049462897926	0.515151515056452	0.6889547363967653	0.5501592337705528
2	0.6925440004757907	0.5285087719773561	0.6870999613385291	0.5628980893617982
3	0.689863253628428	0.53488835730431	0.6851648525067955	0.5788216549120132
4	0.6882884537584284	0.5472488038752829	0.6832227771449241	0.5963375780992447
5	0.686309183898725	0.5420653907496013	0.6811529868727277	0.6082802532584803
6	0.6811056523992304	0.5635964912280702	0.678791187371418	0.6114649689121611
7	0.6775389882175926	0.572169058916101	0.6757691927776215	0.6202229284177161
8	0.6752494755163908	0.5763556619770409	0.6727013675270567	0.6393312109503776
9	0.6739724199547532	0.5875199362516783	0.6690414111325695	0.6488853484202343
10	0.6680709185402549	0.6022727273677905	0.6647820981444826	0.6664012750242926
11	0.66068049376471	0.6180223284535811	0.6594690593184939	0.6799363057324841
12	0.6590503171870583	0.6142344497607656	0.6532860246433574	0.6878980903109168
13	0.6535922877336042	0.628389154609881	0.6465300500013267	0.7038216560509554
14	0.642894130099143	0.6517145134615556	0.6383599122618414	0.7149681532458895
15	0.6370351482806593	0.654306220190757	0.6277827681249873	0.7285031843337284
16	0.6254345413410303	0.67085326953748	0.6174117334329399	0.7181528666216856
17	0.6139829828978726	0.6822169059011164	0.6029051295511282	0.7579617826801957
18	0.6023626506233519	0.6983652313550314	0.5874757778113056	0.7738853506981187
19	0.5918766281061005	0.7075358852625273	0.5700414514845344	0.788216558611317
20	0.5746311672756736	0.716507177128556	0.5512027239343923	0.800955415910976
21	0.5581610926220482	0.7398325358851675	0.5300337892429084	0.8057324829374909
22	0.5373179736700164	0.7525917064440117	0.5054110698639207	0.8288216564306028
23	0.5203353585809042	0.7669457735247209	0.48203591518341354	0.8343949033196565
24	0.4887200907657021	0.7876794258373205	0.4562704874451753	0.8439490464842243
25	0.4720338508367919	0.7882775119617225	0.43279180803876016	0.8495222952715151
26	0.449846321268325	0.8114035086768666	0.40710525755669663	0.8614649658749818
27	0.42460330443804345	0.8255582137161085	0.3844790545998106	0.8694267531109464
28	0.407683910983221	0.83233652322106	0.3648671059851434	0.8734076448306916
29	0.378629461334843	0.8536682615629984	0.34597858349988414	0.8726114638292106
30	0.36494388886425866	0.8584529504631505	0.326097575532403	0.879777068924752
31	0.3389179744598778	0.8704146729511888	0.3096182970863998	0.8853503173323953
32	0.33165049500632704	0.8710127592657171	0.29524667779351493	0.8941082798751296
33	0.31102607067692223	0.876794258468269	0.28118965105645977	0.8996815286624203
34	0.29116767354939355	0.8923444977027187	0.2672366101271028	0.9076433102036737
35	0.2843537653367105	0.9011164275272802	0.25917637623419426	0.9052547782090059
36	0.27385946323997096	0.9009170652956864	0.2467104817271992	0.910031847133758
37	0.26408669632967957	0.9053030303030303	0.23917293520110428	0.912420380267368
38	0.25362633491912334	0.9064992024567708	0.23120591348143898	0.911624201923419
39	0.23781654561915846	0.9172647526960054	0.22123602943815243	0.9140127369552661
40	0.23120036894719947	0.9216507177984126	0.21817387441161332	0.9187898100561397
41	0.2215502802074621	0.9220494417862839	0.20701830611107455	0.9203821637068584
42	0.21957182067860828	0.9234449759814918	0.20344904852900536	0.9227706987387055
43	0.21681201667116398	0.9294258374156374	0.19863679416620048	0.9219745203947566
44	0.20446899937290514	0.9314194578303104	0.1946852330569249	0.9283439471463489
45	0.20553486512608504	0.9302232853913801	0.19201269442108787	0.9315286616610873
46	0.19512952115547144	0.9354066985645934	0.18696717357939216	0.9315286616610873
47	0.18939291993586832	0.9381977670500723	0.18520753512716598	0.9323248400050363
48	0.18622551083659822	0.9415869217550166	0.17942356939908047	0.9402866234445268
49	0.18858457018028607	0.9374003190743295	0.1816697219374833	0.9355095533808325
50	0.1803583148658941	0.9429824561403509	0.17446776901840405	0.9402866234445268
51	0.1756143818655463	0.9453748006379585	0.17359986939248007	0.9386942667566287
52	0.1716020450566374	0.9467703348331664	0.16886367587147244	0.9458598718521701
53	0.1723607281843821	0.9429824561403509	0.1678098778056491	0.9450636935082211
54	0.16257640657622657	0.9489633174794333	0.16345437003928384	0.9474522285400682
55	0.16210785099383937	0.9509569377990431	0.16963172585341582	0.940286622685232
56	0.15819232849080406	0.9517543858698491	0.16164738167623047	0.9474522285400682
57	0.15775225962700837	0.9509569377990431	0.16353623151399527	0.9458598710928753
58	0.14629503105435834	0.956937798947999	0.1633866671354148	0.9434713360610282
59	0.15495549590346155	0.9549441785333259	0.15807380152356093	0.9498407628126205
60	0.15194994657994076	0.9547448166819851	0.15935080313378838	0.9466560494368244
61	0.14774507082155067	0.9539473683259894	0.15456140221683842	0.9482484061247224
62	0.14654112670220065	0.9551435406698564	0.157491551273188	0.9474522289197156
63	0.14507449086773339	0.9581339712918661	0.15400340422323555	0.9466560494368244
64	0.1394118706575421	0.9619218499846816	0.16139696633360187	0.9466560486775295
65	0.1418492364826385	0.9591307814992025	0.15169562636666997	0.9498407658497998
66	0.13828372239971465	0.9577352472089314	0.15920796696167844	0.9474522270214786
67	0.13445074099340318	0.9625199361090835	0.15028944469181596	0.9498407658497998
68	0.13353365478499465	0.9611244019138756	0.1506807342836052	0.9506369422955118
69	0.13794493737023034	0.9609250398724083	0.15050447214940552	0.9514331206394608
70	0.13274358395944563	0.960725677830941	0.15315232126955775	0.9490445837093766
71	0.12846502371762167	0.9595295054870739	0.14623310364735354	0.953025479225596
72	0.1257670093000981	0.9631180222334854	0.14532011396186367	0.9530254761884167
73	0.12714642528711895	0.9631180222334854	0.15204865281369276	0.9522292970851728
74	0.1265086037429136	0.9631180222334854	0.15306887490923998	0.9498407620533257
75	0.1237548194243387	0.9653110046896257	0.14591721079911396	0.953025477327359
76	0.1177907773372279	0.9659090909090909	0.14307460511565967	0.9546178347745519
77	0.12064996025446309	0.9681020732701681	0.14279190711914355	0.9538216575695451
78	0.11963478932706743	0.9681020733652312	0.148127662338269	0.9514331187412237
79	0.1186634158593806	0.9677033492822966	0.1515189932220301	0.9498407650905051
80	0.12107880262025235	0.9663078149920256	0.1469170183038256	0.9522292970851728
81	0.12005139675817231	0.9661084529505582	0.1504507215729185	0.9482484053654275
82	0.11661903226251998	0.9698963316433737	0.1416044231433018	0.9554140142574432
83	0.11013789543884983	0.970693779809243	0.14382564233746498	0.9538216537730709
84	0.11221141858914632	0.9694976075604391	0.14161449651809255	0.9538216575695451
85	0.102833608299066	0.9702950557263084	0.14200938867915208	0.952229300881647
86	0.10998112866372774	0.9665071769384296	0.14132868142644311	0.9546178359134941
87	0.10952473377461354	0.9700956937799043	0.14292989789870134	0.9522292970851728
88	0.10452015584474356	0.9716905901116427	0.1423365464730627	0.9514331206394608
89	0.1070846521475336	0.9702950558213717	0.1433379769704904	0.9514331206394608
90	0.10379263777672008	0.9698963318335002	0.14125172637260644	0.953025477327359
91	0.10215908433927114	0.9714912280701754	0.1411510601544836	0.9538216556713079
92	0.10652488439181965	0.970494417862839	0.1392568892734066	0.9538216575695451
93	0.10259624324632033	0.9726874002239161	0.1408660838938063	0.953025477327359
94	0.1078558686817662	0.9710925038921776	0.13752773850207117	0.9585987276332394
95	0.10304764203097451	0.9700956938749675	0.1397195320789981	0.9554140123592061
96	0.10191459506987764	0.9728867622653833	0.14017946083264746	0.954617834015257
97	0.0953158860048799	0.9760765549288603	0.13950718227465442	0.9538216556713079
98	0.0955666851614746	0.9738835725677831	0.14193279111081628	0.9538216556713079
99	0.09715284006982043	0.9720893141945773	0.13940601283387774	0.954617834015257

The optimal condition:
	epoch: 94
	train_acc: 0.9710925038921776
	val_acc: 0.958598727633
	using time: 258.877579927
