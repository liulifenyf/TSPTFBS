The number of train datas: 5016
The number of test datas: 1256
epoch	train_loss	train_acc	val_loss	val_acc
0	0.703137182923215	0.511562998357572	0.6935484735829056	0.5063694265617686
1	0.6985588683085768	0.5113636363636364	0.6898988056334721	0.5350318475134054
2	0.6948072255323188	0.5235247207980788	0.6873988687612449	0.5589171963132871
3	0.6892412772589323	0.538875598133656	0.6854306501188095	0.5668789789934826
4	0.6877074514469652	0.5458532694424169	0.682962818130566	0.5812101903235077
5	0.6875922524948059	0.5494417863789548	0.6809877445743342	0.596337581895719
6	0.6808096452763206	0.5598086125352546	0.678332135176203	0.6074840752941788
7	0.6800054895440547	0.5639952153110048	0.6755057485999575	0.6058917197452229
8	0.6766379742721241	0.5755582137161085	0.6719349660691182	0.6234076448306916
9	0.6723288630374501	0.5877192982456141	0.6681082377767866	0.6433120996329436
10	0.6695200591756586	0.5929027112287008	0.6636886900397623	0.6480891696966378
11	0.6626016769492835	0.6110446570972887	0.6583141703514537	0.6624203833045473
12	0.6589406476826949	0.6204146731413153	0.6528198681059917	0.6759554136330914
13	0.6555380698596461	0.6253987239878713	0.6469846633589191	0.6863057340026661
14	0.6445525365583064	0.6503189793614109	0.6398342885788838	0.7030254796052434
15	0.6424102765141111	0.6415470494417863	0.6311404067239944	0.7085987242164126
16	0.6291103522743334	0.6640749602226549	0.6215609152605579	0.7261146508204709
17	0.6219376327508565	0.6674641147374727	0.6101052548475326	0.7396496826676047
18	0.6133003844218581	0.6812200955987167	0.5969736872205309	0.7515923566878981
19	0.5992399483586422	0.6935805422647527	0.5821274936578835	0.7683121038090651
20	0.5865723322453111	0.709928229760135	0.5666163172691491	0.7754777085249591
21	0.5673909058030903	0.730861244114202	0.5486578721149712	0.7850318448558734
22	0.556693583108972	0.7366427432216905	0.5294701331739973	0.802547772598874
23	0.5364101999684384	0.7490031896976003	0.5071105121806928	0.812898091449859
24	0.5161152337536667	0.7623604465709729	0.4853875832572864	0.8248407620533257
25	0.49754664962561695	0.7771132375444902	0.46157166456720633	0.8343949044585988
26	0.46722265868856194	0.7988437002545529	0.434300047007336	0.8463375811364241
27	0.44925666829805816	0.8056220094743147	0.41259881341533294	0.8566878973298772
28	0.43099626285607734	0.8183811802232854	0.3884005299799002	0.869426750073767
29	0.4009819728525822	0.8389154705894811	0.36685834853512467	0.877388535791142
30	0.3848265696560557	0.8450956938749675	0.3434869571096578	0.8837579625427343
31	0.3582383599102592	0.8576555024874077	0.3241021991915004	0.8885350326064286
32	0.3439345817769353	0.8698165868267869	0.3079218323443346	0.8964968130087397
33	0.3250275651138555	0.8759968102073366	0.2941355456592171	0.9084394927237444
34	0.30676520412618463	0.8861642744172323	0.28248785179891406	0.9084394908255073
35	0.2945319378014767	0.8923444975125923	0.26547250683140605	0.9132165589909644
36	0.28820208572980127	0.8901515151515151	0.2596817597462113	0.9148089156788626
37	0.27438826799582827	0.9001196172248804	0.24436667941178486	0.9219745234319359
38	0.265853435751734	0.9086921849129113	0.23900052297646832	0.921974520774404
39	0.2527739845774771	0.9074960126641074	0.22877140580468877	0.9251592337705528
40	0.23773063106114783	0.9138755981811876	0.22382662525981856	0.9251592341502002
41	0.2307627667840778	0.925239234544824	0.21641283923653282	0.9283439513224705
42	0.23069393185622383	0.9178628388204073	0.21365902776930742	0.9299363049731892
43	0.22865334352808137	0.9200558212765476	0.2110310458833245	0.9307324863543176
44	0.21368773150862308	0.9286283891547049	0.2032891667572556	0.9315286635593244
45	0.21762139482076087	0.9244417863789548	0.20405191429861033	0.9307324844560806
46	0.2089839715041232	0.928030303030303	0.19851212535694146	0.9347133780740629
47	0.2037649180567816	0.9310207337473758	0.20416896244522872	0.9243630558062511
48	0.1948469592053354	0.9336124400963244	0.19661607360763914	0.9307324863543176
49	0.19580155565883173	0.9350079743865954	0.1918621832967564	0.9347133780740629
50	0.18874163780676312	0.9374003190743295	0.18842207075683934	0.93710191310591
51	0.18351386581358917	0.9409888357256778	0.1878828969161222	0.9347133780740629
52	0.1848256076779662	0.9397926635719372	0.18419873666991093	0.9402866264817061
53	0.18170729284865433	0.9435805422647527	0.1825866047174308	0.9386942697938081
54	0.17787296906042327	0.9391945774475353	0.18338367551754994	0.9378980895516219
55	0.1727180551541479	0.9427830940988836	0.18607957376416323	0.9307324825578435
56	0.1683867410942318	0.9469696970647602	0.1794387385913521	0.9394904481377572
57	0.16545456202264036	0.946969696969697	0.18057851066255265	0.9371019093094358
58	0.16062263848536323	0.9499601276867697	0.181180330123871	0.9339171978318768
59	0.16085198434868878	0.9493620414673046	0.17513223476470655	0.9426751596153162
60	0.1651016971663805	0.9489633172893068	0.17586088199524363	0.9402866245834691
61	0.1599901698090053	0.9473684209575683	0.17347843138275632	0.9378980895516219
62	0.15464212772758765	0.9477671451355661	0.17235891739274287	0.9410828048256552
63	0.15294664903310687	0.9495614034137086	0.17348767902441087	0.9410828040663604
64	0.15477230568584263	0.9527511960771856	0.17116608257126656	0.9418789824103094
65	0.1552196157891214	0.9505582138111717	0.17357236393697703	0.9363057340026661
66	0.14749947477256853	0.9529505582137161	0.17551667959826767	0.9323248422829209
67	0.14412459184488421	0.9567384370966582	0.1687598863414898	0.9410828010291811
68	0.14144394673894276	0.9557416266991952	0.1694425472598167	0.9426751607542585
69	0.14304941230746168	0.9577352471138681	0.17268150541812752	0.9355095556587171
70	0.14175350562427222	0.9561403509722562	0.17185174023649494	0.9355095556587171
71	0.13541778060570478	0.9571371611795927	0.16854563830005134	0.9426751607542585
72	0.13727190294429256	0.9567384369065317	0.16713006168034425	0.9410828029274181
73	0.13156008504129102	0.9605263156944105	0.17132752165672885	0.9402866257224113
74	0.1314685880496171	0.9593301436357331	0.17617123863499634	0.9275477722192266
75	0.13055652163720777	0.9605263156944105	0.17054383513654114	0.9378980906905642
76	0.12649572746415266	0.9619218499846816	0.1648060941392449	0.9426751607542585
77	0.1259543063442863	0.9615231259017469	0.166203088536384	0.9442675174421565
78	0.12900935840663727	0.9629186603821446	0.16709482916601145	0.9410828040663604
79	0.1255348831462708	0.9619218499846816	0.16951675266976568	0.9371019123466151
80	0.12658286960929205	0.9607256777358778	0.1691250972876883	0.9394904473784623
81	0.12621683223348296	0.965311004784689	0.16763749386474586	0.9394904473784623
82	0.12120948748535326	0.9643141944822893	0.16337309777736664	0.9426751596153162
83	0.12128191757382768	0.9657097288676236	0.16403058788199334	0.9426751607542585
84	0.11655217810776054	0.9665071769384296	0.17107456400515927	0.9355095556587171
85	0.10775431468964003	0.9667065390749602	0.16501106264864562	0.9434713360610282
86	0.11490635621395598	0.9679027113237639	0.1763213738134712	0.9307324855950228
87	0.11565628361277745	0.9688995215311005	0.16548039569596576	0.9394904473784623
88	0.11343463348667397	0.9702950558213717	0.16783442258075543	0.9378980906905642
89	0.10503034343262703	0.9688995215311005	0.1718025515983059	0.9378980906905642
90	0.11141697009594627	0.9688995215311005	0.16275860426152589	0.9434713390982075
91	0.10638670374355629	0.9685007974481659	0.16343620011381282	0.9426751577170791
92	0.10428292134351898	0.9704944177677757	0.17907751679040823	0.93312102062687
93	0.11027009596237156	0.9688995216261637	0.16190132318408626	0.94187897937313
94	0.10715607906642713	0.9712918659336449	0.16247102912444217	0.9426751615135534
95	0.10226143445029404	0.9716905900165795	0.16930924963419605	0.9394904473784623
96	0.10717346893543261	0.9690988834775045	0.164991445886861	0.9418789824103094
97	0.09566770201664793	0.9732854863483179	0.17632047708626766	0.9339171989708189
98	0.09710084370068577	0.9730861244019139	0.1719087183855142	0.9363057340026661
99	0.10264948740649071	0.9687001594896332	0.1652965514333385	0.9442675174421565

The optimal condition:
	epoch: 99
	train_acc: 0.9687001594896332
	val_acc: 0.944267517442
	using time: 279.409078121
