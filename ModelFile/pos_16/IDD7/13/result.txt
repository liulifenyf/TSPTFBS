The number of train datas: 3846
The number of test datas: 962
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7105747592430591	0.49765990639625585	0.6963242384103628	0.4989605004475171
1	0.7037167772302018	0.5062402496099844	0.6941279151831248	0.5020790033181839
2	0.7017517680930893	0.5072802912193973	0.6924876699576507	0.513513512522168
3	0.6924133461958657	0.5267810712738453	0.6911213508266917	0.5405405396731133
4	0.6919880799185901	0.5275611024131021	0.6898979021704866	0.5436590435351255
5	0.6906950083240146	0.5351014040639112	0.6883168012337476	0.5519750528424793
6	0.6853743025987519	0.5452418097033825	0.6861204091080013	0.5966735958061694
7	0.6878409509353817	0.5374414976599063	0.6840519564315336	0.5831600843992649
8	0.6807444508783654	0.5686427457408241	0.6817994659259264	0.6018711028004883
9	0.683925831001746	0.5444617784866367	0.6792472757073797	0.6164241144414255
10	0.6794633787557351	0.5626625064692643	0.6764481009415926	0.6133056134295315
11	0.6753395713373701	0.5720228808842409	0.6735155957900065	0.626819124836436
12	0.6748578700930019	0.5767030681304738	0.6702325144577423	0.6237006240723783
13	0.6765685158041201	0.562922516908425	0.668255078321683	0.6299376282027754
14	0.6719493662945256	0.5839833593498712	0.6665996370097456	0.6330561334278876
15	0.6670662759184776	0.6006240249300028	0.6636993007699566	0.6320166336275683
16	0.6605884296101825	0.6034841393810725	0.6581688575338177	0.6632016613428905
17	0.6615140666517813	0.6068642745399871	0.6558541739804828	0.6673596657487311
18	0.653894326709176	0.6216848673637001	0.6503695897649578	0.6787941790420151
19	0.651063883825323	0.6216848673637001	0.6456231626056584	0.6787941773071606
20	0.6437089855758956	0.6372854914351546	0.6389578810104957	0.6819126824083547
21	0.6403939923890482	0.6500260010555394	0.6339403519759307	0.7099792093596191
22	0.6302058965479156	0.6612064482579303	0.6269758186320505	0.7037422033704492
23	0.6255705680192539	0.6638065522310949	0.6181671297228014	0.7203742208698931
24	0.6171330077785784	0.6755070202808112	0.6113299873663334	0.7120582136691485
25	0.6081404239326731	0.6840873634635442	0.6024980229052586	0.7401247417356764
26	0.6000052564663622	0.6877275090693684	0.5913907116019552	0.7484407479450758
27	0.5881662956452035	0.7069682787621449	0.5813456551944391	0.7546777541820819
28	0.5814479836807608	0.7093083723038978	0.5785985302156818	0.739085238961321
29	0.5698157742627263	0.7132085283721293	0.558710902247756	0.7775467761836775
30	0.5577439152196367	0.733489339573583	0.5465063810844183	0.7910602896971911
31	0.53728156401599	0.7574102964273544	0.5348830659895082	0.7806652804174443
32	0.5347271365110167	0.7527301091733726	0.520929886372818	0.8024948021230479
33	0.5116403929838834	0.7641705667916773	0.5060180086108107	0.802494804229657
34	0.49673584563869766	0.7784711388455539	0.49035014165662183	0.813929314672823
35	0.4895189038273945	0.7787311492459699	0.47846096908971825	0.8253638241246436
36	0.46814663056526346	0.7938117524700988	0.46065393660271736	0.8243243250678334
37	0.45398510593457947	0.8166926677067082	0.44957680544833384	0.8357588376176085
38	0.4350774925293181	0.8216328652836169	0.43236785439344555	0.8440748428356623
39	0.42201837416868065	0.8218928757150286	0.4202691260221842	0.8430353447701976
40	0.4048980595045144	0.8382735309412377	0.4024651777347755	0.8534303521911716
41	0.385356093237193	0.8486739469268827	0.39459601695225294	0.8523908532582797
42	0.36882836568870087	0.8603744149456034	0.37832524182890653	0.8638253656841365
43	0.3558862926714506	0.8629745189497636	0.3673300042965308	0.8638253656841365
44	0.339474944757163	0.8671346853874154	0.3591823815803766	0.8596673594195233
45	0.3368224149034225	0.8777951117734766	0.3459098557796399	0.8783783792458056
46	0.31465699124230856	0.8866354653876211	0.334048244226995	0.8846153864741573
47	0.30076546186713954	0.8910556421946934	0.3240861565556199	0.8898128906803171
48	0.29148778399172637	0.9006760270410816	0.3257206547037232	0.886694387561814
49	0.28697076677749134	0.8985959438377535	0.30740526315452155	0.8981288989963254
50	0.2746467531285308	0.9035361414146622	0.3054245101934659	0.8814968833556542
51	0.26647507378398533	0.9048361934477379	0.2965908759349101	0.9002079010753274
52	0.25302872215932815	0.9149765990639626	0.2874671505171643	0.9043659052333316
53	0.2466291218639598	0.9147165886635465	0.2945009986724774	0.8960498969173233
54	0.24302323170304607	0.9183567342383752	0.28001910760967746	0.9054054062728326
55	0.23047115990443584	0.9274570982839313	0.27155568563764654	0.9074844083518347
56	0.22973628254588915	0.9266770670516876	0.2667808723858637	0.9064449073123337
57	0.21268032455174674	0.9282371294851794	0.26205667933902227	0.9095634104308368
58	0.21627342273605657	0.9318772750910036	0.26233480021884187	0.9106029114703379
59	0.21152890510411543	0.9362974518980759	0.25605818678832104	0.9085239093913358
60	0.20719484519165007	0.9303172126885075	0.2525661888526532	0.9106029114703379
61	0.20447454150152033	0.9316172646905876	0.25169846635474485	0.9116424125098389
62	0.19433757657348893	0.9339573582943318	0.24890512283775265	0.9137214145888409
63	0.19315833615810377	0.9394175767030681	0.2449623712816754	0.9106029114703379
64	0.1863916103906825	0.9401976079043162	0.24347524911846788	0.9137214145888409
65	0.18945783639575625	0.9417576703068122	0.24103780127984323	0.9126819135493399
66	0.18150018889009487	0.9440977639105564	0.2401295167059016	0.9168399167159986
67	0.17741126342213098	0.9386375455018201	0.2368979574860753	0.9168399167159986
68	0.17892751205001595	0.9433177327093084	0.2396225859246482	0.9178794167641543
69	0.17541048127927325	0.9490379615184608	0.23678989042363394	0.9189189178036553
70	0.16703615735516966	0.9479979199167967	0.23968979479307445	0.9168399157246532
71	0.17065261758367994	0.9495579823192928	0.23103112394373532	0.9209979218653482
72	0.16236143129540184	0.9516380655226209	0.2343905630546647	0.9189189178036553
73	0.16133886559038688	0.9505980239209568	0.22928267577953498	0.9199584188431563
74	0.15888837222988197	0.952678107124285	0.2269073743954022	0.9178794187468451
75	0.15785584194286378	0.9513780551222049	0.2268132095587229	0.9230769219616595
76	0.15752703110671454	0.9524180967238689	0.2260492799063978	0.9209979228566937
77	0.1573250688577591	0.9500780031201248	0.22229607257674489	0.9272349261196636
78	0.14722552667727895	0.9542381694957854	0.22953878186658613	0.9199584219411109
79	0.15669089184664248	0.9544981799271971	0.218590423402816	0.9261954250801626
80	0.14407417316568963	0.9581383255330214	0.22065411582434252	0.9241164230011605
81	0.14136977776598322	0.9563182527301092	0.2176582563567806	0.9261954250801626
82	0.1414106662825401	0.9586583463338534	0.21632907014502806	0.9261954250801626
83	0.1396009635375895	0.9599583983359334	0.21877235649715093	0.9261954281781171
84	0.13840484557633623	0.9568382735309412	0.22308575131169475	0.924116426099115
85	0.1376233477992002	0.9586583463338534	0.2141159503660678	0.9282744271591646
86	0.13482710659829392	0.9576183047321893	0.21385978784977522	0.9293139281986657
87	0.13495990231989635	0.9591783671346854	0.21411362764369427	0.9293139312966202
88	0.12731274092415937	0.9620384815392615	0.21357842266807436	0.9272349292176181
89	0.13416997838263642	0.9617784711388455	0.21303903238689081	0.925155927138616
90	0.13013406373750278	0.9589183567342694	0.21578693755451211	0.9282744302571192
91	0.12178020487678466	0.9638585543111781	0.2187735734511314	0.9324324344151234
92	0.11959684147725673	0.9615184607384295	0.22009368003839763	0.9272349292176181
93	0.11784436167336447	0.9656786271450858	0.21200954498967114	0.9293139312966202
94	0.11666780270953787	0.9646385855434217	0.21302438883610425	0.9324324344151234
95	0.12136358810463767	0.9635985439417577	0.2143697317635443	0.9303534323361212
96	0.11640472311136185	0.9669786791471658	0.21171594113731088	0.9313929333756222
97	0.12451620079413274	0.9620384815392615	0.20913181644467455	0.9293139312966202
98	0.1199024208587436	0.9612584503380135	0.20953774887472082	0.9303534323361212
99	0.11947898272118854	0.9643785751430057	0.2097933352799029	0.9293139312966202

The optimal condition:
	epoch: 94
	train_acc: 0.9646385855434217
	val_acc: 0.932432434415
	using time: 288.568626165
