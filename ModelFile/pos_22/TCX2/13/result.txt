The number of train datas: 4240
The number of test datas: 1060
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7191518808310886	0.5096698113207547	0.6890641336171133	0.5339622643758666
1	0.6921518505744214	0.5384433962264151	0.6754194302378961	0.6179245278520404
2	0.6861367275130074	0.5490566037735849	0.6653287388243765	0.6584905669374286
3	0.6724456607170824	0.5900943396226415	0.6547535720861183	0.6933962261901712
4	0.6670959666090192	0.6030660377358491	0.6435794762845309	0.7245283012120229
5	0.6517982437925519	0.6205188679245283	0.6273099971267412	0.7547169809071523
6	0.6379384904537561	0.6476415094339623	0.6097632891726944	0.7650943405223343
7	0.6248340746141829	0.6724056603773585	0.5849847058080277	0.8094339629389206
8	0.6038585188253871	0.6952830188679245	0.5564929091705466	0.8339622632512507
9	0.5751546005033097	0.7323113207547169	0.5244589074602667	0.851886792227907
10	0.5462082610940033	0.7490566037735849	0.48373363760282406	0.8745283012120229
11	0.5140167978574645	0.7775943396226415	0.4450716216609163	0.8896226412845107
12	0.4880626365823566	0.7943396226415095	0.410807407239698	0.8924528304136025
13	0.4511545174526718	0.825	0.3718994507249796	0.9094339624890742
14	0.42063171728601995	0.8297169811320755	0.3406159740573955	0.9169811327502413
15	0.39738875560040743	0.845754716981132	0.30035848145215016	0.9254716983381307
16	0.3665405347662152	0.8603773584905661	0.2772767570783507	0.9273584903411145
17	0.3487381065791508	0.8768867924528302	0.254936668782864	0.9292452832437911
18	0.3306754692545477	0.8820754716981132	0.24003546710284251	0.9358490568286968
19	0.32426092613418145	0.878066037735849	0.2289002958333717	0.938679245507942
20	0.31314408441759506	0.8886792452830189	0.21813015724128149	0.9405660379607722
21	0.29693600400438847	0.8957547169811321	0.2115722156920523	0.938679245507942
22	0.2868511202200404	0.9037735849056604	0.20253797240977017	0.9462264157691092
23	0.2769800159166444	0.9037735849056604	0.196437221540595	0.9452830195426941
24	0.27330750047035934	0.9068396226415094	0.19074211885344308	0.9471698119955243
25	0.263915915646643	0.9122641509433962	0.19444524735774635	0.9377358483818342
26	0.2596261128502072	0.9153301886792453	0.1845221518345599	0.9481132082219393
27	0.2562981019604881	0.9172169811320755	0.17884126148133908	0.9509433969011847
28	0.24812691481608265	0.9186320754716981	0.17781909096915766	0.9500000006747695
29	0.2493297707359746	0.9183962264150943	0.1752291349869854	0.9518867931275997
30	0.24728015454591445	0.917688679245283	0.1758399152530814	0.9500000006747695
31	0.2352026253938675	0.9238207547169811	0.17042824378553426	0.9528301893540149
32	0.2430334707476058	0.9191037735849057	0.1696663829515565	0.9537735855804299
33	0.23113565772490682	0.9259433962264151	0.16676844695828996	0.954716981806845
34	0.23092671092951073	0.9264150943396227	0.16829875403980038	0.9518867931275997
35	0.22661444376099785	0.9294811320754717	0.1654290367972176	0.954716981806845
36	0.22631655819011184	0.9257075471698113	0.16539966835165923	0.9537735855804299
37	0.218752155298332	0.9299528301886792	0.16067640995079616	0.9556603780332601
38	0.22185927500139993	0.9283018867924528	0.16056289582882288	0.9528301893540149
39	0.21454783914224157	0.9306603773584906	0.15954510344649261	0.954716981806845
40	0.21023936777744653	0.9306603773584906	0.1582443835600367	0.954716981806845
41	0.2127585564019545	0.9292452830188679	0.15926799684200646	0.9566037742596752
42	0.20606602534370602	0.9334905660377358	0.159623129412813	0.9547169813569987
43	0.2051151988641271	0.930188679245283	0.1562409260362949	0.9584905667125054
44	0.1983837796761742	0.934433962264151	0.15749805884541207	0.9566037742596752
45	0.19899698102249289	0.9318396226415094	0.15581343263949987	0.9556603775834137
46	0.20114553340201108	0.9351415094339622	0.15678097392028234	0.9547169813569987
47	0.1989530881901957	0.9351415094339622	0.15391127354693862	0.9575471704860903
48	0.1919672560017064	0.9379716981132076	0.15465971208968252	0.9566037742596752
49	0.19232939588573744	0.9360849056603774	0.1521340069905767	0.9584905667125054
50	0.19317656460235705	0.9389150943396226	0.15113682960564234	0.9584905667125054
51	0.19099968525598635	0.9415094339622642	0.15104433275618642	0.9566037742596752
52	0.1816048039580291	0.940566037735849	0.15172998590289422	0.9566037742596752
53	0.17724212852289092	0.9433962264150944	0.15402792163614956	0.9556603775834137
54	0.17605649440918328	0.9415094339622642	0.14850004079206935	0.9575471704860903
55	0.17806337726003718	0.9422169811320755	0.14911162864487126	0.9556603780332601
56	0.17949742652335257	0.9424528301886792	0.15049376262808745	0.9547169813569987
57	0.17839999749975385	0.9433962264150944	0.14916119856654472	0.9556603775834137
58	0.17168023563780874	0.9443396226415094	0.1533352480744416	0.958490566262659
59	0.17207605774110218	0.9450471698113208	0.14720672638911123	0.9556603775834137
60	0.1693328582453278	0.9459905660377359	0.14645239812023234	0.9575471704860903
61	0.16582614849760846	0.9445754716981132	0.14545735390681142	0.9566037742596752
62	0.1645714224509473	0.9464622641509434	0.14521131571733725	0.9556603780332601
63	0.16393385715079759	0.9481132075471698	0.1446695866449824	0.9603773591653356
64	0.15777189664120944	0.9476415094339623	0.14360741444353786	0.9575471704860903
65	0.1611377254971918	0.9483490566037736	0.144888511018933	0.9547169813569987
66	0.15548404084061676	0.9507075471698113	0.1427963895617791	0.9556603780332601
67	0.15711883891303585	0.9452830188679245	0.14415577931224174	0.9566037742596752
68	0.1539633299101074	0.9476415094339623	0.14338928685998018	0.9566037742596752
69	0.15035745563372127	0.9511792452830189	0.14628710971688325	0.9556603775834137
70	0.1507101128545572	0.9540094339622641	0.1421798736419318	0.9575471704860903
71	0.1455540803243529	0.9533018867924529	0.1419865052655058	0.9584905667125054
72	0.14743206427907043	0.9521226415094339	0.146333994055694	0.9547169813569987
73	0.1445873831802944	0.9509433962264151	0.14140188738984882	0.9575471704860903
74	0.14572787883709062	0.9544811320754717	0.14153121957239115	0.9566037738098289
75	0.14396048306294207	0.9530660377358491	0.1407000521443925	0.9575471704860903
76	0.14181139272338938	0.9509433962264151	0.1439069853638703	0.9556603775834137
77	0.1376494940862341	0.9542452830188679	0.14196889265528265	0.958490566262659
78	0.1346283328139557	0.9577830188679245	0.13920801000775032	0.9566037742596752
79	0.12852201863842191	0.9599056603773585	0.14001303303916499	0.9584905667125054
80	0.13319544603802122	0.9551886792452831	0.14151091035806906	0.9575471700362439
81	0.13322425726449716	0.9561320754716981	0.14050205327429863	0.9584905651380431
82	0.12861504892133316	0.9584905660377359	0.14049459909493067	0.9584905667125054
83	0.13084561821987045	0.9584905660377359	0.140364204937557	0.9575471704860903
84	0.1307856466410295	0.9577830188679245	0.14030043314088067	0.9566037726852129
85	0.12361226280061703	0.9582547169811321	0.14132982571170016	0.9566037738098289
86	0.12429837124808779	0.9596698113207547	0.14137662986539445	0.9575471704860903
87	0.12742335425232942	0.9596698113207547	0.1402304878774679	0.9556603764587979
88	0.11749364177011094	0.9601415094339623	0.1400969185919132	0.9566037742596752
89	0.11707846308654209	0.9596698113207547	0.13922984543836342	0.9566037726852129
90	0.11794977834764517	0.9613207547169811	0.14425110828201726	0.9566037738098289
91	0.11760798719412875	0.9608490566037736	0.1452084113966744	0.9594339624890741
92	0.1166232566437069	0.9622641509433962	0.14040221324506796	0.9566037742596752
93	0.11096318864597464	0.9639150943396226	0.13937377524825761	0.9566037726852129
94	0.10956772599580153	0.9648584905660378	0.1409283792072872	0.9584905651380431
95	0.10677619711408075	0.9641509433962264	0.14005809100169056	0.9584905667125054
96	0.10829735516377215	0.9660377358490566	0.1432262790652941	0.9603773591653356
97	0.11069383165746365	0.9632075471698113	0.14080054996148594	0.9566037742596752
98	0.11155616341264181	0.9648584905660378	0.14042440720324245	0.9566037726852129
99	0.10636115057288476	0.9658018867924528	0.14018836268838847	0.9566037742596752

The optimal condition:
	epoch: 96
	train_acc: 0.9660377358490566
	val_acc: 0.960377359165
	using time: 309.880691051
