The number of train datas: 4240
The number of test datas: 1060
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7172039004991639	0.5165094339622641	0.6867916131919285	0.5424528292889865
1	0.6894352103179355	0.5476415094339623	0.6719615877799268	0.601886792227907
2	0.6774833755673103	0.5686320754716981	0.6597108726231558	0.6528301884543221
3	0.666536079937557	0.592688679245283	0.6481316395525663	0.6773584896663449
4	0.6572983703523312	0.6160377358490566	0.6345273683655936	0.7339622643758665
5	0.6410700577609943	0.6417452830188679	0.6167028265179328	0.7632075478445809
6	0.6270774355474508	0.667688679245283	0.5997471251577701	0.7537735851305836
7	0.6127982987547821	0.6804245283018868	0.5718640921250829	0.8103773589404124
8	0.5884552514777993	0.7070754716981132	0.5424278198548083	0.835849055929004
9	0.5601106147721129	0.7476415094339622	0.5093520953970135	0.8556603771335674
10	0.5383849544345208	0.7507075471698114	0.4721797239105656	0.8896226412845107
11	0.5087398673003575	0.7752358490566038	0.43530676094990856	0.9009433964513383
12	0.47839291084487484	0.8047169811320755	0.4021347860120377	0.9018867931275998
13	0.4502808818277323	0.8209905660377359	0.37223511900541917	0.9009433969011846
14	0.417071761950007	0.8360849056603774	0.34628658958201136	0.9000000006747696
15	0.3976551930859404	0.847877358490566	0.302468896024632	0.9301886799200526
16	0.3650705974057036	0.8636792452830189	0.28045489349455205	0.9330188685992978
17	0.34773228843257115	0.8764150943396226	0.2607568378718394	0.9349056606022816
18	0.32808006529538136	0.8867924528301887	0.24637178609955987	0.9339622643758666
19	0.3266737897441072	0.8825471698113208	0.2346101057979296	0.9424528308634488
20	0.31321447244230305	0.8915094339622641	0.22444362764088613	0.944339623316279
21	0.2959904020687319	0.897877358490566	0.21779202785132065	0.9443396228664326
22	0.2902571831109389	0.9035377358490566	0.20758039355278016	0.9462264157691092
23	0.2797253003660238	0.9056603773584906	0.201297043179566	0.9471698119955243
24	0.270328680861671	0.9101415094339622	0.1949513447734545	0.9500000006747695
25	0.26193835532890175	0.9141509433962264	0.19878335505161646	0.9415094341871874
26	0.263349859500831	0.9115566037735849	0.1895374615237398	0.9518867931275997
27	0.2637868672047021	0.9125	0.18355638311718994	0.954716981806845
28	0.24988258514764175	0.9214622641509433	0.1813443827179243	0.9537735855804299
29	0.25035318451107674	0.9219339622641509	0.1780019978307328	0.954716981806845
30	0.2480010343047808	0.9183962264150943	0.17873065623472323	0.9518867931275997
31	0.23749838319589506	0.9259433962264151	0.1735663500034584	0.954716981806845
32	0.24604251030481086	0.9228773584905661	0.17430231812989938	0.9547169813569987
33	0.2348730427476595	0.9271226415094339	0.16982193735410583	0.9575471704860903
34	0.22964367472900535	0.9242924528301887	0.170849746184529	0.9518867931275997
35	0.23088148809828848	0.9280660377358491	0.1668882574675218	0.9584905667125054
36	0.2288106050131456	0.9287735849056604	0.16840664002130618	0.954716981806845
37	0.22796579186084134	0.9266509433962264	0.16186340676163727	0.9566037742596752
38	0.227077893828446	0.9273584905660377	0.16374964331680875	0.9556603780332601
39	0.2171385276992366	0.9297169811320755	0.16091851204071406	0.9575471704860903
40	0.21737499833106994	0.9304245283018868	0.1596714050140021	0.9575471704860903
41	0.2130150540819708	0.9351415094339622	0.1602952004041312	0.9575471704860903
42	0.20882283016195838	0.933254716981132	0.15813048650633613	0.9566037742596752
43	0.2074374017569254	0.935377358490566	0.15578065104079697	0.9566037742596752
44	0.20167394248803833	0.9351415094339622	0.158302733133424	0.9566037726852129
45	0.20335357740240276	0.933254716981132	0.15536124003383348	0.9584905667125054
46	0.20581337236008554	0.9356132075471698	0.15437301509785203	0.9575471704860903
47	0.2020434855290179	0.9346698113207547	0.15473805126154197	0.9575471704860903
48	0.1947951485244733	0.9358490566037736	0.15528541516582922	0.9603773587154892
49	0.19563534923319548	0.9370283018867924	0.15223362305254307	0.9556603764587979
50	0.19792516062844476	0.9384433962264151	0.15062138359501676	0.954716981806845
51	0.19524530194840342	0.9400943396226416	0.15117150590104877	0.9594339629389205
52	0.18625856514246958	0.9386792452830188	0.1498765024374116	0.9584905667125054
53	0.18308749182044334	0.940566037735849	0.15470087415767167	0.9603773587154892
54	0.1838384560256634	0.9389150943396226	0.14920517296161293	0.9584905667125054
55	0.1787729356086479	0.942688679245283	0.15072782736904217	0.9603773591653356
56	0.1846429764099841	0.9429245283018868	0.15076108619851886	0.958490566262659
57	0.1810680242079609	0.9408018867924528	0.14955425774151423	0.9594339624890741
58	0.17235208850986553	0.9445754716981132	0.15529446624359994	0.9575471700362439
59	0.1773798665910397	0.9422169811320755	0.14721307254062507	0.9556603764587979
60	0.1702553557899763	0.9488207547169811	0.14619857871307518	0.9603773575908733
61	0.17258362573272776	0.9433962264150944	0.14527594435889765	0.957547168911628
62	0.1697584327661766	0.9443396226415094	0.14525735254557628	0.9556603764587979
63	0.16853492214994611	0.9457547169811321	0.14464816754718995	0.957547168911628
64	0.16486421817878508	0.9450471698113208	0.14387454418641216	0.9566037726852129
65	0.16816999878523484	0.9466981132075472	0.1452528303524233	0.9584905651380431
66	0.16356488359424304	0.9495283018867925	0.14350239403967588	0.9603773575908733
67	0.1629617466398005	0.9459905660377359	0.14577010206456453	0.9603773575908733
68	0.15920937606748545	0.9471698113207547	0.14459476898301324	0.9594339613644582
69	0.16023564271207125	0.9471698113207547	0.1481117219295142	0.958490566262659
70	0.1567439246008981	0.9516509433962265	0.14130098516086362	0.9556603764587979
71	0.1511888951063156	0.9516509433962265	0.1411313551776814	0.9547169802323827
72	0.15499060674096055	0.9476415094339623	0.14771322304347775	0.9603773591653356
73	0.15452036846358821	0.9495283018867925	0.14102524580820552	0.9566037726852129
74	0.1547825241145098	0.9495283018867925	0.14341381720776827	0.9584905651380431
75	0.14414199911198525	0.9533018867924529	0.14025182448468118	0.957547168911628
76	0.15051470725041516	0.9502358490566037	0.14295195116187043	0.9594339613644582
77	0.14878495405867415	0.9507075471698113	0.14217183977927803	0.9594339613644582
78	0.144334347995947	0.9542452830188679	0.14013664233234693	0.9584905651380431
79	0.139477454041535	0.9516509433962265	0.13870928759844797	0.9566037726852129
80	0.1387822615650465	0.9528301886792453	0.1430197220928264	0.9594339613644582
81	0.13603311500178192	0.9554245283018868	0.13889670731886378	0.9594339613644582
82	0.13758370139688816	0.9537735849056603	0.13972303580563022	0.9584905651380431
83	0.1362668236471572	0.9566037735849057	0.14086907669058385	0.9584905651380431
84	0.13625827038063193	0.9566037735849057	0.1396188887785066	0.9594339613644582
85	0.13597775818604343	0.9561320754716981	0.14079862996092382	0.9594339613644582
86	0.13007911232844838	0.9561320754716981	0.14275895655155182	0.9594339613644582
87	0.1350282034783993	0.9570754716981132	0.14054773118136063	0.957547168911628
88	0.13271333884518102	0.9551886792452831	0.14196629349915488	0.9584905651380431
89	0.12954894661341074	0.9584905660377359	0.13961838073325608	0.9594339613644582
90	0.12908118822664585	0.9580188679245283	0.1427614722611769	0.957547168911628
91	0.1274503414642136	0.9563679245283019	0.15126704359954257	0.9566037726852129
92	0.12458466472771933	0.9589622641509434	0.14158508502087502	0.9547169802323827
93	0.12209387697138877	0.9594339622641509	0.13878994235452616	0.9603773575908733
94	0.12225370761358513	0.9617924528301887	0.13938556037983804	0.957547168911628
95	0.11942092218207863	0.9594339622641509	0.14079155382120384	0.9566037726852129
96	0.11909561067257288	0.9608490566037736	0.14906349283344342	0.9566037726852129
97	0.11728394616324947	0.9617924528301887	0.13960822179632368	0.9584905651380431
98	0.11976158673049143	0.9599056603773585	0.13923581568699964	0.9584905651380431
99	0.12180487817188479	0.9606132075471698	0.14377814936188033	0.9556603764587979

The optimal condition:
	epoch: 72
	train_acc: 0.9476415094339623
	val_acc: 0.960377359165
	using time: 288.44650197
