The number of train datas: 4240
The number of test datas: 1060
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7171151239916963	0.505188679245283	0.6955544521223824	0.5047169809071523
1	0.6985295480152346	0.5205188679245283	0.6839508022902147	0.5594339623766126
2	0.6895687562114787	0.5403301886792453	0.675029163315611	0.6047169815819219
3	0.6811525158162387	0.5568396226415094	0.666484357500976	0.6509433955516455
4	0.6742023283580564	0.585377358490566	0.6581096493972922	0.6915094339622642
5	0.6640687728827854	0.6077830188679245	0.6467155011195057	0.7358490568286967
6	0.6563937922693649	0.6058962264150943	0.634233736542036	0.7292452823440984
7	0.6415498263431045	0.6509433962264151	0.6171155720386865	0.7792452836936374
8	0.6257192256315699	0.6650943396226415	0.5962438394438546	0.8066037731350593
9	0.6049142855518269	0.6978773584905661	0.5736485485760671	0.8264150950143923
10	0.5864032893810632	0.7247641509433962	0.541726810977144	0.8566037738098289
11	0.5579044719911971	0.7436320754716981	0.5077698176761843	0.8669811318505485
12	0.5265221071693132	0.7669811320754717	0.47486050938660246	0.8745283021117156
13	0.4941914513426007	0.8009433962264151	0.43442962372078087	0.8858490568286967
14	0.4650337043798195	0.8044811320754717	0.3975505881714371	0.8981132073222466
15	0.4339782035575723	0.8325471698113207	0.35445611825529133	0.9122641502686266
16	0.39716578699507804	0.8544811320754717	0.32140727133121133	0.9179245276271172
17	0.3770069135809844	0.8547169811320755	0.2955749346400207	0.9283018861176833
18	0.35392167388268236	0.8662735849056604	0.27836939298881674	0.9198113200799474
19	0.34174435656025726	0.8733490566037736	0.25895557561010685	0.9367924521554191
20	0.3215239684536772	0.8950471698113207	0.24249808945745793	0.9311320747969285
21	0.3041438593054717	0.8952830188679245	0.23202801436748144	0.9339622634761738
22	0.2934113604280184	0.9002358490566038	0.22098325131074437	0.9405660375109258
23	0.2810939309731969	0.9056603773584906	0.21291714276907578	0.9405660370610794
24	0.2755971112341251	0.9089622641509434	0.20732016754600238	0.9433962261901712
25	0.2648542598733362	0.9120283018867924	0.2096468024658707	0.9330188672497587
26	0.2593379530704246	0.9172169811320755	0.19878022344607227	0.9433962261901712
27	0.2509447143887574	0.9181603773584905	0.19323082436930458	0.9462264153192628
28	0.2432902385603707	0.9207547169811321	0.18912492400070408	0.9500000002249231
29	0.25225671046185044	0.9125	0.1908498489631797	0.9433962261901712
30	0.24710690722150622	0.9209905660377359	0.1881597068512215	0.9509433969011847
31	0.23165932258345046	0.9235849056603773	0.18283839152669007	0.9500000006747695
32	0.24167994581303506	0.9188679245283019	0.18329744012850635	0.9443396224165862
33	0.2320053148663269	0.9257075471698113	0.1793223480008683	0.9481132082219393
34	0.22811121662270348	0.9299528301886792	0.17632936419181103	0.9528301893540149
35	0.21962701644537583	0.9306603773584906	0.17455584153814135	0.9528301893540149
36	0.22116146964846917	0.9266509433962264	0.174728133093636	0.9556603764587979
37	0.21813574171853514	0.9287735849056604	0.17204073093972116	0.9471698119955243
38	0.21371737870405305	0.9278301886792453	0.16911110118874964	0.9556603780332601
39	0.20315706043873194	0.9334905660377358	0.16721751622433934	0.9528301893540149
40	0.2090517835797004	0.9316037735849056	0.1675817589714842	0.9490566044483545
41	0.2063538481604378	0.9337264150943396	0.16782556997155243	0.9500000006747695
42	0.197533277267555	0.935377358490566	0.16744923265475148	0.9500000006747695
43	0.19880324320973092	0.9367924528301886	0.162438221809999	0.9537735855804299
44	0.19392399098372684	0.9356132075471698	0.16323343155519018	0.9584905651380431
45	0.19336759391820657	0.9358490566037736	0.16632473727442185	0.9500000006747695
46	0.1915646607583424	0.9398584905660378	0.16541220028445405	0.9500000006747695
47	0.1872270550086813	0.9391509433962264	0.16032862292145783	0.9509433969011847
48	0.1894681045188094	0.9360849056603774	0.16029261384370191	0.9518867931275997
49	0.17825151513207635	0.942688679245283	0.15716603820054037	0.9556603780332601
50	0.18286831047175064	0.9408018867924528	0.1568542994418234	0.9556603780332601
51	0.1836292896630629	0.9431603773584906	0.155752957429526	0.9556603780332601
52	0.1711035581411056	0.9459905660377359	0.15719587780394645	0.954716981806845
53	0.17467386992472522	0.9441037735849057	0.15874477073831378	0.9518867931275997
54	0.16833796709213616	0.944811320754717	0.15348246148172415	0.9566037742596752
55	0.17164969458332602	0.9452830188679245	0.15779189636122506	0.9528301893540149
56	0.16822093989489215	0.9445754716981132	0.1550762877149402	0.954716981806845
57	0.1650710273463771	0.9466981132075472	0.1557578590680968	0.9537735855804299
58	0.16330920300393734	0.9474056603773585	0.15980058885970205	0.9509433969011847
59	0.16330029762016152	0.9462264150943396	0.15229483989049802	0.9556603780332601
60	0.15909788456727875	0.95	0.14939869732226965	0.9603773591653356
61	0.15501538517902483	0.9504716981132075	0.1492191288268791	0.9594339629389205
62	0.15247447884307716	0.9502358490566037	0.14899740202246972	0.9594339629389205
63	0.1555232270146316	0.9497641509433963	0.14835933053268577	0.9622641500437035
64	0.1532093712743723	0.9502358490566037	0.14739638268947602	0.9613207553917507
65	0.14733735379183066	0.9540094339622641	0.14833598541763593	0.9584905667125054
66	0.14761522656904077	0.9528301886792453	0.14883284726232854	0.9584905667125054
67	0.14789641034209502	0.9483490566037736	0.15145473660163158	0.9556603780332601
68	0.1448290486943047	0.9533018867924529	0.1523086888610192	0.954716981806845
69	0.14219723951141788	0.9509433962264151	0.15269142636712993	0.954716981806845
70	0.14249956290114602	0.9551886792452831	0.1473457581592056	0.9594339629389205
71	0.13703790284552664	0.9530660377358491	0.14652912695452852	0.9594339629389205
72	0.13639081243495896	0.9547169811320755	0.15416429301477827	0.9537735855804299
73	0.1366392600648808	0.9575471698113207	0.14475165937306747	0.9613207553917507
74	0.13080343322933846	0.9561320754716981	0.14617336797264388	0.9594339629389205
75	0.13190769384492118	0.9561320754716981	0.14604527264271142	0.9603773591653356
76	0.13111143202151893	0.9587264150943396	0.1493513675230854	0.9575471704860903
77	0.12708775439071204	0.9589622641509434	0.1503882309175887	0.9566037742596752
78	0.12716173344063308	0.9563679245283019	0.1462464620482247	0.9603773591653356
79	0.12173152883660118	0.9587264150943396	0.14522237519048295	0.9622641500437035
80	0.12553803712691902	0.9589622641509434	0.15226157667501916	0.9556603780332601
81	0.12242839195818271	0.9591981132075472	0.14520404237621234	0.9603773591653356
82	0.11531415637933982	0.960377358490566	0.14618831906678542	0.9603773591653356
83	0.12037453679543621	0.9610849056603774	0.14641752411734382	0.9603773591653356
84	0.1186650571114612	0.9620283018867924	0.14572350259097117	0.9603773591653356
85	0.11406281504709766	0.9606132075471698	0.14427003095734794	0.9613207538172884
86	0.11620773703984494	0.9594339622641509	0.15365458558190545	0.9556603780332601
87	0.11682356922131665	0.9606132075471698	0.14420816178591747	0.9603773575908733
88	0.10896351447082915	0.9658018867924528	0.14644024315870033	0.9603773591653356
89	0.11009162844352002	0.9608490566037736	0.14428247421417595	0.9594339613644582
90	0.10692199955009064	0.965566037735849	0.15361912689119014	0.9556603780332601
91	0.10959254812519505	0.9643867924528302	0.1588296340321595	0.9528301893540149
92	0.10409318942506358	0.9665094339622642	0.14947811128958216	0.9584905667125054
93	0.10466572445518565	0.9658018867924528	0.14585594726058673	0.9632075462701186
94	0.10110231086892901	0.9669811320754716	0.14552097556725987	0.9594339613644582
95	0.09650429048628177	0.9660377358490566	0.14742912447677467	0.9603773591653356
96	0.097845540125415	0.967688679245283	0.1510876901869504	0.9566037742596752
97	0.09797649065840919	0.969811320754717	0.1481069355640771	0.9594339629389205
98	0.10173376785274947	0.9660377358490566	0.14583556742038367	0.9584905667125054
99	0.09660169226381014	0.9679245283018868	0.14610834571550477	0.9594339613644582

The optimal condition:
	epoch: 93
	train_acc: 0.9658018867924528
	val_acc: 0.96320754627
	using time: 339.086898088
