The number of train datas: 3618
The number of test datas: 906
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7109537288390054	0.48590381442676794	0.695027038751059	0.5198675499320293
1	0.6987244772146656	0.5207296848758405	0.6920021303968451	0.5353200885633759
2	0.6968930359371728	0.517412935356332	0.6895312126109142	0.5474613689165768
3	0.6967848707062556	0.5157545605471544	0.687449143553938	0.5695364238410596
4	0.6932920282093974	0.5107794360866725	0.6855075730393264	0.5739514348785872
5	0.6840107601739347	0.5433941406067595	0.68308821524479	0.5949227373068433
6	0.680825898501015	0.5536207852276601	0.6802879437705539	0.6114790289607269
7	0.6808606656036567	0.5646766169154229	0.6772125930449294	0.6280353203514554
8	0.6758734733772384	0.5876174684121768	0.6734759148382983	0.6467991172609476
9	0.6738961064202671	0.5812603650401481	0.6686216529631457	0.6534216338172391
10	0.6711794593309157	0.5812603650401481	0.6629524005959365	0.686534216598696
11	0.6588791227261621	0.6202321723721316	0.655315277197503	0.6953642386737512
12	0.6557522697828302	0.6290768382956535	0.646151887659995	0.7141280355832434
13	0.6450502173949368	0.6448313984968439	0.6342062033038529	0.7262693159364444
14	0.6273963993725162	0.6807628523387456	0.6193104900797998	0.7362030907708814
15	0.6160403574415833	0.6885019349682852	0.6016825586228445	0.7483443711240824
16	0.5932403318851676	0.7045328912648	0.5810912355418764	0.7560706404397556
17	0.5675734241671692	0.7330016585065885	0.5556214805733553	0.7582781459585194
18	0.5426362865270338	0.7451630736530782	0.533968782845975	0.7593818987179013
19	0.5193466080889114	0.7625760090094102	0.5101979776197185	0.7671081680335746
20	0.4971846549665157	0.7830292977569774	0.49191009748324127	0.7792494483867755
21	0.47293388431674543	0.7904919846206822	0.47432583149432084	0.7924944814993583
22	0.46046929627310973	0.7965726918644376	0.45957760081912247	0.7913907287399764
23	0.4383053509420687	0.8181315645979148	0.44523439212613813	0.8035320090931772
24	0.4148956540541599	0.8247650633403911	0.4438475513826669	0.7902869758490169
25	0.4038559016171841	0.8253178552674483	0.4230269355489718	0.8123620310366548
26	0.3798797551013278	0.8419016031285819	0.40307407110732124	0.8333333332017557
27	0.3667677130370986	0.8485351021017008	0.38935181491948645	0.8399558497580472
28	0.35676145046175084	0.8584853510556134	0.392057366586942	0.8256070637545049
29	0.33307006399957034	0.8642896628630233	0.36796774493147993	0.8532008831337851
30	0.3179454896877061	0.8822553894874336	0.36539219849420174	0.8377483441077057
31	0.30863508123301087	0.882531785582758	0.34521409329725944	0.8631346575734894
32	0.29512341846050383	0.886401326765732	0.3478854704508455	0.8487858717015248
33	0.2897057930463714	0.8894416803217119	0.33243423831910224	0.867549668611017
34	0.2706510031203528	0.8988391377110057	0.32410237949678705	0.8730684324079265
35	0.25803510119006934	0.9029850746598146	0.3222713259934853	0.8708609268891627
36	0.24916910897835373	0.9065782198133622	0.30927938183411857	0.8830022072423636
37	0.2511556025299992	0.906025428479386	0.3068854908148448	0.8807947017235997
38	0.2341373368825881	0.9159756772026559	0.3030874996258986	0.8874172182798912
39	0.22760144767344756	0.9181868433622842	0.3060031920079364	0.8830022072423636
40	0.22444192016566242	0.9198452181549873	0.29256663114556153	0.8995584986330921
41	0.21565975305650562	0.9239911553673879	0.30915001745255577	0.8830022072423636
42	0.21154322107402312	0.9278606965503619	0.29163786637335687	0.8951434875955645
43	0.21124389163445478	0.9281370920526052	0.2896411334047254	0.8951434875955645
44	0.20435256118468648	0.9278606962867703	0.2922092606426601	0.8962472403549464
45	0.1942280216431868	0.93559977891631	0.29411997503002746	0.8984547458737102
46	0.19500263849960103	0.9328358206319308	0.27743326288711684	0.9017660041518559
47	0.1858492306973672	0.934217799658799	0.286383357269085	0.900662251392474
48	0.18460676912990573	0.9369817578772802	0.28944729028421784	0.9017660041518559
49	0.17803811647240927	0.9355997786527184	0.27625431972360504	0.9072847679487653
50	0.17974234540005163	0.9375345495077969	0.2778652302476744	0.9061810151893834
51	0.17692860010383274	0.9416804861930143	0.27997926199936185	0.9028697569112377
52	0.16774836581276556	0.9419568820247471	0.270729463489903	0.9083885207081472
53	0.1705636432494262	0.9441680486456606	0.2815390255540675	0.9028697569112377
54	0.16078638101296244	0.946102818973556	0.2686434852629571	0.9128035317456749
55	0.1683700283656732	0.9411276948590381	0.2903956303138607	0.9017660041518559
56	0.16040432799119458	0.9463792150688805	0.2728962137735969	0.9094922734675291
57	0.16853550427390965	0.9458264231747722	0.2709553652251793	0.9083885207081472
58	0.15718020027582655	0.944168048415018	0.27324265004783277	0.9061810151893834
59	0.1523711795204578	0.9455500273759883	0.2853455727068794	0.9039735096706196
60	0.15215638232138884	0.9474847979674753	0.2678930787061224	0.910596026226911
61	0.15048395227404046	0.9483139856933164	0.26661687234116443	0.9128035317456749
62	0.1525441853544737	0.9502487559553139	0.2869288462808327	0.9061810151893834
63	0.14714779380673926	0.947208402465232	0.2722275122901462	0.9072847679487653
64	0.1432343668341966	0.9505251520176893	0.2807287847495763	0.9072847679487653
65	0.13920194458374996	0.9538419016360445	0.25989516339291535	0.9216335538207301
66	0.1375777165185621	0.9541182971382879	0.2935333653264751	0.9083885207081472
67	0.14511922973420754	0.9541182971382879	0.28274768814609014	0.9072847679487653
68	0.14110658082219366	0.9535655055407202	0.2855491561868596	0.9083885207081472
69	0.13470130074808384	0.9560530677627239	0.26588797608748177	0.9150110372644387
70	0.137102047285202	0.9541182974018795	0.2862626627317854	0.9094922734675291
71	0.13036607524648827	0.9563294638250993	0.2688972168410851	0.910596026226911
72	0.12830170746861802	0.9574350470202347	0.26960663158635695	0.9094922734675291
73	0.12833865944887143	0.9577114427860697	0.28777122997553406	0.910596026226911
74	0.12974892719764614	0.9577114427860697	0.27085581573166334	0.9094922734675291
75	0.12692612073718348	0.955776671930991	0.2674674540429189	0.9139072845050568
76	0.11576448687269353	0.9596462133775566	0.2686959678763585	0.9161147900238206
77	0.11913944251995973	0.9596462131139651	0.27474907086648165	0.9128035317456749
78	0.11849050449527648	0.9590934215493463	0.2758727465770629	0.910596026226911
79	0.11679710740622003	0.9590934218129379	0.26101273561418714	0.9216335538207301
80	0.11499432478905251	0.9654505251849667	0.26770138766855067	0.9161147900238206
81	0.11319958709794029	0.9621337755666114	0.27917812175834944	0.910596026226911
82	0.11474152974426055	0.9624101711018037	0.28284751079466697	0.9128035317456749
83	0.1102200928373255	0.9626865671641791	0.27525822979461806	0.9150110372644387
84	0.10801725814426848	0.9660033167495854	0.2681156366603001	0.9183222955425844
85	0.10736806438736424	0.9626865671641791	0.26361048142641585	0.922737306580112
86	0.10465065732128782	0.9626865669335365	0.27631333937444963	0.9172185427832025
87	0.10767410268658034	0.9654505251520177	0.26071740157293694	0.9216335538207301
88	0.10125280487942656	0.9632393587946958	0.2858824953601323	0.9139072845050568
89	0.10204391582622391	0.964621337788615	0.26228268230724544	0.9216335538207301
90	0.10511985741609232	0.9632393584981552	0.2874701841514368	0.9150110372644387
91	0.10189384876685026	0.9676616915422885	0.28343658928839577	0.9150110372644387
92	0.0979017879404107	0.9701492537313433	0.26425435198327035	0.9205298010613482
93	0.0975115587281021	0.9690436702726163	0.26175974181156286	0.9249448120988757
94	0.09728655200132419	0.9676616915752375	0.27049824496768166	0.9194260483019663
95	0.09173695161946904	0.9712548366628871	0.27743568457251877	0.9216335538207301
96	0.09711020827425192	0.9665561083471531	0.2865142110430905	0.9172185427832025
97	0.09108637145840377	0.970702045328911	0.2912871895510103	0.9172185427832025
98	0.09034097635775656	0.969596461870184	0.2885295484239692	0.9172185427832025
99	0.09116397426561995	0.970702045328911	0.31224042558775306	0.910596026226911

The optimal condition:
	epoch: 93
	train_acc: 0.9690436702726163
	val_acc: 0.924944812099
	using time: 353.885071039
