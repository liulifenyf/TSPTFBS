The number of train datas: 2990
The number of test datas: 748
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7064897073949858	0.5103678930563272	0.680499488657171	0.5681818216879737
1	0.6855899223914513	0.5421404678287315	0.6711114453759423	0.6189839572192514
2	0.6755644880808317	0.578260869764564	0.6600561387398663	0.6631016004531779
3	0.6659293319469312	0.5966555186737341	0.6487484223702374	0.6844919802033328
4	0.6532407731914202	0.6301003347272458	0.63562587110754	0.7018716580727521
5	0.6341830124424452	0.6618729100578206	0.6176419707543073	0.7393048163403801
6	0.6172753859523148	0.6849498323772265	0.5958100190774642	0.7433155099338389
7	0.5948269081354939	0.7157190633458038	0.5716399722558292	0.7593582910012434
8	0.5690298491497103	0.7337792642539162	0.5445605156255916	0.7647058810779755
9	0.5372607534147027	0.7558528424505406	0.5147106730364224	0.7687165794525554
10	0.508058821078527	0.7642140464639186	0.49271344341696266	0.774064169848029
11	0.48126177028270073	0.7852842808168469	0.46993342408521926	0.7820855618160676
12	0.4630420625608502	0.796989966435576	0.45800340558118363	0.7794117634309167
13	0.44275363879060264	0.8016722410020222	0.4437580980400351	0.7794117650246237
14	0.4321345987527267	0.8130434779817842	0.4313139599912307	0.7860962570032334
15	0.4178186149700828	0.8170568564663763	0.42619189970633564	0.7860962570032334
16	0.4098541092912489	0.8150501670247337	0.42752727101193394	0.7874331573114038
17	0.4016967726790387	0.8227424748765186	0.4243123150445561	0.791443847398707
18	0.38349011034072444	0.8314381267314771	0.41611019302816954	0.7927807457944288
19	0.3742715856502686	0.8484949836762853	0.4233225558530838	0.7967914479939058
20	0.36788675936568144	0.8424749161088746	0.3986043147543535	0.808823528136799
21	0.35655060249028797	0.8478260865179591	0.4025185159183441	0.8021390415767935
22	0.3585890062875971	0.8451505020709341	0.3961064791615634	0.8088235335554032
23	0.3470052230517601	0.847491638357424	0.39259612353090295	0.8088235335554032
24	0.3388419628542004	0.8511705688808275	0.3850043329963072	0.8221925175126223
25	0.3338799175410765	0.8642140472214358	0.3753593124170354	0.8262032126997881
26	0.32043114093235103	0.8692307687922066	0.36168475967040037	0.8302139008746428
27	0.3143300327967641	0.8769230770825542	0.3608862045295736	0.8315508062826759
28	0.3041254230566248	0.8769230764845143	0.356300246109937	0.8368983998655636
29	0.29559570582814043	0.8769230772420316	0.3573610366665743	0.8328876995785351
30	0.29289513062872613	0.8842809367738041	0.34465976465832104	0.8435828867443105
31	0.2819822295453636	0.8806020070876565	0.34804028169037826	0.8409090918653152
32	0.2789858723962586	0.8832775923719374	0.33600275306140676	0.8502673806353687
33	0.2603946617813812	0.8993311039181457	0.3221120816819808	0.860962567801144
34	0.26191220641335516	0.8903010037431749	0.31743279115401485	0.8663101613840317
35	0.2523153266081443	0.9000000003189547	0.32882152179026986	0.858288767822286
36	0.24088131795360093	0.9033444812465272	0.3120264512969848	0.871657756879368
37	0.22833743585790678	0.9107023406985612	0.3077801887523682	0.8743315485709491
38	0.22416540095239978	0.9180602007486349	0.2957180116106482	0.8783422488579775
39	0.22996243856423676	0.9110367895368748	0.28170149522350435	0.8850267408365872
40	0.21345992942518216	0.9187290971494438	0.2808342517856608	0.8850267408365872
41	0.20610431683900762	0.9244147158785408	0.29859869054613264	0.878342249176719
42	0.20587806264094285	0.9250836124388271	0.29693379814930776	0.8810160459681629
43	0.19362404996336105	0.926755852922548	0.3038204855380211	0.878342249176719
44	0.18755043274582828	0.9334448163724663	0.26578990087152166	0.893048124517349
45	0.17896403066290661	0.9377926421404682	0.2691560142180499	0.8903743312320608
46	0.173576692205209	0.9377926422202069	0.25089862703639554	0.9024064132874025
47	0.17783852869451644	0.9351170571751419	0.25400917327659017	0.8983957216063923
48	0.1685166352768008	0.9361204016567473	0.2426745591954114	0.9037433116831244
49	0.16737838143289688	0.9431438127887688	0.24974380875813132	0.902406416793558
50	0.15544459578085904	0.9448160535117057	0.24996124403202596	0.9037433186954356
51	0.1497776001442635	0.9478260870362604	0.25361408448633666	0.8997326235082698
52	0.1556090571908249	0.9491638799176169	0.2437125142006313	0.9050802170911575
53	0.15052152773408986	0.9498327760792098	0.2638092775714589	0.895721928321104
54	0.1455442368186836	0.948829431438127	0.2564201484867596	0.8997326235082698
55	0.14390525836809023	0.9494983279186746	0.23752393338450772	0.9077540138826014
56	0.14165016582179626	0.9501672243194835	0.23051437767431698	0.9104278106740452
57	0.14088214145954636	0.946822742554655	0.23600145281954882	0.9077540138826014
58	0.13524294584291835	0.9508361204810765	0.23443844368591665	0.9104278106740452
59	0.13382182132240922	0.9558528430485805	0.24045403122423806	0.9064171154868794
60	0.1332797364048336	0.9518394649626818	0.24020662923707045	0.9064171154868794
61	0.12984795016189882	0.9508361204810765	0.22723796485579587	0.9171123026526548
62	0.12193721807920016	0.9581939800128491	0.22085461630062622	0.9184491975422211
63	0.1207326101494274	0.9605351171365949	0.2381998165485693	0.9117647090697671
64	0.11442342461849933	0.9588628764136579	0.22835458508309195	0.9157754042569328
65	0.11400925703969687	0.9608695652173913	0.2409404701090114	0.9064171103870168
66	0.1131729918479122	0.960200669135537	0.2382719664968909	0.9104278106740452
67	0.1153463591101975	0.960200669135537	0.22228433387005392	0.9184492010483767
68	0.11366830390930974	0.9595317726549895	0.22635657818400287	0.9131016074654891
69	0.09862318912078705	0.9655518397040989	0.2362593080111366	0.9104278106740452
70	0.09763449836136107	0.9662207359454305	0.21592449751448503	0.9224598927293869
71	0.1071986816100851	0.9622073579392705	0.23477092620363849	0.914438505861211
72	0.10326343332245996	0.962207358019009	0.2369835195056895	0.9157754042569328
73	0.09766840943724017	0.9635451506611495	0.2073237793968323	0.9304812831037185
74	0.10116956264877	0.9645484950630162	0.22781075537204742	0.914438505861211
75	0.09674510559110737	0.9698996656315781	0.2202171569759833	0.9184492010483767
76	0.09487557779985129	0.9665551841059656	0.22721846800118206	0.9131016074654891
77	0.10120160072344203	0.9612040135374037	0.24583897379072592	0.9131016023656263
78	0.09527314720943221	0.9662207358656918	0.21960060896082995	0.9157754042569328
79	0.09167318150749972	0.9709030101131835	0.22257227689665268	0.914438505861211
80	0.09142083523664188	0.966889632425978	0.2127288176334478	0.9184491975422211
81	0.08951125852389878	0.9705685619526484	0.22897385690301497	0.9171123026526548
82	0.0873443944398376	0.972240802755324	0.23770115960807725	0.9157753991570702
83	0.09146640672781396	0.9668896321070234	0.2164353592829271	0.919786095937943
84	0.08404356740091158	0.9705685619526484	0.220533777486513	0.9184492010483767
85	0.09078124929032597	0.967558528587571	0.2232544654830892	0.9157754042569328
86	0.0800613393452654	0.9698996657113168	0.2261390909951001	0.9171123026526548
87	0.0812391029976084	0.972240802755324	0.23127695838397838	0.914438505861211
88	0.08446106457191965	0.9752508363596173	0.209490562266207	0.9278074863122746
89	0.07436987656016016	0.9759197324414716	0.21798321226223266	0.9171122991464993
90	0.07507158724161295	0.9769230770825542	0.2299432415853847	0.9171123026526548
91	0.07109163790243525	0.9765886290017578	0.22400394707599425	0.9184492010483767
92	0.07519250978594241	0.9735785953974644	0.2253151205293635	0.9197860994440986
93	0.07322432622562683	0.9772575251633507	0.22277230920798	0.9184491975422211
94	0.07253889440991806	0.9729096991561328	0.2386466290821685	0.9144385007613482
95	0.07689182501174135	0.9722408029148013	0.2238113050234509	0.9184492010483767
96	0.0750582773051533	0.9769230772420315	0.22456861789373153	0.9184491975422211
97	0.07124622042561853	0.9772575254025666	0.23298740689767236	0.9171123026526548
98	0.066340259328036	0.9769230769230769	0.24454330587211778	0.9157753991570702
99	0.07042615350871581	0.9752508363596173	0.22713314211942295	0.9211229978398205

The optimal condition:
	epoch: 73
	train_acc: 0.9635451506611495
	val_acc: 0.930481283104
	using time: 279.79886508
