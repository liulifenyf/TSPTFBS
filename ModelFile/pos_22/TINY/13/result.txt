The number of train datas: 1692
The number of test datas: 424
epoch	train_loss	train_acc	val_loss	val_acc
0	0.726574644129327	0.48758865227090553	0.6982685721145486	0.5023584902848838
1	0.6987555152417356	0.5153664306827752	0.6923308811097775	0.48584905435454173
2	0.693116305144966	0.5443262412756611	0.6886279414284904	0.5448113185054851
3	0.6885844053387924	0.5265957449626697	0.684677576119045	0.5943396237661254
4	0.6906302273978014	0.5147754141343119	0.6800307653984934	0.580188680369899
5	0.6766856591752235	0.5620567375886525	0.6762267441119788	0.6132075449205795
6	0.6742421211080348	0.5691489363111221	0.6716744022549324	0.6367924517055727
7	0.6659248612169396	0.5945626473314092	0.6656538214323655	0.6556603762338746
8	0.6603368533418533	0.609338061888449	0.6581611712023897	0.6792452830188679
9	0.6622741220972499	0.6022458631659794	0.6519152893210357	0.6957547158565162
10	0.6537701448086588	0.6099290780141844	0.6437117884743888	0.7193396215168935
11	0.6421637391367703	0.6536643021777448	0.6341796506125972	0.7382075460451953
12	0.6273484857088003	0.6613475181532245	0.6240766284600744	0.7476415094339622
13	0.6182834510262131	0.6832151298827314	0.6115051294272801	0.7570754728227291
14	0.6097423501893984	0.6891252959310022	0.5988275285037059	0.7594339633887669
15	0.597696052093596	0.7033096925304855	0.5855206656006148	0.7594339633887669
16	0.5793299884942689	0.7287234042553191	0.5726516111841742	0.7665094350868801
17	0.5696544113170452	0.7293144208037825	0.557824543062246	0.7735849067849933
18	0.5524240119237427	0.7375886524822695	0.542946384762818	0.7830188690491442
19	0.5280735422251636	0.7730496458127989	0.5300921314167526	0.7830188667999124
20	0.5170907497969643	0.7783687940444225	0.5132920404650131	0.78537735736595
21	0.5094956541455947	0.7777777774959591	0.5045291803917795	0.7806603762338746
22	0.4959269652834457	0.7777777779186871	0.4859371190925814	0.7971698101961388
23	0.4812897136589032	0.7943262415574798	0.4757859043355258	0.794811319630101
24	0.4686814549403269	0.7960992906392326	0.4588204543545561	0.7995283030114084
25	0.4472053390586348	0.8167848698354501	0.45236342695524107	0.7995283030114084
26	0.4418962750733603	0.8079196216084996	0.45315457402535203	0.7971698135699866
27	0.434395303117468	0.8209219856746935	0.43115910044256245	0.8018867935774461
28	0.42908203728655553	0.8108747049144538	0.4249251923471127	0.7995283030114084
29	0.413812049596304	0.8262411344699544	0.420159915708146	0.804245281894252
30	0.40259912525508423	0.8333333334742427	0.4135447256969956	0.8089622630263275
31	0.4050243377826456	0.8315602835470339	0.4006888630255213	0.811320755841597
32	0.3823509018330991	0.8345153662893507	0.39169900484804837	0.820754718105748
33	0.379342695147715	0.8439716312056738	0.3910274921723132	0.8207547158565162
34	0.3690214745400927	0.8563829787234043	0.38900504978197925	0.8160377380982885
35	0.3772896836130895	0.8445626476132277	0.3798935368375958	0.8301886814945149
36	0.34684862967924024	0.8628841611792292	0.35985843246837834	0.8419811332000876
37	0.3461171645785618	0.8628841611792292	0.3642961517819818	0.8396226437586658
38	0.3433341423388632	0.8552009454855682	0.34558179131094013	0.849056602648969
39	0.32717737689367704	0.8676122932851174	0.34059078063604964	0.8537735871548923
40	0.3279033830966228	0.8646572108246192	0.33565809254376394	0.85613207772093
41	0.32078255554463003	0.8770685580605311	0.3241754618455779	0.8679245305511186
42	0.3053107620976495	0.8735224582061136	0.31690123677253723	0.865566039985081
43	0.3163697612482887	0.8747044913030404	0.32033322329791086	0.8632075494190432
44	0.304092140062481	0.882978723263346	0.30401810666300216	0.8679245305511186
45	0.311104910241233	0.8735224582061136	0.30031913743828825	0.8702830211171564
46	0.2900154409538206	0.8823877065739734	0.287627693054811	0.8773584928152696
47	0.281885102074197	0.8900709218449063	0.2790761202011468	0.8844339645133829
48	0.273532360686478	0.890661938111551	0.27652782314228563	0.8867924550794205
49	0.275664616878151	0.8947990542326131	0.26656501585582515	0.891509436211496
50	0.2665091928438092	0.9048463355564902	0.2540113560433658	0.9103773607397979
51	0.2689037133475004	0.8977541369749299	0.25445276498794556	0.8985849079096092
52	0.2614242853706892	0.8953900707810765	0.2446210727376758	0.9150943418718734
53	0.24953118907221666	0.9042553191489362	0.2389522335439358	0.9150943418718734
54	0.2532691466258773	0.9072104021730716	0.22774046884392793	0.9198113230039489
55	0.23632656326671583	0.9083924348472704	0.22273411953224326	0.9198113230039489
56	0.21944653787088733	0.9166666665257573	0.21556043737339523	0.9245283018867925
57	0.23337562026425174	0.9089834518184616	0.20911171413817495	0.9292452830188679
58	0.218377005599492	0.9160756501182034	0.2102995531738929	0.9292452830188679
59	0.2237449873670337	0.9143026004728132	0.19621991042820913	0.9316037735849056
60	0.2172020087569036	0.9219858151801089	0.20430781368939382	0.9292452830188679
61	0.2150673269168705	0.9196217496908021	0.18698883337794608	0.9386792452830188
62	0.20383600055748688	0.9284869979177525	0.1859622282801934	0.9386792452830188
63	0.2130416502062029	0.9267139482723624	0.18050998224402373	0.9386792452830188
64	0.2134575654287992	0.9255319151754356	0.1764766185913446	0.9410377358490566
65	0.20222226560256723	0.9302600475631425	0.17342988500055276	0.9433962241658624
66	0.20507271306030012	0.9278959812283798	0.16794768200730378	0.9410377358490566
67	0.20202285569187597	0.9243498813739623	0.16808727608536775	0.9433962241658624
68	0.20055902310719725	0.9273049643980977	0.1638045996989844	0.9504716958639756
69	0.18600225790313513	0.9414893615612183	0.15667115292459163	0.9504717003624394
70	0.18894592433040588	0.9349881799508494	0.15852965330177882	0.9504716958639756
71	0.19172602853171933	0.9338061468539227	0.1511380098900705	0.9551886769960511
72	0.18896336768958585	0.9326241137569959	0.14776595527271055	0.9481132097964017
73	0.18110664301589308	0.9338061468539227	0.1462674039714741	0.9528301864300134
74	0.17582860856755123	0.942080377827863	0.14302567490991555	0.9551886769960511
75	0.17266520831390475	0.9403073286052009	0.13963210582733154	0.9575471675620889
76	0.17671806243717247	0.9462174936671065	0.13829154675861574	0.9575471675620889
77	0.1638323469505806	0.9515366431669141	0.13517492334797698	0.9504717003624394
78	0.1642494691848473	0.9444444447262631	0.13800051302280067	0.9528301864300134
79	0.16203163058692963	0.9485815605655066	0.130896196050464	0.9551886769960511
80	0.1616555284576636	0.9444444444444444	0.12870059485705393	0.9575471698113207
81	0.16627659417917826	0.9403073288870196	0.13038378672779732	0.9551886769960511
82	0.16342500077635402	0.9473995267640333	0.1267346829738257	0.9599056581281266
83	0.14939611435077432	0.95094562675936	0.12434503604780953	0.9599056581281266
84	0.155231903525109	0.9509456266184507	0.12249598075758736	0.9551886814945149
85	0.14832601113240487	0.94917257711397	0.12080659225301922	0.9599056581281266
86	0.15398687710787387	0.9509456264775413	0.11967633299107822	0.9599056581281266
87	0.14793954097421458	0.9562647756955303	0.1193481739961876	0.9622641486941643
88	0.14800948945554435	0.9574468085106383	0.11713594816765695	0.9551886814945149
89	0.15696664595751897	0.9485815602836879	0.11585106377331715	0.9622641486941643
90	0.1391082980601782	0.9604018908302271	0.11732592672671911	0.9575471709359367
91	0.15006231676884013	0.9527186757002034	0.11400893161881645	0.9599056581281266
92	0.14016261603463062	0.9491725768321513	0.11281362063479873	0.9575471698113207
93	0.13892161118716495	0.9592198581560284	0.11121148095940644	0.9599056581281266
94	0.13575094605379917	0.9556737591470669	0.11167724796061246	0.9622641520680122
95	0.13546783947352822	0.9580378246363737	0.11157228867962675	0.9599056626265904
96	0.13979724826330833	0.9562647749909836	0.10864892320812873	0.9622641486941643
97	0.1441701619267182	0.956855791539447	0.1082411804851496	0.96462264263405
98	0.13513737547059432	0.9574468087924569	0.10674570416504482	0.9575471698113207
99	0.12595080783322066	0.9592198584378471	0.10541579605273481	0.96462264263405

The optimal condition:
	epoch: 99
	train_acc: 0.9592198584378471
	val_acc: 0.964622642634
	using time: 128.849459171
