The number of train datas: 1692
The number of test datas: 424
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7318069609344429	0.4905437353654956	0.6983016999262683	0.46462264179058793
1	0.7005650935161762	0.5065011820330969	0.6914873483046046	0.525943397351031
2	0.6991762155336692	0.5053191485134423	0.6885698448936894	0.5542452841434838
3	0.6970304154898822	0.5135933807555665	0.6855051135117153	0.561320755841597
4	0.6947054059792918	0.5065011818921876	0.6823610787121754	0.5966981120829312
5	0.6842562237811709	0.5585106384387817	0.6800122193570407	0.6179245283018868
6	0.6820123712785419	0.5531914897844301	0.6762143339750901	0.6273584928152696
7	0.6777503793403048	0.5703309691262302	0.6725364586092392	0.6556603773584906
8	0.6683775173856857	0.5851063826969047	0.6674868576931503	0.6650943396226415
9	0.6686222782935375	0.5868794322013855	0.6629145179154738	0.6745282996375606
10	0.6640986932648553	0.6046099293598328	0.6553533976932742	0.7193396226415094
11	0.6532431278668397	0.6111111108292925	0.6470386217225272	0.7264150932150067
12	0.6480940984777807	0.631205674040684	0.6402684258964827	0.7382075471698113
13	0.6387271273784322	0.6465721041598218	0.6301211309882829	0.75
14	0.6308381284100508	0.6560283692170542	0.6191392912054962	0.7547169788828436
15	0.6158551124252608	0.6802600474222332	0.6066426780988585	0.7570754694488814
16	0.5993284515455259	0.7009456264775413	0.5935459553070788	0.7429245260526549
17	0.5919251005136656	0.7080378249181923	0.5793915357229844	0.7523584916906537
18	0.5753209442252527	0.7080378254818296	0.5642020657377423	0.7547169800074596
19	0.5524972350321199	0.7470449169758646	0.5512916951809289	0.7688679234036859
20	0.5374377870108783	0.7606382981541591	0.5336756368853012	0.7641509422716105
21	0.5294788736259965	0.7712765953219529	0.5250986938206654	0.7641509422716105
22	0.5167109389958934	0.7612293144208038	0.5060530957185997	0.7712264139697237
23	0.5008276626291568	0.7783687940444225	0.49405642275540335	0.7688679234036859
24	0.48123682277986063	0.789598108324317	0.47991412934267297	0.7665094328376482
25	0.46929868844384	0.79905437324064	0.47357958274067574	0.7783018890416847
26	0.46040952501567545	0.7978723402846226	0.47002915503843773	0.7806603796077225
27	0.4486037699888784	0.7984633569739953	0.4526253730620978	0.7830188667999124
28	0.44298819285194363	0.8091016547054264	0.44558030704282364	0.7877358513058357
29	0.4335816347570848	0.8114657206174611	0.43999295976926694	0.7924528324379111
30	0.4124297869543657	0.8315602832652152	0.43661981314983006	0.7900943418718734
31	0.4167366714764994	0.8173758861020948	0.4238464916652104	0.7971698101961388
32	0.4083742610669869	0.8167848696945407	0.41944836558036086	0.7971698101961388
33	0.40039418838548324	0.8274231679896091	0.4199826402484246	0.8018867913282143
34	0.39158505595885834	0.8303782504501073	0.4130729594320621	0.7995283007621765
35	0.39159759019565354	0.8291962173531805	0.4106470233989212	0.8066037724602897
36	0.3737683262385375	0.8481087474676452	0.39134588668931203	0.8089622652755594
37	0.370164426999171	0.8439716316284017	0.3944742775188302	0.8089622630263275
38	0.3667659907476276	0.8439716310647645	0.3771472882549718	0.8160377369736725
39	0.35219402185004933	0.8575650119612402	0.37246719733724054	0.8183962275397103
40	0.3527629638958203	0.8563829788643136	0.3735693614437895	0.8160377369736725
41	0.3415426957832724	0.8599290781550937	0.35808912200747794	0.820754718105748
42	0.32861324158402483	0.8741134750363957	0.35285589886161517	0.820754718105748
43	0.34209368717867716	0.8593380617475397	0.35301797907307464	0.8254716992378235
44	0.3357857207175406	0.86583924307609	0.3386054297663131	0.830188680369899
45	0.3357131883466779	0.8599290778732751	0.3378472817393969	0.8325471709359367
46	0.31597498249500355	0.8723404255319149	0.32439113000653824	0.830188680369899
47	0.30806241728735306	0.874704491584859	0.3161818401993446	0.83962264263405
48	0.3026379976359947	0.8705673754637968	0.316026101697166	0.8419811332000876
49	0.3019789537639483	0.8812056736179559	0.3019055999674887	0.8490566048982009
50	0.29660545173266256	0.883569740093628	0.2928180419049173	0.8537735860302763
51	0.2942514667556077	0.8888888887479796	0.28776550011814767	0.8632075460451953
52	0.2786258656364243	0.891843971772115	0.28070625212957273	0.8702830177433086
53	0.2780773780940554	0.8947990546553412	0.27958199944136275	0.8655660366112331
54	0.2791644214315617	0.8953900707810765	0.26193174776041284	0.8915094350868801
55	0.2671327426078472	0.8871158393844082	0.2563375493265548	0.8915094350868801
56	0.25164427920013455	0.9018912532369014	0.24472165951189004	0.8985849067849933
57	0.2589749659700033	0.9072104021730716	0.24435671657886146	0.8985849067849933
58	0.24861514594749357	0.9119385342789598	0.24233823845971306	0.8938679256529178
59	0.2538011559146516	0.9007092201399747	0.2245101287679852	0.9033018845432209
60	0.23338354225699784	0.9190307331423387	0.2305525839328766	0.9033018856678369
61	0.24007672275775432	0.9125295504046952	0.21510734985459526	0.9056603751092587
62	0.23806959434674424	0.9054373525276815	0.2123513935871844	0.9127358468073719
63	0.23553452593214969	0.9131205676577052	0.20456698199488083	0.9127358468073719
64	0.2386013023537665	0.9160756502591126	0.2013505517311816	0.9174528313132951
65	0.22329024100416378	0.9202127658165374	0.19814588213866613	0.9150943407472575
66	0.22486312599328676	0.9172576830742207	0.1897921550948665	0.9174528313132951
67	0.21610016416291536	0.9166666665257573	0.18798035270762894	0.9198113218793329
68	0.2196922821496959	0.9219858157437462	0.18226202928795004	0.9198113218793329
69	0.20748649079608014	0.9290780141843972	0.17469507118441024	0.9363207524677493
70	0.2068875559537405	0.9231678489815822	0.17442459542796296	0.929245281894252
71	0.21224879492822832	0.9225768325740282	0.16770368420852805	0.9433962252904784
72	0.20329602495998356	0.9290780137616692	0.1627153771103553	0.9433962275397103
73	0.20062313938676324	0.9320330972085326	0.15828364187816404	0.9504716969885916
74	0.1944448814394908	0.934397163402386	0.15677116614467693	0.9433962252904784
75	0.19700877877485104	0.934397163402386	0.1503233291068167	0.9528301875546293
76	0.19159237219650413	0.9373522457219748	0.1474289618573099	0.9551886781206671
77	0.17505389071525412	0.9420803781096817	0.14464801100065122	0.9599056592527425
78	0.1787730860512871	0.9373522461447028	0.14738957049711696	0.9457547158565162
79	0.18080832736993793	0.9403073284642917	0.13833228765793568	0.9599056592527425
80	0.1816754266795819	0.9408983451536643	0.13507075523430445	0.9599056592527425
81	0.1790521320299054	0.9338061464311946	0.13548879690890042	0.9551886781206671
82	0.17599048865320552	0.9420803785324097	0.1323522132522655	0.9599056592527425
83	0.17165867832817366	0.9391252950855462	0.1297611841615641	0.9599056592527425
84	0.16548134203357337	0.9420803785324097	0.12713384122218727	0.9599056592527425
85	0.16613301002457914	0.9420803785324097	0.12463001597602412	0.9599056592527425
86	0.16327690518071467	0.9479905440170432	0.12272978166364273	0.9599056592527425
87	0.15487103225843846	0.9456264771186432	0.12066574703972295	0.9599056592527425
88	0.16030231199225073	0.9444444440217165	0.1193140132247277	0.9599056592527425
89	0.1675153787712397	0.9438534281777997	0.1180494708834954	0.9599056592527425
90	0.1537537855529898	0.9533096925304855	0.11669027299251196	0.9599056592527425
91	0.16608864308530838	0.9403073290279289	0.11588574018118517	0.9599056592527425
92	0.15449696826807996	0.9456264771186432	0.11526007978421338	0.9599056592527425
93	0.14917274947601852	0.9539007092198581	0.11334646366677194	0.9599056592527425
94	0.15069242487562465	0.9497635936624333	0.11084401888667413	0.9622641498187803
95	0.14689674737464734	0.9515366426032767	0.11289493149181581	0.9575471686867049
96	0.15203404555154468	0.9468085109201165	0.10759665043848865	0.9622641498187803
97	0.15681278784858418	0.9521276598562868	0.10727006028283317	0.9622641498187803
98	0.14791020712249386	0.9503546102108966	0.10613903122128181	0.9599056592527425
99	0.13281349496074885	0.9556737590061576	0.10425979573771639	0.9622641498187803

The optimal condition:
	epoch: 99
	train_acc: 0.9556737590061576
	val_acc: 0.962264149819
	using time: 144.368229151
