The number of train datas: 9088
The number of test datas: 2272
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7054841980128221	0.4886663732394366	0.6898348591697048	0.5475352104281036
1	0.6934413817566885	0.5224471830985915	0.6852336097771013	0.577024647887324
2	0.6882666937062438	0.539612676056338	0.6797879405424628	0.6038732402761218
3	0.6802202479940065	0.5651408450704225	0.671147968567593	0.6426056346423189
4	0.6703518410803566	0.5960607394366197	0.6571524806425605	0.6923415484562726
5	0.6567966778513411	0.6263204225352113	0.6359197967489001	0.7306338019773994
6	0.6261656922353825	0.6730853873239436	0.5991719667340668	0.7526408442309205
7	0.5881816039622669	0.7122579225352113	0.5560433444842486	0.7495598599944316
8	0.5371153312669673	0.7455985915492958	0.49863404455319255	0.7786091540900755
9	0.4815567265933668	0.7826804577464789	0.45513624288666416	0.7944542261916148
10	0.43872642559064945	0.8078785211267606	0.4242142806170692	0.8076584507042254
11	0.39696091203622413	0.8342869718309859	0.3998912679897228	0.8226232394366197
12	0.3484358787536621	0.8540933098591549	0.3509760490605529	0.8516725343717656
13	0.3160296378421112	0.8763204225352113	0.3285275317833457	0.8591549287379627
14	0.28050519379091937	0.897887323943662	0.30006703671435236	0.8816021118365543
15	0.25230988377416635	0.9082306338028169	0.31907348974909583	0.8785211276000654
16	0.23666594544766653	0.9162632042253521	0.2898455875020632	0.8961267614028823
17	0.23030063782779264	0.9175836267605634	0.28920183141886346	0.8965669022479528
18	0.21567660402244246	0.9261663732394366	0.2910652552062357	0.8952464797127415
19	0.20831848995786317	0.9277068661971831	0.2734812934633712	0.9022887332338683
20	0.20177650273265973	0.9311179577464789	0.2780013294287131	0.900968310698657
21	0.197592781673015	0.9340889084507042	0.28216115836526307	0.8965669022479528
22	0.1902076238897485	0.9356294014084507	0.2861103373514095	0.8952464797127415
23	0.18661754253044935	0.9373899647887324	0.27684171461093593	0.8983274656282344
24	0.18419675497521817	0.938050176056338	0.2771949397111443	0.8987676064733049
25	0.17820255426873624	0.9392605633802817	0.295447094759471	0.8921654921182445
26	0.1743951639239217	0.9417913732394366	0.26962228476161687	0.9000880290085161
27	0.1714103348867994	0.9433318661971831	0.28986054092225894	0.8952464780337374
28	0.1641999372923878	0.9433318661971831	0.26481365653830513	0.9022887332338683
29	0.16607858628874095	0.9452024647887324	0.25850760858033744	0.9027288740789386
30	0.1611961004599719	0.9461927816901409	0.2627345329858887	0.9022887332338683
31	0.16063621587736507	0.9450924295774648	0.252594559702655	0.9036091557690795
32	0.1555163302052189	0.9471830985915493	0.24310544269605422	0.9071302825296429
33	0.15168955659782382	0.9493838028169014	0.24701380210233406	0.9058098599944316
34	0.15255136000858227	0.9499339788732394	0.24786984799823292	0.9053697191493612
35	0.15227393039935072	0.9490536971830986	0.2662594331507112	0.9036091540900755
36	0.1457046047902443	0.9502640845070423	0.24569057353155713	0.9053697191493612
37	0.14287701081222212	0.9499339788732394	0.2431566590889239	0.906249999160498
38	0.14168540975997146	0.9540052816901409	0.23782959973938028	0.9066901416845725
39	0.1385332079420627	0.9523547535211268	0.24711180840369681	0.9066901400055684
40	0.14077206380980115	0.9530149647887324	0.2312196048212723	0.9071302825296429
41	0.13645677331467748	0.9533450704225352	0.2421719029440846	0.9066901400055684
42	0.13498129076521162	0.9523547535211268	0.234970393105292	0.9066901400055684
43	0.13514988302764758	0.953675176056338	0.24194569282338652	0.9066901400055684
44	0.1295723632817537	0.9566461267605634	0.2338857160172832	0.9088908442309205
45	0.13139937356324263	0.9569762323943662	0.2334175365911403	0.9088908442309205
46	0.12582863751851336	0.9576364436619719	0.2265814444128896	0.9106514076112022
47	0.12549174393356685	0.9577464788732394	0.2418242057549282	0.906249999160498
48	0.1229162549888584	0.9570862676056338	0.24666818131653356	0.906249999160498
49	0.12154027578276648	0.9597271126760564	0.22201590528580503	0.9119718301464135
50	0.12067805986169358	0.9606073943661971	0.21895532168343035	0.9137323935266951
51	0.11858163784507295	0.9617077464788732	0.2335930479244447	0.9084507033858501
52	0.11677183189862211	0.9610475352112676	0.2247663068414574	0.9110915484562726
53	0.11328364530919303	0.9587367957746479	0.24373334640978087	0.9049295766252867
54	0.11638041066241936	0.9601672535211268	0.2472569761981427	0.9036091540900755
55	0.11379981964406832	0.9608274647887324	0.22784412138059107	0.9119718301464135
56	0.11197354933115798	0.9609375	0.2125867471938402	0.9159330994310514
57	0.11013406835181612	0.9624779929577465	0.21888000696477755	0.9154929569069769
58	0.1111025180090481	0.9609375	0.22025058612647191	0.9132922526816247
59	0.10799337393591102	0.9636883802816901	0.2251402542624675	0.9119718301464135
60	0.1049120908891651	0.9646786971830986	0.22222366304674618	0.9132922526816247
61	0.10608231071645105	0.9650088028169014	0.2396949895355903	0.9071302808506388
62	0.10525232254409454	0.965669014084507	0.23726516232733996	0.9075704216957092
63	0.10002280052908709	0.9668794014084507	0.21939261131723162	0.9132922543606288
64	0.10010295004492074	0.9669894366197183	0.2500772696565574	0.9058098583154275
65	0.1012591169228856	0.9667693661971831	0.2360353715927668	0.9071302808506388
66	0.09641222377688112	0.9679797535211268	0.25591427533769273	0.9058098583154275
67	0.09442898032950683	0.9683098591549296	0.2511338198583731	0.9071302808506388
68	0.09817155245953882	0.9672095070422535	0.23911828956973386	0.9084507033858501
69	0.09691533000326492	0.9679797535211268	0.21641144822810737	0.9124119726704879
70	0.09479034440198415	0.9695202464788732	0.23080960776604398	0.9088908442309205
71	0.09404587541037882	0.967649647887324	0.24305470481934682	0.9110915484562726
72	0.09296917637259187	0.9678697183098591	0.22364132384389218	0.9106514092902063
73	0.08914803293809084	0.9713908450704225	0.2311241449919385	0.9106514076112022
74	0.09081461364534539	0.96875	0.21770009938889825	0.91461267689584
75	0.09110209623902617	0.9710607394366197	0.21729524622500782	0.9137323943661971
76	0.0870214357552394	0.9706205985915493	0.25342939432028316	0.9084507033858501
77	0.08972365970552808	0.967649647887324	0.24387823758830487	0.9102112667661317
78	0.08436069485377258	0.9724911971830986	0.22009067594165532	0.9124119726704879
79	0.0853654357644034	0.9721610915492958	0.22884683914377657	0.9119718318254175
80	0.08271513060784676	0.9735915492957746	0.2371117204532657	0.9124119709914839
81	0.08437806659076415	0.972931338028169	0.2302798895873654	0.9124119709914839
82	0.0815217178839613	0.9742517605633803	0.22426968812942505	0.9128521135155584
83	0.084497648960268	0.9708406690140845	0.21686453823472412	0.9141725360507696
84	0.07813911748604035	0.9733714788732394	0.23198546411495813	0.9128521135155584
85	0.07876749494126145	0.9740316901408451	0.22842802091593473	0.9132922543606288
86	0.0765354962048816	0.9743617957746479	0.2255620836791858	0.9132922543606288
87	0.07875795817186296	0.9748019366197183	0.21943175079117358	0.9132922535211268
88	0.07635892185212022	0.9762323943661971	0.23725972938495624	0.9150528177409105
89	0.07490006309579796	0.9749119718309859	0.2293543245276095	0.9137323952056993
90	0.07433446103208502	0.9743617957746479	0.23429252065613237	0.9141725360507696
91	0.07473855418428568	0.9749119718309859	0.23222251409586048	0.9150528177409105
92	0.07295126832601889	0.9766725352112676	0.21902182540843185	0.9141725352112676
93	0.07080249281101664	0.9761223591549296	0.24250399877487774	0.9119718318254175
94	0.07328087235735335	0.9763424295774648	0.2352513888667167	0.9137323952056993
95	0.07365646842919604	0.9761223591549296	0.24833470021545048	0.9124119726704879
96	0.0700877983595284	0.975462147887324	0.2135171450569596	0.9168133802816901
97	0.07061101624768384	0.9766725352112676	0.23666026857747158	0.9141725360507696
98	0.06765493931589832	0.9775528169014085	0.23325643279183078	0.9150528177409105
99	0.06825799529086536	0.9781029929577465	0.24782542574783445	0.9119718318254175

The optimal condition:
	epoch: 96
	train_acc: 0.975462147887324
	val_acc: 0.916813380282
	using time: 804.999227047
