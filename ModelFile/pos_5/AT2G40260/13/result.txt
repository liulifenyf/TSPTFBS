The number of train datas: 3126
The number of test datas: 782
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7286683967764837	0.5044785664772575	0.6985676250494349	0.503836317440433
1	0.7121560555654539	0.48880358312043026	0.6928593703852896	0.5153452685421995
2	0.7018961170050706	0.5089571339078843	0.6894318783069815	0.5319693094629157
3	0.6996367981398784	0.5118362124692303	0.6870084032988	0.5383631718128233
4	0.6920403027031106	0.5351887392219793	0.6846140011802049	0.5485933503836317
5	0.6864099010243602	0.5476647472808701	0.6823821028175256	0.5626598465473146
6	0.6893647048844028	0.5403071019943906	0.6798189166561722	0.5754475704087015
7	0.685990054563155	0.547344849571843	0.6777624449766505	0.5920716115580801
8	0.6806434980967223	0.5575815743539704	0.6753505901302523	0.6048593353432463
9	0.680309003084345	0.5716570700046273	0.672607568523768	0.6138107419928627
10	0.677695272751367	0.5646193220839619	0.6697146878827869	0.627877238308987
11	0.674675877133929	0.5719769673704415	0.6665252032487289	0.6432225062414203
12	0.6695696065537227	0.5902111322088114	0.663407737031922	0.632992327670612
13	0.6708869206851976	0.573896353243256	0.6592615676657928	0.6649616372859691
14	0.66380298682992	0.6055662191531938	0.6547817107661605	0.6751918163141022
15	0.6595380969407538	0.6174024312982785	0.6495833704843545	0.6943734019918515
16	0.6538964798644195	0.6183621236245295	0.6439785675319565	0.6943734013820853
17	0.6508770425275435	0.628598848711735	0.6375950917868358	0.7135549870598347
18	0.6434297669948253	0.646513115307191	0.6315555284395242	0.7135549869073932
19	0.6340333925404003	0.6650671787316877	0.623254844447231	0.7493606136583001
20	0.6285446796063345	0.6612284066809803	0.6156834709979689	0.7404092073135669
21	0.6165435912894348	0.6788227766733176	0.6053605750393685	0.7455242968276333
22	0.6167750530188005	0.67562380072709	0.5956299684541609	0.7557544758557664
23	0.6017750346805526	0.6996161232601734	0.584169779592158	0.7749360615335157
24	0.5929575121257828	0.6964171462080376	0.5727741610058739	0.777493606290549
25	0.576515572084804	0.7204094691224687	0.5577969099859448	0.7890025576971986
26	0.5735267068206387	0.7149712087935693	0.5490211563951829	0.7864450129401653
27	0.559774873352783	0.7316058863452514	0.531888632594472	0.7953964195897817
28	0.5497185346108556	0.7392834297221056	0.514463285503485	0.813299233041456
29	0.5283862029751065	0.7559181057865316	0.49716983617419175	0.8273657290526973
30	0.5210706125217909	0.7632757516068979	0.48390431789790883	0.8299232738097305
31	0.5068516813061288	0.7760716569171986	0.46830674136995964	0.8375959080808303
32	0.4929350280105801	0.7824696099536966	0.45146753095909764	0.8439897699734135
33	0.48263083633824333	0.7866282786075228	0.4343434812315285	0.855498721380063
34	0.4641504582120147	0.8023032633753366	0.41657602855616516	0.8618925832726462
35	0.44006444541445466	0.825335892743204	0.40034770988442403	0.8606138108941295
36	0.43718870395052073	0.8138195781546073	0.38961963237399033	0.8657289004081961
37	0.4201239433451791	0.8285348686894315	0.37272714547184116	0.8682864451652292
38	0.41235879797700575	0.8358925148911455	0.3725312226416205	0.8657289002557544
39	0.39807387801293603	0.8400511834687021	0.3525159067814917	0.8721227621483376
40	0.3762485961920164	0.8541266795769763	0.3423658559465652	0.8721227621483376
41	0.3671833593839266	0.8560460657548691	0.326510524963174	0.8797953959621126
42	0.3722190893733646	0.8566858601814192	0.31709859083832986	0.8785166235835961
43	0.34053636685976674	0.8733205375424273	0.3053782155065585	0.8861892578546958
44	0.33743385637866635	0.8755598213530776	0.30044516391309023	0.8887468030690537
45	0.3222326712965279	0.8784388992851999	0.29113203965489515	0.8951406649616368
46	0.32370920960749106	0.8825975687017215	0.2933973790053516	0.8951406649616368
47	0.3170950213496073	0.883237363890967	0.2826868506801098	0.8989769820971867
48	0.30623976702272165	0.8867562377368954	0.27347690008028086	0.9104859335038363
49	0.3075103847475595	0.8851567499544555	0.2688755811099201	0.9092071611253197
50	0.2980102371765266	0.8973128599992412	0.26346666440177147	0.9156010230179028
51	0.2881516137530387	0.8934740881392076	0.25675064832200784	0.9181585677749361
52	0.2859022166587112	0.8934740882154771	0.25323279312504526	0.928388746803069
53	0.27985512628741394	0.9024312217420137	0.24690425799935675	0.9271099744245525
54	0.2805893079104213	0.8989123480867592	0.24410524186880692	0.9296675191815856
55	0.267583125440722	0.9062699935257778	0.24192902466753866	0.9271099744245525
56	0.26153265287764776	0.9149072299915785	0.2357923328838385	0.9322250639386189
57	0.24918255918276133	0.9155470253333631	0.22970169797882706	0.9335038363171355
58	0.24942600864366468	0.9177863084957223	0.2280226076198051	0.9296675191815856
59	0.24816593363814377	0.9123480481668229	0.22371689839969816	0.9335038363171355
60	0.24341351085569488	0.9158669226991771	0.2220303886534308	0.9309462915601023
61	0.23915040007746532	0.923544466152301	0.22101066029056562	0.9360613810741688
62	0.23620985596132674	0.9222648756212709	0.2174805586828905	0.9335038363171355
63	0.22744617589719007	0.9232245685195435	0.21422075394474333	0.9360613810741688
64	0.22823612724674563	0.9305822140729664	0.21650353590469532	0.9373401534526854
65	0.22722585668033007	0.9222648751636536	0.21198626426632142	0.9373401534526854
66	0.21489029276165075	0.9325015998695115	0.21040701525061942	0.9373401534526854
67	0.21453071735985219	0.9350607802832805	0.20668573944312532	0.9386189258312021
68	0.21474063953698178	0.9318618042226487	0.20608649198966258	0.9386189258312021
69	0.2088460137618328	0.9315419067042956	0.2036281359355773	0.9437340153452686
70	0.20915063474892198	0.9296225211746938	0.20309407515522768	0.9437340153452686
71	0.20304419662772427	0.9392194501574194	0.20226346026829747	0.9424552429667519
72	0.2040887348406298	0.9357005753581217	0.20055572785761044	0.9411764705882353
73	0.20404613004688718	0.9357005753581217	0.2005237235551905	0.9386189258312021
74	0.19579816155340607	0.9436980168253507	0.19735769632146183	0.9424552429667519
75	0.18921327558051143	0.9427383237364043	0.1956767274062042	0.9450127877237852
76	0.19600516300283788	0.9411388357632906	0.20071121869261002	0.9398976982097187
77	0.19591960838149164	0.9420985282039459	0.195663791330879	0.9437340153452686
78	0.185268686742296	0.9475367884184409	0.1927699740318691	0.9437340153452686
79	0.18176661172472966	0.9459373002546534	0.1923874026293035	0.9437340153452686
80	0.18286945140769828	0.9440179144581082	0.19055531610308402	0.9437340153452686
81	0.17845097091704398	0.9475367877701499	0.19148015491950238	0.9411764701309107
82	0.17527126438405677	0.9488163783011799	0.1914236125205179	0.9386189253738774
83	0.17721478451312694	0.9507357646697466	0.1892514165367007	0.9475703324808185
84	0.17114313692331162	0.9472168901373924	0.18872058820312895	0.943734014887944
85	0.17298469971329145	0.9478566857842551	0.18833780107671952	0.9462915601023018
86	0.1632540450024437	0.9488163791401448	0.18838218254658878	0.9424552425094272
87	0.17292262514622944	0.9478566862418724	0.18984904797638164	0.9450127877237852
88	0.16456910466354624	0.9548944341625377	0.1868220992062403	0.9424552425094272
89	0.1694784376934714	0.9513755600115311	0.18687534526638364	0.9450127872664605
90	0.160491828440247	0.9529750483659926	0.18637067003323293	0.943734014887944
91	0.1534978633964588	0.9555342294280528	0.18638659651627015	0.9424552425094272
92	0.15485643991581996	0.956813819768409	0.1855105513616291	0.9411764701309107
93	0.155015182853584	0.9584133072839055	0.1851479028115797	0.9424552425094272
94	0.15395910872989027	0.9542546380580578	0.1852413628755323	0.9411764701309107
95	0.15488214712168114	0.9558541266794626	0.1866460493229844	0.9398976977523941
96	0.1558675802123905	0.9564939214873603	0.19308307170486816	0.9386189258312021
97	0.1557692245497432	0.9542546387063489	0.18466582934341164	0.9424552425094272
98	0.15310366246765877	0.9520153546287551	0.18627045263567238	0.9411764701309107
99	0.15356054774325242	0.9552143317952952	0.18383564422731205	0.943734014887944

The optimal condition:
	epoch: 83
	train_acc: 0.9507357646697466
	val_acc: 0.947570332481
	using time: 214.74625802
