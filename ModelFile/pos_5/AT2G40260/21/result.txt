The number of train datas: 3126
The number of test datas: 782
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7378883191735334	0.4932821497120921	0.7002570406555215	0.5
1	0.7146378327315996	0.4894433783859453	0.6930885706716181	0.5191815852204247
2	0.7020201636138667	0.5121561102354595	0.6882377279079174	0.5294117642485577
3	0.6982416602105417	0.5057581575803092	0.6862985862185583	0.5345268537626242
4	0.6888253156832221	0.5390275112726867	0.6841101583922305	0.5575447571856896
5	0.6849283105809949	0.5524632116578285	0.681675288073547	0.5639386190782727
6	0.685865695363653	0.5383877158164978	0.6783351988133872	0.5792838876204722
7	0.6781038382994541	0.5646193218170186	0.6755916543323975	0.5959079285411883
8	0.6768099930297086	0.5758157388491274	0.6722867766304699	0.6023017904337715
9	0.6740636244387636	0.5818937938715202	0.6696444861114482	0.6048593351908047
10	0.6713312734264025	0.5950095968145784	0.6661574471637112	0.6227621484900374
11	0.6671922262936774	0.5927703133852757	0.6621096432971223	0.6317135551396538
12	0.6637152091707851	0.6126039662348942	0.6577962342735446	0.6521739131959198
13	0.6587327745810427	0.6186820214479609	0.6510045036025669	0.6739130436307024
14	0.6524441209040768	0.6231605889548572	0.6459808858764141	0.6713554988736692
15	0.6478535434944998	0.6439539343595352	0.6397690635812862	0.7033248083365847
16	0.6432703105745907	0.6497120919017096	0.6338100187918719	0.6956521734557188
17	0.6348211789695559	0.6567498403943965	0.623732238931729	0.726342711149884
18	0.6290780223491325	0.6625079971357408	0.6173598177902534	0.718670076269018
19	0.613930234219581	0.6852207290615245	0.6060614114832086	0.7352941171897341
20	0.6074917884263485	0.6967370439933342	0.5978770652390502	0.7378516619467674
21	0.5956762867788435	0.7130518231876981	0.586254282604398	0.7468030685963838
22	0.5977594974097424	0.6976967365483938	0.57663489912477	0.7557544752460001
23	0.581477908812039	0.7172104924135458	0.5650871665886296	0.75959079238155
24	0.5747992705627656	0.717210492222872	0.5514680928433947	0.7736572885452329
25	0.5585321775629821	0.7319257832534483	0.53941508449252	0.7838874675733659
26	0.551396844826367	0.7367242478973501	0.5323373532813528	0.7672634266526498
27	0.5362740224245185	0.7584772871155352	0.517564255715636	0.7774936056807827
28	0.533886570657436	0.7463211777190405	0.4976579551501652	0.7966751915109737
29	0.5201981054691649	0.7639155469868173	0.4869065168873428	0.8017902814823649
30	0.5072655617923822	0.7757517590937673	0.4755966561224759	0.804347826239398
31	0.4904529166503816	0.7888675622274993	0.4661369208637101	0.8094629157534645
32	0.47779971349719846	0.796545105871297	0.450091249573871	0.8120204605104978
33	0.46439867021941406	0.799744082389546	0.43476850602328015	0.8145780052675311
34	0.4575299991107643	0.8039027509671026	0.4228625793743621	0.8260869566741806
35	0.43949986774038213	0.8128598844936393	0.4126674837773413	0.8248081836858978
36	0.42564074686529996	0.8096609085474118	0.4004946779412077	0.8312020461882472
37	0.41139080687661395	0.834293026536684	0.3865617620365699	0.8375959080808303
38	0.3999647184472319	0.8390914904560253	0.38956289820354	0.8324808184143222
39	0.4085467089961449	0.8234165065653112	0.372468754229948	0.8503836312562304
40	0.38533263468086454	0.8490083169952388	0.36715274938689474	0.8503836312562304
41	0.3751518293709917	0.856046065106578	0.35187513909071605	0.8618925826628799
42	0.37258762559750414	0.8566858608297103	0.3447227759663101	0.8554987207702969
43	0.3536463147809852	0.8621241202052404	0.33355067403572597	0.8644501274199132
44	0.34490745062257566	0.8717210491116963	0.32651626240566867	0.8657288997984298
45	0.34276000999977246	0.8672424823293606	0.3207828365552151	0.8695652169339797
46	0.3382979023555724	0.8694817661400109	0.32446609075416993	0.8734015345268542
47	0.3271324776604018	0.8784388992089304	0.31106187807172153	0.8759590788265629
48	0.3164675821498351	0.8803582852724189	0.3013641210392003	0.8810741683406293
49	0.3134067147035898	0.8861164430434019	0.2954866457015962	0.8810741683406293
50	0.306011425785277	0.8864363408668332	0.2944027684686129	0.8849104859335039
51	0.29811553884910147	0.8877159305588984	0.29015007961893935	0.8861892583120204
52	0.28912588351442503	0.8979526550740824	0.2779201907117653	0.8913043473687623
53	0.282877007777006	0.9021113242999301	0.2725676448296403	0.8913043473687623
54	0.2819507663744196	0.8966730642761089	0.26873739387678064	0.8964194373401535
55	0.2751558229508342	0.8969929627478314	0.27524081785279464	0.8925831202046036
56	0.26386522684277286	0.9056301980695889	0.2614722947406647	0.8989769820971867
57	0.2641764670629495	0.9126679466385454	0.25678496836396436	0.9028132992327366
58	0.24920890244321037	0.9142674343447157	0.25135100166053725	0.9002557540183787
59	0.251705132839547	0.910748560384383	0.25247309208297364	0.90153452685422
60	0.24863238172201643	0.9139475369026321	0.24579269871534898	0.9053708439897699
61	0.2455569415979483	0.9219449771495485	0.2431174944657499	0.9117647058823529
62	0.2391109009030837	0.9158669221271556	0.23981404647497875	0.9130434782608695
63	0.23209565679613628	0.9235444655040099	0.2356447086614721	0.9104859335038363
64	0.2299684647539832	0.9209852846326236	0.250112498393449	0.9092071611253197
65	0.22551078075258227	0.9235444662667053	0.23226802470281604	0.9156010230179028
66	0.22000560580120587	0.9280230330109063	0.2300201239412093	0.9130434782608695
67	0.21381798092936066	0.9289827259091787	0.2294204252988786	0.9168797953964194
68	0.21578004959582214	0.9283429304529899	0.2246453479275374	0.9168797953964194
69	0.20813813995300617	0.9331413942960616	0.2227570139767264	0.9245524292101945
70	0.20861149425317443	0.9363403714626017	0.22462521693514437	0.9207161125319693
71	0.19615341564705946	0.9404990406884495	0.2213659135962996	0.9207161125319693
72	0.1986368091744791	0.939539346951212	0.21729066987019366	0.9194373396961281
73	0.20136123798401478	0.9350607809315716	0.21909591763297007	0.9245524296675192
74	0.19131882241804937	0.9366602684470682	0.21467057118178023	0.9245524292101945
75	0.1905189727886472	0.9404990398494845	0.21485160148280966	0.9271099739672278
76	0.19153883864463175	0.9408189381305331	0.21614478572326548	0.923273656831678
77	0.1828661298883396	0.9420985286615632	0.21544247332131466	0.9245524292101945
78	0.19050540500490312	0.9424184261036468	0.21114864221314336	0.9245524292101945
79	0.17571768676593985	0.9433781185443022	0.2100212582770516	0.929667518724261
80	0.17850517024424925	0.9417786312194795	0.20790313336702868	0.9245524292101945
81	0.1701745719709079	0.9475367886091148	0.20634118454230715	0.9219948844531612
82	0.16603182152304524	0.9484964808590963	0.20961117620587044	0.929667518724261
83	0.1740423005052812	0.9504158668463152	0.20564833630228896	0.9258312015887111
84	0.16275072491519815	0.951375559553914	0.204847691042344	0.9271099739672278
85	0.16695552323578416	0.9510556625694475	0.20487722706840472	0.9335038358598109
86	0.1610690398297856	0.9526551505425612	0.20273389592957314	0.9283887463457444
87	0.16648864711772457	0.9491362763915547	0.20383426947209538	0.9322250634812943
88	0.15258675044305953	0.9555342285890879	0.20230158515598462	0.9283887463457444
89	0.1525275924756065	0.9536148427925427	0.20341106054499325	0.9347826082383275
90	0.15669554968198293	0.9516954578349626	0.20711782210699434	0.9309462911027777
91	0.1448490396761696	0.9577735128573553	0.20344016317973662	0.9347826082383275
92	0.14857907313436403	0.9545745365297802	0.2035753802798898	0.9373401529953608
93	0.15048858816053193	0.9561740245028939	0.20105486387944282	0.9245524292101945
94	0.1483979484761135	0.9542546380580578	0.2002658227368084	0.929667518724261
95	0.1431732837370551	0.9587332053742802	0.2005475013685958	0.9271099739672278
96	0.1471711278762561	0.9552143309563303	0.21278678240907162	0.9283887463457444
97	0.1445853676997311	0.9587332057556279	0.20039858141213732	0.9283887463457444
98	0.1406752168750885	0.956813819768409	0.1998315250782101	0.9283887463457444
99	0.13986773785592194	0.9552143316046214	0.20233456018711904	0.9335038358598109

The optimal condition:
	epoch: 92
	train_acc: 0.9545745365297802
	val_acc: 0.937340152995
	using time: 275.721946955
