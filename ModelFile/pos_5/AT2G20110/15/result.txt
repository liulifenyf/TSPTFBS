The number of train datas: 3322
The number of test datas: 832
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7262866861988162	0.49608669551577217	0.6925858809397771	0.5300480769230769
1	0.6909399873373524	0.5285972313375662	0.6876498185671293	0.5372596153846154
2	0.6902025840786262	0.5291992768977221	0.6833320305897639	0.5697115384615384
3	0.682160723395982	0.5577965085582515	0.679101811005519	0.6177884615384616
4	0.681996764510888	0.5562913900825505	0.6750498001392071	0.6358173076923077
5	0.6740368357772644	0.5927152322545818	0.6698971436573908	0.6538461538461539
6	0.6755068598921797	0.5788681521464514	0.6647903919219971	0.6694711538461539
7	0.6676527627041223	0.5933172791783599	0.6581027828730069	0.6983173076923077
8	0.6567472554989998	0.6270319085606317	0.649338437960698	0.7127403846153846
9	0.6479769442039826	0.6327513554668943	0.6381099132391123	0.7391826923076923
10	0.6420216920647113	0.6447922935836076	0.6253749315555279	0.7632211538461539
11	0.6272644928820803	0.6715833825350238	0.6102826595306396	0.7752403846153846
12	0.6106071412599209	0.6872366049934194	0.591321573807643	0.7896634615384616
13	0.5931729159033636	0.7143287182141327	0.5701982058011569	0.8004807692307693
14	0.5726978666519702	0.7284768220891729	0.5466546278733474	0.8209134615384616
15	0.5552644876741918	0.7417218541252117	0.5281463746841137	0.8125
16	0.5375246810740839	0.751053582358834	0.5016136948878949	0.828125
17	0.5111055649381887	0.7796508132657827	0.4789914099069742	0.8353365384615384
18	0.49214352198138	0.7859723064140123	0.4561063280472389	0.8341346153846154
19	0.4716435777071655	0.795605058091581	0.44040891298880946	0.8365384615384616
20	0.45025516573669394	0.8082480442803858	0.41890279146341175	0.8449519230769231
21	0.4297179870939915	0.8190848888366212	0.40380876110150266	0.8473557692307693
22	0.4217974666118048	0.8245033118324349	0.39195654025444615	0.8485576923076923
23	0.39819494124854066	0.8326309447472243	0.3873787201367892	0.8413461538461539
24	0.39232737265531736	0.8362432275817453	0.37279405960669887	0.8521634615384616
25	0.3768362665233807	0.8485851902548338	0.3622316144979917	0.8605769230769231
26	0.3658230398915605	0.854304636012783	0.35074952244758606	0.8617788461538461
27	0.3617865517152353	0.8515954250890329	0.3510381006277524	0.8605769230769231
28	0.3467958954211677	0.8618302226497206	0.33599096765884984	0.8665865384615384
29	0.33617331371976267	0.8645394350806321	0.33560124268898595	0.8665865384615384
30	0.3290460790624682	0.8672486449278384	0.3241121172904968	0.8713942307692307
31	0.3184518467619217	0.8726670690360807	0.31371973340327924	0.8786057692307693
32	0.3209851709099723	0.8747742333949007	0.3165294688481551	0.8774038461538461
33	0.2998190310294193	0.8904274543461349	0.3115090074447485	0.8762019230769231
34	0.29501121907905953	0.8829018659149575	0.3061449883075861	0.8810096153846154
35	0.2848469553081333	0.8940397361399968	0.2886967360973358	0.8954326923076923
36	0.27572506962233034	0.8958458755118239	0.2864551062767322	0.8942307692307693
37	0.27228994812863483	0.8958458770189853	0.2969389993410844	0.8762019230769231
38	0.26705662799412627	0.9024683935752768	0.2756295593885275	0.90625
39	0.2652598401550641	0.9036724871357545	0.2719247272381416	0.9086538461538461
40	0.2623448591502153	0.9003612273863322	0.26760735649328965	0.9098557692307693
41	0.2533255907371057	0.9111980737368074	0.2670020117209508	0.9086538461538461
42	0.24036574980926972	0.9114990975754869	0.2568034598460564	0.9182692307692307
43	0.23827333389492655	0.9148103547770886	0.2740236876102594	0.9050480769230769
44	0.2309726732258765	0.9142083082121586	0.2558579364648232	0.9110576923076923
45	0.23452373461720458	0.9169175198894893	0.2599112425859158	0.9086538461538461
46	0.22602596464536048	0.9160144483375664	0.2472972021653102	0.9170673076923077
47	0.2287856580118757	0.9133052370190836	0.24801835532371813	0.9194711538461539
48	0.22268238915764088	0.9226369663651344	0.24475606817465562	0.9194711538461539
49	0.21340169772407078	0.9244431064905423	0.24471812408704025	0.9182692307692307
50	0.21967484197797438	0.920830824050754	0.24421263658083403	0.9194711538461539
51	0.2099347778880259	0.930764599602887	0.23391060875012323	0.9278846153846154
52	0.2076016067830573	0.9226369656115537	0.24977237788530496	0.9182692307692307
53	0.20225790015621978	0.9280553882844041	0.23787095684271592	0.9254807692307693
54	0.19828126518967495	0.9337748351188973	0.22932152793957636	0.9290865384615384
55	0.1986826445093218	0.9286574363206109	0.23034914984152868	0.9302884615384616
56	0.19972945504845946	0.9289584579703177	0.23234067054895255	0.9314903846153846
57	0.1882996102239912	0.9355809745266092	0.2296979702436007	0.9326923076923077
58	0.18822305743267995	0.9331727874415384	0.23047457520778364	0.9326923076923077
59	0.18673536587845196	0.9382901862398247	0.22332795078937823	0.9375
60	0.17597761744838533	0.9431065629936715	0.234328588614097	0.9266826923076923
61	0.17938136933332174	0.9394942797644177	0.23962055032069868	0.9206730769230769
62	0.17225403522131746	0.9470198671549361	0.2317219296327004	0.9302884615384616
63	0.1693429745585713	0.9422034914776333	0.21989234594198373	0.9375
64	0.16738442263819955	0.9437086088409057	0.21802601218223572	0.9399038461538461
65	0.16779302458925321	0.9455147511911708	0.2189453633931967	0.9399038461538461
66	0.16511343388152652	0.9482239610742619	0.22893291597182935	0.9314903846153846
67	0.16431222788760777	0.9437086095944863	0.21457876379673296	0.9375
68	0.16201693442196533	0.9425045164287413	0.22591949426210844	0.9314903846153846
69	0.1585722328003884	0.9443106561953012	0.2176880847949248	0.9387019230769231
70	0.1554482618345689	0.9524382897919018	0.21581390729317299	0.9411057692307693
71	0.15149179609657268	0.9467188436392199	0.21542353584216192	0.9411057692307693
72	0.14909486887524603	0.9506321485540653	0.2179477203350801	0.9338942307692307
73	0.15314005503698977	0.9446116803928286	0.22203598801906294	0.9326923076923077
74	0.14618866036162184	0.9509331734692885	0.21537199043310606	0.9362980769230769
75	0.14243735926543138	0.9545454552272656	0.20911231980873987	0.9411057692307693
76	0.1430035112655572	0.9527393132717332	0.21894450600330645	0.9338942307692307
77	0.13949029303723828	0.9563515957474062	0.2121312411931845	0.9375
78	0.14003737348432932	0.9536423851825041	0.21945260121272162	0.9314903846153846
79	0.1326189251108603	0.9557495484647802	0.21097216583215272	0.9387019230769231
80	0.13527570874808711	0.9548464775946685	0.2157571235528359	0.9350961538461539
81	0.1290577319346947	0.9548464791018298	0.21931019654640785	0.9314903846153846
82	0.12438931568228	0.9614689952992733	0.2127863157253999	0.9375
83	0.1264034819254884	0.958157735549851	0.2168504297733307	0.9314903846153846
84	0.12944154989496906	0.9596628540614367	0.21480423899797293	0.9302884615384616
85	0.12699150417419458	0.9584587590296824	0.21947851203955138	0.9350961538461539
86	0.11916804734408891	0.9626730888238663	0.2102584196971013	0.9362980769230769
87	0.12061596036064991	0.9572546654692047	0.20741666509554937	0.9375
88	0.11772819845738144	0.9593618312993012	0.21291085619192857	0.9350961538461539
89	0.1185395366218993	0.9644792304564355	0.21610903166807616	0.9314903846153846
90	0.11728785278512224	0.9602649010210996	0.2205927251623227	0.9314903846153846
91	0.11441964350645259	0.9623720653440349	0.21296751040678757	0.9375
92	0.11279518182363085	0.964479228626311	0.20574315465413606	0.9375
93	0.11016195282689926	0.9659843463843161	0.2107898249075963	0.9399038461538461
94	0.10767335230277146	0.9641782069766041	0.20497875603345725	0.9350961538461539
95	0.10597022897342398	0.9638771834967726	0.22776873295123762	0.9290865384615384
96	0.10767045788004914	0.9638771834967726	0.21332649829295966	0.9375
97	0.10457522679997237	0.965984346743164	0.2038190674323302	0.9387019230769231
98	0.09863812424812167	0.9665863948152554	0.2091504129079672	0.9387019230769231
99	0.10167739009243548	0.9656833229044846	0.21002334241683668	0.9375

The optimal condition:
	epoch: 75
	train_acc: 0.9545454552272656
	val_acc: 0.941105769231
	using time: 270.191282034
