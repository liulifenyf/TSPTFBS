The number of train datas: 3322
The number of test datas: 832
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7272480323973511	0.5066225169510241	0.6910151472458472	0.5348557692307693
1	0.6953312687167628	0.5126429861529199	0.6874325825617864	0.5240384615384616
2	0.6915174602816293	0.5337146301717374	0.6832049076373761	0.5637019230769231
3	0.6874629067484691	0.5442504523246853	0.6791870960822473	0.5973557692307693
4	0.6858332220651098	0.5448524988896154	0.6754366801335261	0.6262019230769231
5	0.6787155509210365	0.5767609863522396	0.670516848564148	0.6526442307692307
6	0.6779267338296866	0.5710415408813688	0.6653578464801495	0.671875
7	0.6697481816106357	0.589102949743024	0.658264907506796	0.7091346153846154
8	0.6622456656673599	0.6186032518430477	0.6497343732760503	0.7307692307692307
9	0.6527372929505882	0.6342564725430883	0.6381138379757221	0.7439903846153846
10	0.6438908921818214	0.6553281150188596	0.6240292053956252	0.7692307692307693
11	0.6290539654172522	0.6679711018894754	0.6074017194601206	0.7848557692307693
12	0.6097259574593872	0.7089102951824342	0.5865706388766949	0.8004807692307693
13	0.5960624023491471	0.7037928949128713	0.5630181981967046	0.8185096153846154
14	0.5640671172104709	0.7501505108786807	0.5368777972001296	0.8245192307692307
15	0.5472547562993628	0.7573750754352939	0.513740904056109	0.8173076923076923
16	0.5265688371543494	0.7658037321169932	0.48483741741914016	0.8341346153846154
17	0.5027943165958251	0.7847682113822578	0.4603393857295697	0.8413461538461539
18	0.476240208911867	0.7953040343246712	0.4362599207804753	0.8473557692307693
19	0.45378443740492197	0.8100541848005264	0.418373887355511	0.8485576923076923
20	0.44504613471921134	0.8091511136433363	0.3994156809953543	0.859375
21	0.4189576693036196	0.8260084277603154	0.3849694797625908	0.8605769230769231
22	0.41007363333320274	0.8281155932674489	0.3755090351288135	0.8581730769230769
23	0.3984495915252713	0.8308248053036276	0.36989737703250003	0.8533653846153846
24	0.3824602369261678	0.8428657427026449	0.35745893304164594	0.8641826923076923
25	0.36519800742873937	0.8497892838153116	0.3440127372741699	0.8737980769230769
26	0.3618352303549441	0.8555087303268414	0.33748423136197603	0.8689903846153846
27	0.35225669604550636	0.8582179420041722	0.3354352024885324	0.8713942307692307
28	0.3406439898855208	0.8678506918516165	0.32135244516225964	0.8737980769230769
29	0.32891299134632823	0.8732691145603517	0.32247228347338164	0.8786057692307693
30	0.32184436594341836	0.8756773034755471	0.3058126110296983	0.8798076923076923
31	0.3048954288834624	0.8822998193141425	0.3037180866186435	0.8822115384615384
32	0.31394761023860174	0.8780854905965025	0.3058645392839725	0.8894230769230769
33	0.29611929990956753	0.8844069843906585	0.2999221751323113	0.8918269230769231
34	0.2878392671584222	0.8937387115477368	0.29029450049767125	0.8954326923076923
35	0.2773119247619967	0.8940397361399968	0.2782581861202533	0.9002403846153846
36	0.26608917133266996	0.8973509925521331	0.27793529400458705	0.9014423076923077
37	0.26563520093483783	0.8976520178979739	0.2934601650788234	0.8894230769230769
38	0.26333478046497044	0.9006622526604035	0.26628021322763884	0.9074519230769231
39	0.2523486913057927	0.9030704405349396	0.2591954435293491	0.9050480769230769
40	0.25017795989414354	0.910897050256976	0.25641198800160336	0.9074519230769231
41	0.2481559735870304	0.9078868158175097	0.2629551761425458	0.9086538461538461
42	0.22618690832848293	0.9190246849301205	0.24733586723987872	0.9158653846153846
43	0.2341054990430111	0.920228778526483	0.262061758683278	0.9110576923076923
44	0.22016100821403192	0.920228778167635	0.24939598028476423	0.9110576923076923
45	0.22773590307146724	0.9178205906878316	0.25072650611400604	0.9122596153846154
46	0.21075672640598087	0.925948225002128	0.24073915298168475	0.9158653846153846
47	0.20833680519025632	0.9220349186518908	0.24235348518078142	0.9134615384615384
48	0.2072332361101889	0.9304635753694749	0.2368257584480139	0.9182692307692307
49	0.20521408634362345	0.9301625526073394	0.23665829117481524	0.9158653846153846
50	0.20610270153535984	0.9322697181144728	0.2381840508717757	0.9182692307692307
51	0.19295350622334156	0.9337748340423534	0.23041514020699722	0.9242788461538461
52	0.19480147679694657	0.9292594818089972	0.24504258999457726	0.9182692307692307
53	0.1832541356077401	0.9376881392801619	0.2357263874549132	0.9182692307692307
54	0.18919781780723777	0.9340758575221848	0.22275376893006837	0.9314903846153846
55	0.17881468975045178	0.9391932566793191	0.22449435866796053	0.9290865384615384
56	0.18126830613842793	0.9400963281953572	0.2206325393456679	0.9314903846153846
57	0.17692743379943418	0.938591210437352	0.22192735626147345	0.9302884615384616
58	0.17553600815137707	0.9437086095944863	0.22297106224756974	0.9266826923076923
59	0.17352778040218036	0.9428055380784482	0.2162702473310324	0.9362980769230769
60	0.15955948908597428	0.9464178212718172	0.2272472782776906	0.9266826923076923
61	0.16004030737512304	0.949127032231452	0.2212514544908817	0.9314903846153846
62	0.15558075844739158	0.9461167970742898	0.22614189180044028	0.9266826923076923
63	0.1539925096140505	0.9524382897919018	0.21192430418271285	0.9375
64	0.14776147588019914	0.9515352197112554	0.21148243087988633	0.9338942307692307
65	0.14609226532401556	0.9500301019532504	0.21213436814454886	0.9338942307692307
66	0.1503729349622376	0.9560505722675748	0.22293128760961387	0.9254807692307693
67	0.14394135307576697	0.953943407191059	0.2080505650777083	0.9375
68	0.14267917864208549	0.9515352197112554	0.21357170664347136	0.9338942307692307
69	0.1417049329227744	0.9542444306708904	0.2134922295808792	0.9338942307692307
70	0.13768051782693583	0.9572546651103567	0.21220224178754366	0.9338942307692307
71	0.1392238816175742	0.9536423847877714	0.20987834724096152	0.9350961538461539
72	0.1312792513391686	0.957856713900144	0.2087982354255823	0.9362980769230769
73	0.1369733333605589	0.953341360231396	0.21511493279383734	0.9326923076923077
74	0.12872829305289527	0.9611679703481653	0.20291230082511902	0.9387019230769231
75	0.12632422737692006	0.9572546661869006	0.20056274074774522	0.9399038461538461
76	0.12268843679884556	0.9623720642674909	0.20906672798670256	0.9326923076923077
77	0.12513399118762789	0.957856713900144	0.2053288622544362	0.9375
78	0.1259272333496956	0.9599638764288395	0.20803914620326117	0.9326923076923077
79	0.11681300071996066	0.9653823008959298	0.20916621616253486	0.9326923076923077
80	0.11866538651839284	0.9614689956222364	0.20701435093696302	0.9326923076923077
81	0.11696206500629285	0.9644792300975875	0.20691312505648687	0.9326923076923077
82	0.11610352717595672	0.9641782069766041	0.20502966871628395	0.9350961538461539
83	0.11426142473525128	0.9632751365371098	0.2066631672474054	0.9326923076923077
84	0.11268934482133296	0.9665863940975595	0.2143077002121852	0.9338942307692307
85	0.10907453093128273	0.9662853698641475	0.23852178511711267	0.9290865384615384
86	0.10194867399444356	0.9668874171826582	0.20667564983551318	0.9314903846153846
87	0.10312623812321939	0.9668874164649623	0.20074733862510094	0.9387019230769231
88	0.105082555407684	0.964479228626311	0.20411206094118264	0.9375
89	0.10369588103210402	0.9659843460254681	0.20636756603534406	0.9350961538461539
90	0.0948857008998183	0.9695966296135697	0.21240226580546454	0.9326923076923077
91	0.103075153044661	0.9698976516221246	0.2088609320613054	0.9326923076923077
92	0.09537780951441661	0.9695966296135697	0.20044057300457588	0.9399038461538461
93	0.09512573871750346	0.9726068632994553	0.2013655580007113	0.9387019230769231
94	0.093434126817771	0.9701986747431081	0.20788727356837347	0.9338942307692307
95	0.09035152581300024	0.9714027701337103	0.2158171207858966	0.9338942307692307
96	0.09072612234980568	0.9729078878917155	0.21591728524519846	0.9338942307692307
97	0.09170399114606181	0.972305839101928	0.2046058435852711	0.9338942307692307
98	0.08280062103562151	0.9774232400891868	0.2026816468972426	0.9362980769230769
99	0.08721021194547002	0.9735099348513783	0.2000841750548436	0.9387019230769231

The optimal condition:
	epoch: 92
	train_acc: 0.9695966296135697
	val_acc: 0.939903846154
	using time: 312.299016953
