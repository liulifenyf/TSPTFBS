The number of train datas: 3322
The number of test datas: 832
epoch	train_loss	train_acc	val_loss	val_acc
0	0.725527713127986	0.501806141668454	0.69009451682751	0.5564903846153846
1	0.6914878168571146	0.5424443109971367	0.6844510573607224	0.5540865384615384
2	0.6868540652899194	0.5424443107280008	0.6790087223052979	0.5949519230769231
3	0.6788095693714571	0.5659241410424234	0.6734581864797152	0.6418269230769231
4	0.6793091913291591	0.5677302826749927	0.6683538326850305	0.6682692307692307
5	0.66927450008955	0.6074653831251696	0.6615790312106793	0.6887019230769231
6	0.667900158295353	0.607465382371589	0.6537822989317087	0.7055288461538461
7	0.660289894558449	0.6195063211701133	0.6449946165084839	0.7307692307692307
8	0.6503835910777598	0.6393738713054898	0.6347238971636846	0.7548076923076923
9	0.6391832973855149	0.6472004807404479	0.6219703876055204	0.7680288461538461
10	0.6302702711476826	0.6631547269657533	0.6078174205926749	0.7800480769230769
11	0.6175672271250243	0.6785069236835753	0.5915818443665137	0.7944711538461539
12	0.5976326029247581	0.7140276946984164	0.5720642346602219	0.7980769230769231
13	0.5828762013534693	0.7260686335687103	0.5511817290232732	0.8100961538461539
14	0.5588605202227598	0.7507525596325832	0.5288706926199106	0.8197115384615384
15	0.5399614037123881	0.7582781466283689	0.510241659787985	0.8233173076923077
16	0.5269206767696563	0.7528597232378226	0.486593633890152	0.8305288461538461
17	0.50371989473243	0.7814569527093794	0.4681558929956876	0.8401442307692307
18	0.4846301366054172	0.7817579762250957	0.44771541311190677	0.8425480769230769
19	0.4686079616649979	0.7971101744141943	0.43418219456305873	0.8509615384615384
20	0.45356392650486543	0.8070439496433641	0.4151517840532156	0.8533653846153846
21	0.431609875821407	0.8157736305584755	0.4029365915518541	0.8545673076923077
22	0.42306143551401026	0.8190848881189253	0.39104274144539464	0.8581730769230769
23	0.4074483637455212	0.8293196861102307	0.385123821405264	0.8569711538461539
24	0.40068468381524586	0.8326309458237682	0.3723423366363232	0.8677884615384616
25	0.38373633781375116	0.8392534616623637	0.36303719878196716	0.875
26	0.3740582876109273	0.8491872368556487	0.3515808903253995	0.8786057692307693
27	0.3685686103124923	0.8527995186136258	0.35121933542765105	0.8701923076923077
28	0.35348875105632205	0.8609271525690744	0.33713265794974107	0.8858173076923077
29	0.3476208822509024	0.8687537627217283	0.3335538644057054	0.8834134615384616
30	0.34179430245491915	0.8618302234033014	0.3223320543766022	0.8894230769230769
31	0.323608521773541	0.8693558100402391	0.31360356165812564	0.8966346153846154
32	0.33377285343849966	0.8660445517620934	0.31544511364056516	0.8966346153846154
33	0.3158426231680542	0.8789885602824161	0.31528006608669573	0.8870192307692307
34	0.29853909061229206	0.8853100537536088	0.3027099749216667	0.9002403846153846
35	0.29435734186166745	0.8871161942737494	0.2892046593702756	0.9110576923076923
36	0.28178557008953425	0.8889223351168533	0.28661759197711945	0.9134615384615384
37	0.28055277881243373	0.8940397353864161	0.29100737892664397	0.9014423076923077
38	0.2770246174377106	0.8961468990275402	0.27563321131926316	0.9170673076923077
39	0.271121231584503	0.8976520160678494	0.2695005192206456	0.9206730769230769
40	0.2673110407135129	0.9015653230998977	0.26485989414728606	0.9194711538461539
41	0.26037003707268525	0.9057796514586897	0.265102356672287	0.9206730769230769
42	0.2474461425003842	0.9118001199787744	0.2556033810743919	0.9230769230769231
43	0.24415288567722454	0.9099939794586338	0.265897573186801	0.9182692307692307
44	0.2363619679682661	0.9108970499340129	0.25009502470493317	0.9266826923076923
45	0.24019171824159571	0.9102950025796173	0.2510465899339089	0.9230769230769231
46	0.22723679595292154	0.9190246834947287	0.24222982617524955	0.9326923076923077
47	0.22612452630821586	0.9163154718173978	0.2445024847984314	0.9230769230769231
48	0.22459987437488227	0.9163154736475224	0.2407578436227945	0.9314903846153846
49	0.21600556434600343	0.9226369663651344	0.2353674448453463	0.9350961538461539
50	0.22113643376709538	0.9262492481231115	0.23743107341803038	0.9314903846153846
51	0.21056041916779622	0.9307646003564677	0.22841689907587492	0.9362980769230769
52	0.2072014616581419	0.9250451542037859	0.23391991624465355	0.9326923076923077
53	0.2028004489502657	0.9271523189573385	0.22706742126208085	0.9350961538461539
54	0.2013259267749591	0.9283564117642357	0.2228737656886761	0.9375
55	0.2006914916614823	0.9274533413247413	0.22183371277955863	0.9362980769230769
56	0.19862666204885715	0.9268512943650785	0.21977967023849487	0.9362980769230769
57	0.18618494051540566	0.9379891634776892	0.21862386052425092	0.9362980769230769
58	0.18913189893670285	0.9331727885180823	0.21625387439360985	0.9375
59	0.18765710728452695	0.9316676693246854	0.214517647257218	0.9375
60	0.17131870313088338	0.9479229383121263	0.21862730154624352	0.9362980769230769
61	0.17700360823940758	0.939193257397015	0.2201422510238794	0.9362980769230769
62	0.17345416673258943	0.9413004221146829	0.21697846284279457	0.9362980769230769
63	0.1681915061488918	0.9416014448768184	0.21067514786353478	0.9411057692307693
64	0.16323152206914388	0.94491270387266	0.20891044690058783	0.9459134615384616
65	0.16596172580440527	0.9422034918364812	0.2098433065872926	0.9399038461538461
66	0.1668650619618366	0.9458157732356104	0.21465404331684113	0.9350961538461539
67	0.16073596638990123	0.9431065633525194	0.2061815353540274	0.9435096153846154
68	0.15566063928431878	0.9491270326261848	0.214477627323224	0.9362980769230769
69	0.15986997884917445	0.9434075868323508	0.20892261197933784	0.9375
70	0.15550180985258688	0.9473208902759196	0.20527620269702032	0.9399038461538461
71	0.1501768988381661	0.9503311265096257	0.2038411796092987	0.9447115384615384
72	0.14214386369344487	0.9533413609490919	0.20661507661526018	0.9387019230769231
73	0.15116797546390165	0.947019867872632	0.20795441476198342	0.9399038461538461
74	0.1450579980010372	0.9500301026709463	0.20773246311224425	0.9399038461538461
75	0.14129578414126953	0.9503311261507777	0.20074748649046972	0.9435096153846154
76	0.1369669699188028	0.9566526195860856	0.2110714614391327	0.9399038461538461
77	0.13972762219881452	0.9521372670297663	0.20291263438188112	0.9435096153846154
78	0.13835771031529698	0.9530403363927167	0.20754997661480537	0.9435096153846154
79	0.13182827683186976	0.958458760859807	0.19994141161441803	0.9435096153846154
80	0.13442548678841382	0.9545454537559891	0.20082884109937227	0.9435096153846154
81	0.12601958106685157	0.9569536427429539	0.20498993763556847	0.9435096153846154
82	0.1280472914249261	0.9596628529490081	0.1998190192075876	0.9447115384615384
83	0.12509096850299606	0.9572546669404812	0.20790418065511262	0.9423076923076923
84	0.1259024917254026	0.9587597839807904	0.20232245669915125	0.9447115384615384
85	0.12251565197661007	0.9635761589045125	0.20930149119633895	0.9411057692307693
86	0.11537456939928795	0.9632751347069852	0.1992387966467784	0.9447115384615384
87	0.1177172346342263	0.9611679710658612	0.199031528372031	0.9447115384615384
88	0.11697482016702361	0.9605659241061982	0.20078373413819534	0.9459134615384616
89	0.11808107373479043	0.9605659244650462	0.2017738028214528	0.9447115384615384
90	0.11594008578100813	0.9644792300975875	0.20352316934328812	0.9447115384615384
91	0.11321826959180228	0.9608669472271818	0.20219876789129698	0.9447115384615384
92	0.10814830816021746	0.9650812770572504	0.19734537945343897	0.9435096153846154
93	0.10984125471865104	0.9653822990658052	0.20182819091356718	0.9471153846153846
94	0.1075967179049504	0.963877182025496	0.1981768516393808	0.9423076923076923
95	0.09904381025903272	0.968392535694244	0.21475711808754847	0.9399038461538461
96	0.10609164196618848	0.9644792293440069	0.20885132253170013	0.9411057692307693
97	0.10303931369758527	0.9659843460254681	0.19933437498716208	0.9423076923076923
98	0.09613931099651521	0.9726068625817594	0.20320756274920243	0.9447115384615384
99	0.10152208285203258	0.9698976530934011	0.20304052990216476	0.9459134615384616

The optimal condition:
	epoch: 93
	train_acc: 0.9653822990658052
	val_acc: 0.947115384615
	using time: 239.401346922
