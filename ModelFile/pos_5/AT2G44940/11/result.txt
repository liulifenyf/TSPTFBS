The number of train datas: 3448
The number of test datas: 862
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7085655916594574	0.49622969796098854	0.6988973972968878	0.46055684399438845
1	0.6970182198106275	0.5087006967471537	0.6899496457969506	0.5278422259952519
2	0.6901338068625766	0.5382830624375708	0.6827064776088688	0.5939675150503968
3	0.6841770266712127	0.552204176057519	0.6756906502484722	0.6299303912507962
4	0.6779093143558281	0.5693155452436195	0.667817028243691	0.6600928097755893
5	0.6642263617427056	0.6116589332677925	0.6581910612135088	0.6983758724206008
6	0.6544401359392152	0.6299303949847299	0.6466856044295769	0.7296983773913018
7	0.643485902218697	0.6447215786942749	0.6319650324480716	0.7366589339592617
8	0.6262279335418046	0.6815545247768304	0.6124122791389854	0.7656612546980519
9	0.6058362891115334	0.7015661261197862	0.5878603126499327	0.778422275164841
10	0.5775809864710213	0.7320185610700373	0.5570476306840051	0.7993039458367774
11	0.551496244638536	0.7502900232018561	0.5242972517787995	0.8097447812418926
12	0.5116281481049177	0.7845127600528248	0.4903247272747022	0.8074245956270435
13	0.4812706206209975	0.7911832942486916	0.4607344653517907	0.8167053376715587
14	0.44968112051625264	0.8152552211091026	0.43273367419873476	0.8225058017086817
15	0.4237537108828463	0.8314965201364592	0.4052232617983409	0.8248259874618247
16	0.38592272512874026	0.8419373555415745	0.3845187857781651	0.8341067297829277
17	0.3576966972196185	0.8564385145280311	0.35782382341659263	0.8422273795731936
18	0.34024904326053895	0.8680394434320401	0.3370248620720308	0.8549884004548641
19	0.3256968626981545	0.877030162412993	0.31730291447893927	0.8665893285291101
20	0.29870908311514177	0.8880510439452328	0.30200292450092786	0.8596287714079749
21	0.2809299463600681	0.8932714610254682	0.2765808586731311	0.889791184677602
22	0.25969834034514816	0.9048723889614203	0.25787465972717843	0.8979118340529865
23	0.24428269481437664	0.9077726213948633	0.23782987436258046	0.910672854934657
24	0.22875793990430587	0.9196635735007284	0.2201914823940348	0.9234338758163275
25	0.2128696993097075	0.9245939676556952	0.20291115391973552	0.9269141542386012
26	0.19605621927160674	0.9341647324871851	0.18622289722452584	0.9350348038905735
27	0.18177832196317525	0.9341647333169482	0.17511304701287342	0.9361948964214104
28	0.17898037116931376	0.9382250586961096	0.16422503519362475	0.9454756387425133
29	0.1590107226281874	0.9443155442755626	0.15188979744703754	0.9559164738710408
30	0.15168239916145387	0.9527262176825663	0.1351655972667747	0.9593967525699022
31	0.14555951092055114	0.9527262189272109	0.12568831326236857	0.9675174020835806
32	0.13121494541934361	0.9593967513252577	0.11679081380228985	0.9721577731749851
33	0.12767762326032545	0.9599767974523823	0.10835442545104193	0.9744779587898343
34	0.12812944278639596	0.9628770291943561	0.10346397147308646	0.9744779587898343
35	0.11518879601269476	0.9672273783285491	0.09704982036435134	0.9744779587898343
36	0.11708490550518036	0.9628770291943561	0.09199638851419126	0.9756380515972589
37	0.10440503233685018	0.969257540879836	0.0880172881027662	0.9779582372121081
38	0.10437972743383969	0.9709976788463283	0.08350940612242005	0.9825986084418065
39	0.09629597433620152	0.9730278427805535	0.07957705483704874	0.9825986084418065
40	0.09485365858349058	0.9762180967563266	0.07651974260807037	0.9802784228269572
41	0.09122735611109059	0.9733178644611775	0.08027082259859673	0.9791183296046512
42	0.08674275961525202	0.9770881676065396	0.07066345033333085	0.9860788865874925
43	0.08379542589049328	0.9785382833392327	0.0707175834687846	0.9837587008343496
44	0.07766996933419577	0.9808584692306695	0.06622357922336065	0.983758701249231
45	0.07396128360536425	0.9808584677094373	0.0642534113400497	0.9860788865874925
46	0.07740788161754608	0.9782482606905519	0.06368824308889372	0.983758701249231
47	0.0751953772042301	0.9802784225503696	0.06583853816211639	0.9872389792566233
48	0.07530428470909734	0.980278423103545	0.060592370025657996	0.9860788865874925
49	0.07338821013261436	0.9799883996251011	0.05997342908465392	0.9860788865874925
50	0.06961700486196443	0.9820185623146819	0.05874092261503578	0.9883990720640479
51	0.06786799292553329	0.9820185620380941	0.05797692542148024	0.9883990720640479
52	0.06517743260498113	0.984918793780068	0.057431040249609336	0.9895591648714724
53	0.0674612551253384	0.9808584689540819	0.05617842339238545	0.9860788865874925
54	0.06286326847676611	0.984918793780068	0.05612503417406724	0.9860788865874925
55	0.05846906434355645	0.9852088175350995	0.05465328442732309	0.9883990720640479
56	0.06290065818693134	0.9834686765261427	0.0558223949438458	0.984918793780068
57	0.058514386648852425	0.9846287708547995	0.05504584786095365	0.9860788865874925
58	0.060829102595416684	0.9825986081652188	0.05335027249119398	0.9883990720640479
59	0.054513710090704694	0.9852088157372796	0.052734778904444654	0.9883990720640479
60	0.05503766309997184	0.986368909512761	0.05310854939808702	0.9883990720640479
61	0.055435377490769405	0.9860788868640802	0.052181823520538705	0.9883990720640479
62	0.05836437050503811	0.983178654568931	0.052049174801102924	0.9883990720640479
63	0.057966466288659244	0.9860788865874925	0.052312477455061714	0.9883990720640479
64	0.05171095457126812	0.9872389781502726	0.05399595980646992	0.9837587009726434
65	0.05116446197828118	0.9881090492770732	0.050630568325727	0.9907192576788971
66	0.05230960870494422	0.986368910342524	0.05001198324070176	0.9907192576788971
67	0.045563425410651275	0.9892691405632656	0.053363410596089685	0.9837587009726434
68	0.04968315314527454	0.9872389796715049	0.04947227946636019	0.9907192576788971
69	0.050869790504399146	0.9878190257986295	0.05034645256130435	0.9883990720640479
70	0.04931532043592006	0.9895591647331786	0.04955214813455352	0.9907192576788971
71	0.04608546245817242	0.9881090483090164	0.0510020339537386	0.9872389792566233
72	0.04866029406852346	0.9895591647331786	0.049064083331698885	0.9907192576788971
73	0.03994726704265015	0.9875290031499486	0.04841934234387913	0.9907192576788971
74	0.047873505734754275	0.9886890951276102	0.04842186978480102	0.9907192576788971
75	0.04347644977081403	0.9892691420844979	0.04824264845411075	0.9907192576788971
76	0.043723900605796936	0.9904292348919225	0.04846095578991343	0.9907192576788971
77	0.041560466909076665	0.9904292351685101	0.04797803187038395	0.9907192576788971
78	0.04038527380597287	0.9901392114134786	0.049742949015856346	0.9872389792566233
79	0.043944225147401095	0.9883990709576972	0.04846548238929076	0.9907192576788971
80	0.045718237031640144	0.9878190245539848	0.04790714970874123	0.9907192576788971
81	0.03840347453778968	0.9921693741030594	0.04861565712156539	0.9895591648714724
82	0.04068342765702449	0.9883990724789294	0.04889624906388347	0.9895591648714724
83	0.03789459008144392	0.9898491869669779	0.047086853179605266	0.9907192576788971
84	0.04063787859737043	0.9895591647331786	0.04675526774365221	0.9907192576788971
85	0.038428602303678644	0.9912993044974909	0.049431769691597835	0.9883990720640479
86	0.04017706064987072	0.9889791183294664	0.04892974585433017	0.9883990720640479
87	0.03626839011008667	0.9907192580937786	0.047560515059395896	0.9907192576788971
88	0.03776680955581212	0.990719257817191	0.046752225322402544	0.9907192576788971
89	0.040154256860092455	0.9901392114134786	0.048430726952038344	0.9895591648714724
90	0.040746303638248875	0.9901392114134786	0.04642799814726526	0.9907192576788971
91	0.03839713126732136	0.992749420230184	0.04709762896642331	0.9918793504863217
92	0.03786784809800146	0.9912993044974909	0.048479617489048055	0.9883990720640479
93	0.03304057687590128	0.9918793496565587	0.04587856728557644	0.9907192576788971
94	0.035061692935684716	0.9927494199535963	0.04696326267207582	0.9907192576788971
95	0.035719684616872166	0.9898491884882101	0.04790578028857016	0.9907192576788971
96	0.0350436197459836	0.9895591637651218	0.046693224226515694	0.9918793504863217
97	0.03362757814594322	0.9933294663573086	0.04635592788596164	0.9907192576788971
98	0.03518213328674193	0.9912993042209032	0.046266679991287314	0.9907192576788971
99	0.03916569455178874	0.991589327699347	0.0500346528163089	0.9872389792566233

The optimal condition:
	epoch: 96
	train_acc: 0.9895591637651218
	val_acc: 0.991879350486
	using time: 208.139294147
