The number of train datas: 9696
The number of test datas: 2424
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6743976879041187	0.5838490099009901	0.630167011970734	0.7966171613227416
1	0.5683924792820078	0.7652640264026402	0.4538054340349959	0.9034653473215135
2	0.36692628264427185	0.885519801980198	0.2585451484415004	0.9146039615763296
3	0.23614238389451117	0.9254331683168316	0.2126788235586075	0.9129537961663979
4	0.19115020093744736	0.9319306928725919	0.20328885158247287	0.9141914199287742
5	0.1750159555240826	0.9376031355102463	0.19929992824350254	0.9158415849452758
6	0.16197162291201034	0.9439975245557602	0.1682799824147728	0.9323432351102924
7	0.15362327796692896	0.9464727722772277	0.17619953809840844	0.924917492536035
8	0.13823706273100164	0.9524546206587612	0.15951184108361552	0.9360561063974211
9	0.1351701224056801	0.9531765676567657	0.1494601055266637	0.9397689776845498
10	0.12215270500371953	0.957095709374242	0.15794299829370118	0.9344059413809194
11	0.11748148448052186	0.9601897691736127	0.14070086920074504	0.9443069314799293
12	0.11134719978956499	0.9622524752475248	0.14316511209500898	0.9443069314799293
13	0.10728666235511453	0.963180693266022	0.13794143861251892	0.9471947202588072
14	0.10200874888562526	0.9665841584158416	0.1351923736322536	0.9484323440211835
15	0.0922994787986129	0.969059406137309	0.124103745390283	0.9517326740541867
16	0.09256150101376052	0.9692656763709417	0.1125479298013665	0.9558580865954408
17	0.08909039469835388	0.9696782180184972	0.12144014021080515	0.9542079211855092
18	0.08741422413107586	0.9715346534653465	0.11199815871913245	0.9546204624396346
19	0.08128260449189754	0.9733910891089109	0.11664213577021074	0.9570957095709571
20	0.07785604328605601	0.974319306930693	0.10083011373041487	0.9616336637597667
21	0.07687549434430135	0.9760726070640111	0.10663681604558288	0.9599834987432649
22	0.07344046537533845	0.9764851485148515	0.10223222659783986	0.9632838287762683
23	0.07043800622273987	0.977207095512856	0.10664392412999774	0.9603960396039604
24	0.0692833356264204	0.9780321782178217	0.09786279986400416	0.9657590763010208
25	0.06526167466990625	0.9794760728039758	0.09816220785389737	0.9649339933993399
26	0.06347589573451001	0.980713696369637	0.10958677653542938	0.9608085808580858
27	0.05881191695434819	0.980713696566352	0.10386222508111999	0.9636963696369637
28	0.05845560378736198	0.9819513201320133	0.09961668718852128	0.9657590759075908
29	0.058892836542216075	0.9820544552488295	0.11272840944607512	0.9620462046204621
30	0.05778817896402315	0.9812293729372937	0.09700453951155687	0.9657590759075908
31	0.05515053445356514	0.9840140262059253	0.09879736557738124	0.966996699669967
32	0.05353445924892284	0.9839108908923939	0.1033482628308925	0.9657590759075908
33	0.05283545754333534	0.9838077557755776	0.09910993017993941	0.9674092409240924
34	0.05279725447002024	0.9850453795379538	0.10149825196375105	0.9661716171617162
35	0.05465851008596987	0.9836014853452298	0.1037988607731737	0.9661716171617162
36	0.048682836489905616	0.9864892741241077	0.09997259464157936	0.9665841584158416
37	0.05002016937759745	0.9853547854785478	0.1020023359197865	0.9661716171617162
38	0.04817323268025425	0.9850453797346688	0.09949345163933367	0.966996699669967
39	0.0485602973932677	0.9864892741241077	0.0944118858806838	0.9698844884488449
40	0.047493131155080526	0.98628300330033	0.08795287185763516	0.9702970297029703
41	0.0475208974218998	0.985973597163021	0.09298184195459627	0.9702970297029703
42	0.044398895301932945	0.9882425744541408	0.10078422007651956	0.966996699669967
43	0.04529369256087262	0.9872112213188272	0.09285654367036847	0.9707095709570958
44	0.04429995872867186	0.9875206268659913	0.09476614627593716	0.9694719471947195
45	0.04449345596847754	0.9870049504950495	0.09296906295327759	0.9698844884488449
46	0.04369353068986348	0.9884488450812035	0.08813603409710448	0.9731848184818482
47	0.042550351446119475	0.9875206272594212	0.09340498845858297	0.9702970297029703
48	0.04164096534793133	0.9881394387471794	0.098494112881964	0.9674092409240924
49	0.04168145053654221	0.9889645214521452	0.0926545678972952	0.9711221122112211
50	0.04262398032121139	0.9897896039603961	0.08405741046585462	0.9744224422442245
51	0.04002924280689888	0.9894801978230869	0.09150880934799661	0.9723597359735974
52	0.043168089758272805	0.988036303630363	0.09682757072857652	0.9686468646864687
53	0.03985187938750381	0.9889645212554302	0.08821382200831038	0.9735973597359736
54	0.04074425749456135	0.9892739271960242	0.09077983596838593	0.9731848184818482
55	0.03981827484695825	0.9896864684501497	0.09351548895688586	0.9707095709570958
56	0.03781431663793699	0.9902021454112364	0.09239624908790238	0.9723597359735974
57	0.038421112942592345	0.9899958745874587	0.08931725102295429	0.974009900990099
58	0.03750527879106428	0.9899958745874587	0.0892851851902066	0.974009900990099
59	0.03832997981667912	0.9896864688435797	0.09663360021092465	0.9702970297029703
60	0.03517788812278373	0.9914397689768977	0.0949569407231159	0.9723597359735974
61	0.03759324061914836	0.9898927390772124	0.09258377390972065	0.9723597359735974
62	0.034948191522519184	0.990924092409241	0.09629244706977663	0.9707095709570958
63	0.03602595129680417	0.9910272277227723	0.08663666432280795	0.9756600660066007
64	0.034660191616356965	0.9905115513518306	0.09082935417913171	0.9735973597359736
65	0.035949842395758866	0.9895833331366183	0.09528438771979594	0.971947194719472
66	0.03346826323606197	0.9906146866653619	0.08719092334095056	0.9760726072607261
67	0.03404240512439717	0.9910272277227723	0.09070877774953597	0.9731848184818482
68	0.03481283738422315	0.9916460398006754	0.10143469027612395	0.9698844884488449
69	0.033981046445741514	0.9911303630363036	0.0898844111409567	0.9735973597359736
70	0.034305229242091916	0.99123349815312	0.09403858918515295	0.9723597359735974
71	0.03452818638494502	0.9906146866653619	0.08932424667091554	0.9735973597359736
72	0.03171638974139203	0.9917491747207767	0.09342551393520468	0.971947194719472
73	0.03226886321437044	0.99123349815312	0.0913654582478143	0.9731848184818482
74	0.030444562158519678	0.9917491747207767	0.09607108271520941	0.9723597359735974
75	0.030282174940943325	0.9928836631696216	0.09232855516965363	0.9731848184818482
76	0.031205237772401802	0.9913366334666514	0.09047598792578128	0.9735973597359736
77	0.029757112747199662	0.9916460396039604	0.09159886589805556	0.9735973597359736
78	0.03076082997626499	0.991542904290429	0.08626751936265196	0.9752475247524752
79	0.02854579990182576	0.9926773929359889	0.09983955782825871	0.9707095709570958
80	0.03128591973469792	0.9920585808580858	0.09581253208256889	0.971947194719472
81	0.03033196124580163	0.9916460396039604	0.09292696545395397	0.9731848184818482
82	0.028951113496479816	0.9923679867986799	0.09268333240129398	0.9731848184818482
83	0.027303344634647418	0.9933993399339934	0.0891572729801212	0.974009900990099
84	0.029392622042410443	0.9919554453478394	0.08583078023642547	0.9752475247524752
85	0.02743439802979872	0.9926773925425589	0.09366293710644169	0.9731848184818482
86	0.0285404926141349	0.9926773927392739	0.09393631683880764	0.9731848184818482
87	0.02789966175609296	0.9924711223089262	0.08547327603388688	0.9756600660066007
88	0.0273659556501671	0.9932962048171771	0.08655091068360081	0.9748349834983498
89	0.027908517066204903	0.9926773927392739	0.09514508454479498	0.9723597359735974
90	0.02666795428952958	0.9921617161716172	0.0988754543088524	0.971947194719472
91	0.027298836169684485	0.9929867986798679	0.08955265781857541	0.9735973597359736
92	0.025400103801375765	0.9937087458745875	0.08582553175576155	0.9760726072607261
93	0.02629800887145225	0.9925742572290276	0.09528240790473845	0.9723597359735974
94	0.025117155365805718	0.9939150165016502	0.09423399312658352	0.9723597359735974
95	0.024843267770637775	0.9926773927392739	0.08520168180826425	0.9760726072607261
96	0.02526173156012993	0.9929867986798679	0.09618165100872418	0.9723597359735974
97	0.02654949854752018	0.9923679869953949	0.09783946158957633	0.9727722772277227
98	0.025697213416249053	0.9926773925425589	0.08827111543933845	0.9744224422442245
99	0.023761813347489134	0.992986798483153	0.08654553493294287	0.9760726072607261

The optimal condition:
	epoch: 99
	train_acc: 0.992986798483153
	val_acc: 0.976072607261
	using time: 781.149344921
