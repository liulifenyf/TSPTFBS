The number of train datas: 3330
The number of test datas: 834
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7168258396354882	0.5135135135135135	0.6961583250718151	0.505995204837488
1	0.7062235317430696	0.5063063063063064	0.6876637376755548	0.5635491583844741
2	0.6992689724083061	0.5201201201201201	0.6846540481638279	0.5611510802087166
3	0.6940826795480631	0.5264264264264265	0.6823060005117092	0.5791366907904189
4	0.686164433175737	0.5396396396396397	0.6801983669793291	0.5959232606762033
5	0.681808714465694	0.5522522522522523	0.6772248240397702	0.5971222998712846
6	0.6854193983493266	0.5525525525525525	0.6746409925625478	0.6139088730446155
7	0.6733808093958789	0.5855855855855856	0.6695747631345149	0.6199040763097987
8	0.6747188844480314	0.5897897897897898	0.665412467017734	0.6498800939221462
9	0.6677721335723236	0.5954954954954955	0.6601067960119362	0.6642685831307793
10	0.6610874609904246	0.603003003003003	0.6529446225658023	0.6714628288785902
11	0.6569633778509077	0.6057057057057057	0.6462850141868317	0.6810551575905414
12	0.6485282352736762	0.6333333333333333	0.6386165018561932	0.6966426841360773
13	0.6351492301837818	0.6684684684684684	0.6305784701729278	0.699040765384976
14	0.6293847058270429	0.6624624624624624	0.6199717949048507	0.7182254179490271
15	0.6160097775874553	0.6792792792792792	0.6089779480184011	0.7398081520478502
16	0.6009570264959478	0.7	0.5930234025136458	0.7470023996538395
17	0.5847439520351879	0.7066066066066066	0.5778239123541102	0.7577937671320616
18	0.5707046158320911	0.7333333333333333	0.5582880120483233	0.7721822524814012
19	0.539055579864943	0.7576576576576577	0.5350620808075371	0.7925659491003846
20	0.527892184543896	0.7549549549549549	0.5150919994004339	0.797362112169929
21	0.49984761823763	0.7858858858858859	0.49951018360878924	0.7913669057601361
22	0.4783371446189938	0.7927927927927928	0.47476247188856274	0.8069544347355978
23	0.4655532232454947	0.7963963963963964	0.46147820946695706	0.8213429266600301
24	0.43733666975934943	0.8162162162162162	0.4353533427921131	0.8405275787952706
25	0.41409049424323235	0.8258258258258259	0.4174617255906121	0.8441247023838602
26	0.39409246791948427	0.8483483483483484	0.4120546784475267	0.8381294974034352
27	0.3806592483330775	0.8465465465465466	0.39078689364792346	0.8525179866120683
28	0.3621641779805089	0.8663663663663663	0.3792957051766576	0.8609112718408343
29	0.3477114599746269	0.8732732732732733	0.37288161762040867	0.8645083954294237
30	0.33687498472832345	0.8726726726726727	0.37485199058942087	0.8561151077707323
31	0.31867403931826266	0.8846846846846846	0.3680760845434751	0.8561151077707323
32	0.3086719199343845	0.8840840840840841	0.3969317104319017	0.8441247025267969
33	0.3272180338387375	0.8762762762762762	0.35991720129831806	0.8621103127511571
34	0.3095809855663383	0.8882882882882883	0.34157661100228626	0.874100720425018
35	0.2911985771389337	0.8948948948948949	0.34935743631504707	0.8729016796576319
36	0.28413725029061865	0.9024024024024024	0.3302834564976269	0.8764988019597902
37	0.2769823888669143	0.8984984984984985	0.3355506401267841	0.8836930465641067
38	0.2647535588424485	0.9123123123123124	0.32733514894255633	0.8776978427271763
39	0.25991788329304877	0.9108108108108108	0.3226116235307652	0.8752997611924042
40	0.2664472055148792	0.9036036036036036	0.33100950024682557	0.8669064768212591
41	0.2863164219054374	0.9	0.3208223844317795	0.8776978427271763
42	0.2644208608474862	0.9114114114114115	0.316358199508356	0.8752997611924042
43	0.25078145779065186	0.9132132132132132	0.31982680101045885	0.8836930465641067
44	0.24398796827764482	0.9117117117117117	0.3328419825870642	0.8788968847809936
45	0.246462812862015	0.921021021021021	0.31126839619317503	0.8848920873314928
46	0.2378035782581872	0.9195195195195195	0.3106704434330801	0.8836930465641067
47	0.23280152339298088	0.9183183183183183	0.31734144973526185	0.8884892084901568
48	0.2302872422265935	0.9246246246246246	0.30699486280087945	0.8896882504010372
49	0.23439311965091808	0.9204204204204204	0.3156239799172472	0.8872901677227706
50	0.2273900192644861	0.9195195195195195	0.308787337381491	0.8848920873314928
51	0.2161912291352679	0.9255255255255255	0.3097070780732363	0.8824940057967207
52	0.22172512909671566	0.9240240240240241	0.3061704287211672	0.8848920873314928
53	0.21410189998020102	0.9261261261261261	0.3033387145693068	0.887290168866265
54	0.2109675397609805	0.93003003003003	0.30012306474524436	0.8920863319358094
55	0.21111226418354848	0.9285285285285285	0.2980886189628848	0.8884892096336511
56	0.21431112909639205	0.9297297297297298	0.3008719187417476	0.8884892084901568
57	0.20614492936177298	0.9327327327327327	0.30105255762164257	0.8872901677227706
58	0.21239291067953942	0.9288288288288288	0.2969782004396407	0.892086330792315
59	0.2024119846903168	0.9357357357357358	0.29378221335885624	0.8920863319358094
60	0.199071550968889	0.9309309309309309	0.31106292426014404	0.8860911293853101
61	0.20802360536815884	0.9306306306306307	0.30760167742804656	0.8860911293853101
62	0.21342322459449997	0.9282282282282283	0.2864944045063403	0.8932853727031955
63	0.19844976771376782	0.9303303303303303	0.289245430299704	0.8920863319358094
64	0.18842999349507664	0.9342342342342342	0.2901361956299066	0.8896882504010372
65	0.1892184419406427	0.9381381381381382	0.292297221595149	0.892086330792315
66	0.1870965924885896	0.9366366366366367	0.2883557085510638	0.8908872911684232
67	0.18792594397837692	0.9363363363363363	0.29035846796110093	0.8908872911684232
68	0.18748641859840703	0.9372372372372373	0.2860388305190084	0.8908872911684232
69	0.18236579376611264	0.9387387387387387	0.28835311260440655	0.8896882504010372
70	0.1774703575582761	0.9426426426426426	0.28408824929373444	0.8932853727031955
71	0.1739921455889627	0.9396396396396396	0.28618289555291193	0.8896882504010372
72	0.1780129872105859	0.9417417417417417	0.29464160213224605	0.8896882481140485
73	0.1753088624314503	0.93993993993994	0.28606569327467635	0.8884892096336511
74	0.17433182011853468	0.9423423423423424	0.2893486425316305	0.8932853715597011
75	0.17066090563843558	0.9465465465465466	0.2845270831664975	0.8932853727031955
76	0.16814459877329188	0.93993993993994	0.2926725885279173	0.8908872888814345
77	0.17029869594015518	0.9447447447447448	0.3301015450871534	0.8812949663157658
78	0.17155083106444763	0.942042042042042	0.2814216201396869	0.8932853738466898
79	0.18131428843436836	0.9375375375375375	0.2748402463589355	0.8920863319358094
80	0.15908249541222155	0.9525525525525526	0.283281797842442	0.8932853715597011
81	0.15965499200441458	0.9456456456456457	0.28535534141303825	0.8884892084901568
82	0.16207705775986206	0.9429429429429429	0.2858800995621464	0.8896882481140485
83	0.15657265129032077	0.9471471471471471	0.2755207710986515	0.8932853727031955
84	0.15773737341076047	0.9471471471471471	0.3063335491956281	0.8908872924548544
85	0.16327109585988808	0.9417417417417417	0.277751175012234	0.8944844134705816
86	0.15198730572767266	0.9495495495495495	0.2794431538032971	0.8920863319358094
87	0.1526609840760897	0.9498498498498499	0.2802923709082661	0.8956834530944733
88	0.14722405009799533	0.9513513513513514	0.27762710383470107	0.8920863330793037
89	0.14996315343333436	0.9486486486486486	0.2785127211531861	0.8920863319358094
90	0.15615334253053406	0.9459459459459459	0.2762854414449321	0.8920863295058838
91	0.16020384496217732	0.9471471471471471	0.2705528161151232	0.892086330792315
92	0.14769574671357244	0.951051051051051	0.2807979388274163	0.8920863319358094
93	0.13682979260859368	0.954954954954955	0.2790212762012756	0.8956834542379677
94	0.14087732057492655	0.9558558558558559	0.2775622446188252	0.8968824950053538
95	0.1363966895804346	0.954954954954955	0.2790327910825217	0.8968824950053538
96	0.13254699696067934	0.9546546546546546	0.2765658392037133	0.8932853738466898
97	0.1389091535373493	0.9540540540540541	0.27743686978622595	0.8968824961488482
98	0.13961539369512785	0.9531531531531532	0.277865309688113	0.8932853727031955
99	0.1285214058383628	0.9531531531531532	0.28409345104968803	0.892086330792315

The optimal condition:
	epoch: 97
	train_acc: 0.9540540540540541
	val_acc: 0.896882496149
	using time: 301.057311058
