The number of train datas: 3330
The number of test datas: 834
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7256090724432432	0.496996996996997	0.6968131934424384	0.49760191817935423
1	0.7101703117559622	0.5051051051051051	0.6868665511373707	0.5515587521399812
2	0.6984172637756164	0.5252252252252252	0.6836230577610666	0.5863309362523561
3	0.6942257569000886	0.5285285285285285	0.6809489869957062	0.587529975018627
4	0.6862237358236456	0.5480480480480481	0.6794642851792937	0.5767386098273938
5	0.680036546160151	0.5690690690690691	0.6736681178319368	0.6103117485984052
6	0.6824234581208444	0.5606606606606607	0.670159954961827	0.6378896886782108
7	0.6697495491297037	0.5963963963963964	0.6641221755414272	0.6486810545841281
8	0.6657148282449167	0.5996996996996997	0.6575381031139291	0.6582733792938489
9	0.6592080241925008	0.6075075075075075	0.6498043702946579	0.6942446061747252
10	0.6515919971036481	0.6195195195195196	0.6405417027233316	0.687050359855167
11	0.6443122119158954	0.6339339339339339	0.6312762787587923	0.7254196649832692
12	0.6372909671193486	0.6441441441441441	0.6228277971990389	0.7242206243588198
13	0.6211454317734406	0.6732732732732732	0.6122966917584555	0.7194244605745915
14	0.6134973368487201	0.6744744744744745	0.5973808592457851	0.7541966432575985
15	0.5979246783900906	0.7009009009009008	0.5869242721896092	0.770983213143383
16	0.5757703140691236	0.7255255255255255	0.570828143212435	0.7637889669667617
17	0.567380311396029	0.7231231231231231	0.5514023604152871	0.7841726627281244
18	0.5481818825453967	0.748048048048048	0.5323533302874303	0.7925659492433214
19	0.5209834347795079	0.772972972972973	0.5140997239296956	0.805755396541074
20	0.5010533135932487	0.7753753753753754	0.49312629073643854	0.8201438856067703
21	0.4764164223864272	0.8045045045045045	0.47676683272675074	0.8045563543443199
22	0.4629348825406026	0.7936936936936937	0.45548359438669767	0.8225419671415425
23	0.4479339794622169	0.8114114114114114	0.44583382530749843	0.8417266185620992
24	0.42580452790489426	0.8324324324324325	0.42339180813704747	0.8537170262359601
25	0.4083095393023333	0.8378378378378378	0.4204674897719916	0.8489208631664157
26	0.3924616236228485	0.8465465465465466	0.4161724967779301	0.8429256593294853
27	0.3808510387444997	0.8492492492492493	0.3937220564134401	0.8609112708402766
28	0.3664139123292299	0.8615615615615616	0.3836412285443404	0.8441247009544921
29	0.3730374083773152	0.8576576576576577	0.37191415068914563	0.8681055165880875
30	0.3404554559840812	0.878078078078078	0.3750359957381118	0.8621103116076627
31	0.32692999896165487	0.8801801801801802	0.3679308072268534	0.8633093523750488
32	0.3150523949671794	0.8855855855855855	0.3875442288405032	0.8537170250924657
33	0.3280125384842669	0.8798798798798799	0.3641091351457637	0.8693045562119792
34	0.30767727785550797	0.8906906906906907	0.3454835851201051	0.8752997611924042
35	0.2993177188722579	0.8933933933933934	0.35671572394365314	0.8705035969793654
36	0.2919610092187071	0.8993993993993994	0.3368868357200417	0.8812949650293346
37	0.28868022742751126	0.8972972972972973	0.3384261859192265	0.8752997611924042
38	0.2771794577523529	0.9042042042042042	0.33841085101631907	0.8776978427271763
39	0.2662214539251528	0.9114114114114115	0.32746577491577294	0.8812949650293346
40	0.27396756707727016	0.9039039039039038	0.33000898389793415	0.881294962599409
41	0.30272222596245846	0.8885885885885886	0.3283221865300652	0.8800959254054429
42	0.2803845493315912	0.9078078078078078	0.32065944963221926	0.8836930465641067
43	0.2576623506732173	0.9132132132132132	0.3636213623934227	0.8645083919989405
44	0.2601230671679651	0.9096096096096096	0.3377342632562994	0.8764988019597902
45	0.2520789753254111	0.9141141141141141	0.3268388519755942	0.8800959242619485
46	0.24534101933688374	0.9171171171171171	0.3251700287314056	0.8800959242619485
47	0.24411416322261364	0.9159159159159159	0.344745412611847	0.8752997589054153
48	0.24557906562859588	0.921021021021021	0.3229370554931444	0.8788968834945624
49	0.24254955477542706	0.9198198198198199	0.335042875233314	0.878896882351068
50	0.23359589290332508	0.9234234234234234	0.321167381940414	0.8848920873314928
51	0.22871263574853584	0.9261261261261261	0.3152476664570024	0.8836930465641067
52	0.23437231675282613	0.9186186186186186	0.3145209275346866	0.8848920873314928
53	0.22098963848586464	0.9279279279279279	0.31481269873875223	0.8884892096336511
54	0.22335523046978242	0.9276276276276276	0.3079979485816521	0.887290168866265
55	0.22592551933752525	0.9252252252252252	0.3074112845410546	0.8932853702732699
56	0.23619559218396655	0.9183183183183183	0.3171091440627329	0.8872901677227706
57	0.22018947691486046	0.9255255255255255	0.3145256150755093	0.8872901677227706
58	0.21280950926266634	0.9279279279279279	0.3192100489525486	0.8848920861879984
59	0.21789793912489136	0.9297297297297298	0.30292408418455286	0.8860911280988789
60	0.21289800356726746	0.9303303303303303	0.30992288112068633	0.892086330792315
61	0.21486665439140332	0.9309309309309309	0.31015837767856014	0.8920863319358094
62	0.21292625122868622	0.9258258258258258	0.30395192947747895	0.8896882504010372
63	0.21107593482365838	0.9303303303303303	0.3033803620641466	0.8896882504010372
64	0.19907028078361674	0.9351351351351351	0.30595485923244514	0.8908872911684232
65	0.19710554915505488	0.9345345345345345	0.3182553891583884	0.8884892084901568
66	0.2008859952290853	0.9351351351351351	0.30238623720564717	0.8932853727031955
67	0.20560645566688285	0.9321321321321321	0.3002995097880169	0.8908872911684232
68	0.19640883210901025	0.9330330330330331	0.30694812625575124	0.890887290024929
69	0.1938512438329289	0.9351351351351351	0.3054035578986152	0.892086330792315
70	0.19165081375644907	0.9387387387387387	0.30014045043386145	0.8908872911684232
71	0.18585088166321542	0.9369369369369369	0.3019385901000574	0.8944844123270872
72	0.19136818101903696	0.9390390390390391	0.30599564671230545	0.892086330792315
73	0.18168588704891034	0.9432432432432433	0.308092950845508	0.8932853715597011
74	0.18299514531820743	0.9426426426426426	0.297016473160945	0.8884892107771455
75	0.1835197224676072	0.93993993993994	0.29450240559715163	0.8908872911684232
76	0.18329859282877353	0.9402402402402402	0.3530067203463696	0.8776978440136075
77	0.20515297887561557	0.9294294294294294	0.32759787142276764	0.8812949627423458
78	0.18670669289322586	0.9342342342342342	0.28668913073676955	0.8968824925754282
79	0.19123364465462195	0.9384384384384384	0.2856767166146843	0.8968824950053538
80	0.17571084195518638	0.9444444444444444	0.2963450115075786	0.8944844123270872
81	0.16918416550836046	0.9453453453453453	0.2929138227832689	0.895683455381462
82	0.18024274394274115	0.9381381381381382	0.293615561059053	0.892086330792315
83	0.17188397141190262	0.9429429429429429	0.28427196688932194	0.8944844146140759
84	0.17558158868783946	0.9423423423423424	0.34177331504918973	0.8776978440136075
85	0.19709677614898116	0.936036036036036	0.2887644319297027	0.8944844134705816
86	0.17607658584196648	0.9438438438438439	0.28419041576431237	0.895683455381462
87	0.17442245551261928	0.9414414414414415	0.29128249568476094	0.8932853727031955
88	0.16309954293139345	0.9492492492492492	0.2830655522269311	0.9004796184510064
89	0.16452040610549687	0.9468468468468468	0.28484216307421667	0.8944844146140759
90	0.1645983569972866	0.9462462462462462	0.2780042635165244	0.9016786592183925
91	0.18750224143277866	0.9369369369369369	0.28118035318754275	0.892086330792315
92	0.16373099899506785	0.9477477477477477	0.3011029898334178	0.892086330792315
93	0.15770362458966516	0.9486486486486486	0.291421334270379	0.8944844123270872
94	0.1518484884487079	0.9492492492492492	0.2858532168310609	0.8980815369162343
95	0.15710357029337782	0.9447447447447448	0.2851893217157689	0.8968824961488482
96	0.1511505424394622	0.9507507507507508	0.285097121870775	0.9004796184510064
97	0.1510350743728178	0.9507507507507508	0.2844569893906728	0.8944844146140759
98	0.148212681804132	0.9513513513513514	0.2839056422098649	0.8968824961488482
99	0.14389826204549444	0.9519519519519519	0.29479548413690615	0.8932853727031955

The optimal condition:
	epoch: 90
	train_acc: 0.9462462462462462
	val_acc: 0.901678659218
	using time: 235.904395103
