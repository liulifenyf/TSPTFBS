The number of train datas: 3330
The number of test datas: 834
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7168225937777454	0.5078078078078078	0.7021566263491588	0.5023980823923929
1	0.7046744282181199	0.5195195195195195	0.6912136968377111	0.5311750610955328
2	0.6988335537838865	0.5180180180180181	0.6863982653160461	0.5479616317674696
3	0.6887019565155557	0.5480480480480481	0.6827230846567406	0.5731414859529308
4	0.6822676769963972	0.5606606606606607	0.6791991328449843	0.5911270987501533
5	0.6781707702456294	0.5645645645645646	0.6749255372751817	0.6103117484554684
6	0.6787114393245709	0.5657657657657658	0.6707253155948447	0.6235011980402098
7	0.6657165441427145	0.5942942942942943	0.6652131143519633	0.6462829729064191
8	0.6636176702854512	0.6012012012012012	0.6581798526022932	0.6426858503183872
9	0.6536465311193609	0.6192192192192192	0.6497286086459811	0.671462829021527
10	0.6457090545344997	0.6348348348348348	0.641577862721267	0.6606714628297362
11	0.6417430201450268	0.642942942942943	0.6340068491528646	0.6906474802991469
12	0.6286910170191401	0.6630630630630631	0.6232360591419595	0.701438848492053
13	0.6139844601218765	0.6888888888888889	0.610189025207675	0.7362110314609336
14	0.6081239008330726	0.6771771771771772	0.5968374645681405	0.7565947237918131
15	0.5879004163427037	0.7057057057057057	0.5839244078675048	0.7589928054695221
16	0.5763588973530778	0.7267267267267268	0.5663435384809828	0.7829736193878759
17	0.5608718894265435	0.7288288288288288	0.5526310453454939	0.7781774566042051
18	0.5365525670237727	0.7537537537537538	0.5272000491333236	0.7949640296345992
19	0.5157063342250503	0.7645645645645646	0.5083206774090692	0.8033573150063018
20	0.4983686387717903	0.7732732732732732	0.4922945059174828	0.8117505989486365
21	0.4824593107263605	0.7903903903903904	0.4728203393000779	0.8237410079089286
22	0.45274103393067827	0.8081081081081081	0.4498398206788573	0.8357314168692207
23	0.4380652945768368	0.8135135135135135	0.45207420920582414	0.8129496412883274
24	0.4170797021897347	0.8315315315315316	0.41381316069218754	0.840527579938765
25	0.40101235763088716	0.8342342342342343	0.40299999585254587	0.8525179877555628
26	0.3801894607531416	0.8486486486486486	0.4080412299227086	0.8357314170121575
27	0.37296532520481773	0.851951951951952	0.37990147104080346	0.8621103138946515
28	0.36192955390827075	0.8531531531531531	0.37191733160464885	0.8525179853256372
29	0.35292257584251086	0.8702702702702703	0.36772187829589387	0.8621103138946515
30	0.3343456645090659	0.86996996996997	0.3769428910826036	0.8549160692903349
31	0.3237599342524468	0.8801801801801802	0.3546147057049566	0.868105517731582
32	0.312100163379589	0.8792792792792793	0.3985471673649278	0.8405275777947131
33	0.3291614579322102	0.8717717717717718	0.3594332010768872	0.8621103138946515
34	0.3063035413622856	0.890990990990991	0.3418795729784085	0.869304558498968
35	0.2951180306193349	0.893993993993994	0.3464621482349986	0.8681055165880875
36	0.2864154606610089	0.9012012012012012	0.3215353889145154	0.8741007179950925
37	0.28807517231942653	0.8936936936936937	0.32734077650723126	0.8729016808011263
38	0.27146518370052714	0.8996996996996997	0.32323218592636876	0.8776978438706706
39	0.26508487028939587	0.9027027027027027	0.3167215167618484	0.8824940069402151
40	0.2715808747408984	0.903003003003003	0.3158650322497892	0.8729016772277064
41	0.29103938094130505	0.8948948948948949	0.315274730289011	0.8741007179950925
42	0.2728478507572287	0.9	0.3133095139079243	0.881294966172829
43	0.2589449249403747	0.9051051051051051	0.32035256775734805	0.8752997611924042
44	0.24673513992054685	0.9141141141141141	0.323814765762368	0.8729016796576319
45	0.25237341701268434	0.912012012012012	0.31555323159809023	0.8776978427271763
46	0.24168603115074627	0.9141141141141141	0.3111132099974356	0.8824940069402151
47	0.2382314369485185	0.9177177177177177	0.339478593507259	0.8741007181380293
48	0.24591828681327202	0.9123123123123124	0.31086303508110186	0.8812949650293346
49	0.2438798188805222	0.9177177177177177	0.33237922874143083	0.8800959219749597
50	0.23569926380574166	0.9207207207207208	0.31253078222560654	0.8812949638858402
51	0.22473667436936595	0.9177177177177177	0.3104742389145515	0.8812949638858402
52	0.2277443171621443	0.9240240240240241	0.3100366380146081	0.8812949638858402
53	0.2250292618633122	0.9204204204204204	0.30398744191054244	0.8836930465641067
54	0.22241748841675194	0.9246246246246246	0.3020437315142126	0.8848920861879984
55	0.2181742051700214	0.9303303303303303	0.29702520527713877	0.8848920860450616
56	0.23220672750616217	0.9186186186186186	0.3053061114512473	0.8836930454206123
57	0.2131528194691684	0.9324324324324325	0.3047941949584787	0.8824940046532262
58	0.2217653826102838	0.9219219219219219	0.3019652514220428	0.8824940046532262
59	0.21285362568524507	0.9258258258258258	0.29481819043342444	0.8884892096336511
60	0.2081164347158896	0.9288288288288288	0.32926102204145574	0.8776978404401875
61	0.21330965331366827	0.9318318318318318	0.3334965705335569	0.8764987996728014
62	0.22753774495991141	0.9219219219219219	0.30132235818915515	0.8800959219749597
63	0.20624088367318605	0.9324324324324325	0.2942040532970314	0.892086330792315
64	0.20135283191596065	0.9306306306306307	0.29655759851280733	0.8860911269553845
65	0.19388349071234554	0.9378378378378378	0.2948194066111704	0.8884892084901568
66	0.1957888440640123	0.9363363363363363	0.29371594217755526	0.890887290024929
67	0.19741890338940304	0.9342342342342342	0.2912403160362221	0.890887290024929
68	0.19144793676810937	0.9393393393393393	0.29096671492218684	0.890887290024929
69	0.1865406430765494	0.9378378378378378	0.2979605849698293	0.8860911269553845
70	0.18534139140813916	0.9336336336336336	0.2916426951650807	0.8932853715597011
71	0.18317013697715492	0.9348348348348349	0.2988804386531135	0.8848920861879984
72	0.1881238251387536	0.9387387387387387	0.2927751184867726	0.8872901677227706
73	0.17844071088878957	0.9414414414414415	0.2972069936904976	0.8860911269553845
74	0.18398424775392802	0.9417417417417417	0.30509641191227543	0.8860911269553845
75	0.18935599276969384	0.9375375375375375	0.28734822896458834	0.8944844134705816
76	0.1809869088926115	0.9387387387387387	0.30349730941460284	0.8860911269553845
77	0.18007416286626018	0.9375375375375375	0.32708002589374996	0.8800959219749597
78	0.17907740568613506	0.9402402402402402	0.2823335326832833	0.8932853702732699
79	0.17664454357849585	0.9387387387387387	0.2849959404134064	0.8932853715597011
80	0.17437649215753373	0.9387387387387387	0.28872721533266477	0.8956834530944733
81	0.17103884690650947	0.9426426426426426	0.285584696155372	0.8980815346292454
82	0.1727564501332807	0.9456456456456457	0.29330733039682144	0.8896882492575429
83	0.16234593616949544	0.9456456456456457	0.28390924075095775	0.8980815357727399
84	0.16472981530087846	0.9477477477477477	0.2911367353489645	0.8896882492575429
85	0.1667220138035737	0.9426426426426426	0.28683896927381874	0.8932853715597011
86	0.15991823666871668	0.9471471471471471	0.2887252250449549	0.8896882492575429
87	0.1611733666651913	0.9495495495495495	0.2906873237243373	0.8896882492575429
88	0.15912852086820403	0.9468468468468468	0.28901855772633633	0.8896882479711117
89	0.1716726531316568	0.9405405405405406	0.29282114524349606	0.8860911279559421
90	0.17605014584801934	0.9372372372372373	0.28872540085721643	0.884892087188556
91	0.1742802759481443	0.9411411411411411	0.2764167300731444	0.8980815346292454
92	0.16083419237050925	0.9486486486486486	0.2939523890149965	0.8920863296488206
93	0.1444390841740164	0.9516516516516517	0.2898558119861342	0.890887290024929
94	0.15531728120000513	0.9507507507507508	0.28666899290730913	0.890887290024929
95	0.1510454562322066	0.9495495495495495	0.2868433623648376	0.892086330792315
96	0.14559340678300853	0.9546546546546546	0.2827438448759006	0.8980815357727399
97	0.14909246217112643	0.951051051051051	0.28285849637550703	0.8980815369162343
98	0.1489899279104333	0.948948948948949	0.2833561973034335	0.8980815357727399
99	0.13972708001207035	0.9552552552552552	0.2940890793320086	0.8956834519509789

The optimal condition:
	epoch: 97
	train_acc: 0.951051051051051
	val_acc: 0.898081536916
	using time: 318.028229952
