The number of train datas: 3330
The number of test datas: 834
epoch	train_loss	train_acc	val_loss	val_acc
0	0.716183595650189	0.5162162162162162	0.6908650372525771	0.5419664264297028
1	0.702865341046193	0.5123123123123123	0.682927593052816	0.547961631481596
2	0.6973151021175557	0.5303303303303303	0.6805334855898393	0.5587529984595393
3	0.6908627829036197	0.5342342342342342	0.677155728534543	0.5911270984642797
4	0.6844198763907493	0.548948948948949	0.6721961198093223	0.6211031163625008
5	0.6771270716870511	0.5777777777777777	0.6671828844850298	0.6294964025203559
6	0.6788398758427159	0.5630630630630631	0.6624898568903513	0.6546762568487537
7	0.6649626377824549	0.5954954954954955	0.6559695307013514	0.6690647483443757
8	0.6703801208072239	0.5894894894894895	0.6507378379218012	0.6762589928057554
9	0.6567102350630202	0.6246246246246246	0.6437345184296441	0.6966426871377501
10	0.6518694151987184	0.624024024024024	0.6344369624158461	0.6966426858513189
11	0.644621576060046	0.6249249249249249	0.6244615429311061	0.7314148693919468
12	0.6330474325844475	0.6567567567567567	0.6164255469537182	0.7470023975097876
13	0.6185775906832011	0.6801801801801802	0.604903784444292	0.7589928070418268
14	0.6133241280063136	0.687987987987988	0.5933399580651336	0.7625899276287436
15	0.5992851837977274	0.7054054054054054	0.5775200042793219	0.784172663728682
16	0.5794071511105374	0.7231231231231231	0.5616542329605249	0.7781774583194467
17	0.5603736043155372	0.7336336336336337	0.5431726594908918	0.8045563557736879
18	0.5414608319242438	0.7534534534534535	0.5213922163565382	0.8189448461258154
19	0.5173948065117673	0.7687687687687688	0.49654710778801275	0.8321342944241256
20	0.49380117980567545	0.7846846846846847	0.47676643064553786	0.8429256590436117
21	0.4650137265165289	0.8123123123123123	0.45631726282677776	0.8177458037861245
22	0.44340215803266647	0.8126126126126126	0.4326759931280744	0.8393285388855054
23	0.4359660915605299	0.8165165165165165	0.4400211776332032	0.8285371725507777
24	0.41657874322868327	0.8351351351351352	0.3941543411722572	0.8609112694109087
25	0.38911245640691694	0.8486486486486486	0.38389168054365713	0.8645083931424349
26	0.3750436696920309	0.8525525525525526	0.395995172022058	0.8489208655963413
27	0.3612868218942805	0.8660660660660661	0.36347642283645465	0.865707433909821
28	0.3472857967869298	0.86996996996997	0.34497223061909205	0.87410071899565
29	0.33280016258582695	0.8858858858858859	0.34158124862243233	0.8729016785141376
30	0.3210581644161328	0.887987987987988	0.3605796800528785	0.8597122325028161
31	0.30518806243354496	0.8894894894894895	0.338431586643203	0.8693045550684849
32	0.293380438816082	0.8966966966966967	0.39284388188549657	0.8429256606159164
33	0.3066902051190356	0.8864864864864865	0.3372819286456211	0.870503595835871
34	0.2949934463869702	0.8957957957957958	0.325855132773054	0.8764987996728014
35	0.27771285771987997	0.9033033033033033	0.32298890352963827	0.8752997600489097
36	0.2796384159285385	0.9054054054054054	0.312728341713512	0.878896882351068
37	0.27948739758214436	0.9069069069069069	0.3151958675192986	0.8788968812075736
38	0.2696860560711037	0.9066066066066066	0.3167397470282708	0.8812949627423458
39	0.25751341363868196	0.9105105105105105	0.29995946854138544	0.890887290024929
40	0.262395631944811	0.9129129129129129	0.29802809401953534	0.8884892072037256
41	0.2817334293245195	0.9021021021021021	0.316674157405357	0.8800959244048853
42	0.2543793655260726	0.9135135135135135	0.2975158320485259	0.8872901677227706
43	0.24521198713027678	0.9213213213213213	0.29759665462467594	0.8896882492575429
44	0.23551543107082895	0.9195195195195195	0.3083482717367099	0.8836930478505379
45	0.242711100201528	0.9219219219219219	0.30233135347743684	0.884892088617924
46	0.24071730367235236	0.9198198198198199	0.29300742287287035	0.8896882481140485
47	0.23054800822928145	0.9237237237237237	0.3249848937209276	0.8741007205679548
48	0.23118224659481565	0.9228228228228228	0.3137769833814612	0.8788968836374992
49	0.2437562134888795	0.9183183183183183	0.3031229326050344	0.8860911282418157
50	0.22933306286821853	0.9258258258258258	0.29312688726887143	0.896882496291785
51	0.2186208676736992	0.9258258258258258	0.2862676988474185	0.896882492718365
52	0.2209177356716749	0.9252252252252252	0.2843840105070485	0.898081537059171
53	0.21427788558128003	0.9258258258258258	0.28643413852873467	0.8956834555243989
54	0.21458457701199046	0.9303303303303303	0.28395996298149623	0.898081537059171
55	0.21476524341571795	0.9264264264264265	0.27567367909623564	0.8992805753966315
56	0.23548081791973688	0.9126126126126126	0.2968174007227667	0.8908872913113601
57	0.21085979541142783	0.9294294294294294	0.28427867462737955	0.8968824951482905
58	0.21263584572452682	0.9297297297297298	0.28497517673517586	0.8956834543809045
59	0.20331385826787074	0.9348348348348349	0.2760179555244583	0.8944844111835928
60	0.20648308137694638	0.9267267267267267	0.28501175226067466	0.8980815359156766
61	0.21079248411877377	0.9312312312312312	0.2833475163228792	0.8956834543809045
62	0.20822107350235586	0.93003003003003	0.27670680175868156	0.9016786582178349
63	0.2021989059273724	0.9336336336336336	0.2745441052196123	0.898081537059171
64	0.19257997078065936	0.9357357357357358	0.27701392158758725	0.8992805766830627
65	0.20097201627654	0.9324324324324325	0.2765007740516457	0.8992805766830627
66	0.19541029446833844	0.9342342342342342	0.2739217927773222	0.8992805778265571
67	0.19649105975935768	0.9321321321321321	0.2895643050364739	0.8920863320787462
68	0.19520904515777623	0.9345345345345345	0.2735466002631816	0.9028777001287154
69	0.18966670021660872	0.936036036036036	0.2797643917856171	0.8956834543809045
70	0.18921973642867965	0.9351351351351351	0.26847595644654704	0.9004796150205232
71	0.18425009095196698	0.9354354354354354	0.27075862873801226	0.8992805766830627
72	0.18590392962590352	0.9387387387387387	0.2712581629733102	0.9016786593613293
73	0.18054879101457538	0.93993993993994	0.2744078826990059	0.8980815359156766
74	0.18039470590628662	0.9402402402402402	0.2723081131204427	0.898081537059171
75	0.1784354208132347	0.9348348348348349	0.272693990446109	0.8980815359156766
76	0.18043316690413444	0.9408408408408409	0.3067356399852309	0.889688250543974
77	0.1998781568742729	0.9303303303303303	0.3105435922956295	0.8908872913113601
78	0.1781345521365558	0.9390390390390391	0.26021994443105567	0.9028776965552955
79	0.18734774129974233	0.9369369369369369	0.26687008131751055	0.9016786582178349
80	0.17291797805387338	0.9438438438438439	0.2716703997741786	0.902877698985221
81	0.17047939444626417	0.9432432432432433	0.2655841752493696	0.9064748212873793
82	0.171491988014441	0.9405405405405406	0.2709779689352004	0.902877698985221
83	0.16841930054329537	0.9441441441441442	0.25836025106964067	0.9028776965552955
84	0.17381181344613655	0.9414414414414415	0.33091097099961136	0.8693045574984104
85	0.1974352018577648	0.9315315315315316	0.26168956637954255	0.9016786582178349
86	0.1650861434034399	0.9453453453453453	0.2623829449966943	0.9064748212873793
87	0.16709983320487243	0.9435435435435435	0.26835606827867403	0.9016786582178349
88	0.15701747617206058	0.9501501501501501	0.25761038994045854	0.9052757816634875
89	0.17057745685806502	0.9426426426426426	0.2620264186347417	0.902877698985221
90	0.16482722508656728	0.9408408408408409	0.2538196830440768	0.9052757816634875
91	0.1767249658524811	0.9414414414414415	0.2640033177406096	0.8992805766830627
92	0.1644713668851881	0.9459459459459459	0.27863561231598294	0.8944844136135184
93	0.15573449157200775	0.9459459459459459	0.2653564633153897	0.902877698985221
94	0.15625708831681145	0.9498498498498499	0.25799078042272755	0.9052757816634875
95	0.1544332481529172	0.9456456456456457	0.2591742099189072	0.9076738620547654
96	0.15038056909456268	0.951051051051051	0.257871481440336	0.9076738631982597
97	0.1522846308019426	0.948948948948949	0.26138621833112885	0.9100719435895376
98	0.1489329607102897	0.9480480480480481	0.2618034559545471	0.9088729028221515
99	0.1446136606661407	0.9495495495495495	0.271997221332374	0.9004796174504488

The optimal condition:
	epoch: 97
	train_acc: 0.948948948948949
	val_acc: 0.91007194359
	using time: 262.442422867
