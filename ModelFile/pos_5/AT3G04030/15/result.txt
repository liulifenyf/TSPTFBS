The number of train datas: 9792
The number of test datas: 2448
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7055791822913425	0.508578431372549	0.6856834031398	0.545751633986928
1	0.6898927466542113	0.5387050653594772	0.6796372552323185	0.5890522875816994
2	0.6852174475302104	0.546875	0.6742065120366664	0.6127450980392157
3	0.6777419619310915	0.5742442810457516	0.6665737235468198	0.6405228758169934
4	0.6737617667204414	0.579248366013072	0.6583824399250006	0.6556372549019608
5	0.6652038744072509	0.602328431372549	0.6466827236748989	0.6858660130718954
6	0.6528946691089206	0.6283700980392157	0.6307696894882551	0.7107843137254902
7	0.6412807227739321	0.6453227124183006	0.6121214293186961	0.7299836601307189
8	0.6261977744258307	0.6626838235294118	0.5907114954555736	0.7467320261437909
9	0.6082400091333326	0.6769812091503268	0.5663630023501278	0.7589869281045751
10	0.5863285921757517	0.6985294117647058	0.5383049027592528	0.7716503267973857
11	0.5629792766633377	0.7179330065359477	0.5106478485406614	0.7883986928104575
12	0.5413885155534433	0.7417279411764706	0.4836622823297588	0.7969771241830066
13	0.5156532442258075	0.7573529411764706	0.4582870957119013	0.8100490196078431
14	0.48656293107014076	0.7790032679738562	0.43322887666085186	0.8198529411764706
15	0.4615414053006889	0.7962622549019608	0.40797632971620246	0.8280228758169934
16	0.4392511768668306	0.8103553921568627	0.38104289059155905	0.8484477124183006
17	0.41256260092741526	0.829248366013072	0.3577567851231768	0.860702614379085
18	0.38990923411705913	0.8463031045751634	0.3386690501683678	0.8754084967320261
19	0.37250858818004334	0.8542687908496732	0.3224072910212224	0.8839869281045751
20	0.3486992062306872	0.8709150326797386	0.3069489143447938	0.891748366013072
21	0.330690782054577	0.8818423202614379	0.2933673710604898	0.8921568627450981
22	0.32060657022825256	0.8854166666666666	0.28154713879613313	0.9027777777777778
23	0.31047172600926914	0.891748366013072	0.27329672717191034	0.9064542483660131
24	0.29558125469419694	0.8979779411764706	0.2644353275205575	0.9089052287581699
25	0.2890533064705095	0.9026756535947712	0.25568099271238237	0.9097222222222222
26	0.278888525526508	0.9044117647058824	0.25295144718846463	0.9183006535947712
27	0.27523162444822147	0.9108455882352942	0.24516263633382088	0.9166666666666666
28	0.26449112204554814	0.9133986928104575	0.24048283900700362	0.9195261437908496
29	0.2559197083407757	0.9171772875816994	0.23545803782207514	0.9183006535947712
30	0.24636632301448996	0.9193218954248366	0.23157905938189013	0.9191176470588235
31	0.24366147864877788	0.9215686274509803	0.23233010955885344	0.9219771241830066
32	0.24112234756447912	0.9222834967320261	0.22635494703366085	0.9199346405228758
33	0.24015946403827543	0.9235089869281046	0.2231727497639999	0.9223856209150327
34	0.2326416780356488	0.9243259803921569	0.21968883373378928	0.9244281045751634
35	0.2275677401255938	0.927593954248366	0.22366299972035528	0.9219771241830066
36	0.22561436229281956	0.9277982026143791	0.2180712395438961	0.9219771241830066
37	0.22351343413583594	0.9288194444444444	0.21321712297941345	0.9248366013071896
38	0.21584613733237085	0.9303513071895425	0.21226971211776235	0.9248366013071896
39	0.21613446296819674	0.9309640522875817	0.21442172486408084	0.923202614379085
40	0.21051711925104552	0.9310661764705882	0.20924569783257504	0.9256535947712419
41	0.2099908220222573	0.9322916666666666	0.20819032124054979	0.9244281045751634
42	0.20004885590154362	0.9336192810457516	0.21025666818509695	0.9248366013071896
43	0.20292158770600174	0.9328022875816994	0.2046951021926076	0.9227941176470589
44	0.19805077633826562	0.9352532679738562	0.2066327319328302	0.926062091503268
45	0.1958962036114113	0.9362745098039216	0.20098150677345936	0.9244281045751634
46	0.19475949706594928	0.9367851307189542	0.2016376798448999	0.926062091503268
47	0.19207072063209185	0.9371936274509803	0.19971135083366842	0.9256535947712419
48	0.18780870940171035	0.938827614379085	0.1974064626919678	0.9240196078431373
49	0.18409853686694228	0.938623366013072	0.19704145728762634	0.9252450980392157
50	0.18164103278537203	0.9396446078431373	0.19626537408509287	0.9223856209150327
51	0.18026582312350178	0.9387254901960784	0.19610490981075498	0.9268790849673203
52	0.17741498185528648	0.9404616013071896	0.19452465464379273	0.9272875816993464
53	0.173901286097913	0.9417892156862745	0.19222670121520175	0.9244281045751634
54	0.17419600155618456	0.9430147058823529	0.19133352519932137	0.9276960784313726
55	0.17031424468249276	0.9429125816993464	0.1910185874774565	0.9276960784313726
56	0.16869881807589063	0.9440359477124183	0.19171792263883392	0.9285130718954249
57	0.16586759735166637	0.9438316993464052	0.19519849316357007	0.9281045751633987
58	0.1660688704524944	0.9463848039215687	0.1879757859445865	0.9268790849673203
59	0.1619259880648719	0.946078431372549	0.18755163123307664	0.9281045751633987
60	0.1583704593427041	0.9448529411764706	0.1890853704044632	0.9252450980392157
61	0.15380350351820585	0.9475081699346405	0.1906632709444738	0.9301470588235294
62	0.15527507166067758	0.9481209150326797	0.18749908464991188	0.9285130718954249
63	0.151195714335426	0.9485294117647058	0.18713902584672754	0.9305555555555556
64	0.1506134467382057	0.9490400326797386	0.18612187204797284	0.9272875816993464
65	0.14637100813435575	0.9501633986928104	0.18618393514086218	0.9285130718954249
66	0.1495984786865758	0.950265522875817	0.18561141382829816	0.928921568627451
67	0.1437497992141574	0.9514910130718954	0.18642283082495328	0.9297385620915033
68	0.13970479705170089	0.953125	0.18886958464395767	0.9313725490196079
69	0.1431426674711938	0.9515931372549019	0.1895753167374851	0.9325980392156863
70	0.14219673260364657	0.954452614379085	0.1848462066716618	0.9309640522875817
71	0.14058129328723049	0.9516952614379085	0.18405531293231678	0.9313725490196079
72	0.13782012443137326	0.9526143790849673	0.1906314537026524	0.9338235294117647
73	0.134266969960889	0.9553717320261438	0.1850544632795979	0.9321895424836601
74	0.13326110306128958	0.9549632352941176	0.1840782784948162	0.9330065359477124
75	0.13242241204564087	0.9552696078431373	0.18547193143589824	0.931781045751634
76	0.12772309346721064	0.9552696078431373	0.18441488067893422	0.9325980392156863
77	0.13065347104680305	0.9562908496732027	0.18477830651149252	0.9330065359477124
78	0.12728369620695612	0.9575163398692811	0.18624273181156395	0.9330065359477124
79	0.12709063539902368	0.957312091503268	0.18399832965014806	0.9330065359477124
80	0.12530703837770263	0.9578227124183006	0.18405418777290514	0.9354575163398693
81	0.1235928480921228	0.9582312091503268	0.1841679100263742	0.9342320261437909
82	0.12062047173579533	0.9595588235294118	0.19325036319350106	0.9321895424836601
83	0.12123391265962638	0.9580269607843137	0.18495229237219868	0.9342320261437909
84	0.12166308908680686	0.9589460784313726	0.18414110709833942	0.9358660130718954
85	0.1141811483143981	0.9619076797385621	0.18639863891149658	0.9325980392156863
86	0.11540619361829134	0.9602736928104575	0.18383162174057338	0.9358660130718954
87	0.11179775593717114	0.9627246732026143	0.187901448848006	0.934640522875817
88	0.11469358478496278	0.9604779411764706	0.1847754342639758	0.9350490196078431
89	0.11264028229744606	0.9599673202614379	0.185111276415828	0.9358660130718954
90	0.11009990209652708	0.9608864379084967	0.18591858431989072	0.9362745098039216
91	0.11124917292614388	0.9616013071895425	0.18557224724612204	0.9342320261437909
92	0.10725671335373049	0.9636437908496732	0.19379386632076276	0.9281045751633987
93	0.10526901741627774	0.9646650326797386	0.18747604243895588	0.9342320261437909
94	0.10633082454111062	0.9637459150326797	0.1892538931147725	0.9362745098039216
95	0.10459712094146442	0.9657883986928104	0.18989581044982462	0.9350490196078431
96	0.10358279734070784	0.9637459150326797	0.19569625940441696	0.9338235294117647
97	0.10039449371154012	0.9652777777777778	0.1870095321750329	0.9383169934640523
98	0.10070720865251193	0.9655841503267973	0.1873971674274775	0.9358660130718954
99	0.1007183713753239	0.9667075163398693	0.18731427124512742	0.9338235294117647

The optimal condition:
	epoch: 97
	train_acc: 0.9652777777777778
	val_acc: 0.938316993464
	using time: 520.207042933
