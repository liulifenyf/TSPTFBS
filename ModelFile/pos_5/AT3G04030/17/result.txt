The number of train datas: 9792
The number of test datas: 2448
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7046164827409134	0.5140931372549019	0.6846478343789094	0.5633169934640523
1	0.6895648564388549	0.5343137254901961	0.6779562663408666	0.5902777777777778
2	0.6847183201827255	0.5506535947712419	0.6712823724435046	0.6237745098039216
3	0.6763530217744167	0.577001633986928	0.6620844438964245	0.6535947712418301
4	0.6701842655543409	0.5873161764705882	0.6516455493721307	0.6870915032679739
5	0.65951993029102	0.6139705882352942	0.6371032015170927	0.7120098039215687
6	0.6463329566070457	0.6400122549019608	0.6174184064459957	0.7434640522875817
7	0.6275807385351143	0.6656454248366013	0.5924251749624614	0.7679738562091504
8	0.6068622364717371	0.6856617647058824	0.5614242039474786	0.7867647058823529
9	0.5846792412739173	0.7035334967320261	0.5295045629046322	0.7990196078431373
10	0.5561390830800425	0.7270220588235294	0.49501481437994765	0.8092320261437909
11	0.5267135329495848	0.7526552287581699	0.463137170652938	0.8259803921568627
12	0.49902744542539507	0.7724673202614379	0.43355825640796836	0.8349673202614379
13	0.4730660420617247	0.7859477124183006	0.4074327209416558	0.8419117647058824
14	0.4480270603123833	0.8052491830065359	0.3832169732237174	0.8525326797385621
15	0.42277150041137646	0.8200571895424836	0.363481716782439	0.8529411764705882
16	0.4035053407055101	0.8333333333333334	0.3458487460621042	0.872140522875817
17	0.38114025098046445	0.8531454248366013	0.3288711885026857	0.8754084967320261
18	0.36548448017999235	0.8575367647058824	0.3155468941903582	0.8819444444444444
19	0.34786605250601677	0.8680555555555556	0.3034547159290002	0.8921568627450981
20	0.33398517216342727	0.8734681372549019	0.29284552187701457	0.8966503267973857
21	0.3192307982179854	0.8804125816993464	0.28655891480788687	0.8921568627450981
22	0.3113008640170877	0.8879697712418301	0.2763038795757917	0.9027777777777778
23	0.2986883351615831	0.8951184640522876	0.26920376669347673	0.9093137254901961
24	0.288859815671553	0.8988970588235294	0.26552309899353516	0.9080882352941176
25	0.28486450026237886	0.9011437908496732	0.2559294058801302	0.9121732026143791
26	0.27545469064338535	0.9078839869281046	0.2561747685951345	0.9105392156862745
27	0.2734359656673631	0.9061478758169934	0.2499344652774287	0.9150326797385621
28	0.2622229992564208	0.9121732026143791	0.24455165366331735	0.9154411764705882
29	0.2503072962262272	0.9166666666666666	0.2384027996483971	0.9162581699346405
30	0.24532217527526656	0.9171772875816994	0.23570155045565436	0.9154411764705882
31	0.24085525905384736	0.9188112745098039	0.23329917604432387	0.9158496732026143
32	0.23525411075626323	0.9217728758169934	0.22888968904423557	0.9174836601307189
33	0.23658295862035814	0.9208537581699346	0.22763924295800964	0.9187091503267973
34	0.2274723027656281	0.9234068627450981	0.22443915616258298	0.9191176470588235
35	0.2240899928839378	0.9249387254901961	0.22690437101071176	0.9203431372549019
36	0.22434709079904494	0.9255514705882353	0.2211550903670928	0.920751633986928
37	0.2196926653774735	0.9287173202614379	0.21871970330967622	0.9191176470588235
38	0.21194754501962973	0.9276960784313726	0.2179194923027668	0.9223856209150327
39	0.21193134287993112	0.9290236928104575	0.21610196825920366	0.9219771241830066
40	0.20572968986299303	0.9323937908496732	0.21619204300291398	0.9236111111111112
41	0.20116949334643244	0.9347426470588235	0.2127862350613463	0.920751633986928
42	0.19505530624997383	0.9324959150326797	0.21294004160886496	0.9256535947712419
43	0.19572503129446428	0.933312908496732	0.2077437823796584	0.9240196078431373
44	0.19384337839932222	0.9353553921568627	0.20953656881560687	0.9252450980392157
45	0.18918615647780349	0.9375	0.20473386736866694	0.9227941176470589
46	0.190624655072206	0.9357638888888888	0.20734233102377722	0.926062091503268
47	0.18613033600492415	0.9382148692810458	0.2016016473275384	0.926062091503268
48	0.18253054835048377	0.9389297385620915	0.20027852525898054	0.9268790849673203
49	0.17870136550049376	0.9412785947712419	0.20210497261457194	0.9272875816993464
50	0.1753846326100281	0.9401552287581699	0.1974153026841045	0.9276960784313726
51	0.1729273423065547	0.941687091503268	0.20041867075305358	0.9264705882352942
52	0.17231295973646873	0.9400531045751634	0.19724016782699846	0.9285130718954249
53	0.1704246597547157	0.9426062091503268	0.19450387899197785	0.9281045751633987
54	0.16911632426423964	0.943218954248366	0.19343689495539354	0.9276960784313726
55	0.16333653334698645	0.9426062091503268	0.1930941741889209	0.9309640522875817
56	0.15975076179294026	0.9465890522875817	0.1935750118219385	0.9276960784313726
57	0.15935368534007105	0.9463848039215687	0.1956514701539395	0.9276960784313726
58	0.1585857745479135	0.9483251633986928	0.19100403466742802	0.9281045751633987
59	0.15610899186991398	0.9481209150326797	0.1901773421300782	0.9297385620915033
60	0.15260483470617556	0.9490400326797386	0.18899466034049303	0.9313725490196079
61	0.14894542614229364	0.9501633986928104	0.19450903959036653	0.9297385620915033
62	0.14752803626013736	0.9490400326797386	0.1889450590497528	0.9338235294117647
63	0.14590369617822124	0.9523080065359477	0.18841173395124916	0.9325980392156863
64	0.14599296138956655	0.9505718954248366	0.1874682660780701	0.9313725490196079
65	0.14197999696715985	0.953125	0.18562576669006567	0.9354575163398693
66	0.1388093358745762	0.9540441176470589	0.18845008255219928	0.931781045751634
67	0.13945522434473817	0.9529207516339869	0.19319851362919496	0.931781045751634
68	0.13518826342096515	0.9552696078431373	0.1887783735893131	0.9301470588235294
69	0.1342310786636826	0.9536356209150327	0.19165192230367192	0.9342320261437909
70	0.13597056586173625	0.954452614379085	0.19070780150641023	0.9338235294117647
71	0.13151128249230729	0.9534313725490197	0.18386245451964975	0.9325980392156863
72	0.13074339536669988	0.9552696078431373	0.18749119718772134	0.9338235294117647
73	0.12824243492160747	0.9565972222222222	0.18156883875334184	0.9350490196078431
74	0.12556534245902418	0.9595588235294118	0.18223579464102882	0.9330065359477124
75	0.12202190466566024	0.9590482026143791	0.18274806995017856	0.9362745098039216
76	0.12423190333290038	0.9566993464052288	0.1810766818379265	0.9338235294117647
77	0.12366591374468959	0.9590482026143791	0.18108115101756614	0.9362745098039216
78	0.11928021274750529	0.9605800653594772	0.1878217604327825	0.9342320261437909
79	0.12060932206367356	0.9604779411764706	0.18347525813318546	0.9358660130718954
80	0.11889591014463138	0.9613970588235294	0.18077661734975242	0.9391339869281046
81	0.11868412826770271	0.9611928104575164	0.18050635708313362	0.9379084967320261
82	0.11404037266190535	0.9631331699346405	0.19240598597265537	0.9342320261437909
83	0.11333496542343127	0.9616013071895425	0.18131595572420195	0.9362745098039216
84	0.11290485616408143	0.963031045751634	0.18228090027335034	0.9362745098039216
85	0.1100120033119239	0.9629289215686274	0.1822134492176226	0.9375
86	0.11151719439068651	0.9612949346405228	0.18107058043329935	0.9358660130718954
87	0.10506564412826026	0.9657883986928104	0.1819185594011561	0.9350490196078431
88	0.10923156078929215	0.9623161764705882	0.1818680490665381	0.9362745098039216
89	0.1045005934105979	0.9653799019607843	0.18338894391176747	0.9366830065359477
90	0.10421438252224642	0.9641544117647058	0.18033290174759292	0.9350490196078431
91	0.10324241367040896	0.9651756535947712	0.1797278424104055	0.9370915032679739
92	0.10194797098052268	0.9656862745098039	0.18050459857567464	0.9370915032679739
93	0.09821756249841522	0.965890522875817	0.1819247520388731	0.9366830065359477
94	0.10029898082313973	0.9661968954248366	0.18292887524695567	0.9387254901960784
95	0.09651880238959992	0.9685457516339869	0.1812922465888893	0.9370915032679739
96	0.09829895656093274	0.9659926470588235	0.18661261606791052	0.9366830065359477
97	0.09198287338797563	0.9690563725490197	0.18051779121647474	0.9358660130718954
98	0.09183606247301974	0.9713031045751634	0.18218999737082353	0.9375
99	0.09195542983175103	0.9688521241830066	0.182051154766597	0.9375

The optimal condition:
	epoch: 80
	train_acc: 0.9613970588235294
	val_acc: 0.939133986928
	using time: 490.173608065
