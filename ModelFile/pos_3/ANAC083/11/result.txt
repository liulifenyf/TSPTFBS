The number of train datas: 5206
The number of test datas: 1302
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7177400437401571	0.502305032688977	0.6920127622359725	0.5138248850673025
1	0.6993974722031672	0.5170956592215422	0.6887628645757743	0.5407066055889687
2	0.6951124305638999	0.5247791011288585	0.686067448050562	0.5460829494003143
3	0.6864125732957882	0.5472531691680173	0.6832653002987992	0.572196620675276
4	0.6823266446704915	0.5624279679127304	0.6798746482384735	0.5875576035035187
5	0.679276850903167	0.5635804843316388	0.6759693326854852	0.6082949306924589
6	0.6781814655935219	0.5745293895327216	0.6707018177080813	0.6213517663299396
7	0.6725216616679283	0.581252400823799	0.665113845362275	0.6397849460534419
8	0.662944989391258	0.6094890513925703	0.6579698364489273	0.6443932415336691
9	0.6536170655930907	0.61813292384743	0.6509047276962737	0.6589861754814418
10	0.6498343991720351	0.6235113327566404	0.6438527162173926	0.6605222737917336
11	0.6384355963948045	0.6438724545163006	0.6339846160005315	0.6712749619637767
12	0.6279478005798698	0.6567422203545016	0.6248215857189372	0.6889400922574572
13	0.6191653979543627	0.6659623514309875	0.6120518625423472	0.6981566816614154
14	0.6047433787843057	0.6842105265218754	0.6010073564385855	0.7058371734875505
15	0.5884529017641872	0.7007299273049791	0.5872090938179174	0.7150537633493016
16	0.5791968975761419	0.7078371114379115	0.5728553242397748	0.7304147464522202
17	0.562421871912374	0.7203227043426637	0.5594270720093664	0.7250384025493158
18	0.5472811386075058	0.7379946216362694	0.5401302548139693	0.7534562208319223
19	0.5257447941505675	0.7447176336371986	0.5225650639761061	0.75576036829736
20	0.5083454868173398	0.7645024969813186	0.5047588792447854	0.7665130572018719
21	0.47824553847083945	0.7864003076582655	0.4814864038139261	0.7864823353272247
22	0.46993925838895456	0.7877449099485387	0.45966938994080975	0.8064516133610188
23	0.4503640554132619	0.803111793694476	0.44164669760910596	0.8102918585873968
24	0.4267517378867886	0.8127160969487621	0.4177900003398069	0.8241167439293752
25	0.4081180349845315	0.8261621203323625	0.3971915452436368	0.8364055304117101
26	0.3914756473673338	0.8334613909320194	0.3786271689216479	0.8502304152043367
27	0.3705273068184767	0.8507491357730436	0.36351052063950745	0.859447005066088
28	0.347458366529327	0.8638109871162344	0.3440493334273589	0.8648233491521095
29	0.33546599310680025	0.8674606221527308	0.32961254167483517	0.8763440864792984
30	0.3251663488674017	0.8711102577387897	0.31747280081845647	0.8786482339447361
31	0.30210912129167317	0.883403764772177	0.304207973926115	0.8771121356344442
32	0.2987039465653269	0.8860929695359112	0.29728327020888323	0.8794162830998821
33	0.2812421842808454	0.8941605842850825	0.2881665628992834	0.8863287247637267
34	0.2750175123461109	0.8953131006123971	0.28261046953922775	0.8909370196946023
35	0.26498905895903985	0.9031886288490472	0.2763636946311927	0.8901689705394563
36	0.26351891954930706	0.904533231322508	0.2731496835450789	0.8932411671600401
37	0.2580728797307163	0.9072224358114608	0.26549913240925693	0.8940092163151859
38	0.24690240149858866	0.914521706067641	0.26061438568817674	0.8978494620909157
39	0.2347518032015263	0.9152900503774446	0.2582321757316223	0.9024577570217912
40	0.23218373650319293	0.9185555129384609	0.25324496961042814	0.8993855604012074
41	0.22452441547130375	0.9225893200840622	0.2518640554491459	0.9001536095563534
42	0.2239350069384368	0.9206684596301316	0.24806135267980636	0.9024577570217912
43	0.21747354769816638	0.9243180947582217	0.2435342279676285	0.9062980027975208
44	0.21789140114292382	0.9270072997051434	0.24630779103474684	0.9055299536423749
45	0.208077178189629	0.9289281593576285	0.24205936381619098	0.9101382485732504
46	0.20847847081700793	0.929120245412181	0.2360187188225774	0.9093701994181046
47	0.2096182623541085	0.9295044177044735	0.23476990410763365	0.9124423960386883
48	0.20019043400408532	0.9331540527409697	0.2347170753596199	0.9132104451938342
49	0.2037224846187574	0.936995773648831	0.23475780526888534	0.9101382485732504
50	0.1992800173178298	0.9335382246668871	0.23155154480088141	0.9147465435041261
51	0.1929149042000644	0.9373799457579359	0.2336872130540842	0.9078341011078127
52	0.18843808137610285	0.9362274303236605	0.22796185373023908	0.9170506912442397
53	0.18866128569788718	0.9377641178670407	0.22878053661910802	0.9147465435041261
54	0.18188327989393227	0.9406454086853273	0.2276231986220165	0.9170506909695638
55	0.1872090758083877	0.9379562041963745	0.228327543081318	0.9132104451938342
56	0.18392907647481113	0.9406454089601086	0.22455589657509198	0.9185867895545314
57	0.1812963068794389	0.9423741839777448	0.22720281168612466	0.9139784946236559
58	0.17424894350105372	0.9416058396679412	0.22095769631194262	0.9193548387096774
59	0.1775540632671271	0.9444871304862279	0.22124704237907164	0.9208909370199693
60	0.17448073151566823	0.9439108724141643	0.21910814136358267	0.9208909370199693
61	0.1703526859403893	0.9464079903219006	0.23068370911565977	0.9101382485732504
62	0.17106832659478102	0.9458317324330245	0.21940351042970901	0.9216589861751152
63	0.170324273639306	0.9448713020686685	0.21730564667424115	0.9216589861751152
64	0.1650678957030721	0.9462159043589419	0.22234864589027178	0.9170506912442397
65	0.160830312458955	0.9483288509590188	0.2207535947866154	0.9185867895545314
66	0.1620368200668774	0.9469842486687454	0.217202466994112	0.9224270353302612
67	0.15962016322877925	0.9492892813233746	0.2155932703737839	0.9231950844854071
68	0.15997433207308015	0.9462159051603873	0.22858347029592585	0.9109062984608651
69	0.16014314029842353	0.9460238189226474	0.2146475173521518	0.9254992319508448
70	0.16031965086701006	0.95236265810462	0.21425199349583934	0.923963133640553
71	0.15203836749733937	0.9512101416857115	0.21426414899791257	0.9254992319508448
72	0.1537914787559751	0.9487130229765298	0.21531701187521632	0.923963133640553
73	0.1540896992985899	0.9521705721416612	0.22342970241690926	0.9170506909695638
74	0.15357464423694384	0.9525547440675786	0.21729175859744648	0.923963133640553
75	0.15011839055117396	0.9525547449606179	0.21868195843678281	0.9224270353302612
76	0.14345848665093625	0.9529389168865352	0.2243863353577261	0.9216589859004394
77	0.1537829056250513	0.9537072603948933	0.21701487561204283	0.9224270350555853
78	0.14429603441490652	0.9525547440675786	0.21800694190045838	0.9216589859004394
79	0.14512274423174065	0.9546676914691009	0.21614402442163402	0.9247311827956989
80	0.1439846125998453	0.9552439491976878	0.21242076061242554	0.9278033794162827
81	0.13837671372073457	0.9550518628683541	0.21312340451390147	0.9285714285714286
82	0.13969701560034553	0.9565885513047736	0.21639523450313808	0.9254992319508448
83	0.14268202125980356	0.9550518628683541	0.21331393598548828	0.9278033794162827
84	0.1376975644415633	0.9571648093768371	0.21847918518631507	0.9254992316761691
85	0.13591261472248178	0.9565885513963673	0.2127429141781755	0.9293394777265745
86	0.1320398606580356	0.9602381862496762	0.21738960829702209	0.9247311825210232
87	0.13406333354771527	0.9538993467242269	0.21386377455040056	0.9308755760368663
88	0.135095109046078	0.956972723597066	0.21856999216449607	0.926267280831315
89	0.12836927793207326	0.9594698420314665	0.2210851982464805	0.9247311825210232
90	0.13251286307711166	0.9583173257957456	0.21653520462379294	0.9285714282967528
91	0.1336371834964831	0.958509411850298	0.2163422496248317	0.9278033791416068
92	0.1250691751974892	0.9610065313609252	0.21450701223174182	0.9285714282967528
93	0.13417419809540373	0.9579331536866407	0.21884951069836608	0.9254992316761691
94	0.12744754352479817	0.9590856700139553	0.22092639939850925	0.9247311825210232
95	0.12303460008975317	0.9596619282692064	0.22708486576783493	0.9247311825210232
96	0.12037720115904711	0.9608144453063727	0.22423662730534138	0.9247311825210232
97	0.12613434690582812	0.9590856701055491	0.21517371017766254	0.9278033791416068
98	0.12062538409039601	0.9613907030349597	0.21708673681668972	0.9270353299864609
99	0.11781859385866501	0.9611986165224384	0.21646322629281453	0.9278033791416068

The optimal condition:
	epoch: 87
	train_acc: 0.9538993467242269
	val_acc: 0.930875576037
	using time: 327.437167883
