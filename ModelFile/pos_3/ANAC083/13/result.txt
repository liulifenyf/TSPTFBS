The number of train datas: 5206
The number of test datas: 1302
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7109807772999125	0.5067230120352768	0.6906363208722409	0.521505376344086
1	0.6985248296571337	0.5121014214711513	0.6864659017132174	0.5506912443311899
2	0.6915154828276031	0.5268920476373415	0.6830361139389777	0.5875576037781945
3	0.684508208650559	0.554744525639039	0.6805074618708703	0.604454685191405
4	0.6839737416092267	0.5526315786954855	0.6774625077774997	0.6159754225185939
5	0.6806152932377353	0.5674222048044296	0.6738268159867798	0.6274961593879899
6	0.6788483978783311	0.5610833654392695	0.6693549701878185	0.6328725034740114
7	0.6736504233117018	0.5810603148608404	0.6656937030603259	0.6443932408012003
8	0.6666037621884634	0.5983480601140365	0.6598747603354915	0.6497695851618976
9	0.6599038706300261	0.6091048791918716	0.6532123776441712	0.6628264207993785
10	0.6535448128106363	0.6213983863397511	0.6454052758473222	0.6843317971434645
11	0.6453021939928331	0.6381098734292899	0.6363960679408776	0.6835637482629943
12	0.6365180464831399	0.6461774874457111	0.6276799572228287	0.7019969281696138
13	0.6271765399931762	0.6552055321012695	0.6161153662589288	0.710445468418426
14	0.612510055223429	0.6828659241400084	0.6035728200056952	0.7073732720725181
15	0.597569263375268	0.6872839030283394	0.5925135779582227	0.706605223192048
16	0.5860919153465933	0.702074528908299	0.5754195916854108	0.7334869430728039
17	0.5703075527686867	0.7141759504137981	0.5604110148645216	0.7442396309701712
18	0.5547506283028419	0.7343449865997731	0.5467380344318354	0.7396313360392955
19	0.5350658795121904	0.7447176330876359	0.5286489771807799	0.7619047615385275
20	0.5220011246923387	0.7512485591256064	0.5117650097050059	0.767281105624549
21	0.4953656578883729	0.7794852095111902	0.4951924078292378	0.764208909278641
22	0.4784737329069944	0.7881290818057608	0.4719274735304251	0.7857142853480513
23	0.454211171869585	0.803111793694476	0.4502456881758255	0.800307219295824
24	0.43919577085188705	0.8065693427680137	0.43068273244182453	0.8072196619668132
25	0.41226237079202327	0.8265462923498736	0.40814169334925815	0.8248847928098453
26	0.3905299730910918	0.8326930468969972	0.3863373849249106	0.8294930877407208
27	0.3749366642945187	0.851133308065336	0.3670739136899488	0.8425499233782017
28	0.3483923009116971	0.8653476755526539	0.34883184344171564	0.853302611275569
29	0.33957980359649365	0.8647714173889967	0.3332898263832391	0.8586789551784733
30	0.31865909346424065	0.8751440647927972	0.3200269790563715	0.8663594467299325
31	0.30663862156950417	0.8845562810078978	0.3123105920038648	0.870967741660808
32	0.29380640957706305	0.8870533998086734	0.2995707752975634	0.880952381410174
33	0.2791499457036904	0.8962735308851593	0.2890804217021037	0.8855606756085808
34	0.27192989942595175	0.8964656167565243	0.2828350855458167	0.8878648230740185
35	0.26134738401637553	0.9085670382849217	0.27572755062360366	0.8947772654703319
36	0.2554514659879943	0.9091432964485789	0.28459678713901804	0.8840245772982889
37	0.25038448847398087	0.9108720707563634	0.27035002632441424	0.8901689705394563
38	0.24154920053972082	0.9197080287391115	0.2670676533573417	0.8940092163151859
39	0.2341388788215939	0.9162504801006441	0.26397874690420614	0.8940092163151859
40	0.23031983505383483	0.9247022665925453	0.2571685020504276	0.9055299536423749
41	0.22009192526775556	0.9229734925595422	0.254090706759151	0.9070660519526668
42	0.21809877973884242	0.928159816032458	0.25222534783607986	0.9055299536423749
43	0.21019779310013942	0.9260468693407874	0.251508341727352	0.9070660519526668
44	0.21200708149604233	0.9289281594492224	0.24809335389628023	0.9078341018402815
45	0.2096653362214451	0.9323857084311662	0.24640867663418642	0.9093701994181046
46	0.2028276576155019	0.9339223976690312	0.24803525870937723	0.9055299536423749
47	0.20722315062296834	0.9296965037590258	0.24299481147170615	0.9093701994181046
48	0.1942930620219494	0.9358432574131101	0.24161003124878702	0.9116743468835423
49	0.1982635097507326	0.9362274303236605	0.24290883417503076	0.9086021502629587
50	0.19957830986745806	0.9352669998677108	0.24094323546106364	0.9124423960386883
51	0.1890514547257894	0.9379562048146325	0.2398706494663168	0.9147465435041261
52	0.18121228680512652	0.9435266995036139	0.23903902916498082	0.915514592659272
53	0.1840792084331014	0.9368036884873178	0.23897593627510716	0.9162826418144179
54	0.18194077554066915	0.938724548139803	0.23666853387875858	0.915514592659272
55	0.18364161266142068	0.9400691514147093	0.23659216503851607	0.9147465435041261
56	0.17687013372922009	0.9417979253790171	0.2368143417524852	0.915514592659272
57	0.17730863972828564	0.944871302503739	0.23717640063363468	0.915514592659272
58	0.16936999250273496	0.9454475608505838	0.2363547444023112	0.9155145929339478
59	0.17544435746638629	0.9442950445232692	0.23505241434145632	0.9170506909695638
60	0.16658374775935264	0.9467921632324509	0.23457186854517406	0.9185867895545314
61	0.1681100836326377	0.9485209369219774	0.23541521738796922	0.9193548387096774
62	0.1638959857005135	0.9466000766512342	0.23452111885249158	0.9185867895545314
63	0.1628916645297352	0.9498655395786257	0.23478082462161	0.9162826420890937
64	0.16382648170715655	0.9479446788499138	0.23430278487560752	0.9193548387096774
65	0.15507326107092925	0.9506338844150934	0.23558447648486416	0.9147465435041261
66	0.1561334544146606	0.951594313978004	0.2339452296472548	0.9193548387096774
67	0.15693517340131782	0.950633883613648	0.2333205699027958	0.9208909367452935
68	0.15688629017350678	0.9479446795597656	0.24175135631074188	0.9124423960386883
69	0.15211894094394438	0.9517864000325564	0.23358037924757385	0.9147465437788018
70	0.15403753768651246	0.9521705720500675	0.23248056039649037	0.9201228875901476
71	0.1483887652399629	0.9510180565241984	0.2337661061075426	0.9178187403993856
72	0.14351699196440507	0.9538993465410395	0.23527663623407688	0.9216589859004394
73	0.14563319866147995	0.9567806373593261	0.23775856853813254	0.9185867892798557
74	0.14675853873130407	0.9573568956145772	0.2339353923515607	0.9201228875901476
75	0.142241864612228	0.9531310031242751	0.23349023066724317	0.9201228878648233
76	0.13899706810701365	0.9587014978132566	0.2354206292104611	0.9193548384350017
77	0.14313159830355893	0.9546676907592492	0.23344213040559889	0.9178187401247098
78	0.13464828027906758	0.9558202069949701	0.2378515678525154	0.9208909367452935
79	0.13644416776818127	0.958509411850298	0.23537977940521665	0.9208909367452935
80	0.13568682357228082	0.9565885513047736	0.23680322217868038	0.9170506912442397
81	0.1327309995958359	0.9581252400159744	0.237009680639672	0.9170506912442397
82	0.1361722986811727	0.9569727233222847	0.2340946632069743	0.9216589861751152
83	0.1337706274651721	0.9581252398327869	0.2352409238387729	0.9193548387096774
84	0.12993827454181894	0.9596619288874644	0.2356693732985703	0.9178187401247098
85	0.13263000794616608	0.9575489816691296	0.2351590642525304	0.9193548384350017
86	0.12782983112074162	0.9590856708154007	0.23609429363235718	0.9185867892798557
87	0.12476759756007563	0.9602381864328637	0.237673683798716	0.9185867892798557
88	0.1279460724573432	0.9602381864328637	0.2396974054189505	0.9216589859004394
89	0.12365467637445302	0.9611986173238839	0.2411355257217419	0.9162826418144179
90	0.12438781798756035	0.9600461003783113	0.23766706161738907	0.9170506909695638
91	0.12547908747683933	0.9592777562516953	0.2370041407495966	0.9185867892798557
92	0.11816028199010842	0.9623511330329405	0.238458539483734	0.9162826418144179
93	0.11564656187605958	0.9635036493602552	0.2399801209843653	0.9162826418144179
94	0.11773538473840406	0.961774874960877	0.24097241624937996	0.9170506909695638
95	0.11622305237303501	0.9604302723958223	0.2445679342920696	0.915514592659272
96	0.11330536609823962	0.9611986167056259	0.2459004897217963	0.9139784943489802
97	0.11575857223030515	0.9621590469783882	0.24141601446769936	0.9170506909695638
98	0.1130886560179296	0.964464079816205	0.24232855907279408	0.9147465435041261
99	0.10944882264239852	0.9644640794498298	0.2441112025427745	0.9185867895545314

The optimal condition:
	epoch: 82
	train_acc: 0.9569727233222847
	val_acc: 0.921658986175
	using time: 354.56192708
