The number of train datas: 2000
The number of test datas: 500
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7113462343215943	0.5	0.6910939826965332	0.528
1	0.7028083643913269	0.5100000009536744	0.6900370969772339	0.5540000004768372
2	0.6998183450698853	0.5215000009536743	0.6880844612121582	0.5599999961853027
3	0.697367434501648	0.5119999990463256	0.6858914699554444	0.5819999942779541
4	0.6937043333053589	0.5090000004768371	0.6841264219284058	0.5920000033378601
5	0.6904267210960389	0.525	0.682001259803772	0.5840000042915344
6	0.6883491592407227	0.551	0.680293996334076	0.6119999985694885
7	0.6847724838256836	0.5410000004768372	0.6783817539215088	0.6160000004768371
8	0.6814364271163941	0.5580000009536743	0.6766864929199219	0.6220000004768371
9	0.6872587361335755	0.5485	0.6745718722343444	0.6300000004768371
10	0.6791754264831543	0.5629999995231628	0.6723713130950928	0.632
11	0.6726087765693665	0.5835000004768371	0.6697831373214722	0.6499999980926514
12	0.6711646680831909	0.5790000009536743	0.6666289854049683	0.6499999980926514
13	0.6673674654960632	0.5915000004768372	0.6632291779518128	0.6620000047683716
14	0.6663684468269349	0.5924999990463257	0.659541759967804	0.662
15	0.6615834431648254	0.6045	0.6551653714179992	0.6659999933242798
16	0.6602230806350708	0.6034999995231628	0.6516228642463684	0.6759999952316285
17	0.6588681936264038	0.6155000009536743	0.6469706687927246	0.684
18	0.6477137517929077	0.6424999995231628	0.6411708712577819	0.6979999952316284
19	0.6438909459114075	0.6419999995231629	0.6345442395210266	0.7139999971389771
20	0.6442459597587585	0.6384999990463257	0.6276822028160095	0.7220000066757202
21	0.6319241037368775	0.6475000009536743	0.620369234085083	0.7240000047683716
22	0.6292291688919067	0.6594999990463257	0.6137898206710816	0.7299999947547913
23	0.6161232690811157	0.6785	0.6060023703575135	0.7340000019073486
24	0.6101202573776245	0.6834999995231629	0.5968923711776734	0.734
25	0.6167660093307495	0.668	0.5905129027366638	0.7379999952316284
26	0.6042108812332153	0.6870000009536743	0.5831151938438416	0.7359999952316284
27	0.5984905552864075	0.6885	0.5759285020828248	0.7440000019073486
28	0.5867635178565979	0.6995000009536743	0.5694327254295349	0.7419999947547913
29	0.5827804856300354	0.7069999995231628	0.5609577903747559	0.7479999995231629
30	0.5817395071983338	0.7039999995231628	0.5560039110183715	0.7480000038146972
31	0.5766683721542358	0.7074999995231629	0.5481757984161377	0.7600000066757202
32	0.5708337831497192	0.717	0.5427469534873962	0.7580000042915345
33	0.5612920083999634	0.7259999995231629	0.5371659851074219	0.754
34	0.559459831237793	0.7325	0.5322266025543213	0.7580000066757202
35	0.5524336919784546	0.7295000004768372	0.5284035081863403	0.7640000042915345
36	0.5445578927993775	0.7315000009536743	0.5248673386573791	0.7660000042915345
37	0.5452619976997376	0.7494999990463257	0.5254667661190033	0.7459999947547913
38	0.5359440445899963	0.7420000004768371	0.5181067514419556	0.7679999952316284
39	0.5408861742019654	0.73	0.5186820695400238	0.7460000019073486
40	0.5400436654090881	0.7365000004768372	0.5139386343955994	0.7659999952316284
41	0.530846182346344	0.7484999990463257	0.5141359777450561	0.7520000019073486
42	0.5335652430057526	0.7424999995231628	0.5095405197143554	0.7639999952316284
43	0.5221116623878479	0.7535000009536743	0.5101669230461121	0.7500000019073486
44	0.520868902683258	0.7539999995231629	0.5058905882835388	0.7619999952316284
45	0.522947319984436	0.7575	0.507551766872406	0.7480000042915345
46	0.5224010190963745	0.747	0.504710212469101	0.7600000066757202
47	0.5147423152923584	0.7615	0.5027389039993286	0.7680000066757202
48	0.5092496278285981	0.7590000004768371	0.5023372359275818	0.7600000042915345
49	0.5111050908565521	0.7554999995231628	0.5033166816234589	0.7540000042915345
50	0.5180836791992187	0.7585000009536743	0.49836761379241945	0.7679999952316284
51	0.5058635458946228	0.7555000009536743	0.5022333199977875	0.7520000019073486
52	0.5057528569698334	0.7630000009536743	0.5011890132427216	0.7480000019073486
53	0.505562462091446	0.7649999990463257	0.49509573268890383	0.7699999952316284
54	0.5063470330238342	0.7665000004768372	0.4952950720787048	0.7659999952316284
55	0.5054409084320068	0.7700000004768371	0.49576397132873534	0.7639999952316284
56	0.5034527878761291	0.7640000009536743	0.4972028546333313	0.7600000042915345
57	0.49840812826156616	0.7715000009536743	0.49338625621795656	0.7639999952316284
58	0.4969922332763672	0.7719999990463257	0.49716797733306883	0.7520000019073486
59	0.48807813477516176	0.7780000004768372	0.4921827301979065	0.7719999952316284
60	0.47870788431167605	0.7705	0.4935385026931763	0.7600000042915345
61	0.4906714174747467	0.7650000004768371	0.49181986784935	0.7660000066757202
62	0.483469161272049	0.7769999990463257	0.4914326930046082	0.7600000066757202
63	0.4856146922111511	0.7780000004768372	0.4896394791603088	0.7679999952316284
64	0.4764043045043945	0.7779999995231628	0.4884620122909546	0.7659999952316284
65	0.4788139359951019	0.7754999990463257	0.48862366485595704	0.7639999952316284
66	0.4727378921508789	0.7719999990463257	0.48727236986160277	0.7659999976158142
67	0.4708098015785217	0.7835	0.49200623941421506	0.7540000019073486
68	0.46575904631614684	0.7794999995231628	0.48685009479522706	0.7659999976158142
69	0.4696682019233704	0.7809999990463257	0.4872275719642639	0.7680000066757202
70	0.468861499786377	0.7905000004768371	0.4886604228019714	0.7540000019073486
71	0.4679886245727539	0.7884999995231629	0.48774746417999265	0.7560000019073486
72	0.4618523213863373	0.7895	0.48364634704589843	0.7679999976158142
73	0.47002165818214414	0.7905000004768371	0.4852626881599426	0.7660000066757202
74	0.45734185934066773	0.7920000004768372	0.4842841637134552	0.7580000042915345
75	0.469762056350708	0.7890000009536743	0.48143452215194704	0.7679999952316284
76	0.4544089360237122	0.7960000009536743	0.4856799557209015	0.761999997138977
77	0.45168489503860476	0.7965	0.4840842788219452	0.7600000019073486
78	0.45243504333496093	0.7835000009536743	0.48183618211746215	0.7660000066757202
79	0.45491680335998536	0.8020000004768372	0.48277345395088195	0.7620000066757202
80	0.4496522727012634	0.796	0.4851445639133453	0.757999997138977
81	0.44535858011245727	0.8005000004768371	0.48173967766761777	0.7679999952316284
82	0.4548617658615112	0.7975000004768371	0.48574655652046206	0.7639999947547913
83	0.43615274572372437	0.8079999990463257	0.4804233064651489	0.7659999952316284
84	0.44473329973220826	0.8069999990463257	0.4803778064250946	0.7720000019073486
85	0.4375032203197479	0.8134999995231629	0.4817688674926758	0.767999997138977
86	0.4410675656795502	0.8019999990463257	0.47886708307266235	0.769999997138977
87	0.4447872853279114	0.7989999995231628	0.4771983599662781	0.7680000066757202
88	0.42946394300460816	0.8119999990463257	0.4777943365573883	0.775999997138977
89	0.43406678581237795	0.8105000004768371	0.48714510846138	0.7520000038146972
90	0.4282985200881958	0.8125	0.4777299430370331	0.769999997138977
91	0.4263586690425873	0.81	0.4764826197624207	0.773999997138977
92	0.4257637274265289	0.8119999990463257	0.48493914914131164	0.7500000061988831
93	0.4249372708797455	0.8215000009536744	0.4754364666938782	0.773999997138977
94	0.4149630026817322	0.8175	0.4740420043468475	0.7740000019073486
95	0.4113934097290039	0.8189999995231628	0.4723041605949402	0.7740000023841858
96	0.4107076778411865	0.8124999990463256	0.47546318888664246	0.775999997138977
97	0.4173798260688782	0.8115000004768371	0.4742970383167267	0.771999997138977
98	0.40670153093338013	0.8229999990463257	0.47178096079826354	0.7759999995231628
99	0.4062851028442383	0.8235000004768371	0.4799296407699585	0.7620000061988831

The optimal condition:
	epoch: 98
	train_acc: 0.8229999990463257
	val_acc: 0.775999999523
	using time: 159.896555901
