The number of train datas: 2488
The number of test datas: 624
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6990287144851072	0.5064308681672026	0.6841255334707407	0.551282055867024
1	0.6882375361835075	0.534967845659164	0.6730874746273725	0.6009615354048901
2	0.6782077867118492	0.5602893886842145	0.6632627722544547	0.647435894379249
3	0.6682209027541796	0.5827974280360427	0.6518352551338	0.6874999954150274
4	0.6612152875044721	0.600884243798026	0.6385462757868644	0.7275641071490753
5	0.6475343817299969	0.6225884242456442	0.6255073348681132	0.7596153861437088
6	0.6293468262604962	0.6744372994186794	0.6106275671567672	0.7756410210560529
7	0.6198219193139644	0.6824758838610634	0.592460056145986	0.7836538446255219
8	0.6071077107999869	0.6925241151806626	0.5737459506743994	0.7964743635593317
9	0.5879405578808002	0.715032154340836	0.5535539556772281	0.8125000045849726
10	0.5613504113491709	0.7483922835331638	0.528480331103007	0.8141025641025641
11	0.5493226193155123	0.7479903533144396	0.5066305299599966	0.8237179517745972
12	0.5208673091946691	0.7733118971061094	0.48210747883870053	0.8269230769230769
13	0.5016322597813376	0.7829581991652583	0.4599754756841904	0.8397435943285624
14	0.48554780523493357	0.7849678450841996	0.4508438331958575	0.7996794871794872
15	0.4596132229762062	0.795819936074628	0.4226518716567602	0.842948717948718
16	0.45970838102497086	0.7954180068141777	0.4119121218338991	0.8349358928509247
17	0.43961881173001993	0.8078778135048231	0.39502800962863827	0.8493589774156228
18	0.4323549218883085	0.8066720257234726	0.387296702617254	0.8477564056714376
19	0.42195239308562693	0.8078778133131683	0.3757286576124338	0.8493589758872986
20	0.40759152633967505	0.8215434081684738	0.36590694311337596	0.8509615399898627
21	0.39233862558361804	0.8307877815421372	0.3568591987475371	0.8509615399898627
22	0.3885116743888119	0.8303858526649965	0.3489211461482904	0.8541666681949909
23	0.3758208637643857	0.836414791571749	0.3423374532124935	0.854166662081694
24	0.364404908522149	0.8436495176848875	0.3347086868225	0.8605769184919504
25	0.3612969741943948	0.844453376014133	0.3234798640776903	0.8621794825945145
26	0.3514455251180091	0.8553054664295969	0.3155581255753835	0.8637820528103755
27	0.3504129069411103	0.8573151125401929	0.31183330217997235	0.8669871749022068
28	0.34006696939468384	0.858118971252748	0.3115670180473572	0.8685897435897436
29	0.3256523245975519	0.876607716658491	0.29539190041713226	0.870192309220632
30	0.3225472507177825	0.8705787785183579	0.29525233193849904	0.8733974358974359
31	0.32019003267456864	0.8701768486829433	0.29002960140888506	0.8733974358974359
32	0.3149231640663944	0.8733922827665446	0.2770310770242642	0.8814102579385806
33	0.30490425631547663	0.8834405144694534	0.2744412727845021	0.8830128205128205
34	0.30745738409339807	0.8802250801941973	0.2672496686379115	0.8926282005432324
35	0.29512149009290617	0.8818327970443431	0.2635919906390019	0.8910256410256411
36	0.28421284157746857	0.8987138259832499	0.2640621673602324	0.8846153846153846
37	0.27913349723125963	0.9003215439833245	0.2540596467562211	0.8974358974358975
38	0.27348944046489676	0.8959003215434084	0.24867965854131258	0.8958333333333334
39	0.28018213065874154	0.9011254017376057	0.24570315388532785	0.8990384615384616
40	0.26609374515688305	0.9019292600668511	0.24057083481397384	0.9038461538461539
41	0.26766718305958814	0.8991157560103192	0.24830586176652175	0.8958333318050091
42	0.2625399968823436	0.9031350480398564	0.23608539463617864	0.9070512866362547
43	0.2604263184825707	0.9027331187794063	0.23349319665859908	0.9070512866362547
44	0.2533781749834202	0.9075562695214986	0.23165381451447806	0.9070512866362547
45	0.24903805424546122	0.9087620573028491	0.23396665965899444	0.9054487164203937
46	0.24432767328725366	0.9180064306765124	0.22166112332771987	0.9166666712516394
47	0.24222653730505916	0.9123794206469006	0.22011410349454635	0.9134615430465112
48	0.24405482569499798	0.9127813499073507	0.2237170541133636	0.910256408728086
49	0.235401198220023	0.9151929258533613	0.21463190324795553	0.9166666666666666
50	0.2432538468354768	0.9172025721556121	0.21809317286197955	0.9134615369332142
51	0.22817383716152412	0.9172025717723025	0.20996803389145777	0.9198717948717948
52	0.23106849322939993	0.9172025719639573	0.20810576547414827	0.9198717994567676
53	0.22645795968184518	0.9188102893890675	0.21059603607043242	0.9166666651383425
54	0.21994221766278674	0.92403536939161	0.2045938945733584	0.9214743635593317
55	0.2213613197351192	0.9204180066225229	0.2038049170604119	0.9230769276618958
56	0.230739760389282	0.921623793828909	0.20279191701840132	0.9230769276618958
57	0.21086827356524024	0.9260450160771704	0.20121395855377883	0.9230769276618958
58	0.21365711385222494	0.9272508032835565	0.19848693372347417	0.9230769276618958
59	0.20914203441219698	0.9340836014778284	0.19884858108483827	0.9214743574460348
60	0.21349151624168997	0.9256430872000299	0.1941774586836497	0.9214743635593317
61	0.2019740526603349	0.9296623799961863	0.1940994354394766	0.9198717994567676
62	0.21004223445029122	0.9312700968463321	0.19407187172999749	0.9214743574460348
63	0.2023504528777009	0.928456591064907	0.19397357679330385	0.9214743574460348
64	0.20589305144222603	0.9252411581312345	0.1915549670274441	0.9230769215485989
65	0.20482840733991942	0.9304662379421221	0.19113613321230963	0.9214743574460348
66	0.19505489231880838	0.9292604495858073	0.19283691488015345	0.9230769200202746
67	0.191464838347251	0.9316720261067822	0.18907959759235382	0.9230769215485989
68	0.19255632746641277	0.9336816716424139	0.18812852448377854	0.9230769215485989
69	0.19012571037582263	0.9372990347948105	0.1860439636004277	0.9230769215485989
70	0.19790179428563623	0.9356913183279743	0.18590802947680155	0.9294871779588553
71	0.18340860609072965	0.9336816718340687	0.18479933685217148	0.9310897420614194
72	0.18512742096779813	0.9364951770405294	0.18400208766643816	0.9294871779588553
73	0.1784040297821787	0.9377009640552607	0.18984772112125006	0.9246794887078114
74	0.1819112412272159	0.9320739551755777	0.18772126524112162	0.9246794887078114
75	0.18043657246126624	0.9417202566597622	0.18583036672610503	0.9262820528103755
76	0.18396873566115401	0.9393086812887161	0.18244246202401626	0.924679485651163
77	0.1800491428931043	0.9372990355614297	0.18056062532541078	0.9230769215485989
78	0.17584012995003886	0.9405144700283407	0.18267491249701914	0.9246794887078114
79	0.17490429529423115	0.9377009652051895	0.179467757160847	0.9310897420614194
80	0.17540119406303026	0.9377009640552607	0.1789636799158194	0.9326923107489561
81	0.16826711738799546	0.940916399097136	0.17789608698624831	0.9278846123279669
82	0.16766867245221062	0.9433279744681822	0.17723944324713486	0.9326923107489561
83	0.16615791086981918	0.9429260453993867	0.17763247455541903	0.9278846169129397
84	0.16047130527507839	0.9453376211537425	0.1771024335653354	0.931089746646392
85	0.16499537838041975	0.9461414794829881	0.17692195375760397	0.9342948748515203
86	0.16551376792970576	0.9381028935073656	0.17671267000528482	0.9262820482254028
87	0.15675291778381997	0.9453376207704329	0.17807337316947106	0.9278846169129397
88	0.1534932729132306	0.9457395502225379	0.17585738671895784	0.931089746646392
89	0.1589556543869221	0.9445337624411875	0.17612633930566984	0.9246794841228387
90	0.14950046350526655	0.9445337616745682	0.17903505380337054	0.9278846169129397
91	0.15729775964926293	0.9453376211537425	0.17484504710405302	0.9326923046356592
92	0.1527474081904367	0.9477491963331339	0.17513587478643808	0.9246794887078114
93	0.15050268017498244	0.9469453380038884	0.17455877382785845	0.9230769200202746
94	0.15145018344619265	0.9461414792913333	0.17379676951811865	0.9391025610459156
95	0.1487052212574091	0.9493569131832797	0.17385824578694808	0.9278846169129397
96	0.15012792881182918	0.9489549841144844	0.1724633692930906	0.9326923046356592
97	0.14039663450606765	0.9521704183897405	0.1720607817555085	0.9342948687382233
98	0.14267319379751706	0.9489549841144844	0.17381115181323809	0.9278846169129397
99	0.13968773291616962	0.9521704174314665	0.1798178547850022	0.9310897451180679

The optimal condition:
	epoch: 94
	train_acc: 0.9461414792913333
	val_acc: 0.939102561046
	using time: 176.558847189
