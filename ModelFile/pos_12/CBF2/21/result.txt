The number of train datas: 2488
The number of test datas: 624
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7027480205538955	0.5036173631523967	0.693578146971189	0.5144230815080496
1	0.6949449641528237	0.5357717039884095	0.6870964138935773	0.5496794825945145
2	0.6874402096417173	0.5265273309980558	0.6815953759046701	0.5721153830870603
3	0.6800989696450556	0.5663183285492409	0.6758488844602536	0.6089743620310074
4	0.6765367729870836	0.5651125403845808	0.6682168749662546	0.6506410210560529
5	0.6670653097499222	0.6032958199356914	0.6599284517459381	0.6698717902868222
6	0.6577335783906305	0.6229903540810589	0.6497975603128091	0.7179487148920695
7	0.6508914257169153	0.6410771702263516	0.6380654802689185	0.7259615399898627
8	0.640914074286004	0.6398713824450012	0.6238637597132952	0.7435897405330951
9	0.6236764267326551	0.6881028935073656	0.6077433702273246	0.7580128205128205
10	0.6029482430200485	0.6961414789080237	0.5858876766302646	0.7676282020715567
11	0.5874394414125915	0.7315112540192926	0.5625525728250161	0.7772435866869413
12	0.5680816131389409	0.7351286169800344	0.5376193263591864	0.7980769246052473
13	0.536730187115562	0.7608520900321544	0.5121636856824924	0.807692303107335
14	0.5193437244922785	0.764067523732446	0.49109550775625765	0.8076923122772803
15	0.49094669324408774	0.780546623985867	0.4641521389667804	0.8157051297334524
16	0.4877545936122968	0.778536976916997	0.4495749450646914	0.8157051312617767
17	0.46428201771625754	0.7905948553054662	0.4281956599308894	0.8269230799797254
18	0.4535148427417424	0.8022508032835565	0.4176765229457464	0.8269230815080496
19	0.44384801109887395	0.801446945912585	0.4064012979849791	0.8285256456106137
20	0.4328884106740308	0.817524115755627	0.3985417622786302	0.831730767702445
21	0.4238640314321426	0.808279743148583	0.3922219352844434	0.8381410225843772
22	0.41391761414107786	0.8207395504141927	0.38520779747229356	0.8413461507895054
23	0.40615908480533836	0.82596463060839	0.3767977272852873	0.8429487148920695
24	0.39138621503900484	0.8219453378122336	0.3732667160339845	0.8477564071997618
25	0.38956917204274244	0.8376205783948254	0.3633595040211311	0.8413461523178296
26	0.3785082870357673	0.8444533762057878	0.3556734422842662	0.8413461584311265
27	0.38031601388354774	0.8460610932475884	0.34717824520208895	0.8509615430465112
28	0.3686327411047515	0.8424437295202274	0.34940182322110885	0.8477564071997618
29	0.3557781024186174	0.8512861734417857	0.3362198838820824	0.8557692353542035
30	0.3555666518747998	0.8444533767807522	0.3322247923948826	0.8589743635593317
31	0.35428829419267904	0.8456591636038286	0.3354185555989926	0.8557692277125823
32	0.3410445044469987	0.8496784565916399	0.3181959894987253	0.8685897481747162
33	0.34173996895072545	0.8577170421839527	0.3115857121271965	0.8701923122772803
34	0.3365168968197617	0.8625401927343902	0.30577325897339064	0.8685897481747162
35	0.3270077495521288	0.8593247590340986	0.302551459807616	0.8717948763798444
36	0.3147610945812759	0.872588424437299	0.3020299650155581	0.8717948687382233
37	0.30510787086088176	0.8806270100296119	0.29035059802043134	0.8733974343691117
38	0.2967347158688058	0.8842443733736634	0.2860345374315213	0.8798076892510439
39	0.3039251027383222	0.8778135044398415	0.2786983289779761	0.8830128174561721
40	0.2928381739513667	0.8826366555652434	0.27123795946439105	0.8910256394973168
41	0.29112792158816786	0.88906752469072	0.2775333191339786	0.8830128205128205
42	0.2848307509514297	0.8914790998701114	0.2661474969906685	0.8878205128205128
43	0.2846591271388186	0.8902733118971061	0.26494854803268725	0.8862179487179487
44	0.27422990355269317	0.8922829578160473	0.25855019573981947	0.8942307692307693
45	0.26973285092418214	0.897508038585209	0.26424629795245635	0.8878205174054855
46	0.263402734682491	0.9011254019292605	0.24760225300605482	0.8974358974358975
47	0.2658924492992389	0.8987138259832499	0.24573935606540778	0.9006410302259983
48	0.2589999969174241	0.9019292610251252	0.25092760339761394	0.8942307738157419
49	0.2587790089596506	0.8983118969144546	0.2341426630050708	0.9182692307692307
50	0.2544604756441147	0.9063504826984221	0.23741414226018465	0.9038461584311265
51	0.23752414562119548	0.921623794787183	0.22800238239459503	0.9182692353542035
52	0.23757235792097173	0.9091639871382636	0.2233967192662068	0.9214743635593317
53	0.23776818050065607	0.9103697745363045	0.22308072600609216	0.9182692353542035
54	0.23067948993570936	0.9155948558804307	0.2184421794536786	0.9198717994567676
55	0.23500276531820513	0.9107717043717191	0.21975756952395806	0.9214743574460348
56	0.23524218064604083	0.9123794214135198	0.21631769148203042	0.9198717994567676
57	0.22573525369933947	0.915594855497121	0.21708637743424147	0.9230769215485989
58	0.22319248725938642	0.9200160765954536	0.2096213323947711	0.9230769276618958
59	0.22378243065148687	0.9224276533080834	0.21087607550315368	0.9214743574460348
60	0.21484315150995348	0.9244372992270246	0.20599338030203795	0.9198717994567676
61	0.21491270370997034	0.9200160765954536	0.20522149747762924	0.9230769215485989
62	0.2079013050369128	0.9328778140797875	0.20438858675651062	0.9246794902361356
63	0.2050022415792827	0.9284565916398714	0.2013858594955542	0.9246794902361356
64	0.20650750034491733	0.9276527336939355	0.2010893057554196	0.9230769261335715
65	0.2003470754364679	0.9340836014778284	0.20221050140949395	0.9262820543386997
66	0.19738367722157113	0.9256430872000299	0.19956021354748651	0.9278846184412638
67	0.19465525716639026	0.9340836007112092	0.19756574279222733	0.9262820543386997
68	0.19382521260972957	0.9336816714507591	0.1944083735728875	0.9262820543386997
69	0.19038341263866118	0.9312700962713677	0.19233698837268046	0.931089746646392
70	0.1943308053196818	0.9348874596154192	0.19068056344985962	0.9342948702665476
71	0.18453199064233294	0.9316720257234726	0.1896747954380818	0.9326923107489561
72	0.18144308056957853	0.9348874601903836	0.1885221948226293	0.9326923107489561
73	0.17618223167117386	0.9385048227678158	0.19360585797291535	0.9294871825438279
74	0.17965052916497662	0.9352893894508337	0.1960791933995027	0.9262820543386997
75	0.18017643196598127	0.9368971064926344	0.1948914701739947	0.9262820543386997
76	0.1849673607916694	0.9377009652051895	0.18926485494161263	0.931089746646392
77	0.17404917388004507	0.9409163987138264	0.1849197451120768	0.9342948748515203
78	0.167125878178805	0.9449356909350184	0.1878908267005896	0.9342948748515203
79	0.17116470596606326	0.9372990357530845	0.18333082550611252	0.9342948748515203
80	0.17499901704082918	0.9377009640552607	0.18263317606387994	0.9342948748515203
81	0.16278274558556424	0.9425241163305914	0.18583588359447625	0.9342948748515203
82	0.16494845150942972	0.9417202576180363	0.18260730019746682	0.9342948748515203
83	0.15958645877539154	0.9469453380038884	0.18269395331541696	0.9342948748515203
84	0.16808637459178447	0.9401125407678904	0.18108905851840973	0.9358974389540844
85	0.15864691610217477	0.9525723476501906	0.18130866896647674	0.9342948748515203
86	0.15969500774547601	0.9401125396179616	0.18482017497985792	0.9326923107489561
87	0.15632359865585707	0.9457395492642638	0.18451423866626543	0.931089746646392
88	0.14916335242737527	0.9513665589105661	0.17954472471506167	0.9358974389540844
89	0.16044741545555294	0.9441318329890824	0.18544997504124275	0.931089746646392
90	0.1476685774192166	0.9505627003896658	0.18202832837899527	0.9326923107489561
91	0.15285937825870669	0.9449356917016376	0.18014239386106148	0.9375000030566485
92	0.15135462836053978	0.9489549843061392	0.18173397064973146	0.9326923107489561
93	0.14447652182011742	0.9505627015395947	0.17935251750243017	0.9358974389540844
94	0.1438646904908576	0.9513665596771853	0.17818026779553828	0.9342948748515203
95	0.13997254657208727	0.9505627009646302	0.17710288709554917	0.9375000030566485
96	0.1429181175599911	0.9525723474585358	0.1776505897824581	0.9358974389540844
97	0.1424097346914543	0.9513665596771853	0.17620226912773573	0.9358974389540844
98	0.13613732607130835	0.9529742765273312	0.1845287650059431	0.9310897405330951
99	0.14304871090547064	0.9497588430186943	0.1849331485155301	0.9278846123279669

The optimal condition:
	epoch: 95
	train_acc: 0.9505627009646302
	val_acc: 0.937500003057
	using time: 219.152026892
