The number of train datas: 5712
The number of test datas: 1428
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7093329104054876	0.5010504201680672	0.6952724894221757	0.5084033615114976
1	0.6948951147183651	0.5220588238633314	0.6913946494668806	0.528011204314833
2	0.6936349466401321	0.5260854343406293	0.6885886796716214	0.5539215682935315
3	0.691360238720389	0.5285364143988666	0.6865582118849126	0.5623249299719888
4	0.6854640467494142	0.5456932769770048	0.683412249849624	0.593137254735001
5	0.681983536698905	0.5519957984862875	0.6799143040213598	0.5980392155193147
6	0.6783705488974306	0.5733543420706143	0.676019445520823	0.6169467787114846
7	0.6778195762500709	0.5742296918767507	0.6718563325598794	0.6330532212885154
8	0.6708306758677592	0.5803571428571429	0.6663155714336898	0.6491596638655462
9	0.6653536274319604	0.6018907564694808	0.6583700851232064	0.6708683471719757
10	0.6576484770667987	0.6083683476728552	0.6503940660412572	0.6855742298588365
11	0.6493995540282306	0.6323529410095108	0.6399516947463113	0.7023809522139925
12	0.641295638738894	0.6440826330532213	0.6275317864257748	0.7254901964123509
13	0.6303752420329246	0.6566876749030682	0.613632879170383	0.7352941176470589
14	0.614459138958394	0.6827731094106573	0.5964333147895771	0.7591036417905022
15	0.596769640425674	0.6948529411764706	0.5768092262978647	0.7654061627989056
16	0.5800987370207864	0.7099089632515146	0.5531114139476744	0.7962184875619178
17	0.5615789215771758	0.7303921570297048	0.5311064427974177	0.8053221285176211
18	0.5383393151753423	0.7505252104179532	0.5032705479309338	0.8263305318789655
19	0.517142565560942	0.7685574228022279	0.47451719040630247	0.8452380949041757
20	0.49275360220954534	0.7818627449310794	0.44742809290311586	0.8494397762442837
21	0.4631519165693545	0.8096988797187805	0.4216959698527467	0.8529411761366686
22	0.4495598880850634	0.8046218484055763	0.3966168235330021	0.8697478994935834
23	0.4247929847874895	0.828606442410071	0.37523788414081605	0.8767507006140316
24	0.40880629770896015	0.8375350136716827	0.3533688888830297	0.8788515402823269
25	0.3856775921766831	0.8529411768045078	0.3346606800202228	0.8872549016268647
26	0.36889222606557426	0.8615196075092176	0.3195119263077317	0.8921568630790176
27	0.356539423726186	0.8662464987663996	0.30244311164407167	0.8998599436436715
28	0.3359009242859207	0.8753501400560224	0.2906220736456852	0.9026610647596899
29	0.31782984883845355	0.885329131652661	0.27486311721534623	0.9089635851002541
30	0.30946769734390644	0.8874299721557553	0.265486243475719	0.9089635851002541
31	0.29960939747278764	0.891806722355156	0.2560532060490937	0.9110644254363885
32	0.28703945140544773	0.9030112044817927	0.24718513871942246	0.9138655458845678
33	0.27965081055291224	0.8995098042554882	0.24063316780645974	0.9159663862207023
34	0.27009989158446046	0.9061624649859944	0.23462301601214902	0.9215686271170608
35	0.2627714596041778	0.9096638657131783	0.22961639272732562	0.9180672265568367
36	0.2597934899209928	0.9136904758565566	0.22154613845154686	0.9264705879013745
37	0.2522804673228945	0.9171918765837405	0.21808906233444267	0.9236694674531952
38	0.24751599901029708	0.9168417363607583	0.21497539808603228	0.9271708680134193
39	0.23335564441206744	0.9219187671730832	0.21704391822093674	0.9271708680134193
40	0.22793950703965515	0.9264705885692137	0.20403659552419218	0.9292717083495539
41	0.22684729658588976	0.9276960784313726	0.20303876526883335	0.9327731089097779
42	0.228570714300754	0.9257703079562896	0.1997324954979226	0.9320728287977331
43	0.21540854249347827	0.9285714285714286	0.19644834522773572	0.9334733890218228
44	0.21433412611317568	0.9338235297456843	0.1939930930441501	0.935574229524917
45	0.2132805031972105	0.9317226894095498	0.19455326976729373	0.939075630085141
46	0.20448383279875212	0.937149859610058	0.19192648476579277	0.9369747895820468
47	0.20246897892457763	0.935399159329946	0.18803682572701397	0.9397759101971859
48	0.1968323453551247	0.937675070194971	0.18410626062158109	0.9411764704212755
49	0.19344135434353718	0.9369747899159664	0.18327142531965293	0.9404761903092307
50	0.18609779872814147	0.9417016803383493	0.18125527070350006	0.9446778709814996
51	0.18337390260870048	0.9434523807854212	0.1800869948723737	0.9439775908694548
52	0.18335173093304247	0.9445028011204482	0.17813212981744975	0.9439775908694548
53	0.18382350845831116	0.9417016803383493	0.17691150090607607	0.946778711317634
54	0.1809370614358691	0.9452030815664125	0.17672995079298312	0.9488795516537685
55	0.17873036085056657	0.9481792715417237	0.17552921297002574	0.946778711317634
56	0.17599440827256158	0.9481792720426031	0.17280716067101776	0.9474789914296788
57	0.16813490909187734	0.9511554625187936	0.17122707000466622	0.946778711317634
58	0.16799005365171352	0.9488795514868087	0.17057786869401692	0.9495798317658133
59	0.16373746351701537	0.9494047615708423	0.1694925669528523	0.9488795516537685
60	0.16777687622051612	0.948704481792717	0.17605890308608527	0.9446778708145398
61	0.1603677158429175	0.9516806722689075	0.16702164626088128	0.9488795516537685
62	0.1619292515583065	0.9551820726621718	0.16804092145767532	0.9488795516537685
63	0.15987458249100117	0.9537815127720018	0.165997613962291	0.9495798317658133
64	0.158706506176823	0.9502801120448179	0.16628122655283503	0.9474789914296788
65	0.1563644289803438	0.953956582800013	0.16615068048489193	0.9502801118778581
66	0.15006205535569445	0.9537815124380822	0.16484013729903543	0.9502801118778581
67	0.1506321367596378	0.9560574228022279	0.17188863251723496	0.9453781509265846
68	0.14350445086465163	0.9564075626912905	0.162909369759199	0.9495798317658133
69	0.14785305905241927	0.9572829129983064	0.16093478692012006	0.9537815124380822
70	0.14448033062433327	0.9551820731630513	0.16127375619752066	0.9509803919899029
71	0.14221257605806453	0.9590336137792977	0.16095694649119338	0.9537815124380822
72	0.13858402157280625	0.9581582636392417	0.16098219508967815	0.9502801118778581
73	0.1384736501118716	0.9599089632515146	0.16366178243934942	0.9509803918229431
74	0.13592453463738705	0.9581582631383624	0.1619723551497072	0.9509803918229431
75	0.1361708904013914	0.9586834730554361	0.1582708355842852	0.9551820726621718
76	0.1319413962317448	0.95780812308234	0.1589843490961887	0.954481792550127
77	0.13137801454848602	0.959908963752394	0.16040668025070212	0.9509803919899029
78	0.13190020017680668	0.9634103644795778	0.16011733743322998	0.9523809522139925
79	0.1289290889304559	0.9630602240896359	0.1562116690793959	0.9558823527742166
80	0.12864462100491136	0.9620098042554882	0.1575350118200986	0.9551820726621718
81	0.12350947891964632	0.9625350140056023	0.1586161285680549	0.9488795516537685
82	0.1252838079334975	0.9632352939506873	0.15872606511960843	0.9530812323260374
83	0.1257588380650312	0.9667366943439516	0.1557370958959355	0.9565826328862616
84	0.12476839016632539	0.9632352937837275	0.15492350689503326	0.9558823527742166
85	0.12099917679607701	0.9667366948448309	0.15759020300806403	0.9530812323260374
86	0.12209894076114942	0.962710084367533	0.1540105719359315	0.9558823527742166
87	0.12078243807083418	0.9648109247036675	0.15413553190498458	0.9551820726621718
88	0.11520723869152763	0.9649859943977591	0.15592697170936093	0.9516806721019477
89	0.1192728643323861	0.9662114847607973	0.15544998316036887	0.9530812323260374
90	0.1160886789194676	0.9655112044817927	0.15573867187112653	0.9530812323260374
91	0.11229747951197691	0.9674369749568758	0.15261564654212037	0.9551820726621718
92	0.11046865398810357	0.9672619044279852	0.15583096131557175	0.9537815124380822
93	0.11513554594930814	0.9672619044279852	0.15191566357676053	0.954481792550127
94	0.10913850060280632	0.9669117648728421	0.1539080681420174	0.9551820726621718
95	0.11002364550151077	0.968487395124943	0.15228859241269216	0.9558823527742166
96	0.1065495883216377	0.9691876754039476	0.16148603020929822	0.954481792550127
97	0.10442550941592171	0.9711134452111915	0.1513828076735264	0.9537815124380822
98	0.1071663040156458	0.96953781545997	0.15301113331518254	0.954481792550127
99	0.10536687894194734	0.96953781545997	0.15235525273642286	0.9565826328862616

The optimal condition:
	epoch: 99
	train_acc: 0.96953781545997
	val_acc: 0.956582632886
	using time: 451.706224918
