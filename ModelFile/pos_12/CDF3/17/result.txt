The number of train datas: 5712
The number of test datas: 1428
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7149588575884074	0.49439775893668164	0.697786605992571	0.49509803938264607
1	0.6986846376200017	0.5224089632515146	0.6932765385683846	0.5238095234756043
2	0.6954138955148328	0.5236344536145529	0.6903709907825587	0.5427170870016936
3	0.6912107063608677	0.5320378152930102	0.6882974031258698	0.553921568627451
4	0.6870169175439188	0.5483193273971728	0.6860048560535207	0.5637254898621589
5	0.6840704899876058	0.5469187671730832	0.6830566286706791	0.584733893557423
6	0.6809960435084602	0.5688025210084033	0.6802355880830803	0.5938375350140056
7	0.6786487870523575	0.5661764704212755	0.6761845478824541	0.6148459380414305
8	0.6745641543751671	0.5759803918229431	0.6719466192381722	0.6274509803921569
9	0.6702144039111311	0.5941876752369878	0.6649796433475506	0.6582633049882093
10	0.6624402317012391	0.6130952377613185	0.6572552445222016	0.6750700280112045
11	0.657869681924665	0.6150210084033614	0.6477069208601943	0.6946778711484594
12	0.6514994300046221	0.6306022408963585	0.6381658195447522	0.707983193277311
13	0.6382066579092116	0.6509103638117387	0.6252391922707651	0.739495798152368
14	0.6250551219413928	0.6652661066095368	0.6092113752325042	0.7521008403361344
15	0.6116021430792928	0.6757703077893297	0.5923884312311808	0.7661064427439906
16	0.5959260647370368	0.7008053221288515	0.5720939061888793	0.7913165264436844
17	0.580577980236513	0.7158613445378151	0.5522427315137634	0.7892156864414696
18	0.559425392237698	0.7317927169198749	0.5265517213932273	0.7976190477860075
19	0.5361474365079436	0.7522759105311054	0.5003464499107596	0.8277310926039346
20	0.5166324171699396	0.7662815126050421	0.47453583647557	0.8382352942846069
21	0.4879448036519753	0.7911414562487135	0.44765771453787967	0.8438375351809654
22	0.47486311781640145	0.7953431370879421	0.42375387455902847	0.8578431374218618
23	0.45192602034710366	0.8105742296918768	0.40236703696705045	0.8662464987663996
24	0.43576476570604894	0.8210784315395088	0.3811508459704263	0.8746498602778972
25	0.4128016342802876	0.8333333333333334	0.36373541727453385	0.878851540950166
26	0.39400631581701817	0.8466386554621849	0.3454150804618494	0.8858543420706143
27	0.38211502548025433	0.8527661062756172	0.328390388428664	0.8949579828593577
28	0.3561699284391911	0.865721288682366	0.31598115535009474	0.8921568630790176
29	0.3391075680235855	0.8704481789377891	0.2974749378630427	0.9075630248761645
30	0.32685131827990216	0.8778011207820988	0.28465974422729984	0.9138655458845678
31	0.31840602439992566	0.8849789914296788	0.2719586203579141	0.9187675066688815
32	0.3008285927839306	0.8954831936112305	0.2614926311816154	0.9222689072291056
33	0.2878856426026641	0.8965336132784184	0.25131287511323347	0.92436974756524
34	0.2814068015383071	0.9005602242565957	0.2437625673054313	0.9299719884615987
35	0.27386203800596776	0.9051120451518467	0.236815579047724	0.9327731089097779
36	0.26335671051543635	0.9166666663327471	0.22730878321062617	0.938375350140056
37	0.25752375936474786	0.9175420168067226	0.2213139005568849	0.9397759101971859
38	0.25255190816914	0.9119397762442837	0.21550695740041279	0.9425770306453651
39	0.23781987770097932	0.9243697478991597	0.21333463302179545	0.9376750698610514
40	0.2292013884592457	0.9262955178733633	0.20403204641255343	0.946778711317634
41	0.22574098028388678	0.927696078097453	0.19992763759876167	0.9467787114845938
42	0.2264244166575894	0.9303221286845809	0.1984817884048494	0.9474789914296788
43	0.2147353974377074	0.9355742298588365	0.1924732656789427	0.9467787114845938
44	0.2152446148609247	0.9353991594969058	0.19002769566049763	0.9523809523809523
45	0.2126224904167218	0.937675070194971	0.1892315365520178	0.9495798319327731
46	0.20251051634967493	0.9371498597770178	0.18497451179835642	0.9509803921568627
47	0.19749014125484712	0.9441526612313855	0.18172948258597643	0.9502801120448179
48	0.19697217459605187	0.9427521005064166	0.17910973239345712	0.9502801120448179
49	0.19159627211194077	0.9441526613983453	0.17627483719036358	0.9537815126050421
50	0.1819816676258039	0.9478291313187415	0.17416998126259706	0.9516806721019477
51	0.1767779712040885	0.9490546221826591	0.1711047267546507	0.9537815126050421
52	0.181791536280421	0.9480042020145919	0.17137606947028003	0.9544817927170869
53	0.17786755602733761	0.948004201847632	0.16976740989698416	0.9558823529411765
54	0.17588728981442145	0.9506302522678002	0.1684927386062152	0.9544817927170869
55	0.16969752457796358	0.951505602574816	0.16800557703030208	0.9523809522139925
56	0.16957856426719858	0.9523809520470328	0.16506678421123355	0.9530812323260374
57	0.16431824124159933	0.9550070024672008	0.16308305577403692	0.9565826330532213
58	0.16176172439791575	0.9541316524941046	0.1628955238256134	0.9544817927170869
59	0.16040440554879293	0.9558823527742166	0.1616650075137782	0.954481792550127
60	0.16394482866054824	0.9551820731630513	0.1680213811100364	0.9509803919899029
61	0.15481143855915017	0.9569327732762035	0.1582210895394077	0.9586834733893558
62	0.15630603663059844	0.9592086833064296	0.1572494467600387	0.9586834733893558
63	0.1542334716443588	0.95780812308234	0.15671368147812637	0.9558823527742166
64	0.15266016108983038	0.9564075628582503	0.1563653505983807	0.9558823527742166
65	0.14627821801924237	0.9592086836403492	0.15517863101151144	0.9579831931103512
66	0.1452069499162065	0.9599089634184744	0.15394548493690519	0.9565826328862616
67	0.14631213790395348	0.960259103307537	0.16129743497745663	0.9537815124380822
68	0.13957935619671472	0.961834734227477	0.1527482204619242	0.957983193277311
69	0.13880649674422935	0.9628851537277051	0.15215859775032317	0.9593837535014006
70	0.13606296168739387	0.9621848742834994	0.15205266241098986	0.9572829129983064
71	0.13580360303238995	0.9635854338397499	0.15083352292702645	0.957983193277311
72	0.13632325116409308	0.9614845941714546	0.15133969274973	0.9551820728291317
73	0.13439354271280998	0.9618347335596379	0.1501544967544179	0.9558823527742166
74	0.13100087467361898	0.9641106440907433	0.15218753974978663	0.9572829129983064
75	0.13312271387637162	0.9646358546756563	0.14945749821616153	0.9586834733893558
76	0.12750195367496556	0.9648109247036675	0.15120246422057057	0.9572829129983064
77	0.12611387248466663	0.9653361346207413	0.1490002370932523	0.958683473222396
78	0.12920434848100198	0.9667366946778712	0.1531139021160222	0.9558823527742166
79	0.12850013266758425	0.9649859943977591	0.1479413734764612	0.9600840336134454
80	0.1241770018132127	0.9649859942307993	0.14754962052951673	0.957983193277311
81	0.12106836301271989	0.9642857146196339	0.14777514680760914	0.9600840336134454
82	0.11907840739278232	0.96796218454003	0.1486113945058748	0.9600840336134454
83	0.12463379905921738	0.9667366948448309	0.14830063187441572	0.9565826328862616
84	0.11942437781589706	0.9688375353479252	0.14721951326903174	0.9572829131652661
85	0.11609853332450076	0.9660364147327861	0.14980492897394324	0.9572829129983064
86	0.11506506637865756	0.9669117650398019	0.1467942736145495	0.9586834733893558
87	0.11205039292323489	0.9691876752369878	0.1464557459249216	0.9600840336134454
88	0.11000154386548434	0.96953781545997	0.14736195273843467	0.9558823527742166
89	0.11062940873769152	0.9691876749030682	0.14676922636957063	0.9558823529411765
90	0.10936929597532381	0.9688375350140056	0.15147449355833337	0.954481792550127
91	0.10709511190235448	0.9693627450980392	0.14690190551578164	0.9600840336134454
92	0.10519546445678263	0.9693627447641197	0.1476235190609924	0.957983193277311
93	0.1085179378839434	0.9718137258241156	0.14730691690655315	0.9600840336134454
94	0.10921860510269467	0.9690126047080972	0.15105400628903332	0.954481792550127
95	0.10264245744178943	0.9707633049882093	0.15140803717598528	0.9537815124380822
96	0.09764191965345576	0.973039216020194	0.14759009725907268	0.9544817927170869
97	0.1040083026351715	0.9718137253232363	0.14656278916767665	0.957983193277311
98	0.10184204186044153	0.971988795685167	0.1478679570622471	0.9558823529411765
99	0.10237702253569408	0.9716386557961044	0.14606369733393026	0.9586834733893558

The optimal condition:
	epoch: 93
	train_acc: 0.9718137258241156
	val_acc: 0.960084033613
	using time: 492.391277075
