The number of train datas: 5712
The number of test datas: 1428
epoch	train_loss	train_acc	val_loss	val_acc
0	0.713742271023972	0.49527310957761705	0.6989091412693846	0.48529411731313926
1	0.7003694906288168	0.515406162381506	0.6936904662797431	0.5147058821859813
2	0.6927917743263459	0.5250350136716827	0.6899087238712471	0.5350140056857208
3	0.6915017226163078	0.5288865549557683	0.6869205470178642	0.5504201680672269
4	0.6863173670461532	0.5358893555753371	0.6831679300767701	0.5686274509803921
5	0.6796358356288835	0.5654761904761905	0.6790150821375913	0.5910364142319068
6	0.676394030159595	0.5768557426308384	0.6744636210406861	0.6071428568089375
7	0.6751110603829392	0.577205882519901	0.6694108780358686	0.6218487391618788
8	0.6686107397747307	0.5926120444840076	0.6632645445711473	0.6309523809523809
9	0.6619298877168436	0.6052170866677741	0.6543782338374803	0.6617647057153931
10	0.6518880658123005	0.624299720054915	0.6451429702988526	0.687675070194971
11	0.6415253954441273	0.6500350143395218	0.6335520246783558	0.695378151427464
12	0.6356783906618754	0.6460084033613446	0.6212817412130639	0.7037815127720018
13	0.6251923294962287	0.6694677867809263	0.6068301446297589	0.7254901959114716
14	0.6095854518126372	0.6885504201680672	0.5911849329785472	0.7387955183742427
15	0.5972864043478873	0.6990546218487395	0.5744305034311545	0.7492997202218747
16	0.5819621460110533	0.712535014172562	0.5541055586491647	0.7703081234162595
17	0.5622305354150403	0.7309173672806983	0.5341005779448009	0.7773109247036675
18	0.5432270247729218	0.742647059157449	0.512344467706707	0.7878151263843397
19	0.5273439218016232	0.7528011204481793	0.4884032789064723	0.8053221291854602
20	0.5048285346238219	0.7640056019069768	0.46392090973399935	0.8228291318196208
21	0.48118104554024066	0.7883403358005342	0.4419260504199009	0.834033613612338
22	0.46753674720515725	0.790966386387662	0.4205541477984741	0.8508403364683733
23	0.44728819779655177	0.8053221286845809	0.4028245034505005	0.8480392156862745
24	0.4364393106361731	0.8126750698610514	0.38449129529026044	0.8641456585972249
25	0.41381317043170873	0.8270308119910104	0.36740367494377435	0.8704481796056283
26	0.3957361679952018	0.8324579830263176	0.3495512716576499	0.8774509807260764
27	0.38610256569726126	0.8429621850409094	0.3350861888973653	0.8830532209545958
28	0.363360687631185	0.8539915966386554	0.3239592789601879	0.8872549017938245
29	0.3553539886861956	0.8573179270039085	0.30926085920894847	0.893557422635268
30	0.3445820421898732	0.8646708685142988	0.29816517175412643	0.9012605038677611
31	0.3275493612977303	0.8755252104179532	0.2859978150753748	0.9061624651529542
32	0.31583058216324705	0.8802521006733763	0.27514680301775785	0.9110644254363885
33	0.3074937104677954	0.8841036412896228	0.2653918126050164	0.9166666663327471
34	0.2911463778893821	0.8989845941714546	0.2561320826119068	0.9201680668929711
35	0.28597288614227656	0.898984593837535	0.248772374054297	0.9222689072291056
36	0.2735867545384319	0.9063375348470458	0.2400057531204544	0.9229691873411504
37	0.26479537814271215	0.9121148459383753	0.23414132725290893	0.928571428237509
38	0.26217128482519414	0.9073879555159924	0.22656491357071393	0.928571428237509
39	0.25508195003207657	0.9150910360806462	0.2282745422435408	0.9299719891294378
40	0.24009428530180155	0.9191176473927432	0.2149201826888974	0.9327731089097779
41	0.24511045401169806	0.9156162464985994	0.21196100040644156	0.936274509470002
42	0.2335000112444079	0.9236694674531952	0.20573667735278772	0.9341736691338676
43	0.22839910810401126	0.9252450983731353	0.20177229930038879	0.9383753498061365
44	0.22644025446320115	0.9289215687944108	0.1986632668504528	0.9369747895820468
45	0.2211754665989168	0.9280462183204352	0.19534520032693023	0.9418767503663605
46	0.21236074730461718	0.930847339102534	0.19434879549077244	0.9383753498061365
47	0.2054111848191387	0.9355742298588365	0.1899054587221279	0.9446778708145398
48	0.2020882269581493	0.9367997202218747	0.18493138804656117	0.9446778708145398
49	0.19998138032707513	0.9394257706420428	0.18342598671672725	0.9446778708145398
50	0.19000163999926142	0.9410014007271839	0.17988887654633082	0.9474789912627191
51	0.187846397276686	0.9394257699742037	0.17785133642642773	0.9474789912627191
52	0.1883930343539775	0.9390756299181813	0.17697464413836556	0.9481792713747639
53	0.1859668676926642	0.9434523812863005	0.1738477271645009	0.9502801117108983
54	0.18468103392952295	0.9424019604503941	0.173201370890401	0.9481792713747639
55	0.17681441737824127	0.9443277309254772	0.17615932267920978	0.9460784310386294
56	0.1791004660416718	0.942226890422383	0.17016890198409723	0.9509803918229431
57	0.17399658834566922	0.9446778709814996	0.16798639668970883	0.951680671934988
58	0.17427208067990152	0.9450280112044818	0.16644711955254818	0.9537815122711224
59	0.16453803833626232	0.9495798319327731	0.16548137178941935	0.9523809520470328
60	0.16384322561469733	0.9488795518207283	0.17474082863631368	0.943977590702495
61	0.1635221780097785	0.9488795516537685	0.1653663440495312	0.951680671934988
62	0.16205702016667492	0.9511554625187936	0.16262217634031417	0.955182072495212
63	0.1643749318536924	0.9525560227428832	0.16403197232080774	0.9530812321590776
64	0.1580211344469829	0.9523809523809523	0.16097139281218126	0.955182072495212
65	0.15308204501950773	0.9536064425770309	0.16170475880304971	0.9530812321590776
66	0.1495931503318605	0.9543067225221158	0.16122997166061936	0.9544817923831672
67	0.15147614875594442	0.9537815126050421	0.1666753552958411	0.9481792713747639
68	0.15014566940252855	0.9546568625781382	0.1611055533091227	0.9544817923831672
69	0.14957755689277036	0.9548319324391896	0.15936353514675333	0.955182072495212
70	0.1439988380219756	0.9572829129983064	0.16043868289441288	0.9544817923831672
71	0.14730529203301385	0.9572829129983064	0.1580689338659372	0.9544817923831672
72	0.13835093341454738	0.9609593839204612	0.15713948708455436	0.9558823527742166
73	0.14064561920005733	0.9571078434711745	0.15734642051181205	0.9544817923831672
74	0.13489708364928135	0.9613095234756043	0.16142216591941877	0.9523809520470328
75	0.13796047711906648	0.9574579828593577	0.15620358342550048	0.9558823526072568
76	0.13028010717627048	0.9616596635316267	0.1627397603180562	0.9488795514868087
77	0.13364929106889986	0.9590336134453782	0.15756661250811665	0.9523809520470328
78	0.13027521815537071	0.9604341740033874	0.16260152395699873	0.9481792713747639
79	0.1273861068720911	0.9602591036414566	0.15712562825332502	0.9530812321590776
80	0.12698947126958884	0.9623599436436715	0.15570519634989463	0.9565826328862616
81	0.1247750743180096	0.961484593837535	0.15641873288137906	0.9544817927170869
82	0.12596009024718896	0.9627100838666537	0.15531389452830083	0.9544817927170869
83	0.12465815214800234	0.9653361346207413	0.15598645626830787	0.9530812323260374
84	0.12090884720911833	0.96796218454003	0.1566888410337165	0.9530812323260374
85	0.12187934760786906	0.9653361347877011	0.1578165427559898	0.9509803918229431
86	0.12350327331645816	0.9618347340605172	0.1548486266399966	0.9558823529411765
87	0.11974438094124407	0.9662114849277571	0.15500157015497276	0.9558823529411765
88	0.11197828852078494	0.9677871150128982	0.15439078019780605	0.9565826330532213
89	0.11205512001400902	0.9658613442038956	0.15610168506952227	0.9544817927170869
90	0.11559946302856718	0.9641106445916227	0.15654252381885753	0.9544817923831672
91	0.11016320514411819	0.9674369749568758	0.15741180497057297	0.9530812321590776
92	0.10892802376707061	0.967261904594945	0.16251881712791966	0.9488795514868087
93	0.10942691476906047	0.9656862741758844	0.15540833086693653	0.9544817927170869
94	0.10848908049135315	0.9688375351809654	0.16502512206717365	0.9481792713747639
95	0.10939309927595764	0.968312324929972	0.1586933006175092	0.9509803918229431
96	0.10315115420090384	0.9707633053221288	0.1601758396425167	0.9509803918229431
97	0.10489782958137554	0.96796218454003	0.1552474108271572	0.9544817927170869
98	0.1046144822899367	0.9684873946240636	0.15660572064523937	0.9523809523809523
99	0.10255700364416721	0.9688375353479252	0.15660495020929172	0.9523809522139925

The optimal condition:
	epoch: 88
	train_acc: 0.9677871150128982
	val_acc: 0.956582633053
	using time: 354.213035822
