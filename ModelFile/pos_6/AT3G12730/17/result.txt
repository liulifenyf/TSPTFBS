The number of train datas: 5798
The number of test datas: 1450
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7092162209076897	0.4962055880824382	0.6890405686970414	0.5303448278739534
1	0.6924270654843157	0.5277681959296309	0.6831923409166007	0.5675862071431916
2	0.6849109714259028	0.5507071403521182	0.6770065264044137	0.605517241543737
3	0.6796034703011264	0.560710589961374	0.6686577244462638	0.6489655180635123
4	0.674125256909301	0.5819248016146226	0.6600508305122113	0.6737931030372093
5	0.6662441641349306	0.5969299759771052	0.6502584730345627	0.699310344498733
6	0.6579362730109802	0.611935149907819	0.6378252758650944	0.7317241374377547
7	0.6464169489880931	0.6390134527708753	0.6230167443998929	0.725517240721604
8	0.6333686687815555	0.6576405656300729	0.6056167995518652	0.7806896554190537
9	0.6170646038578477	0.683684028934388	0.5843569315713028	0.7924137925279552
10	0.593813215608883	0.7064505002341546	0.5616517891554997	0.7882758625622454
11	0.5752223350542008	0.7242152467190129	0.5297122379007011	0.8282758623156055
12	0.5455973701318324	0.7507761298438195	0.49668297348351315	0.826206895976231
13	0.5119574123125481	0.7749223871944937	0.462962673738085	0.839310344252093
14	0.4814668775488895	0.7909624010129154	0.426419089621511	0.8634482752043625
15	0.4510231467311487	0.8159710246556872	0.395500957595891	0.8724137932678749
16	0.4228476707834176	0.8247671612750748	0.36581892490386964	0.8772413794747714
17	0.39535922606717555	0.8427043808415332	0.34273492036194636	0.8820689657638813
18	0.37235855758087355	0.8539151429677676	0.3304194150710928	0.8800000002466399
19	0.34932296404183916	0.8665056915149971	0.3073208473674182	0.8931034484402887
20	0.33056172966011316	0.8771990340469047	0.29111349319589547	0.8944827587851163
21	0.3118403278350337	0.8880648501333017	0.28019766719176853	0.9082758622333921
22	0.3036129304708058	0.8920317351016228	0.2694926151324963	0.9048275855491901
23	0.2875026577544566	0.901345291644304	0.2621097548254605	0.9041379303767764
24	0.2736179612348227	0.9041048636433173	0.24820609238641014	0.9158620683078108
25	0.2578522442959226	0.9103139013658519	0.24183946149102573	0.918620688997466
26	0.25416921390135067	0.9153156262218808	0.23310207763622548	0.9227586199497354
27	0.23866984738013217	0.9211797171438427	0.22859622252398523	0.9262068967161508
28	0.23170386001380322	0.9258364952404198	0.22347823944585077	0.9296551715916601
29	0.22873451143616272	0.9270438082302879	0.21792762439826438	0.931034482840834
30	0.22293925970001194	0.9284235943634372	0.21520675449535764	0.9331034483580753
31	0.2132699725627077	0.9329078992961727	0.2095747176737621	0.9351724138753168
32	0.20707524643145006	0.9358399449524776	0.20659798215175498	0.934482758702903
33	0.20383348569618337	0.9375646773516289	0.20284185818557082	0.9372413793925581
34	0.1960516288059257	0.9391169370187074	0.20149825846326763	0.9413793104270409
35	0.19307314544638587	0.9451535012073129	0.1992676192522049	0.9337931035304892
36	0.1889838148737291	0.9430838218842263	0.19784005915296488	0.9337931035304892
37	0.19249360847777439	0.9446360814279423	0.19289618516790455	0.9413793104270409
38	0.1753772420589576	0.9448085545712235	0.19621743450904713	0.934482758702903
39	0.18126292814567774	0.9429113487615056	0.18826192378997803	0.9448275862891099
40	0.17367304820039223	0.9494653328734046	0.18672353290278337	0.9427586207718684
41	0.16713986398023176	0.9517074854836952	0.18586056411266327	0.9386206897373858
42	0.16776654459651727	0.9491203862167548	0.18345668285057462	0.9455172414615236
43	0.1666504862278484	0.9491203864840402	0.1834795027662968	0.9475862060744187
44	0.16510843156884153	0.9499827525499731	0.18151376268987	0.9475862060744187
45	0.1603285566655962	0.951879958606416	0.17973674850217228	0.9468965518063512
46	0.16044351669550763	0.9499827525499731	0.18097355645278404	0.9475862060744187
47	0.15538746033219808	0.9532597449040487	0.17744800997191462	0.9489655173235926
48	0.1504028021194434	0.9551569508165686	0.1775862674466495	0.9455172414615236
49	0.15008013111305632	0.9558468438831433	0.17474349174006232	0.94965517159166
50	0.14567979041611626	0.956364263415789	0.17438592881991946	0.9489655164192463
51	0.14506835127830833	0.9577440495489383	0.173658135101713	0.9503448267640738
52	0.1405477748323449	0.9587788891488003	0.17364306622538073	0.9482758612468325
53	0.13814035916932907	0.9596412556259416	0.17202963485799988	0.9510344819364877
54	0.13638100801366657	0.9594687824826604	0.17116330175564207	0.94965517159166
55	0.13586719836313668	0.9591238359493731	0.1709349601433195	0.9517241371089015
56	0.1345573519750088	0.9617109348051052	0.16975474986536748	0.9503448267640738
57	0.1334984436741715	0.9620558813383926	0.1727835581631496	0.9462068966339374
58	0.12427865745960412	0.9613659881484554	0.1703609529240378	0.9510344819364877
59	0.1243691509419287	0.9632631942048983	0.1683888746541122	0.9524137922813153
60	0.1281893649859731	0.9620558813383926	0.16712144639985316	0.9517241371089015
61	0.1244278361043588	0.9622283546050362	0.16752942494277295	0.9482758621511789
62	0.12471350423012491	0.961021041615168	0.16639058259026757	0.9537931026261428
63	0.11873643119794083	0.963090720958815	0.16666687383733947	0.9524137922813153
64	0.12200569085681714	0.9642980339486832	0.1640957594328913	0.9537931026261428
65	0.11783118829228788	0.9634356674715419	0.16500438266787035	0.9524137922813153
66	0.11582450842129523	0.9653328734046223	0.17175218129980152	0.9524137922813153
67	0.11457777639356882	0.9661952396144782	0.16344959529309439	0.9537931026261428
68	0.11397806700240665	0.9653328734251827	0.1655949176591018	0.9496551724960064
69	0.11063314351841431	0.9672300793582631	0.1635047707475465	0.9524137922813153
70	0.1103079500516588	0.9667126595377716	0.1633144711420454	0.9551724129709704
71	0.11246869397208624	0.9649879270152578	0.16194219044570266	0.953103447453729
72	0.10983506829528283	0.9663677130044843	0.16369511468657133	0.9503448276684202
73	0.10554775635757789	0.9692997585374267	0.16521196169072183	0.953103447453729
74	0.1017099909713121	0.9679199725482003	0.1619248834149591	0.953103447453729
75	0.10242852367519839	0.96757502587099	0.16453507285693597	0.9524137922813153
76	0.10231508976783411	0.9677474990142712	0.16234446930474247	0.9524137922813153
77	0.09910212856823102	0.9677474990142712	0.162944458455875	0.9524137922813153
78	0.10274950294874585	0.9691272851474205	0.16099473774433137	0.9531034483580754
79	0.09969859631689058	0.9686098656147749	0.1606508876126388	0.9551724138753167
80	0.09754031766546557	0.9710244910805009	0.16106499147826228	0.9537931026261428
81	0.0978419824010876	0.9694722319479933	0.15860757172107698	0.9544827577985566
82	0.09308358113512412	0.9732666438141541	0.16107138350092132	0.951034482018701
83	0.09456086262068529	0.9720593306803629	0.1597906468654501	0.9544827577985566
84	0.09444782476089625	0.9710244912244238	0.16027010091419877	0.9517241371911147
85	0.09060900730202016	0.9725767506036564	0.15983439096089067	0.9537931026261428
86	0.0942929543660155	0.97119696461443	0.15947154947395983	0.9544827577985566
87	0.087582729255672	0.973784063614085	0.15847549187725987	0.9558620681433843
88	0.09204578355710315	0.9708520178138572	0.1570589228334098	0.9551724129709704
89	0.0913574679601435	0.972231804214292	0.15803548107887136	0.9531034483580754
90	0.08850987186503127	0.9730941704035875	0.15909282536342226	0.9537931026261428
91	0.08713647249537362	0.9746464298033805	0.15827590297008381	0.9551724129709704
92	0.0835042527821217	0.9737840633467997	0.16804877410674918	0.9524137922813153
93	0.08362817533234557	0.9730941702802249	0.1584911817723307	0.9544827577985566
94	0.081445826630668	0.976198689079811	0.16190341236262487	0.9537931026261428
95	0.08187391675517822	0.9760262158131674	0.15872854588360621	0.9531034483580754
96	0.07942464769852906	0.9749913762133053	0.15732664225430323	0.9537931035304892
97	0.08109690284175929	0.974818903213947	0.1617637085298012	0.9544827577985566
98	0.07210651444089376	0.977750948623527	0.15921598422116245	0.9524137923635285
99	0.07308527552524326	0.9772335286796731	0.16369277037423233	0.951034482018701

The optimal condition:
	epoch: 87
	train_acc: 0.973784063614085
	val_acc: 0.955862068143
	using time: 485.122445107
