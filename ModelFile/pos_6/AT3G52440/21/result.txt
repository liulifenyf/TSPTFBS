The number of train datas: 3284
The number of test datas: 822
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7089478103455324	0.5051766135225052	0.6992317529490394	0.5072992695654106
1	0.7013347461075499	0.5106577344701584	0.6960545280844046	0.5194647211372997
2	0.6997089271278242	0.517052374644053	0.693427476279637	0.5206812649167657
3	0.6927834903133917	0.5222289897637594	0.6911133027424777	0.5316301705338369
4	0.6925451086151179	0.5240560293052432	0.689553535042598	0.5389294400992475
5	0.6901333952792233	0.5389768578538651	0.6876681016309418	0.5510948890607142
6	0.6868660272837557	0.5438489652580233	0.6864276724140139	0.5498783440485487
7	0.685762521410395	0.5517661387098547	0.6852727686111655	0.5608272491580378
8	0.6836002249810641	0.5526796588072969	0.6838997178994246	0.5608272516234367
9	0.6831804779647475	0.5654689410426875	0.682791313840815	0.5693430674337122
10	0.6815736256766697	0.5645554201466447	0.6813079798888696	0.5790754275310358
11	0.6807320969549079	0.5685140078889612	0.6795589749830483	0.5839416051142987
12	0.6771915470784242	0.5724725951230772	0.6781328124721555	0.5961070559610706
13	0.6778514720635641	0.5630328862153076	0.6764991373331297	0.6046228695959941
14	0.6777713424395702	0.5721680884239299	0.6748193785221908	0.608272506372772
15	0.6707463808965741	0.590133983238025	0.6729813983840663	0.6094890521100548
16	0.668757608979396	0.6050548114962467	0.6714080042792643	0.6070559628108412
17	0.6676573419396683	0.5965286230489194	0.6691939518979576	0.6131386864214338
18	0.6659279425745324	0.6044457976623516	0.6668524185236353	0.6180048664700956
19	0.6637233250324096	0.6065773450645837	0.6646739472147902	0.6277372251171845
20	0.6579225546840338	0.6184531066217318	0.6628038085580162	0.6265206830054885
21	0.6588145736945241	0.6218026800945529	0.6598374776886617	0.6350364944650599
22	0.6575940186010354	0.6190621198748264	0.6572118202845255	0.6411192202510044
23	0.6508929931289822	0.6324604136935105	0.6540283942164585	0.6508515796232107
24	0.647435029880138	0.6342874545417952	0.6518540708688054	0.6435523131758047
25	0.638771058145307	0.6446406815142056	0.6474226114233624	0.6472019477772306
26	0.6416632821295641	0.6446406823854063	0.6438095156293716	0.6581508496962034
27	0.6329783363841773	0.6595615108614281	0.6402062570671676	0.6545012168350591
28	0.6300462164919501	0.6607795373676174	0.6359380659105714	0.664233575482148
29	0.6275183688418148	0.6568209494075008	0.6318913480661211	0.6569343054091553
30	0.6263164120672972	0.6580389762040904	0.6272191735949829	0.664233577947547
31	0.6189964957417292	0.6702192454041865	0.6251215292299461	0.673965936304589
32	0.612653451773194	0.6760048721797864	0.6189873344706793	0.6739659355794716
33	0.6083402807907123	0.6793544458704076	0.612970250656425	0.6727493905673062
34	0.6016659678553257	0.6836175400940713	0.607594976605	0.6763990248786852
35	0.597583252677964	0.6869671137846924	0.6017523930020576	0.681265204927347
36	0.5873313854730957	0.7021924488146616	0.5970023552866748	0.7031630165965598
37	0.590429586266484	0.6881851401456817	0.5905632482537968	0.7031630151463251
38	0.5740711733281395	0.7265529834396511	0.5834956733269703	0.7055961061858202
39	0.5711392686950739	0.7232034097490299	0.5760738137574671	0.7104622869595995
40	0.5617115676185246	0.732643117785599	0.5710959054547795	0.7226277360660897
41	0.5568770136089767	0.7289890381944311	0.5624348096313848	0.7335766421907429
42	0.5518156907880786	0.7311205847980625	0.5552855667696672	0.7445255480253493
43	0.5409196880572316	0.7381242382976518	0.5477443273630166	0.7542579073975556
44	0.5318765733912859	0.7499999995643997	0.5390582682152444	0.7542579073975556
45	0.5302657402244177	0.7478684531785684	0.5313268625823251	0.7639902660446446
46	0.512333220308794	0.7658343483556638	0.5231806266046789	0.7639902674948792
47	0.5106351188271693	0.7624847750280429	0.5157036438330537	0.7725060828700843
48	0.49577269528002166	0.7813641905929807	0.5101522787353998	0.7664233582443274
49	0.492893187558317	0.780146163578591	0.5003907164227933	0.77858880619063
50	0.4866287320235179	0.7813641903025805	0.49478916921754823	0.7773722626286992
51	0.4771436102933338	0.7962850181252018	0.486459734521063	0.7834549869644091
52	0.47023663186126735	0.799939099386171	0.4795527439337867	0.7968369841285575
53	0.4710326447774374	0.7941534713037702	0.4781021510597563	0.7785888090910993
54	0.46293192811482714	0.7999390982245702	0.4640607320479233	0.7968369816631586
55	0.4536310736720658	0.8042021928112342	0.45637969081709273	0.8029197074491032
56	0.452976669267673	0.8075517668648556	0.45173582826217595	0.811435524274543
57	0.4369858593002742	0.8099878200224343	0.4436056922096986	0.8065693446609515
58	0.4265569057882776	0.8221680882787298	0.43672093850562754	0.8138686125585922
59	0.42936670870931953	0.8242996340837606	0.43200799982333127	0.824817516942964
60	0.4197996661665959	0.837393422147098	0.4261261004311035	0.8199513383445368
61	0.41375468371846646	0.827344701801235	0.4238456663134034	0.8175182483202059
62	0.4072605560961362	0.8340438488194771	0.4178222990674114	0.8345498802308039
63	0.4035068841494538	0.8355663819522138	0.414170810848547	0.8272506084175295
64	0.39212544413054323	0.8480511565446563	0.4093134453986973	0.8272506084175295
65	0.3994933405253542	0.8413520096716143	0.40727918839802707	0.8309002434540259
66	0.39291079384110295	0.8431790497212985	0.4048059299189389	0.832116787741074
67	0.38625832067192256	0.8492691837042461	0.40086931990881036	0.8418491471132803
68	0.38286479875608714	0.8504872105008356	0.3974268495891506	0.8357664227775704
69	0.3761557338806947	0.8517052369344249	0.3949095567647558	0.8406326028262322
70	0.374290365467118	0.8517052373700252	0.3943284697776293	0.8381995128019013
71	0.36562081982679984	0.8559683307224882	0.3895142644716295	0.8467153271619421
72	0.36876601793879277	0.8584043843882674	0.3905462783618565	0.8418491478383976
73	0.3569123654577532	0.8596224111122568	0.39034087916070237	0.8381995128019013
74	0.3540580255613548	0.8608404384170467	0.3847239393822468	0.8467153271619421
75	0.3507885145937772	0.860840438707447	0.3832725118981661	0.8479318721741075
76	0.35721820142759914	0.8590133985125626	0.37927827797376906	0.8552311422471003
77	0.34199020252012885	0.8690621195844263	0.3792455302972863	0.8430656935756804
78	0.3471311189588182	0.8644945190972155	0.37452542796332183	0.8540145972349348
79	0.33571554511676605	0.8687576133208792	0.37410632334196364	0.8503649621984385
80	0.3390894125643369	0.8730207062377419	0.3724564273281979	0.8503649621984385
81	0.33283557591281476	0.8772838000258052	0.3840270073599479	0.8442822393129632
82	0.3260639042714917	0.8748477468682265	0.3728475493091156	0.8503649621984385
83	0.32582654409228523	0.8763702794927627	0.3711727710390903	0.8479318721741075
84	0.3206872725167315	0.8806333737164264	0.36739358741001493	0.849148417186273
85	0.3253297991279272	0.8724116928394471	0.3676991990592938	0.8467153271619421
86	0.32269307960110666	0.8806333741520267	0.36430703912048157	0.8503649621984385
87	0.3185227144505016	0.8888550545934056	0.3656424114303867	0.8479318743494595
88	0.3064713207653176	0.8897685751264481	0.36814490033182207	0.8467153293372941
89	0.31011914535358676	0.8839829482056482	0.36831623185290036	0.8467153293372941
90	0.2976502128916449	0.8955542015390477	0.36152054068525924	0.8515815079357212
91	0.29517535467821554	0.8955542016116478	0.35998707132327873	0.8467153286121768
92	0.29713407267751707	0.8888550553920063	0.35832796225872643	0.8527980522227694
93	0.2987117817428022	0.892509134620174	0.3569883008797963	0.8540145972349348
94	0.2990457643544921	0.8946406821676062	0.35749666693726884	0.852798053673004
95	0.286641516907642	0.8934226550080163	0.3561867857646478	0.856447687984383
96	0.2832351782870786	0.8985992686031216	0.3544411224170323	0.8515815086608386
97	0.2791986629711725	0.8934226550806164	0.35258693133827546	0.8576642329965485
98	0.2775489708247632	0.9049939092852166	0.35209297713282045	0.8600973230208794
99	0.265094991160804	0.9019488433101436	0.3556215401258492	0.852798053673004

The optimal condition:
	epoch: 98
	train_acc: 0.9049939092852166
	val_acc: 0.860097323021
	using time: 222.354468107
