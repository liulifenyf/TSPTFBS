The number of train datas: 16440
The number of test datas: 4112
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6883126322370376	0.5437956203509421	0.666201303441237	0.6245136186770428
1	0.6553675700858271	0.6120437955914333	0.6283837531327273	0.6833657587548638
2	0.6132487420908146	0.6735401458983874	0.5831739624186713	0.7137645914396887
3	0.5549563045049236	0.7279197081162112	0.5322988342914136	0.7419747081712063
4	0.5018199440046529	0.7666058393870537	0.47852161631046103	0.7784533073929961
5	0.4424054141027214	0.8104014599410286	0.4351855633555683	0.808852140077821
6	0.4025865812371247	0.8371654501216546	0.406911642982802	0.8263618677042801
7	0.371993816304961	0.8548661799906524	0.3884780413909645	0.8382782101167315
8	0.35383454603290326	0.866484185001856	0.37606882538776915	0.8426556420233463
9	0.3320326882702301	0.8775547444385333	0.3753633639459944	0.8509241245136187
10	0.32454582799380133	0.8811435522534261	0.36511505856124343	0.854328793774319
11	0.3076251502744763	0.886922141061212	0.35642567247964063	0.8562743190661478
12	0.3065729235500605	0.8893552312015617	0.353844595384505	0.8594357976653697
13	0.2954533434987358	0.8927615570906015	0.34783007813334926	0.8611381322957199
14	0.2895187977891769	0.8922141118931364	0.34721484565781247	0.8628404669260701
15	0.2850607651356073	0.8976277373132915	0.33972852471273696	0.8647859922178989
16	0.2775762575531238	0.8984793188218073	0.33796100898243575	0.8664883268482491
17	0.2759502895919656	0.9001824818388389	0.3422015687660948	0.8630836575875487
18	0.2683485783364651	0.9029197080872065	0.34120948212619884	0.8655155642023347
19	0.2630270773331904	0.9029805353088101	0.33281419153691266	0.8655155642023347
20	0.2640986052597816	0.9040145985111413	0.3316041213471138	0.8662451361867705
21	0.25726835685634847	0.9060218977232048	0.3306027462684227	0.8672178988326849
22	0.25354910057101515	0.9069951337329373	0.32126970223879536	0.8708657587548638
23	0.2532157398705935	0.908029197167306	0.32633268125790105	0.8686770428015564
24	0.24776325019896756	0.9093673965066599	0.32248455668701737	0.8684338521400778
25	0.24464273224709387	0.9103406326034064	0.3202722501661991	0.868920233463035
26	0.2406699941468645	0.91070559619407	0.31660468137101905	0.8711089494163424
27	0.23802516464769405	0.9125912407888983	0.32142211520022457	0.8708657587548638
28	0.23544906554720987	0.9125912407888983	0.3117108974127454	0.8723249027237354
29	0.23397779080409492	0.912591240817903	0.3149257788166462	0.8728112840466926
30	0.22850969934115445	0.9153284671532846	0.3155403697884964	0.8718385214007782
31	0.22673586050814376	0.916058394247598	0.30804796600967993	0.8732976653696498
32	0.22351259519583988	0.9178223845152379	0.3165685164847263	0.8740272373540856
33	0.22275647122204448	0.9167274939172749	0.3041099020015405	0.8747568093385214
34	0.21652350849188737	0.9194038929150342	0.30086200292936094	0.8767023346303502
35	0.21497464862328086	0.9193430656064165	0.30048942441258447	0.8764591439688716
36	0.211982855179014	0.9226885644478809	0.2982348003044203	0.8771887159533074
37	0.20899837311456965	0.9203771289247666	0.3022685531628271	0.8767023346303502
38	0.20528655283497488	0.9225060826380468	0.3065872228331139	0.8767023346303502
39	0.2041651062939289	0.9243309001562949	0.29861882853716726	0.8781614785992218
40	0.2025411771125457	0.924391727522922	0.3025884438987372	0.878647859922179
41	0.19948787109115118	0.9250608273376224	0.3055869135063446	0.8776750972762646
42	0.19733817540381077	0.9257299269202852	0.29018526272087247	0.8791342412451362
43	0.19168571990046768	0.9267031629880269	0.29355960814753396	0.879863813229572
44	0.18995596801277495	0.9282238442242291	0.2909418025021423	0.879863813229572
45	0.1878255528762683	0.928771289624727	0.29360050664569615	0.8796206225680934
46	0.1874075806706491	0.9302919708899338	0.2885395557500045	0.8791342412451362
47	0.18245991245818544	0.930596106968947	0.2865984645683014	0.8796206225680934
48	0.1791101037368287	0.9314476885354722	0.2946049356506956	0.8805933852140078
49	0.1813325317744211	0.9310218977522096	0.2925993733484921	0.8815661478599222
50	0.17519196619590124	0.9327250609142647	0.29935441661901513	0.8832684824902723
51	0.17433564225687598	0.9327858879908448	0.28596020260905475	0.8813229571984436
52	0.17251242198358197	0.9341849148708539	0.28855047151736246	0.8827821011673151
53	0.1709889099364443	0.9357664233866689	0.2955611986234958	0.8827821011673151
54	0.168512229291482	0.9350973236589826	0.2856039066548941	0.8837548638132295
55	0.16631447792488294	0.9364355231723647	0.2985627347248306	0.8835116731517509
56	0.16367332176135405	0.9374695862876817	0.30750960447908837	0.8861867704280155
57	0.16212482050677576	0.9386861314738754	0.280495861219061	0.8857003891050583
58	0.16036609293045498	0.9386253042232672	0.29056391667879045	0.8878891050583657
59	0.15920081508783238	0.938990267697912	0.2834962735728067	0.8859435797665369
60	0.157561822141319	0.9403892944619023	0.2834465154356066	0.8878891050583657
61	0.154460969864597	0.9413017031050076	0.28164717105692	0.8871595330739299
62	0.15362786588297564	0.9424574208955695	0.2793372265617671	0.8874027237354085
63	0.1502184272320021	0.9428223845152379	0.28376296435116793	0.8881322957198443
64	0.14769699630801114	0.9439781021607764	0.280222651849461	0.8883754863813229
65	0.14929209572700397	0.943065693517671	0.2821555460879311	0.8888618677042801
66	0.14594866513770863	0.9428223845152379	0.2954086181834514	0.8883754863813229
67	0.14823714335541946	0.9442214112502235	0.28728864031774987	0.8893482490272373
68	0.1445675283525402	0.9454987833679738	0.30234734458914064	0.8876459143968871
69	0.13991028243027753	0.9476277371392633	0.291188253778312	0.8891050583657587
70	0.14025976425829886	0.9462287105493011	0.27271965125771347	0.8895914396887159
71	0.13633301998431954	0.9478710462287104	0.27417712965943936	0.8900778210116731
72	0.13837951434064666	0.9471411192794206	0.27590056534871055	0.8903210116731517
73	0.13604181441512422	0.9473844282818537	0.27754849897052525	0.8895914396887159
74	0.13473058981762026	0.9473236010022407	0.2893688897620379	0.8895914396887159
75	0.1318967044897323	0.9501216545882306	0.2977358100624168	0.8888618677042801
76	0.1310034883138327	0.9490875911828666	0.2977554530543112	0.8883754863813229
77	0.13004079695673174	0.9501824817808295	0.2893454920688956	0.8895914396887159
78	0.1280252135293037	0.950729927036304	0.28123888550217513	0.8917801556420234
79	0.12481034545277737	0.9536496349494823	0.2945485783574182	0.8910505836575876
80	0.12692357237176594	0.9517639902966446	0.2909006784572212	0.8900778210116731
81	0.12310893502077337	0.9538321167883211	0.3256325704056465	0.8869163424124513
82	0.12267975753893817	0.9527980535569852	0.29220411539483626	0.8900778210116731
83	0.1194107545734612	0.9545012164579981	0.28472895937670994	0.890807392996109
84	0.11916206849970086	0.953649635065501	0.2907341910156526	0.8903210116731517
85	0.11904038044549253	0.9536496350364964	0.31981909849068535	0.8874027237354085
86	0.11970877506002023	0.9535279804772704	0.3147850168093401	0.8878891050583657
87	0.11408191187683393	0.9563868612848639	0.30622811582127896	0.8895914396887159
88	0.11518782060729327	0.9564476886224863	0.2874968677527246	0.890807392996109
89	0.11509063956293747	0.9551094891091043	0.2935303270034057	0.8915369649805448
90	0.11123177148492377	0.9567518248755277	0.33282260861291263	0.8859435797665369
91	0.11494931544193096	0.9569343066563571	0.2868595753256449	0.8925097276264592
92	0.11047654891536184	0.9572384427933798	0.28116157772708034	0.890807392996109
93	0.10765794802031088	0.9595498782874894	0.32337307825626566	0.8881322957198443
94	0.10819236099212419	0.9577858881358683	0.30685760901247944	0.8905642023346303
95	0.10723091985332414	0.9595498782584847	0.31858726128471965	0.8888618677042801
96	0.10684982950452471	0.9598540146275448	0.31948978603176104	0.8900778210116731
97	0.1065524080954039	0.9601581507935721	0.3134646054487748	0.8903210116731517
98	0.10284687194728503	0.9611922141409268	0.2835558080313734	0.8917801556420234
99	0.1025537349881917	0.9610097323600973	0.3233381312499946	0.8900778210116731

The optimal condition:
	epoch: 91
	train_acc: 0.9569343066563571
	val_acc: 0.892509727626
	using time: 1381.21693897
