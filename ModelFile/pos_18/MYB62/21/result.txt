The number of train datas: 7736
The number of test datas: 1936
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7212063840281261	0.5069803514179794	0.6866020348446429	0.5495867768595041
1	0.6987690216136447	0.5204239915420745	0.6823918824353494	0.5831611570247934
2	0.6906829202680578	0.5411065149948294	0.6785522039271583	0.5981404958677686
3	0.6840571952827714	0.5573940021298911	0.6726162709480474	0.6213842975206612
4	0.6775154425168358	0.570449844757798	0.6649677467740271	0.6508264462809917
5	0.6724639655762152	0.5789813856674202	0.6557190221203261	0.6745867768595041
6	0.6625060214744852	0.6059979319325893	0.6438701024725417	0.6952479338842975
7	0.6490498258507856	0.6273267838059932	0.6278724079289713	0.7143595041322314
8	0.6321981226892481	0.6527921406411582	0.6055351751894991	0.7381198347107438
9	0.617025318227115	0.6695966906729997	0.5819552060493753	0.743801652892562
10	0.5858758887682484	0.7094105481485053	0.5488108672386358	0.765495867768595
11	0.5599678015758235	0.7251809720785936	0.5118111325196983	0.7902892561983471
12	0.5298473160663829	0.7487073423573988	0.4751305875699382	0.809400826446281
13	0.49264263542756176	0.7790847982837594	0.4422548464999711	0.824896694214876
14	0.45790233637948813	0.8002843848182102	0.3990341254994889	0.8517561983471075
15	0.4254262106186848	0.8185108581397994	0.3704039471701157	0.8646694214876033
16	0.39058955067685863	0.8355739400823212	0.33484386043115094	0.881198347107438
17	0.36188582692299165	0.8513443639507708	0.31011282523308903	0.8946280991735537
18	0.3375623857346291	0.8700879007238883	0.284614593283204	0.8992768595041323
19	0.31285685981934913	0.8822388831437435	0.268241210417314	0.9049586776859504
20	0.2961416840861477	0.886633919399798	0.2551644054079844	0.9106404958677686
21	0.2792639006564881	0.8954239916037132	0.2464084388795963	0.9173553719008265
22	0.26790013884684416	0.9011116858105624	0.23440247343098822	0.9178719008264463
23	0.2507743689365446	0.9086091001253217	0.23561551107847986	0.9209710743801653
24	0.24284688602928786	0.9117114786771362	0.23042857757777221	0.9235537190082644
25	0.23207075647324046	0.9189503618825184	0.21838066474465298	0.9287190082644629
26	0.22753554716660046	0.9234746639706356	0.2146769912898048	0.9297520661157025
27	0.22003188945021723	0.9232161323065102	0.21194710527077193	0.9292355371900827
28	0.21188347941532254	0.9276111684392871	0.20843763464738516	0.9297520661157025
29	0.20834924565722554	0.9289038264517208	0.21151357987695488	0.9323347107438017
30	0.2034845632166749	0.9290330922221447	0.2019363388049701	0.9333677685950413
31	0.1997199890039083	0.9331695966291575	0.20362301195455976	0.9338842975206612
32	0.1912361976402622	0.9340744572686804	0.19748007795534844	0.9328512396694215
33	0.192486413123689	0.9347207859358841	0.1988838574856766	0.934400826446281
34	0.18665702089343716	0.9347207857509681	0.20361453848929445	0.9333677685950413
35	0.18258387444400245	0.9398914168144825	0.18907754652756303	0.9333677685950413
36	0.17836480882816255	0.9383402275693946	0.20376784212825713	0.934400826446281
37	0.16994730252945928	0.9432523269687838	0.1841895301972539	0.9338842975206612
38	0.1685838479752871	0.9411840745187224	0.1899894256729725	0.9369834710743802
39	0.1670052681769309	0.9419596688947115	0.1904886743623363	0.9359504132231405
40	0.1649211781039726	0.9429937951813809	0.18956120219851327	0.9354338842975206
41	0.15961882555250545	0.9464839712293835	0.18024347550120234	0.9364669421487604
42	0.15668754382858355	0.9475180973927755	0.1907463240598844	0.9359504132231405
43	0.1540611334676703	0.9486814892649528	0.17919734785379457	0.9375
44	0.1476583786717122	0.9488107550970154	0.1818801133839552	0.9369834710743802
45	0.14844262217014503	0.9521716650664005	0.18162580450211674	0.9380165289256198
46	0.14431627513118467	0.9508790073621606	0.1740419257524585	0.9375
47	0.1415944928158895	0.9519131332173589	0.18948578717541104	0.9333677685950413
48	0.14408933046161204	0.9511375388413699	0.1822550134225325	0.9349173553719008
49	0.13569041385460787	0.9550155118308121	0.18059080303454203	0.9369834710743802
50	0.13344298289258577	0.953593588417787	0.18328417905352332	0.934400826446281
51	0.13822744617232863	0.9520423989877829	0.17084175914772287	0.940599173553719
52	0.1339925135165114	0.9546277146428176	0.1755310251446795	0.9390495867768595
53	0.12845999087209908	0.9568252328633029	0.17245170763455148	0.9395661157024794
54	0.12534258399840595	0.9572130301745749	0.16889134886836218	0.9421487603305785
55	0.1249738344970817	0.9578593588417788	0.1620979940842006	0.9467975206611571
56	0.12052263979026673	0.9582471562146894	0.16862185459491635	0.9421487603305785
57	0.12235262401348063	0.9581178903826267	0.1751241235693624	0.9380165289256198
58	0.11956736747456682	0.9607032059760227	0.16787579667962288	0.9411157024793388
59	0.11544130390823935	0.9608324715615305	0.17279732276585477	0.9400826446280992
60	0.11429594198266871	0.9619958636802626	0.17210971028351588	0.9400826446280992
61	0.1103396889866323	0.9636763186341357	0.15994803471998734	0.9483471074380165
62	0.11478451417514432	0.9605739400206825	0.16253404405491412	0.9452479338842975
63	0.11095520043447074	0.9623836609298958	0.1757149395863872	0.9395661157024794
64	0.11082102348324925	0.9634177870932877	0.16267492788389695	0.9447314049586777
65	0.10911492099590607	0.965356773588009	0.17892795659540114	0.9385330578512396
66	0.10415570514186091	0.9657445708992809	0.17048066916051974	0.940599173553719
67	0.10184266220204216	0.9647104445509728	0.15627787908739296	0.9493801652892562
68	0.1013395073395049	0.9671664943123061	0.1627146042575521	0.9457644628099173
69	0.0963280913039595	0.9683298863693994	0.17677453326538575	0.9395661157024794
70	0.10027341753429317	0.9671664943739449	0.16449903321167655	0.943698347107438
71	0.09773946666729857	0.9656153052521343	0.15672728874959235	0.9504132231404959
72	0.09742684336427326	0.9665201654601862	0.15453195177819118	0.9504132231404959
73	0.09451671002862248	0.968459152016546	0.16457389467511296	0.9462809917355371
74	0.09279966222617347	0.9678128232260648	0.1584524818934685	0.9509297520661157
75	0.0911667695097556	0.9702688728641207	0.15731800119738934	0.9493801652892562
76	0.0922489593531686	0.9707859359458166	0.16022992503544517	0.949896694214876
77	0.08979904766443966	0.9700103413849114	0.1676911720929067	0.9452479338842975
78	0.08617056872322	0.972207859543758	0.15414897654174772	0.949896694214876
79	0.08388797104582113	0.9709152016546019	0.15447340991871417	0.9504132231404959
80	0.08422412748728814	0.9724663907764123	0.15255205283972842	0.9514462809917356
81	0.08269272667607205	0.9724663907764123	0.1550314166575424	0.9504132231404959
82	0.0797579783711278	0.9736297828335057	0.1637698452581059	0.9473140495867769
83	0.07755872992087914	0.9746639090585364	0.16415136362895494	0.9493801652892562
84	0.07719238755036041	0.9747931748289603	0.1622208961524254	0.9483471074380165
85	0.07627448093265511	0.9733712512926577	0.15869056193296574	0.949896694214876
86	0.07516149045454557	0.9742761118705419	0.1523615116915427	0.9514462809917356
87	0.07678667235167962	0.9736297828951445	0.1675350693139163	0.9447314049586777
88	0.07431747110978525	0.9735005172479979	0.16127502967503446	0.9478305785123967
89	0.07094158102770749	0.9775077560078642	0.1577164802915794	0.9519628099173554
90	0.06984885780462434	0.9772492244053774	0.15665190242046168	0.9524793388429752
91	0.0739146442823844	0.9741468457302855	0.15788214499792777	0.9483471074380165
92	0.07209668206792583	0.9754395036810803	0.15566969127201838	0.9519628099173554
93	0.0684817620430762	0.9776370217782882	0.15071170647774845	0.9540289256198347
94	0.0670557783910814	0.9780248190279214	0.16404100193465052	0.9457644628099173
95	0.06629987172358655	0.9777662875487122	0.15998483098242894	0.9483471074380165
96	0.06907166349927914	0.9771199587582309	0.15504897909223542	0.9524793388429752
97	0.0634662577614666	0.9803516029571919	0.1758834396388905	0.943698347107438
98	0.05983929923950331	0.9817735264318559	0.15742273677971738	0.9535123966942148
99	0.0632808140624457	0.979705274105072	0.15613413817626387	0.9535123966942148

The optimal condition:
	epoch: 93
	train_acc: 0.9776370217782882
	val_acc: 0.95402892562
	using time: 696.269016027
