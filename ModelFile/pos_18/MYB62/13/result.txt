The number of train datas: 7736
The number of test datas: 1936
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7139151971613855	0.5138314373737284	0.6875737166601764	0.5408057851239669
1	0.6943722137374246	0.5310237848401193	0.6826773207049724	0.5728305785123967
2	0.6890164161911918	0.5359358840854116	0.6786295648448724	0.59400826446281
3	0.6820018995387601	0.5508014477149901	0.6744333604150567	0.6084710743801653
4	0.680041464001341	0.5595915200421827	0.6692368654180164	0.6358471074380165
5	0.6762551176511021	0.5747156152126092	0.662826930195832	0.6544421487603306
6	0.6684994332669563	0.5920372284186046	0.6543707423958897	0.6797520661157025
7	0.6599574050834285	0.6127197518713595	0.644569983659697	0.7076446280991735
8	0.6449871087271524	0.639607032057911	0.6298801184685763	0.7277892561983471
9	0.6354739850284888	0.6491726988843702	0.6116462029701422	0.743801652892562
10	0.6130979808188027	0.679291623701354	0.5877458142840173	0.7639462809917356
11	0.5908991814029501	0.7057911065766336	0.5578705249739088	0.78150826446281
12	0.5639975115333249	0.7263443638274933	0.5236449537198405	0.8099173553719008
13	0.529784138039941	0.7546535679201799	0.4858991538197541	0.8217975206611571
14	0.496132290689997	0.778826266619634	0.44607905686394245	0.8290289256198347
15	0.4647292736705851	0.7961478801646424	0.41022340867145	0.8455578512396694
16	0.43272534817179825	0.8111427093489094	0.37561038555192555	0.8605371900826446
17	0.3993692782080531	0.8366080662457132	0.34494228254665027	0.8729338842975206
18	0.3704032644305875	0.8495346432881123	0.3166355682798654	0.881198347107438
19	0.34525056160223644	0.8596173733811837	0.2949069684202021	0.8961776859504132
20	0.32122429558138565	0.8777145810556264	0.2756318496771095	0.8941115702479339
21	0.3017126572045816	0.8845656670113754	0.25843834187373643	0.9085743801652892
22	0.2833292643773642	0.890770423991727	0.24466944652155412	0.9111570247933884
23	0.2669493865140838	0.9017580146626825	0.2350005407101852	0.9173553719008265
24	0.25588502147020203	0.9073164424210818	0.23048340757031086	0.9168388429752066
25	0.24053255053316056	0.915460186019432	0.21247568886634732	0.9214876033057852
26	0.2286570202231777	0.9219234746022703	0.20637005850795873	0.9276859504132231
27	0.22835111223554166	0.9211478799797264	0.20336836342476616	0.9307851239669421
28	0.2182749610436616	0.9211478799797264	0.1962954527583004	0.9318181818181818
29	0.2147996912420474	0.9273526372066329	0.20105332641069554	0.9297520661157025
30	0.20538081219487253	0.9286452945410404	0.1876813408202869	0.9318181818181818
31	0.2012612669889535	0.930325749618191	0.18427578978671516	0.9333677685950413
32	0.19660317153509055	0.934591519980544	0.1791181336811259	0.9364669421487604
33	0.19521918493749685	0.9356256463904908	0.18088627157132486	0.9349173553719008
34	0.18642021472168066	0.9370475696802386	0.17693949189067873	0.9359504132231405
35	0.18402541421870042	0.9387280248806666	0.17428106223502435	0.9385330578512396
36	0.17467522658908502	0.9391158222535774	0.18013292243165419	0.9338842975206612
37	0.1747632777277908	0.9414426061828479	0.17060842635956677	0.9369834710743802
38	0.17079082826362402	0.9428645295342344	0.16702510145577518	0.9400826446280992
39	0.16458622417812388	0.944157187300113	0.16516416535274056	0.943698347107438
40	0.163337997683818	0.9449327819842956	0.16245536216773276	0.9442148760330579
41	0.15954098771128808	0.9453205789873741	0.16048747861434606	0.943698347107438
42	0.15620253967061531	0.9472595657902888	0.16653534625310543	0.9400826446280992
43	0.1543614114976595	0.9480351604128328	0.15831157066359008	0.9421487603305785
44	0.14775138450815364	0.949715615120151	0.1546700570947868	0.9483471074380165
45	0.14798339917839745	0.9521716651280392	0.1561137514173492	0.9442148760330579
46	0.1504784828165571	0.950103412431423	0.15599595121115692	0.9431818181818182
47	0.14270141867163755	0.9528179936719656	0.157174116200652	0.9421487603305785
48	0.14456451728154115	0.9526887280864578	0.15801787793574748	0.9421487603305785
49	0.13829502930254084	0.9537228540032948	0.1522246987120179	0.9488636363636364
50	0.13611338229035147	0.9528179938568817	0.15445509669948215	0.9473140495867769
51	0.13666897939735756	0.9539813858523364	0.1493045969689188	0.949896694214876
52	0.13130314618487762	0.9552740434332989	0.15131316814294532	0.949896694214876
53	0.13002866229202287	0.954756980536519	0.1479387953877449	0.9509297520661157
54	0.12936411744066453	0.956178904011183	0.14771244902748706	0.9519628099173554
55	0.12591962242785998	0.9564374353671148	0.1442038366678825	0.9519628099173554
56	0.12113541463291756	0.9574715613455905	0.14414708618043867	0.9509297520661157
57	0.12525276375131253	0.9570837642808735	0.15124798738513112	0.9457644628099173
58	0.1221792826269134	0.9578593589650561	0.14332686804912306	0.9504132231404959
59	0.11846743975578197	0.9596690796277145	0.14942745925966372	0.9509297520661157
60	0.11594501371960605	0.9596690798126307	0.14733971455249906	0.9524793388429752
61	0.11558149053860599	0.9607032056061904	0.140980950779905	0.9509297520661157
62	0.12178709564466635	0.9594105481485053	0.1413074284176196	0.9519628099173554
63	0.1146910026199507	0.9590227508372333	0.14459810636876044	0.9514462809917356
64	0.11441345422720342	0.9603154085414732	0.1441526306131162	0.949896694214876
65	0.11346187327739002	0.9625129266386812	0.15274710768510488	0.9462809917355371
66	0.10973003653822912	0.9627714583028065	0.15128372477228977	0.9483471074380165
67	0.1044430187686646	0.9623836609298958	0.14122294148137746	0.9535123966942148
68	0.1035862253148652	0.9632885211995863	0.14498586666362345	0.9519628099173554
69	0.1039786785224601	0.9636763183259421	0.15846208793934713	0.9452479338842975
70	0.10318633160460451	0.9653567737112864	0.1416816242223929	0.9519628099173554
71	0.10250154314822717	0.965744570652726	0.14181615991040694	0.9535123966942148
72	0.10105884359858645	0.9661323682105529	0.1388033992988019	0.9524793388429752
73	0.100464499847349	0.9663908997514009	0.14373332163519112	0.952995867768595
74	0.09699234915772047	0.9687176836806715	0.14068693670728974	0.9535123966942148
75	0.09892402850515224	0.9675542917468555	0.13927714545125805	0.9535123966942148
76	0.09373510830805491	0.9675542917468555	0.14192971614889863	0.952995867768595
77	0.09109532061844848	0.9702688729257594	0.1472188277739631	0.9504132231404959
78	0.09422780197371865	0.9689762152831581	0.1385624246779552	0.9535123966942148
79	0.089857653729163	0.96858841778697	0.1399280076677149	0.9514462809917356
80	0.09202222877414175	0.96716649412739	0.13866092824985174	0.952995867768595
81	0.09148190806946316	0.9701396072169741	0.14535165033187747	0.949896694214876
82	0.08840982505190643	0.9654860392967942	0.14248643784729903	0.952995867768595
83	0.0863735642064567	0.9694932783032154	0.14162500873823797	0.9524793388429752
84	0.0849938054627815	0.9706566702370313	0.14052665941725093	0.9535123966942148
85	0.08647893693571623	0.9711737332570886	0.14123903399656626	0.9519628099173554
86	0.0833340641785309	0.9720785937733339	0.1398540280205159	0.9524793388429752
87	0.08588039273282488	0.9709152017778793	0.13908270555586855	0.9514462809917356
88	0.08469540124225518	0.971820062232486	0.13989123671261733	0.9519628099173554
89	0.07867855954657173	0.9738883145592698	0.14027410425430487	0.9524793388429752
90	0.08097915079024733	0.9710444675483033	0.13836791212401114	0.9545454545454546
91	0.08381301701654446	0.9697518098440634	0.14082562295365925	0.9493801652892562
92	0.07684403726101045	0.9736297828335057	0.14188126998006806	0.9514462809917356
93	0.07871360912718718	0.9728541883342392	0.13882567462596027	0.9524793388429752
94	0.07535529704311826	0.9763443640124095	0.1427223638069531	0.949896694214876
95	0.07491026129169079	0.9736297829567832	0.14165724937088234	0.9514462809917356
96	0.07511028780716528	0.9749224405993844	0.1398378148798115	0.9524793388429752
97	0.07436221570639477	0.9746639091201751	0.14147819701797706	0.9519628099173554
98	0.07079974212900436	0.9745346432881123	0.14145234467323162	0.9514462809917356
99	0.07462390405130731	0.9740175802680551	0.1409197128878152	0.9524793388429752

The optimal condition:
	epoch: 90
	train_acc: 0.9710444675483033
	val_acc: 0.954545454545
	using time: 527.770739079
