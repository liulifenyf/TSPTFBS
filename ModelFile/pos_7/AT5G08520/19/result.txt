The number of train datas: 4100
The number of test datas: 1026
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7133431153181122	0.5065853658536585	0.6960158327169585	0.49317738791423
1	0.6970977815186105	0.514390243902439	0.6933946236532335	0.5077972709551657
2	0.6969717400248457	0.5173170731707317	0.6909580442175763	0.5214424951267057
3	0.6920356448103742	0.5358536585365854	0.6892488957845677	0.5467836257309941
4	0.6927176153369066	0.5221951219512195	0.6883275887654771	0.5487329434697856
5	0.6904312946156758	0.5324390243902439	0.687633969862791	0.5448343079922028
6	0.6901300947840621	0.5392682926829269	0.6865217936666388	0.5730994152046783
7	0.6869676482386705	0.5536585365853659	0.6852211614101253	0.5838206627680312
8	0.6848386844193063	0.5473170731707317	0.6838628904164186	0.5857699805068226
9	0.6830289780221335	0.556829268292683	0.6824392145372506	0.5857699805068226
10	0.6830473318914088	0.5595121951219513	0.6805855972260295	0.5974658869395711
11	0.6796828834021964	0.5663414634146341	0.6787005890647337	0.6091617933723197
12	0.675630663662422	0.578780487804878	0.676306642054582	0.6208576998050682
13	0.6759026107555482	0.5841463414634146	0.6741827017614949	0.6198830409356725
14	0.6740503078553735	0.59	0.6720632860767446	0.615009746588694
15	0.6754076886758572	0.5790243902439024	0.6696973060771504	0.6228070175438597
16	0.6707500459508198	0.5904878048780487	0.6667519940270318	0.6247563352826511
17	0.6625403464131239	0.608780487804878	0.6627757051999573	0.6393762183235867
18	0.6625817370996243	0.6131707317073171	0.6572073054360135	0.6598440545808967
19	0.6582986695591997	0.6139024390243902	0.6520889347989192	0.6676413255360624
20	0.6520895742788547	0.6282926829268293	0.6455597406939456	0.6871345029239766
21	0.650531750074247	0.6268292682926829	0.6449218200661285	0.6608187134502924
22	0.6437004715058862	0.6458536585365854	0.634171866534049	0.695906432748538
23	0.6422010835787145	0.6397560975609756	0.6268450022905658	0.7173489278752436
24	0.6288914692111132	0.6602439024390244	0.61778976415333	0.7241715399610137
25	0.6300730621523973	0.6529268292682927	0.6121568154638042	0.7358674463937622
26	0.6143441036852395	0.6809756097560976	0.6011388341353419	0.7475633528265108
27	0.6067470911072521	0.6853658536585366	0.5901324207555017	0.7582846003898636
28	0.5997801752788264	0.6897560975609756	0.5797138890327765	0.7690058479532164
29	0.5824864907381011	0.7104878048780487	0.5651477104739139	0.7729044834307992
30	0.576175934396139	0.7146341463414634	0.5470897426382143	0.7884990253411306
31	0.5531327629089355	0.7295121951219512	0.538724376444231	0.7729044834307992
32	0.5478542022007268	0.7390243902439024	0.5181468188995042	0.7894736842105263
33	0.5231412606704526	0.7602439024390244	0.4929698138673868	0.817738791423002
34	0.5058639249278278	0.7770731707317073	0.4752055049872073	0.8226120857699805
35	0.48716358152831474	0.7858536585365854	0.44489704063761304	0.8723196881091618
36	0.46346819267040346	0.8046341463414635	0.4195606994350054	0.8771929824561403
37	0.44186973135645796	0.811219512195122	0.3978425622799708	0.8713450292397661
38	0.42309053150618947	0.8246341463414634	0.38018998033122015	0.8713450292397661
39	0.4047194986808591	0.8351219512195122	0.36276986352649115	0.8771929824561403
40	0.381468251391155	0.8521951219512195	0.35383223386419677	0.8606237816764133
41	0.36031614799325057	0.8592682926829268	0.30937134046071224	0.9035087719298246
42	0.34145170575234945	0.8734146341463415	0.3031195943002348	0.8898635477582846
43	0.3216750341944578	0.8751219512195122	0.2702239714054569	0.9171539961013645
44	0.29889014424347293	0.8926829268292683	0.255969559733863	0.9142300194931774
45	0.28379202726410657	0.896829268292683	0.23761294697925128	0.9249512670565302
46	0.2677708848947432	0.906829268292683	0.23098126518563686	0.9200779727095516
47	0.2526160632400978	0.9175609756097561	0.21598903108642348	0.9307992202729045
48	0.24821668168393576	0.9134146341463415	0.20163719167253893	0.9405458089668616
49	0.2309639311200235	0.9258536585365854	0.20213534911008837	0.9327485380116959
50	0.22389950486218058	0.9275609756097561	0.18509189133871834	0.9434697855750487
51	0.21271396038735785	0.93	0.17650656123258915	0.949317738791423
52	0.20661957264309977	0.932439024390244	0.16814959136366148	0.9483430799220273
53	0.1868248886015357	0.9429268292682926	0.1630871397739033	0.9502923976608187
54	0.19535773070847115	0.9385365853658536	0.159906161386251	0.9522417153996101
55	0.1832773027768949	0.9470731707317073	0.151510687091081	0.9541910331384016
56	0.17965580903902287	0.9473170731707317	0.1459882570899021	0.9571150097465887
57	0.1708362836663316	0.9480487804878048	0.14248913321752996	0.9590643274853801
58	0.17361389115089323	0.9456097560975609	0.1391915338981686	0.9619883040935673
59	0.16082704743234122	0.9470731707317073	0.1496439751230369	0.9473684210526315
60	0.1610415226875282	0.9517073170731707	0.13492737284935938	0.9629629629629629
61	0.16103228177239257	0.9504878048780487	0.1318691148192097	0.9619883040935673
62	0.14906998170585167	0.9582926829268292	0.13181687841377063	0.9619883040935673
63	0.1473236814686438	0.9568292682926829	0.12776040577749062	0.9639376218323586
64	0.14857885013993194	0.9551219512195122	0.12341190270396933	0.9629629629629629
65	0.13482436022198782	0.9607317073170731	0.1201826121810584	0.9629629629629629
66	0.14270787275419003	0.9573170731707317	0.11949946169267621	0.9629629629629629
67	0.12482626089235631	0.9629268292682926	0.11921095085597178	0.9658869395711501
68	0.1308864012142507	0.9607317073170731	0.11771649218093581	0.9658869395711501
69	0.1338726486083938	0.9629268292682926	0.11717089667161074	0.9658869395711501
70	0.1260676089147242	0.9636585365853658	0.11765762196298231	0.9649122807017544
71	0.12990172675288306	0.9592682926829268	0.1199598325376506	0.9639376218323586
72	0.12222272862384959	0.9619512195121951	0.11318510650252274	0.9668615984405458
73	0.11677961175034686	0.9641463414634146	0.11719328556100876	0.9658869395711501
74	0.11623681360628546	0.964390243902439	0.1115442369329302	0.9639376218323586
75	0.11416929919181801	0.9653658536585366	0.1129377795452321	0.9629629629629629
76	0.1157620254813171	0.9663414634146341	0.11290549483244647	0.9629629629629629
77	0.11203610817106759	0.9658536585365853	0.11348893735231015	0.9649122807017544
78	0.11114119498468027	0.9646341463414634	0.11044736153157482	0.9629629629629629
79	0.10746885002204558	0.97	0.10926690730711057	0.9649122807017544
80	0.10380738528763375	0.9714634146341463	0.12057255390399729	0.9619883040935673
81	0.10763954046295911	0.968780487804878	0.1079793574495448	0.9639376218323586
82	0.10309186100959777	0.9709756097560975	0.11942591812991724	0.9600389863547758
83	0.10532843631215212	0.9680487804878048	0.11205262962009824	0.9639376218323586
84	0.09607266494050258	0.9702439024390244	0.10742851804222978	0.9629629629629629
85	0.09807204226168191	0.9695121951219512	0.10925538664353289	0.9639376218323586
86	0.10212752805977333	0.968780487804878	0.11598433511509591	0.9639376218323586
87	0.09990422474174965	0.9741463414634146	0.10741391024946237	0.9629629629629629
88	0.09621758530052697	0.9709756097560975	0.10603830758591144	0.9639376218323586
89	0.09470952459951726	0.9724390243902439	0.10821543556599937	0.9639376218323586
90	0.09470441741187398	0.9741463414634146	0.11460129670856872	0.9639376218323586
91	0.09239089705776878	0.9724390243902439	0.10581315941672925	0.9629629629629629
92	0.08436340940071316	0.9758536585365853	0.10652903531320379	0.9639376218323586
93	0.08300620958390759	0.9753658536585366	0.10721723765105765	0.9629629629629629
94	0.08733224349777872	0.9726829268292683	0.10629754984791283	0.9629629629629629
95	0.08196767223135727	0.9763414634146341	0.10510823796693868	0.9619883040935673
96	0.08017301658304726	0.974390243902439	0.13516716417251973	0.9522417153996101
97	0.08785549442579106	0.9729268292682927	0.10727896202776806	0.9619883040935673
98	0.08023767235075555	0.9763414634146341	0.10551916264709209	0.9649122807017544
99	0.07740603858741318	0.9768292682926829	0.10437612914522024	0.9639376218323586

The optimal condition:
	epoch: 72
	train_acc: 0.9619512195121951
	val_acc: 0.966861598441
	using time: 201.578558922
