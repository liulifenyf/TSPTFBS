The number of train datas: 4100
The number of test datas: 1026
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7158851647958523	0.5065853658536585	0.6956519632079216	0.5126705653021443
1	0.701815270679753	0.5039024390243902	0.6932130638386539	0.5331384015594542
2	0.6951515557126301	0.5287804878048781	0.691329718100862	0.5253411306042886
3	0.6927372348599318	0.5365853658536586	0.6902209839858042	0.5331384015594542
4	0.6935891873080556	0.5265853658536586	0.6889505458389342	0.543859649122807
5	0.6921107174129021	0.5302439024390244	0.6872101299479226	0.5477582846003899
6	0.692175618439186	0.5248780487804878	0.6858291210022122	0.5526315789473685
7	0.6883080247553384	0.5443902439024391	0.6850611970670971	0.5623781676413255
8	0.6880277227773899	0.5434146341463415	0.6838682478631449	0.5672514619883041
9	0.6819905012409861	0.555609756097561	0.6819716812806752	0.5818713450292398
10	0.6829459809675449	0.5651219512195121	0.6802115166164049	0.5867446393762183
11	0.6787668012991184	0.5587804878048781	0.6763647018585056	0.6120857699805068
12	0.6767253898992771	0.5692682926829268	0.6738329507686474	0.6228070175438597
13	0.6780704329071975	0.5682926829268292	0.6724850759636356	0.6179337231968811
14	0.6744597167503543	0.5741463414634146	0.6692016333864447	0.6306042884990254
15	0.673842443431296	0.5792682926829268	0.666627495377152	0.6471734892787524
16	0.6703096739257254	0.5892682926829268	0.6632054314511097	0.645224171539961
17	0.6601264990248331	0.6121951219512195	0.6584579962038855	0.672514619883041
18	0.6617098886792253	0.5980487804878049	0.65346894336258	0.6773879142300195
19	0.6587602456604562	0.6146341463414634	0.6484917257031967	0.6929824561403509
20	0.6524940455250624	0.6282926829268293	0.6432718140804744	0.695906432748538
21	0.6493670528690989	0.6217073170731707	0.6420615421168753	0.6861598440545809
22	0.6408548842406855	0.64	0.6309626241873579	0.716374269005848
23	0.6395809531793362	0.6463414634146342	0.6235224036445395	0.7270955165692008
24	0.6284432722882527	0.6590243902439025	0.6150626080077991	0.7339181286549707
25	0.6270124586617074	0.6560975609756098	0.6109885246897766	0.7358674463937622
26	0.6126857094648408	0.6790243902439025	0.60151465013478	0.7621832358674464
27	0.6041947241527278	0.6865853658536586	0.5887720422205637	0.7699805068226121
28	0.5966697599829697	0.6970731707317073	0.5766640269500702	0.7777777777777778
29	0.5841604625887987	0.7065853658536585	0.5641530651098107	0.7816764132553606
30	0.5727466814692428	0.7234146341463414	0.5504457183748658	0.7992202729044834
31	0.5592502202348011	0.7302439024390244	0.5376658561053099	0.7884990253411306
32	0.5510337485336676	0.724390243902439	0.5215691611548381	0.7904483430799221
33	0.5275908258484631	0.7507317073170732	0.4984239494939994	0.8226120857699805
34	0.5094792948699579	0.775609756097561	0.4812562803775943	0.8196881091617934
35	0.4942273292890409	0.7897560975609756	0.45935262213905886	0.8411306042884991
36	0.4703978662374543	0.8002439024390244	0.4329445733893917	0.8538011695906432
37	0.44746061168065887	0.8114634146341464	0.4118799878026542	0.8557504873294347
38	0.4282465036613185	0.8260975609756097	0.39309402678677446	0.8693957115009746
39	0.4146583095701729	0.8341463414634146	0.37452818043747843	0.8723196881091618
40	0.39169227405292234	0.844390243902439	0.3697694480767724	0.8489278752436648
41	0.36999661018208757	0.8553658536585366	0.32982972258480436	0.8908382066276803
42	0.3618233026527777	0.8619512195121951	0.31992801745035493	0.8830409356725146
43	0.3387878225489361	0.8736585365853659	0.2946654258996655	0.9005847953216374
44	0.3113330915788325	0.8814634146341463	0.2813766223412973	0.9064327485380117
45	0.3019226595395949	0.8870731707317073	0.2623636365285394	0.9200779727095516
46	0.2876536717938214	0.8980487804878049	0.25283905637194537	0.9132553606237817
47	0.26859451724261774	0.91	0.2426364952244489	0.9132553606237817
48	0.2722195847732265	0.9070731707317073	0.22897327781362609	0.9327485380116959
49	0.24702953993547253	0.9139024390243903	0.22258620120977102	0.9239766081871345
50	0.24605839985172923	0.9158536585365854	0.2082308302206835	0.935672514619883
51	0.23443798262898516	0.92	0.1998021005567519	0.9395711500974658
52	0.22503180083705157	0.922439024390244	0.19654330023025213	0.935672514619883
53	0.20494267068258146	0.9373170731707318	0.20296329851707054	0.9249512670565302
54	0.21829050234178218	0.9295121951219513	0.18168712096546594	0.9502923976608187
55	0.19866844793645347	0.9385365853658536	0.17548890366830788	0.949317738791423
56	0.1988159441221051	0.936829268292683	0.1712176218323889	0.9512670565302144
57	0.18762639861281324	0.9404878048780487	0.16659189951669634	0.949317738791423
58	0.18999143737118418	0.9395121951219512	0.164233302933547	0.949317738791423
59	0.1833280527300951	0.9436585365853658	0.21106204472946957	0.9122807017543859
60	0.18522826045024685	0.94	0.1583505997517769	0.9522417153996101
61	0.1782238066850639	0.9412195121951219	0.1534466136457511	0.9532163742690059
62	0.17513661124357363	0.9463414634146341	0.15479614832538377	0.9541910331384016
63	0.15955561855944192	0.9512195121951219	0.16083565960342308	0.9463937621832359
64	0.17044546734269073	0.9517073170731707	0.14599156927237503	0.9551656920077972
65	0.15051567009309444	0.9541463414634146	0.1431712530168467	0.9551656920077972
66	0.15966799847236493	0.9460975609756097	0.14202983172693912	0.9590643274853801
67	0.148145492890986	0.954390243902439	0.13952858321237982	0.9580896686159844
68	0.15130943275079495	0.9585365853658536	0.1452590602742359	0.9551656920077972
69	0.14870758444797702	0.9536585365853658	0.13758481201692166	0.9571150097465887
70	0.141936780766743	0.96	0.1372806024111328	0.956140350877193
71	0.14507370815044496	0.9568292682926829	0.13377191992494736	0.9590643274853801
72	0.14109853530802377	0.9563414634146341	0.13836265583731394	0.9532163742690059
73	0.13511066521086343	0.9568292682926829	0.13420053018478506	0.9580896686159844
74	0.13439865466298126	0.9592682926829268	0.13185973876640636	0.9580896686159844
75	0.12575776698385796	0.9651219512195122	0.1294003875352457	0.9619883040935673
76	0.12939274892574404	0.958780487804878	0.1290812217457979	0.9619883040935673
77	0.12887327943633242	0.9609756097560975	0.14096069264953653	0.9532163742690059
78	0.12991279973671205	0.9612195121951219	0.12816064442611402	0.9610136452241715
79	0.12676407651203433	0.9607317073170731	0.12780268876277795	0.9619883040935673
80	0.12057914151105939	0.9653658536585366	0.12922775345449616	0.9600389863547758
81	0.12148177914503144	0.964390243902439	0.12975102884705828	0.9610136452241715
82	0.12294274667414223	0.9673170731707317	0.13808772832402127	0.9590643274853801
83	0.12721071222388164	0.9621951219512195	0.1271418916410086	0.9610136452241715
84	0.11817060793681843	0.9648780487804878	0.1250036446374004	0.9629629629629629
85	0.11335860079563245	0.9658536585365853	0.1242823183734413	0.9619883040935673
86	0.11735450494580152	0.9641463414634146	0.12451332385904114	0.9600389863547758
87	0.11433304202265855	0.9665853658536585	0.12343249639557932	0.9639376218323586
88	0.10644778953092854	0.9697560975609756	0.12158509194996157	0.9619883040935673
89	0.10718614395071821	0.9668292682926829	0.12176449283354754	0.9649122807017544
90	0.11005568033311425	0.9678048780487805	0.12342920147343657	0.9619883040935673
91	0.10547433993074952	0.9697560975609756	0.12153352609314533	0.9649122807017544
92	0.0977943314875408	0.9734146341463414	0.12098488679653138	0.9649122807017544
93	0.09844705381044527	0.9695121951219512	0.12451560534427912	0.9619883040935673
94	0.09964429640915336	0.9719512195121951	0.12216037535789417	0.9580896686159844
95	0.09972413564237152	0.9702439024390244	0.12113858590930061	0.9590643274853801
96	0.09726758584743593	0.9709756097560975	0.14581916561862182	0.956140350877193
97	0.1077491566929512	0.9682926829268292	0.1229186208199775	0.9580896686159844
98	0.09701371078084155	0.9721951219512195	0.12033634108253419	0.9619883040935673
99	0.0902947856399526	0.9741463414634146	0.12600817299515124	0.9610136452241715

The optimal condition:
	epoch: 92
	train_acc: 0.9734146341463414
	val_acc: 0.964912280702
	using time: 222.750678062
