The number of train datas: 4100
The number of test datas: 1026
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7158057509399042	0.5119512195121951	0.6946882735683672	0.5146198830409356
1	0.7025880859537822	0.504390243902439	0.6935676594226681	0.5126705653021443
2	0.6990037385428824	0.5126829268292683	0.6921668585978056	0.5194931773879142
3	0.6951211431549816	0.5182926829268293	0.6913745138380263	0.5224171539961013
4	0.6955626418532395	0.5092682926829268	0.6902611671600193	0.530214424951267
5	0.6932192968740696	0.5292682926829269	0.6889969021023831	0.530214424951267
6	0.6910154282174459	0.5319512195121952	0.6874089954424555	0.5633528265107213
7	0.6901378943280476	0.5407317073170732	0.6860908983278925	0.5545808966861598
8	0.6879568200576596	0.5451219512195122	0.6851060677457739	0.5604288499025342
9	0.6864285026527033	0.5429268292682927	0.6843921482911584	0.5682261208576999
10	0.6851712475753412	0.5421951219512195	0.6831165180336429	0.5769980506822612
11	0.6842941319070212	0.5551219512195122	0.6812883610846239	0.5886939571150097
12	0.6792669132279187	0.5760975609756097	0.6795753779699463	0.594541910331384
13	0.6786036585598457	0.5702439024390243	0.6788165304395888	0.5750487329434698
14	0.6809727914158891	0.563170731707317	0.6776060767573455	0.5828460038986355
15	0.6792627582898954	0.5660975609756097	0.6741350559230901	0.6198830409356725
16	0.6733967890972045	0.5895121951219512	0.6716971771526522	0.6179337231968811
17	0.6701311519669323	0.6036585365853658	0.6696099179994758	0.6208576998050682
18	0.6688303545044689	0.594390243902439	0.6660446518810637	0.6364522417153996
19	0.6676069528882096	0.5929268292682927	0.6625525678342779	0.6276803118908382
20	0.6653513625772988	0.5960975609756097	0.6598140143046834	0.6510721247563352
21	0.6601474866634462	0.6090243902439024	0.6575905874691047	0.6237816764132553
22	0.6539368539903222	0.63	0.6496589415022271	0.6588693957115009
23	0.6536752685686437	0.6163414634146341	0.6448577272961711	0.6666666666666666
24	0.6482429980068672	0.6270731707317073	0.6387779052726938	0.695906432748538
25	0.6465966182801781	0.634390243902439	0.6360704145933452	0.6939571150097466
26	0.6345494586665456	0.6480487804878049	0.6293663399958471	0.7095516569200779
27	0.633684395580757	0.646829268292683	0.6225334480259619	0.7251461988304093
28	0.6255297417756988	0.66	0.6125533523847717	0.7339181286549707
29	0.6213828631145198	0.6721951219512196	0.6035333909021716	0.746588693957115
30	0.6103959913951594	0.688780487804878	0.5940114266691152	0.7563352826510721
31	0.5951373783553519	0.6929268292682926	0.5861417185261003	0.7504873294346979
32	0.5926500668176791	0.6980487804878048	0.573138504871848	0.7582846003898636
33	0.5728246149202673	0.7121951219512195	0.5559417424146195	0.7787524366471735
34	0.5615488196582329	0.7165853658536585	0.5429580981968439	0.7953216374269005
35	0.5461982294408286	0.7404878048780488	0.5237679888746659	0.8128654970760234
36	0.5315221388747052	0.7517073170731707	0.5050249967077787	0.8216374269005848
37	0.5120039959651668	0.7726829268292683	0.4853437723007351	0.8372319688109162
38	0.5007286254371085	0.7709756097560976	0.46732974284805984	0.8372319688109162
39	0.48046474166032743	0.7890243902439025	0.4477367676489534	0.8450292397660819
40	0.46102600580308495	0.8048780487804879	0.4432872991290009	0.8235867446393762
41	0.44058360454512807	0.8114634146341464	0.4031210079876303	0.868421052631579
42	0.4272283690150191	0.8258536585365853	0.39497197142005197	0.8489278752436648
43	0.40489668692030556	0.8375609756097561	0.3599806812829674	0.8859649122807017
44	0.3825829987409638	0.848780487804878	0.3454982218338035	0.8840155945419104
45	0.36369361435494774	0.8568292682926829	0.32164445926106694	0.8957115009746589
46	0.3453968546448684	0.8658536585365854	0.30526655058414615	0.9035087719298246
47	0.32574722388895544	0.8739024390243902	0.29406503484844	0.9035087719298246
48	0.32164972787950097	0.884390243902439	0.2722849596081189	0.9171539961013645
49	0.2972738920624663	0.8936585365853659	0.2611928629973943	0.9220272904483431
50	0.2912203451191507	0.8897560975609756	0.25209909323130897	0.9132553606237817
51	0.2743097912247588	0.9014634146341464	0.23636545085477084	0.928849902534113
52	0.2673373500312247	0.9080487804878049	0.22917431590036574	0.9249512670565302
53	0.24938568312947343	0.9160975609756098	0.23177491477009846	0.9220272904483431
54	0.24500062627036398	0.9139024390243903	0.2192224668044793	0.9259259259259259
55	0.2379356940781198	0.9204878048780488	0.20027535960630136	0.935672514619883
56	0.22599962778934618	0.9270731707317074	0.19151504329799676	0.9405458089668616
57	0.21203995703923992	0.9329268292682927	0.18743501623210154	0.9395711500974658
58	0.2137690802463671	0.9297560975609757	0.18173240569599888	0.9444444444444444
59	0.20193067219199204	0.9343902439024391	0.20990881650231155	0.9269005847953217
60	0.2100799756660694	0.9331707317073171	0.17299129617115444	0.9454191033138402
61	0.19554648671208358	0.936829268292683	0.16669028769401548	0.9463937621832359
62	0.1908823905703498	0.9395121951219512	0.16353372989865075	0.9473684210526315
63	0.18014869730647018	0.9429268292682926	0.16286546335379515	0.9502923976608187
64	0.1829426477413352	0.9417073170731707	0.15590736190071347	0.949317738791423
65	0.1669830811350811	0.9473170731707317	0.1538961264059732	0.9512670565302144
66	0.1719881005621538	0.9451219512195121	0.1508136693148585	0.9522417153996101
67	0.15807506880745656	0.9514634146341463	0.14853075967618712	0.9541910331384016
68	0.15766303550906297	0.9568292682926829	0.14579248835004097	0.9541910331384016
69	0.15529799035409603	0.954390243902439	0.14579848881600313	0.9541910331384016
70	0.15586849467056554	0.9524390243902439	0.14345579571136025	0.9522417153996101
71	0.15059106146417012	0.9541463414634146	0.14152746423570617	0.9551656920077972
72	0.15044673749949874	0.9556097560975609	0.1396620183979791	0.9541910331384016
73	0.14485859958136954	0.9551219512195122	0.14271809180316172	0.9512670565302144
74	0.14774194965275322	0.9563414634146341	0.13689246645004835	0.9571150097465887
75	0.13635561916886307	0.9595121951219512	0.13386396627662592	0.9571150097465887
76	0.1395598991324262	0.9592682926829268	0.13412587439594154	0.9571150097465887
77	0.13348594215948406	0.9602439024390244	0.1357543013870106	0.9551656920077972
78	0.13723813714050664	0.9607317073170731	0.13187191159179396	0.9600389863547758
79	0.13193645496920842	0.9619512195121951	0.12983802241249623	0.9580896686159844
80	0.12769126507203754	0.9602439024390244	0.13714661996640976	0.9541910331384016
81	0.130903328773452	0.9621951219512195	0.12853999694239268	0.9590643274853801
82	0.1302590067502929	0.9609756097560975	0.12964025358388065	0.9580896686159844
83	0.12332193240159896	0.9670731707317073	0.12775303104612795	0.9580896686159844
84	0.1218987690493828	0.9624390243902439	0.13060498784603025	0.9571150097465887
85	0.11719591618674557	0.9685365853658536	0.12513628471497498	0.9580896686159844
86	0.12271473545853685	0.9634146341463414	0.13450413635527064	0.956140350877193
87	0.12405470632925267	0.9604878048780487	0.1230801785851286	0.9590643274853801
88	0.11794987839169618	0.964390243902439	0.12322732320937671	0.9571150097465887
89	0.1176822895029696	0.9648780487804878	0.12677183875824974	0.956140350877193
90	0.11334541746755926	0.9682926829268292	0.12374332523950127	0.9580896686159844
91	0.11295482022733223	0.9653658536585366	0.12311649793798927	0.9580896686159844
92	0.1056343651054109	0.9685365853658536	0.12469423961413563	0.956140350877193
93	0.10723523312589017	0.9668292682926829	0.12109437451260364	0.9610136452241715
94	0.10115833765122949	0.9702439024390244	0.12815227136142973	0.9541910331384016
95	0.1072594387247795	0.9702439024390244	0.12104899038380959	0.9600389863547758
96	0.10183171359504141	0.9724390243902439	0.1717343207350687	0.9454191033138402
97	0.121990257923196	0.9604878048780487	0.12172328340993435	0.9580896686159844
98	0.09874750784439285	0.9709756097560975	0.12057762029608003	0.9610136452241715
99	0.09961287770874616	0.9678048780487805	0.12027061053825866	0.9590643274853801

The optimal condition:
	epoch: 98
	train_acc: 0.9709756097560975
	val_acc: 0.961013645224
	using time: 223.525355101
