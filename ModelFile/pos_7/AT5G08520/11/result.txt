The number of train datas: 4100
The number of test datas: 1026
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7160557421242318	0.4970731707317073	0.6927604155930859	0.5146198830409356
1	0.7038719682577179	0.5002439024390244	0.6924015337031255	0.5116959064327485
2	0.6998470804749466	0.501219512195122	0.6906684204848886	0.5350877192982456
3	0.6939157719728424	0.5195121951219512	0.6892715826136792	0.550682261208577
4	0.693924268047984	0.5192682926829268	0.6886523862098858	0.5448343079922028
5	0.6926042224139702	0.5163414634146342	0.6881651434517279	0.5370370370370371
6	0.6933446163084449	0.5253658536585366	0.6873728947797482	0.5721247563352827
7	0.690897368279899	0.53	0.6869324417839273	0.5760233918128655
8	0.6894374625857284	0.5307317073170732	0.6863712683523375	0.5847953216374269
9	0.6885946958820994	0.5329268292682927	0.6856253991814849	0.5828460038986355
10	0.6894422118256732	0.5331707317073171	0.6843348656713847	0.5955165692007798
11	0.6883200865838586	0.5331707317073171	0.683623725210714	0.5906432748538012
12	0.6852634357824559	0.5441463414634147	0.682841581675509	0.5964912280701754
13	0.6834814329263641	0.5548780487804879	0.682014754408749	0.5935672514619883
14	0.6838962186255106	0.5541463414634147	0.6802173167409024	0.6052631578947368
15	0.6804138610421158	0.5653658536585365	0.6777819109241865	0.615009746588694
16	0.6770835485690978	0.5839024390243902	0.6758780191283942	0.631578947368421
17	0.6757406406286286	0.5656097560975609	0.6738799145811947	0.6345029239766082
18	0.676864894308695	0.5692682926829268	0.6713514632416515	0.6354775828460039
19	0.6752555505822344	0.5704878048780487	0.6691223238876224	0.645224171539961
20	0.6720624483503946	0.5873170731707317	0.6664605498546281	0.6617933723196882
21	0.6656108389249662	0.6012195121951219	0.6645542982726069	0.6306042884990254
22	0.6654687260999912	0.6048780487804878	0.6595767860756515	0.6530214424951267
23	0.66634263154937	0.5946341463414634	0.6553136279940838	0.6666666666666666
24	0.6550334159920855	0.6219512195121951	0.6502588944360759	0.6764132553606238
25	0.6538942981347805	0.6190243902439024	0.6458381697913127	0.6773879142300195
26	0.6455030315678294	0.6387804878048781	0.6388623946823804	0.6949317738791423
27	0.6458555151195061	0.6341463414634146	0.6324132067418238	0.7095516569200779
28	0.6348821766783551	0.6580487804878049	0.6234805839568318	0.7192982456140351
29	0.6265073783804731	0.6636585365853659	0.6149773547756276	0.7270955165692008
30	0.6222744510813457	0.6631707317073171	0.6058152211107474	0.7446393762183235
31	0.6096975598684171	0.6795121951219513	0.597501734834433	0.7339181286549707
32	0.6042298613525019	0.6819512195121952	0.5840010787659918	0.7514619883040936
33	0.586414123453745	0.7014634146341463	0.5674083179432978	0.7582846003898636
34	0.5719466103867786	0.7129268292682926	0.550325639531394	0.776803118908382
35	0.5592300648224063	0.7321951219512195	0.5316766002024823	0.8031189083820662
36	0.5441626862491049	0.7451219512195122	0.5116421586124056	0.8157894736842105
37	0.525855766912786	0.7597560975609756	0.49028535980230187	0.8255360623781677
38	0.5088804074613059	0.7729268292682927	0.47191755842511884	0.8391812865497076
39	0.4916001903720018	0.78	0.4507938271377519	0.847953216374269
40	0.46507625946184483	0.8065853658536586	0.4473515341737349	0.817738791423002
41	0.4444378083508189	0.8078048780487805	0.40336144083773184	0.854775828460039
42	0.4247395010401563	0.8285365853658536	0.374159295162727	0.8762183235867447
43	0.3944658430829281	0.8468292682926829	0.34452254649026587	0.8947368421052632
44	0.3725304901890638	0.8529268292682927	0.32407221790642765	0.8937621832358674
45	0.35501349643963137	0.8680487804878049	0.30103796970309804	0.9074074074074074
46	0.3418657859941808	0.8721951219512195	0.32383419927681634	0.8762183235867447
47	0.31628088142813704	0.8814634146341463	0.2660783888448981	0.9161793372319688
48	0.30348798696587725	0.8917073170731707	0.2501733993083878	0.9239766081871345
49	0.28491554491403626	0.8990243902439025	0.2358356635531022	0.9269005847953217
50	0.2707292333463343	0.9031707317073171	0.22292688718432338	0.9278752436647173
51	0.25484597828330063	0.9151219512195122	0.21310782892226476	0.9376218323586745
52	0.24389483469288523	0.9163414634146342	0.20194106658677377	0.9376218323586745
53	0.22934738537160362	0.9251219512195122	0.20518716138589685	0.9317738791423001
54	0.23621373301599083	0.92	0.1879198657926063	0.9415204678362573
55	0.2180458899242122	0.9292682926829269	0.18165105306788495	0.942495126705653
56	0.20732905076771246	0.9373170731707318	0.1746149591803841	0.9454191033138402
57	0.19870425475806724	0.9402439024390243	0.16867231263563065	0.9463937621832359
58	0.19994738578796387	0.9380487804878048	0.17641926171225414	0.9454191033138402
59	0.19625727102523896	0.9365853658536586	0.16348292043552412	0.9502923976608187
60	0.18781540654054502	0.9441463414634146	0.15822497051623133	0.9512670565302144
61	0.1867855809447242	0.9436585365853658	0.15448063649019303	0.9512670565302144
62	0.17428428907219956	0.9460975609756097	0.152440716343665	0.9541910331384016
63	0.17409513422628728	0.9497560975609756	0.14839947705118978	0.9522417153996101
64	0.17112873189333008	0.947560975609756	0.151172344335019	0.956140350877193
65	0.16001131592000403	0.9519512195121951	0.14455664523860864	0.9541910331384016
66	0.17152376651763915	0.947560975609756	0.14254756083759185	0.9551656920077972
67	0.15416278022091562	0.954390243902439	0.1403484012619329	0.9551656920077972
68	0.1578806875137294	0.9568292682926829	0.14236047013788022	0.956140350877193
69	0.15153876439827244	0.9556097560975609	0.13811002245815526	0.9580896686159844
70	0.1485899633750683	0.9580487804878048	0.1354911619031232	0.956140350877193
71	0.14997828646403988	0.9556097560975609	0.13765685035362404	0.956140350877193
72	0.13897425871796723	0.96	0.13434940021027597	0.956140350877193
73	0.1459366280421978	0.9556097560975609	0.1354644859362154	0.9571150097465887
74	0.14292474010368672	0.9565853658536585	0.13190460415306496	0.9571150097465887
75	0.1359237696412133	0.9585365853658536	0.13117187298638255	0.9580896686159844
76	0.1435843909949791	0.9556097560975609	0.13068089981655978	0.9590643274853801
77	0.13229312321216594	0.9626829268292683	0.13538982930137516	0.9571150097465887
78	0.13363701153092267	0.9624390243902439	0.1293873607215506	0.9590643274853801
79	0.13371989261449838	0.9604878048780487	0.13160768915040394	0.9600389863547758
80	0.1274424466563434	0.965609756097561	0.12871749713457759	0.9571150097465887
81	0.128198057267724	0.9612195121951219	0.1590596025176056	0.9434697855750487
82	0.14213147401809692	0.9575609756097561	0.15007733508988083	0.9463937621832359
83	0.13116615889275945	0.9634146341463414	0.1292318000728682	0.9541910331384016
84	0.12367674894449188	0.9639024390243902	0.1299450530563472	0.9571150097465887
85	0.12133652953839884	0.9660975609756097	0.1286425665620039	0.9600389863547758
86	0.1231111949100727	0.9636585365853658	0.13364380660428726	0.9541910331384016
87	0.12098600343233201	0.9663414634146341	0.12696035723356244	0.9571150097465887
88	0.11889264232865195	0.9665853658536585	0.12731641749388467	0.9571150097465887
89	0.11976943505246465	0.9673170731707317	0.1270205106996508	0.9571150097465887
90	0.11912081616680796	0.964390243902439	0.13864417471260296	0.9483430799220273
91	0.11648235146047138	0.9658536585365853	0.1271420286017058	0.9590643274853801
92	0.10702547037746848	0.9712195121951219	0.1268270894826969	0.956140350877193
93	0.10949567955623313	0.9648780487804878	0.12659301812675205	0.9571150097465887
94	0.110891227307843	0.9670731707317073	0.12603458513725427	0.9571150097465887
95	0.10679643126522623	0.9680487804878048	0.12755274200053127	0.956140350877193
96	0.106230639015756	0.9695121951219512	0.1517790430978841	0.9473684210526315
97	0.12122465430054723	0.9636585365853658	0.1264046100231494	0.9580896686159844
98	0.1041438636474493	0.9712195121951219	0.12701466435758982	0.9551656920077972
99	0.10496309655377778	0.9697560975609756	0.12926561978680115	0.9571150097465887

The optimal condition:
	epoch: 85
	train_acc: 0.9660975609756097
	val_acc: 0.960038986355
	using time: 204.951790094
