The number of train datas: 10236
The number of test datas: 2560
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6905627654557491	0.5389800702701001	0.6321101099252701	0.75703125
1	0.5675487466485485	0.7558616644099803	0.4491630718111992	0.897265625
2	0.3553711305655926	0.8856975377747304	0.2741549380123615	0.90234375
3	0.23075044000810271	0.9211606096364223	0.22305927574634551	0.909765625
4	0.19297882099899755	0.9312231336873507	0.20741159282624722	0.91953125
5	0.177955763269654	0.9369871044540927	0.21164351385086774	0.91328125
6	0.16667281033565123	0.9406017974141334	0.2275998404249549	0.9078125
7	0.15970148999810266	0.9439234073248726	0.20118509382009506	0.91796875
8	0.1549699592952525	0.9440211016435835	0.2110457943752408	0.91484375
9	0.1439225543385001	0.9491989055663732	0.21158517003059388	0.916015625
10	0.14265536849691607	0.9514458769464362	0.18983043488115073	0.92578125
11	0.1394692505970044	0.951543571800867	0.18870323225855828	0.92734375
12	0.13396704060088474	0.9552559594755855	0.19795397259294986	0.92421875
13	0.13063367310912874	0.9562329032217073	0.19149870807304978	0.926171875
14	0.13007568205506972	0.954474403994211	0.1746361915022135	0.93359375
15	0.12552673826463617	0.9576006249880222	0.18891034154221414	0.92734375
16	0.12630991930314553	0.9550605701859829	0.17077672779560088	0.933984375
17	0.11960644177122944	0.9592614298968075	0.17082124296575785	0.935546875
18	0.11735765682842732	0.9590660410730482	0.16441391166299582	0.937890625
19	0.11415065737348741	0.9603360686138208	0.1576497727073729	0.940625
20	0.1134106275764188	0.9615084013700392	0.152623625472188	0.941796875
21	0.10648708851973775	0.9650254008265947	0.17105467524379492	0.9359375
22	0.10521465443269776	0.9653184835265138	0.1724953269585967	0.93671875
23	0.10381083541570486	0.9655138727928242	0.17040034728124737	0.9375
24	0.10085985280541342	0.9670769831266847	0.17280123867094516	0.937109375
25	0.0976871922874227	0.9681516214710234	0.1503410642966628	0.944140625
26	0.10008402283319089	0.9663931224065724	0.15489152111113072	0.943359375
27	0.09635529543108286	0.9682493161391168	0.13953752182424067	0.946875
28	0.09677718463890624	0.9692262600016994	0.15283356579020618	0.94453125
29	0.09254538383438234	0.9706916767156138	0.1597131117247045	0.94453125
30	0.09081474148048559	0.970203204563047	0.15268060173839332	0.9453125
31	0.09056472618768997	0.969714731967929	0.1423228464089334	0.94765625
32	0.08741108183401457	0.972059397946209	0.14628106290474535	0.94609375
33	0.08699078468482864	0.9718640095650009	0.1415576921775937	0.950390625
34	0.08817532821039802	0.9725478699124386	0.13492452269420027	0.949609375
35	0.08712772845540628	0.9724501761294473	0.14600771614350377	0.94765625
36	0.08666446813443714	0.9726455649532066	0.13209861190989614	0.9515625
37	0.08210598062774827	0.9746971472532966	0.14718268280848862	0.94921875
38	0.07950994269300038	0.9746971469737906	0.14363096943125128	0.9515625
39	0.0810951640761751	0.9738178978957623	0.13689600895158946	0.952734375
40	0.07854091810173894	0.9758694799163463	0.13865256854332983	0.953125
41	0.07689778097687218	0.9764556463876242	0.1293089254759252	0.953515625
42	0.07931428408194166	0.9734271196193554	0.14526958791539074	0.951953125
43	0.07675980567064496	0.975087925157029	0.1279897354543209	0.95390625
44	0.07750228325421105	0.9763579519757446	0.1346780107822269	0.953515625
45	0.07801845532177062	0.9760648690894881	0.14202223857864738	0.95234375
46	0.07197177286822845	0.9793864792797332	0.13265518229454756	0.955078125
47	0.0739042840551566	0.9755763967738761	0.1346135132946074	0.954296875
48	0.07467225498522385	0.9774325909489717	0.13141037849709392	0.95546875
49	0.07113311238566522	0.9788003128084554	0.1260901004076004	0.956640625
50	0.0712491580521329	0.9775302855471887	0.14319748049601913	0.953515625
51	0.07093044207513262	0.978604923984696	0.13730496494099498	0.955078125
52	0.07151818459750899	0.9787026179540246	0.13393892715685068	0.955078125
53	0.06983592072388957	0.9788003127152867	0.13046363657340407	0.955078125
54	0.07052588390332733	0.9781164520184665	0.1298105236608535	0.95546875
55	0.0677691328835329	0.9808518951085453	0.1345013207755983	0.95625
56	0.0674631042611953	0.9793864791865645	0.14375979765318334	0.9546875
57	0.06649868579558815	0.9786049240778647	0.14120184127241373	0.9546875
58	0.0640600643667708	0.9795818680103238	0.13117110440507532	0.955859375
59	0.06412494070784289	0.9804611175541954	0.13976352056488395	0.955078125
60	0.06437094787797364	0.9803634233053609	0.12972515155561268	0.956640625
61	0.06489502821130741	0.9789957016322146	0.14043216207064688	0.95546875
62	0.06204584076412491	0.9798749508965803	0.12682371204718948	0.958984375
63	0.06352938876872	0.9801680344816016	0.129939753562212	0.957421875
64	0.0612520700092775	0.9812426731054463	0.1343622644431889	0.95703125
65	0.06318453409945234	0.9809495896834701	0.13197107976302505	0.95703125
66	0.05965336156341539	0.9805588120359515	0.1290857507381588	0.9578125
67	0.06050297994226299	0.9823173116361223	0.12037274315953254	0.959765625
68	0.0593104754130954	0.9820242284004834	0.14020529249683022	0.955859375
69	0.05833003624557471	0.9824150058616647	0.1372433497570455	0.95703125
70	0.05572207296800688	0.9831965614362078	0.1458573991432786	0.95390625
71	0.059585503384401065	0.981340367517326	0.14287900489289312	0.95546875
72	0.057529178726435544	0.9820242283073148	0.1278313735499978	0.958984375
73	0.05751684880165813	0.9830988669311596	0.13535724082030356	0.958984375
74	0.0552465138667936	0.9830011724261112	0.12329255142249167	0.959765625
75	0.05490622572795913	0.9834896443923408	0.13161121774464846	0.959765625
76	0.0563868878030041	0.9838804222261966	0.13886893992312252	0.958203125
77	0.05571604181763808	0.983489644578678	0.13553738889750094	0.959375
78	0.0549829155949118	0.9839781167312449	0.1360594850499183	0.959375
79	0.05272474154268055	0.984661977428065	0.12741176807321608	0.959765625
80	0.05325605732218834	0.9837827272785973	0.12981175840832293	0.959765625
81	0.053470985003138904	0.9837827276279797	0.1285746312700212	0.960546875
82	0.053364514843089454	0.983782727814317	0.1392144331242889	0.958984375
83	0.05421907372696994	0.9832942556617501	0.12953280368819833	0.959765625
84	0.05146793954746944	0.984955060663704	0.13798574318643658	0.9578125
85	0.05175806257921814	0.9842711998737151	0.13697591605596243	0.958984375
86	0.05110846399961039	0.9840758109567872	0.13650399944745004	0.958203125
87	0.05297377333772886	0.9839781166380762	0.14479364608414472	0.95625
88	0.049644823564233234	0.9837827279074857	0.13404010294470936	0.959375
89	0.048540404582510424	0.984759671746776	0.13987818034365773	0.9578125
90	0.05085986828480255	0.9844665887906431	0.12929872630629688	0.960546875
91	0.04839475885406282	0.9858343104637894	0.1271794111467898	0.9609375
92	0.04853693869994133	0.9858343103706207	0.12866731530521064	0.961328125
93	0.045967784963894656	0.9868112543962485	0.13354166245553642	0.96015625
94	0.04800131963875295	0.9852481439925116	0.13213258965406566	0.960546875
95	0.04678257982763009	0.9870066432200079	0.12937591902446002	0.960546875
96	0.04599278102854166	0.9864204768418986	0.14070393475703896	0.9578125
97	0.0461329786574971	0.9863227823368503	0.13441522766370326	0.9609375
98	0.04700924248091408	0.984759671746776	0.12660531103610992	0.9625
99	0.045157263124592374	0.9873974210538636	0.15502751378808172	0.9546875

The optimal condition:
	epoch: 98
	train_acc: 0.984759671746776
	val_acc: 0.9625
	using time: 784.499574184
