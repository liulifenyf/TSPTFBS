The number of train datas: 10236
The number of test datas: 2560
epoch	train_loss	train_acc	val_loss	val_acc
0	0.692108688316293	0.5317506840705126	0.6405916333198547	0.74296875
1	0.5845942657503499	0.7379835876881866	0.4756271243095398	0.893359375
2	0.37378860075476583	0.8763188745836673	0.27542467787861824	0.90546875
3	0.238869940543976	0.9178389995393459	0.22415797114372255	0.914453125
4	0.19484211757470501	0.9323954668162436	0.2104772709310055	0.91953125
5	0.18010112218742214	0.9347401328876923	0.21032624822109938	0.9171875
6	0.1701209327470236	0.9399179363446386	0.22664718069136142	0.905078125
7	0.1636149780377134	0.9414810471210502	0.1995743816718459	0.921875
8	0.15799592657508957	0.9407971860515554	0.2118504248559475	0.915625
9	0.1468456229133129	0.9467565452693821	0.215380322560668	0.915234375
10	0.14604907148328783	0.9500781552732899	0.18785579726099969	0.924609375
11	0.14235765357392988	0.9509574054227578	0.18788608219474554	0.92421875
12	0.13667806652245368	0.9527159045803775	0.19819701220840216	0.91953125
13	0.13459215413061332	0.9543767093959941	0.1908367035910487	0.924609375
14	0.13418524819176939	0.95203204369722	0.17180101498961448	0.934375
15	0.1286114612423195	0.9566236809623945	0.18590268930420278	0.928515625
16	0.12914832622022449	0.9557444310691404	0.173191792704165	0.933984375
17	0.12219486230399842	0.9579914031712605	0.17096430538222193	0.934375
18	0.12160177557391084	0.9577960137186129	0.16718100607395173	0.937109375
19	0.11726273734001687	0.9601406797900616	0.1583203285932541	0.9390625
20	0.11612522930500795	0.9606291516631225	0.15310119595378638	0.9421875
21	0.11092951558544888	0.9627784292601943	0.17069794507697225	0.935546875
22	0.10999062776728596	0.962485345675173	0.16762235844507814	0.937109375
23	0.10743767461852666	0.9647323175909558	0.17589410645887255	0.934765625
24	0.10579672521588018	0.9642438451821751	0.17465563137084245	0.93359375
25	0.10053149241285894	0.9666862053859975	0.15476715434342622	0.944921875
26	0.10284955551663662	0.966197733582813	0.15567182945087552	0.94453125
27	0.09988666907674915	0.9662954279946927	0.14031026558950543	0.947265625
28	0.10098049102257173	0.9680539269659751	0.15611594244837762	0.94375
29	0.09515627792986542	0.968835482796732	0.16458922130987047	0.938671875
30	0.09476472495612151	0.969128566032371	0.15743163200095295	0.941796875
31	0.09457291646970814	0.968444704799831	0.14452419690787793	0.94609375
32	0.09255518134786729	0.9690308717136599	0.15199433760717512	0.944921875
33	0.09029196043349234	0.9705939822105655	0.14322073720395564	0.94609375
34	0.09166191050716563	0.9713755371562202	0.13702655900269747	0.950390625
35	0.09101336512273529	0.9693239549492988	0.14518926991149783	0.94609375
36	0.08961464973598218	0.9720593978530404	0.13292303793132304	0.951953125
37	0.08663784167807566	0.9723524811818479	0.1485949226655066	0.946484375
38	0.0850079978301964	0.9721570923580887	0.14883014438673853	0.946875
39	0.08604493655698194	0.9721570928938084	0.13857226725667715	0.94921875
40	0.08345376874271805	0.9738178978957623	0.13939501298591495	0.949609375
41	0.08042021593913849	0.9726455644174868	0.13123547816649078	0.952734375
42	0.08174785005890238	0.9723524810886793	0.14769465429708362	0.948046875
43	0.08127824260899451	0.9740132865331843	0.1332095805555582	0.953515625
44	0.08138719633448725	0.9750879247144779	0.13707178058102726	0.951171875
45	0.08272161216254158	0.9739155921213046	0.1447024899534881	0.95
46	0.07755673297066948	0.9766510357471032	0.1397108810953796	0.951953125
47	0.07707285377349458	0.9746971470669593	0.1374728988856077	0.953515625
48	0.07798503941393028	0.9766510356539346	0.13967112503014506	0.95234375
49	0.07576158536061639	0.976357952604633	0.12836467185989023	0.954296875
50	0.07573375798508543	0.9765533408926725	0.14852201482281088	0.95
51	0.07428790660354484	0.9771395078065014	0.14532858333550394	0.951171875
52	0.0742952923329373	0.9759671744213947	0.1339597943238914	0.953125
53	0.0738788233307853	0.9781164518321291	0.134586917841807	0.95390625
54	0.07388736918166822	0.9769441190759108	0.13697738898918033	0.955078125
55	0.0715614812781262	0.9788980068709525	0.13662863397039474	0.9546875
56	0.07004966022284434	0.9769441189827421	0.147606048732996	0.95234375
57	0.0706337967151634	0.9772372023115498	0.14410799564793705	0.953125
58	0.06775670652628969	0.9786049238915274	0.13320365864783526	0.95390625
59	0.06767868682969218	0.9783118404928434	0.1445034695789218	0.953125
60	0.06739928471175616	0.9781164517389606	0.13416531207039953	0.9546875
61	0.0683152003300381	0.9779210631015386	0.14717476340010763	0.952734375
62	0.06644842857236553	0.9789957017253833	0.12896932391449809	0.95703125
63	0.0663280152555973	0.9803634232121923	0.1358692363835871	0.95546875
64	0.0628805946472824	0.980070340069722	0.1455556435044855	0.954296875
65	0.06675588566229045	0.9795818680103238	0.13453139923512936	0.95625
66	0.0631960174399994	0.9787026182102384	0.13432482592761516	0.956640625
67	0.06382585857129042	0.9803634233985296	0.12828645603731276	0.9578125
68	0.06063425441786804	0.9812426731054463	0.15526853278279304	0.95078125
69	0.059761382396296164	0.9821219227191944	0.14098994825035333	0.95546875
70	0.056904488097950554	0.9822196172242428	0.14941094850655645	0.953515625
71	0.06193939613010232	0.9808518954579277	0.14393747120629996	0.95546875
72	0.060397332297632965	0.9805588121291202	0.13841861793771387	0.95625
73	0.058798507808031815	0.9810472842816871	0.14632576731964947	0.9546875
74	0.058356558807243726	0.9816334506597962	0.13478744076564908	0.95859375
75	0.05718882744400331	0.9816334508461335	0.13625308154150845	0.958203125
76	0.05839470310421277	0.9829034782005689	0.14163689222186804	0.95546875
77	0.058379678354802754	0.9818288390410044	0.13703848216682674	0.9578125
78	0.056071003238790995	0.9835873390837263	0.14479415956884623	0.95546875
79	0.05560274583758112	0.9829034780142316	0.13594139278866352	0.957421875
80	0.055027556036798785	0.9830011719835601	0.13456266205757855	0.95859375
81	0.0559450315749007	0.9839781167312449	0.13620593105442821	0.958203125
82	0.053372704540788775	0.9829034780142316	0.14400776950642466	0.956640625
83	0.05502317028120888	0.9833919500736298	0.13674235369544477	0.95703125
84	0.05364011764241038	0.9830988668379909	0.14181079273112118	0.95703125
85	0.05260608714305362	0.9823173116361223	0.13712220990564675	0.95859375
86	0.05104854545436273	0.9834896444855095	0.1460536447353661	0.95546875
87	0.05394440324232419	0.9838804222261966	0.1472036127001047	0.9546875
88	0.050863386699933476	0.9848573662518244	0.13578257255721837	0.958203125
89	0.05094409446061333	0.9842711997805466	0.1472506811376661	0.954296875
90	0.05193577884853282	0.9837827277211483	0.1296002092771232	0.9578125
91	0.05002400975189623	0.9843688941924261	0.13138516158796848	0.95859375
92	0.0485534684564416	0.9836850334024373	0.14128607525490225	0.95546875
93	0.04822556706725526	0.9855412270418132	0.14042057553306223	0.95625
94	0.049481952659736254	0.984857366344993	0.13992376462556422	0.95625
95	0.047503720128260214	0.9854435326299336	0.1323998849838972	0.958984375
96	0.045471094325970934	0.9855412272281505	0.1519680482102558	0.95390625
97	0.04572525178200568	0.9861273936994284	0.14052280981559306	0.955859375
98	0.04713332545101037	0.9838804220398594	0.12945853201672436	0.95859375
99	0.04521802796219047	0.9857366160519098	0.16217390076490118	0.953125

The optimal condition:
	epoch: 95
	train_acc: 0.9854435326299336
	val_acc: 0.958984375
	using time: 809.568723917
