The number of train datas: 10236
The number of test datas: 2560
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6900916388138237	0.5316529893558348	0.6390992790460587	0.736328125
1	0.569724253224134	0.7632864403417214	0.4488936275243759	0.905078125
2	0.3573728204938107	0.8873583430561902	0.26711123138666154	0.908984375
3	0.2290732266556802	0.9205744430719758	0.21594324968755246	0.916796875
4	0.18880577017409395	0.936010159869453	0.19713574796915054	0.922265625
5	0.16845666681499674	0.9408948808361096	0.20070147719234227	0.921875
6	0.15634915009053624	0.9442164904673428	0.20732157174497842	0.918359375
7	0.14868929487809207	0.9475381004712506	0.1961002169176936	0.9234375
8	0.14338055827471835	0.9503712388583113	0.19458508659154178	0.926953125
9	0.1318692617400776	0.9532043769891582	0.1917645201086998	0.928125
10	0.12940507893126288	0.9572098474336723	0.172902886942029	0.931640625
11	0.12607643599853052	0.9582844862205622	0.17466797903180123	0.931640625
12	0.12303701779743619	0.958186792018312	0.1801853345707059	0.930078125
13	0.1208353467626281	0.9592614300831448	0.16992019955068827	0.934375
14	0.11716795441355729	0.959456818906904	0.16263094544410706	0.9375
15	0.11397953260138241	0.9629738175482339	0.17739324299618603	0.93203125
16	0.1122808907997706	0.9618014851413978	0.1640595999546349	0.937890625
17	0.10910269622401643	0.9646346225501877	0.15211993344128133	0.944921875
18	0.10497183774879268	0.9660023448522224	0.15506301615387202	0.9421875
19	0.10452228680911033	0.9662954277384789	0.14756407961249352	0.946875
20	0.10289364032980146	0.9659046499977917	0.14530514981597661	0.94765625
21	0.09882817728479144	0.9677608443592246	0.15716917673125863	0.942578125
22	0.09683074303125673	0.9687377879423013	0.1630077725276351	0.941015625
23	0.09672137084604475	0.9695193436798895	0.1632757826708257	0.940625
24	0.09459067945743083	0.9701055098017849	0.16361015401780604	0.940625
25	0.09163520822607944	0.9710824538274127	0.14442395558580756	0.94765625
26	0.09365343485477381	0.971375537412434	0.14791373424232007	0.9453125
27	0.09155466106486256	0.9701055101511673	0.1339924966916442	0.95
28	0.09285384860587055	0.9700078152035679	0.1466898842714727	0.946484375
29	0.08674250813888916	0.9723524817175677	0.15121681988239288	0.946484375
30	0.08737299849409151	0.9736225089788344	0.14428971875458957	0.946875
31	0.08526692152803603	0.973427119712524	0.14452635068446398	0.947265625
32	0.08703624138018264	0.9718640091224497	0.14257140029221774	0.948828125
33	0.08374172338474165	0.9731340369194361	0.13535175351426004	0.949609375
34	0.08485594528664271	0.9730363419718367	0.12767578223720194	0.953125
35	0.08380550262709295	0.9742086754501122	0.14358487278223037	0.94921875
36	0.08399326889111502	0.9730363426007251	0.12718488425016403	0.953515625
37	0.07997400450457255	0.9742086751007297	0.1379115989431739	0.951171875
38	0.07607385697263254	0.9769441190759108	0.1428043314255774	0.9515625
39	0.07996899019686586	0.9745994530976307	0.13896202351897954	0.9515625
40	0.07674765339519372	0.9753810084858365	0.13423104779794812	0.952734375
41	0.0759608922304237	0.976064868926443	0.12697542160749437	0.9546875
42	0.07539042500300816	0.9758694799163463	0.14312495971098543	0.950390625
43	0.0755439331815456	0.9755763970300899	0.12352973408997059	0.954296875
44	0.0762171776773828	0.9767487296232631	0.13541274145245552	0.95390625
45	0.07655556742487685	0.97753028545402	0.13845671489834785	0.951171875
46	0.07055517353027209	0.9780187575134182	0.12678653206676244	0.9546875
47	0.07337269349145256	0.9763579519757446	0.13197085550054907	0.95390625
48	0.0730790948985132	0.9772372021252124	0.13065418330952525	0.954296875
49	0.06942003626331261	0.9793864791865645	0.12279475973919034	0.95546875
50	0.07043953431495795	0.9775302855471887	0.1331368106417358	0.954296875
51	0.07198161076886805	0.9789957016322146	0.13547554351389407	0.953125
52	0.07148533703445596	0.9780187571640357	0.13106737229973078	0.954296875
53	0.06903651742764683	0.9797772568340831	0.13134345142170786	0.954296875
54	0.06890947897541845	0.9790933961372629	0.1300936601124704	0.95546875
55	0.0680254933108758	0.9791910901065914	0.13511768244206906	0.95390625
56	0.06772693545033849	0.9784095350677681	0.13972838227637113	0.953125
57	0.06638481207381193	0.978800312901624	0.13937865826301277	0.953125
58	0.0649383202174787	0.980070340069722	0.12748539242893459	0.9546875
59	0.0654298124799229	0.9803634229559784	0.14019453153014183	0.953125
60	0.06577010809626953	0.9798749512459627	0.12648577392101287	0.955078125
61	0.06535278912597263	0.978604923984696	0.13862376864999532	0.953515625
62	0.06269989957528545	0.9799726458441796	0.12277252459898591	0.9546875
63	0.06500178597788878	0.9804611177172405	0.12783679142594337	0.955078125
64	0.0628778660359118	0.9806565067273372	0.13099150033667684	0.95625
65	0.06323399746462255	0.9816334506597962	0.13028266541659833	0.95625
66	0.06229182885069547	0.9801680344816016	0.12430304083973169	0.955859375
67	0.06151013226030324	0.9796795624222034	0.11862798351794482	0.957421875
68	0.05930190042517249	0.9821219227191944	0.13507426166906952	0.95625
69	0.058402427595549845	0.9818288393903869	0.1293923574499786	0.95625
70	0.056704716114221766	0.9825127005530503	0.14168589524924755	0.953515625
71	0.06004881753137495	0.9808518953647591	0.13627326069399714	0.95625
72	0.05835835746154276	0.9828057836023519	0.12868949733674526	0.95546875
73	0.05808090208074272	0.9831965613430391	0.13239762280136347	0.95546875
74	0.05782333035902755	0.9826103947785927	0.11732316929847002	0.958203125
75	0.05637182150547068	0.9830011724261112	0.12329225912690163	0.9578125
76	0.057237961437609945	0.982708089283641	0.1304763319902122	0.955859375
77	0.057152947654780954	0.9819265339886039	0.12371894321404397	0.9578125
78	0.05638423657402158	0.9825127000173306	0.13206582134589553	0.95625
79	0.05658643645128499	0.9824150058616647	0.12220701347105205	0.958203125
80	0.05592044039646505	0.9828057837886892	0.12166862506419421	0.9578125
81	0.05565144067492602	0.9831965614362078	0.11943054012954235	0.958203125
82	0.05537480393649545	0.9832942557549188	0.1359577151015401	0.956640625
83	0.05720591974627021	0.9832942555685815	0.12819598927162587	0.955859375
84	0.05380224836273275	0.9841735053686669	0.1343097486998886	0.95703125
85	0.05553259560201446	0.9823173111004027	0.12921734172850846	0.95703125
86	0.05383714961907788	0.9828057836023519	0.12784821018576623	0.95625
87	0.05451002627634453	0.9842711997805466	0.13580468930304052	0.955859375
88	0.050485113113769194	0.984661977428065	0.13108662236481905	0.95625
89	0.0518857597476421	0.9831965611567018	0.13215567832812666	0.95625
90	0.0518988384084573	0.9841735053686669	0.12126739677041769	0.95859375
91	0.05099561037339238	0.9850527551687523	0.12403323738835752	0.95859375
92	0.05115985072459174	0.9845642831093541	0.1276442606933415	0.957421875
93	0.04972112321175836	0.9834896443923408	0.12755985716357826	0.957421875
94	0.04990880581324293	0.983782727814317	0.12493666410446166	0.958203125
95	0.049571334562348454	0.9855412270418132	0.12483448390848935	0.957421875
96	0.0486515666830931	0.9850527550755837	0.13160078637301922	0.957421875
97	0.05030019083884649	0.9846619776144024	0.12539748959243296	0.958984375
98	0.04937023820443608	0.9838804220398594	0.12475073225796222	0.957421875
99	0.04981181929968865	0.9847596718399447	0.14320177948102356	0.95390625

The optimal condition:
	epoch: 97
	train_acc: 0.9846619776144024
	val_acc: 0.958984375
	using time: 728.927325964
