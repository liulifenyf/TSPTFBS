The number of train datas: 1670
The number of test datas: 418
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7084193778609087	0.5005988024309009	0.6824255055217652	0.5454545464527094
1	0.694401210582185	0.5191616766467065	0.674957422548504	0.6196172245951931
2	0.6979014967729945	0.5203592814549715	0.6674819357657547	0.6315789475110158
3	0.6837575835382154	0.5317365269639535	0.6611262471481943	0.6602870816249026
4	0.674376107404332	0.5814371258198858	0.6544630675794976	0.74641148182764
5	0.6703391235031767	0.5994011976047904	0.6452844399584537	0.7727272713013242
6	0.6630813083962765	0.5982035927429884	0.6341546038121127	0.7822966495769446
7	0.6557468513528744	0.6047904190902939	0.62350630646117	0.7129186600018916
8	0.6447588286000098	0.6245508982749757	0.6093082385200063	0.7990430636269054
9	0.6401209826240997	0.6407185629456343	0.5946195527697294	0.8205741615386671
10	0.627888075962752	0.656886227616293	0.5775283583613674	0.8373205730219206
11	0.6188364684938671	0.6724550898917421	0.5594432399603739	0.8660287067080229
12	0.6021209905247489	0.7137724550184376	0.5422471998410933	0.8684210532019583
13	0.5832072045988665	0.7365269461791673	0.5214933325229079	0.8660287087043507
14	0.5654543028620189	0.7532934131022699	0.49841112839548213	0.8755980866947813
15	0.5486124583347115	0.7562874250783178	0.4785878390216371	0.85645933071392
16	0.5284979317359582	0.7718562873537669	0.45068290016867896	0.877990431192389
17	0.5109592723275374	0.7784431138081465	0.42839607553618947	0.8755980844132638
18	0.4966598012490187	0.7898203593528199	0.4095943476024427	0.8827751179060868
19	0.4809715756756103	0.7868263472340065	0.3968547451439086	0.8540669836496052
20	0.4709667013790793	0.7904191616052639	0.3751613494882173	0.8779904286256818
21	0.4558465801848623	0.8053892215568862	0.3576729856609728	0.8851674624036944
22	0.4381139621049344	0.8233532933417909	0.35289553563560594	0.8564593281472128
23	0.43118266438295744	0.8155688622754491	0.3339519497880525	0.8827751179060868
24	0.4179751463992867	0.8305389220843058	0.3371580896195042	0.8636363616400358
25	0.41643776829371193	0.8161676647420415	0.3197348052234741	0.8875598066161123
26	0.39821402459087485	0.8239520958083832	0.3079667018646258	0.8851674649704016
27	0.39143864955016955	0.8407185628742515	0.3013438084764344	0.8875598091828195
28	0.3893554012218635	0.8233532933417909	0.28996135572497356	0.8875598094680093
29	0.3783840052381961	0.8407185628742515	0.2870047207939568	0.8899521536804272
30	0.3705852485256281	0.8479041916167664	0.2760157483901704	0.8971291871732502
31	0.36770011836183286	0.8473053891501741	0.2711455342872291	0.8899521536804272
32	0.3536682824531715	0.8526946108498259	0.2637212441868759	0.9019138761684655
33	0.3506843323122242	0.8526946107070603	0.26212993264198303	0.8923444981780349
34	0.34450760494449184	0.8538922154974795	0.2539759864362233	0.8947368429608322
35	0.33517278944125434	0.8634730538922155	0.25254973284365456	0.8923444981780349
36	0.3299209272790098	0.8658682634016711	0.24297941244390023	0.8971291874584398
37	0.33643441769534244	0.8676646706586826	0.24139436195341593	0.9090909070945813
38	0.314481435011247	0.8784431137724551	0.23225612261078574	0.9090909096612885
39	0.31910984123538355	0.8718562873537669	0.22534160308860707	0.9090909073797709
40	0.3031148533621234	0.8766467065868263	0.22032184250046763	0.9186602853702016
41	0.3036458149641574	0.8766467065868263	0.21951787879592494	0.9114832515921889
42	0.2876764170423953	0.8874251497719816	0.20931049639528448	0.9186602876517191
43	0.28756400728654	0.8844311377959337	0.20711578321799137	0.9186602850850119
44	0.28013694393420646	0.8880239520958084	0.2022207566140371	0.9210526295826196
45	0.2767523783855809	0.8934131736526946	0.2004536790996077	0.9234449740802272
46	0.26823060157413253	0.8982035928143712	0.19272427496157193	0.9306220075730501
47	0.2589977092014815	0.9011976047904192	0.18555841477293716	0.9330143520706579
48	0.26141124480141853	0.8994011976047904	0.18678425858465678	0.9306220075730501
49	0.24613220775555708	0.9065868263473054	0.17663761845045683	0.9330143520706579
50	0.23478726055807697	0.9155688622040663	0.17153742823874552	0.9377990410658732
51	0.2270001294370183	0.921556886156162	0.16690793619201513	0.9425837300610884
52	0.2371465891421198	0.9113772454375992	0.16230793618129202	0.9473684190563038
53	0.22963940490505652	0.9047904190902938	0.16027437072051198	0.9425837300610884
54	0.2183151188367855	0.920359281365743	0.15743214847368486	0.9401913855634808
55	0.21906276898469754	0.9233532934131736	0.15310577884245147	0.9473684190563038
56	0.20836458249006443	0.9209580838323354	0.1479505510136271	0.9521531080515191
57	0.20209373602877834	0.9287425149700599	0.147715828492881	0.9449760745586961
58	0.1955620540562504	0.9275449101796407	0.13874028501898478	0.9569377970467344
59	0.2011470519140095	0.9281437125034675	0.13965593920084848	0.9521531080515191
60	0.19051251476574801	0.9365269461077844	0.13508881364712874	0.9569377970467344
61	0.17868520811110913	0.9407185628742515	0.13404476236213336	0.9545454525491267
62	0.18692512259244204	0.9389221556886228	0.13021676969585236	0.959330141544342
63	0.18486832257159455	0.9347305388507728	0.12484769280732534	0.9569377970467344
64	0.17378148551651104	0.9389221556886228	0.1220261245680768	0.9569377970467344
65	0.17795627676173598	0.944311377245509	0.1195984126991062	0.959330141544342
66	0.1655404712402535	0.9425149700598803	0.1169425902897091	0.959330141544342
67	0.1616840677347012	0.9473053892929397	0.11977525076797704	0.9617224860419497
68	0.16970383145227402	0.9502994011976048	0.11798049038962315	0.9545454525491267
69	0.15558550277512945	0.9497005988023952	0.11393754426657297	0.9569377970467344
70	0.14995228630340027	0.9556886227544911	0.11069421562851901	0.9545454525491267
71	0.15230992803138174	0.9544910179640719	0.11035221437232916	0.9617224860419497
72	0.1481226163174578	0.9479041915453836	0.10811458264241379	0.9569377970467344
73	0.148006738445716	0.9514970060594068	0.10503450506611874	0.966507175037165
74	0.14613718768793665	0.9574850299401197	0.10434593759370192	0.966507175037165
75	0.14120191728283546	0.9562874250783178	0.10236418197314705	0.966507175037165
76	0.13947404083645273	0.9574850299401197	0.10171859686454518	0.9641148305395574
77	0.13329837129501526	0.9520958083118507	0.09829362991609071	0.966507175037165
78	0.12575330694880849	0.9652694610778443	0.09706060460024474	0.966507175037165
79	0.13087613825312633	0.961676646635204	0.09485626284870805	0.9641148305395574
80	0.13745168392842044	0.9604790419161676	0.09619151711749117	0.966507175037165
81	0.13357211986701645	0.9628742514256232	0.09520935484667144	0.966507175037165
82	0.12594461424978906	0.9658682634730539	0.0980924108382047	0.9712918663138979
83	0.12195421937340034	0.9652694610778443	0.09214102081134559	0.966507175037165
84	0.11962452222130256	0.968862275377719	0.08867439249771063	0.966507175037165
85	0.12097369370435526	0.9622754491017964	0.08877797909615713	0.9736842108115055
86	0.11691988480840615	0.9646706586826347	0.08606971793197558	0.9688995195347727
87	0.11635312970705375	0.9634730538922156	0.0870565841215079	0.9712918663138979
88	0.11797309785322872	0.9646706586826347	0.08586121411129619	0.9712918663138979
89	0.11287996048431197	0.9688622754491018	0.08402263989859221	0.9688995195347727
90	0.11432958652159411	0.9646706586826347	0.08506515622138977	0.9760765553091131
91	0.1063895767141959	0.9670658681920903	0.08224646404884649	0.9641148305395574
92	0.10223189403197008	0.9730538922155688	0.08069062076116863	0.9712918663138979
93	0.10679279700434671	0.9694610778443113	0.08010270835109876	0.9736842108115055
94	0.09674352743846927	0.9748502994011976	0.07929034324353962	0.9712918663138979
95	0.09964800205996294	0.9706586826347305	0.0802149873529895	0.9736842108115055
96	0.10695066166495135	0.9658682634016711	0.0862690521199167	0.9736842108115055
97	0.11397557604812576	0.9670658682634731	0.0792759164240942	0.9712918663138979
98	0.09830337000598094	0.9706586826347305	0.07831748721131868	0.9712918663138979
99	0.102771619854573	0.9688622754491018	0.07746422141077416	0.9712918663138979

The optimal condition:
	epoch: 90
	train_acc: 0.9646706586826347
	val_acc: 0.976076555309
	using time: 156.363188982
