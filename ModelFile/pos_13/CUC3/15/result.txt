The number of train datas: 3680
The number of test datas: 920
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7108981770017873	0.49239130408867543	0.69702293769173	0.496739130175632
1	0.6991243657858476	0.5122282608695652	0.6950500260228696	0.5043478258278059
2	0.700116949496062	0.5038043480852376	0.6933939850848654	0.5141304347826087
3	0.6946455587511478	0.5097826086956522	0.6922066040661023	0.5358695652173913
4	0.6927986248679783	0.5173913043478261	0.6912499308586121	0.5510869565217391
5	0.6928984849349312	0.5182065217391304	0.6901613157728445	0.5554347826086956
6	0.6920233213383219	0.5263586956521739	0.6892573527667833	0.5652173913043478
7	0.6886955432269884	0.5364130439965621	0.6882713571838711	0.5717391309530838
8	0.6875767028850058	0.5451086951338726	0.687345534303914	0.5793478260869566
9	0.6877963377081829	0.5339673907860466	0.686205822488536	0.5869565212208292
10	0.6854788365571395	0.5464673907860466	0.6851458715355915	0.5945652168730031
11	0.6845384851745937	0.5557065217391305	0.6843796895897907	0.5891304347826087
12	0.6824485908383908	0.5605978266052578	0.6828328801238018	0.6032608700835187
13	0.6788179827773053	0.5774456521739131	0.6813627683598062	0.605434783126997
14	0.6759549861368925	0.5798913048661274	0.67958700708721	0.6032608700835187
15	0.6780496514361838	0.5660326092139535	0.6773399461870608	0.602173912525177
16	0.6725982899251192	0.5891304347826087	0.6748676486637282	0.6086956521739131
17	0.6689441250718158	0.595108695652174	0.6719842392465343	0.6206521744313447
18	0.6630278297092603	0.6249999994816987	0.6684380495029947	0.6217391309530839
19	0.6619692569193633	0.6122282608695652	0.6645306804905767	0.63913043530091
20	0.6551884034405584	0.6105978255686553	0.6600793719291687	0.6369565222574317
21	0.6473530090373495	0.6385869560034378	0.6551877078802689	0.6478260864382205
22	0.6471051594485407	0.6374999994816988	0.6503643341686415	0.6467391309530839
23	0.6338222073472064	0.6625	0.6432170489560003	0.6576086961704751
24	0.629463573642399	0.6709239135617795	0.6356230626935544	0.665217391822649
25	0.6222332342811253	0.6660326086956522	0.6276288514551909	0.6771739130434783
26	0.6156696734221085	0.677173912525177	0.6222886090693267	0.6565217396487361
27	0.6034658121026081	0.6956521733947422	0.6123161041218301	0.6750000005183012
28	0.5934164601823558	0.696467391822649	0.6028084760126861	0.6826086961704751
29	0.5885599348856055	0.6989130439965622	0.5943030580230381	0.6945652179096056
30	0.5741387559020001	0.7138586951338727	0.5835641145706176	0.7032608700835187
31	0.5599127090495566	0.7230978260869565	0.5733824807664623	0.7130434782608696
32	0.5483364753101183	0.7350543483443882	0.5629384274068086	0.7228260869565217
33	0.5428098038486813	0.73288043530091	0.5527310443961102	0.7260869565217392
34	0.5257496445075326	0.7456521744313447	0.5434233934982963	0.731521739648736
35	0.5141812008360158	0.7605978266052578	0.5296290527219357	0.7478260869565218
36	0.49906927787739297	0.7747282613878664	0.5222983974477519	0.7402173918226491
37	0.4864535834478295	0.775	0.505196025578872	0.7619565217391304
38	0.4752586678318355	0.7858695657356926	0.493881022411844	0.7684782608695652
39	0.46293518361837965	0.7904891299164813	0.48127877401269	0.7739130434782608
40	0.45077829982923423	0.7956521739130434	0.47339636320653167	0.7771739130434783
41	0.4313991305620774	0.8138586951338727	0.4546046840107959	0.7967391304347826
42	0.4293159357879473	0.8192934787791708	0.44426494888637375	0.8043478260869565
43	0.42039327206818955	0.8214673913043479	0.4423263031503429	0.8032608695652174
44	0.3971271973589192	0.8358695657356926	0.4299476408440134	0.8097826086956522
45	0.3940148281014484	0.8347826086956521	0.41095120284868325	0.816304347826087
46	0.3751951507900072	0.8505434782608695	0.40040070492288343	0.8260869565217391
47	0.3709959919038026	0.8456521733947422	0.391507880843204	0.8358695652173913
48	0.35238588711489804	0.8603260864382205	0.38061064637225606	0.8391304347826087
49	0.3529817687428516	0.8605978255686553	0.3719081124533778	0.8510869565217392
50	0.34158790500267694	0.8682065212208292	0.3627816456815471	0.85
51	0.33882279888443323	0.8668478260869565	0.357401115220526	0.856521739648736
52	0.31992960675902987	0.8847826081773509	0.3504982108655183	0.8597826092139534
53	0.3203009387721186	0.8779891309530838	0.34172635259835615	0.8608695657356925
54	0.30717023870219357	0.8842391299164813	0.3403100024098935	0.8673913038295248
55	0.300600942062295	0.8785326086956522	0.33497813369916835	0.8684782608695653
56	0.29795902086340864	0.8839673913043479	0.32390311826830326	0.8673913048661274
57	0.2860021526398866	0.8923913038295248	0.319233275755592	0.8706521733947422
58	0.2773524302503337	0.8951086961704752	0.3131262190963911	0.8739130439965621
59	0.2717517409635627	0.8961956516556118	0.3105137135671533	0.8815217391304347
60	0.26754311349080956	0.9019021739130435	0.311295216239017	0.8826086956521739
61	0.2687197090491005	0.8983695657356926	0.3083709760852482	0.883695652173913
62	0.2607444016829781	0.9043478260869565	0.2968609817650007	0.8880434777425683
63	0.24812719886717588	0.9100543473077857	0.2924167228781659	0.8836956516556118
64	0.25296780648438827	0.9116847831269969	0.290029397736425	0.8923913043478261
65	0.2538193599037502	0.9127717391304347	0.28657619460769324	0.8869565212208291
66	0.24445752980916396	0.9157608695652174	0.2844651934893235	0.8913043478260869
67	0.24099101087321406	0.9133152179096056	0.2799111374046492	0.8902173907860466
68	0.2252303263415461	0.9184782608695652	0.2824256409769473	0.8956521739130435
69	0.23246897757053375	0.9144021733947422	0.27498581927755605	0.8978260869565218
70	0.2245053593231284	0.9244565222574317	0.2717290108618529	0.8923913038295248
71	0.21786765015643575	0.9192934777425683	0.2693342903385992	0.8956521739130435
72	0.2203519149966862	0.9184782613878665	0.2677330846371858	0.8956521733947422
73	0.21795263899409253	0.9277173907860465	0.26726959619833074	0.9010869570400404
74	0.2135335437629534	0.9285326086956521	0.26447455053744107	0.9043478266052578
75	0.21438335296900377	0.9247282608695652	0.2618643108917319	0.9043478266052578
76	0.2034622855808424	0.9326086951338727	0.25829991788967793	0.9021739135617796
77	0.2074744122183841	0.9282608700835187	0.2589345475901728	0.8880434777425683
78	0.20657506481460902	0.9260869560034378	0.25658096023227855	0.9119565222574317
79	0.19471850187882134	0.9320652173913043	0.25732455149940825	0.9097826092139535
80	0.20251297017802364	0.929076087474823	0.25078057750411653	0.9086956526922143
81	0.1907042445048042	0.9342391299164814	0.25008389483327453	0.9097826092139535
82	0.18435157524502796	0.9369565222574316	0.24946212613064309	0.9065217396487361
83	0.18643243857052016	0.9385869570400404	0.24867269150588822	0.9086956526922143
84	0.1900781801213389	0.9350543483443882	0.24829839778983076	0.9108695657356926
85	0.1855228974767353	0.9355978266052578	0.246030182035073	0.9108695657356926
86	0.18175111775812897	0.938858695652174	0.25092984010343966	0.9108695657356926
87	0.17794803335614826	0.939945652173913	0.24854055967019953	0.9130434787791708
88	0.1755357572565908	0.9426630429599596	0.24225126699261043	0.9097826092139535
89	0.17038503289222717	0.9437499994816987	0.24327149896518044	0.9119565222574317
90	0.17487894970437753	0.9391304347826087	0.24141695019991502	0.91413043530091
91	0.1748286731865095	0.93913043530091	0.24166313824446306	0.9130434787791708
92	0.1686176077179287	0.9432065222574317	0.24034639687641807	0.9130434787791708
93	0.1650475693785626	0.946195652173913	0.24199256015860515	0.9130434787791708
94	0.16132418623437053	0.9415760864382204	0.2432402272587237	0.91413043530091
95	0.16207404460596	0.9459239130434782	0.23818068309970525	0.9130434787791708
96	0.16028666107550912	0.9448369565217392	0.2386390623839005	0.9163043483443882
97	0.15192734748125075	0.9524456521739131	0.24105209008507106	0.91413043530091
98	0.15627441198929495	0.9489130434782609	0.23796235011971514	0.91413043530091
99	0.15154770217511965	0.9513586956521739	0.23730761266273	0.9119565222574317

The optimal condition:
	epoch: 96
	train_acc: 0.9448369565217392
	val_acc: 0.916304348344
	using time: 297.293902159
