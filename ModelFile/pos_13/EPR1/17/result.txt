The number of train datas: 14182
The number of test datas: 3546
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6956751173767447	0.5312367791837671	0.6719176823717689	0.6212633950725088
1	0.6681174976989457	0.5937103369797155	0.6453877497848924	0.714326001665919
2	0.6372374292573914	0.6573825975833533	0.5970645369074133	0.7803158484403521
3	0.5850521896558257	0.7113242139014047	0.5158663367189664	0.8384094758014926
4	0.49881941597882995	0.7827527852879477	0.41081299423095674	0.8708403837324467
5	0.40096323799639794	0.8405725565939793	0.3203175248093882	0.89001691986865
6	0.3149298749367116	0.8833732901196473	0.2591445626374765	0.9080654252268
7	0.2610926057661627	0.9064306868280952	0.22619762791460407	0.9162436549568068
8	0.224051717192275	0.9227189395512096	0.2096693230697279	0.9266779470833694
9	0.1925497474370832	0.9344944293736706	0.19161384646427276	0.9328821208002335
10	0.1712059310075679	0.943872514244801	0.18468156288017074	0.93457416817756
11	0.1602273388484556	0.9476096460469905	0.1720518092616964	0.9390862945170976
12	0.14819181194057957	0.9529685517104518	0.16309817051289113	0.9447264524415194
13	0.1325141853261374	0.9577633620333964	0.15798522792525435	0.9486745622154016
14	0.12839532663835287	0.9615004933816794	0.15356083365143589	0.9509306253851704
15	0.11843182526275614	0.9631222674783102	0.15368543229093676	0.9506486182285444
16	0.11584468565155212	0.9650260894091102	0.14875093297019087	0.9529046813983132
17	0.10847925527267943	0.9686927088745019	0.14765847604606222	0.9531866892945343
18	0.10552300334170076	0.9696093637891825	0.13975362500277738	0.9591088551151773
19	0.10014809503628092	0.9715131857536051	0.13705334437142236	0.9599548788038406
20	0.09661835809467441	0.9719362570257353	0.14955995771224997	0.9557247603269061
21	0.09507950924798171	0.9735580313156966	0.1335552116899052	0.961082910388725
22	0.09219204036049002	0.9732759836580467	0.13542249228950282	0.9627749577324335
23	0.08404360953027583	0.9770131150147354	0.13451306222692694	0.9633389735248757
24	0.0831624760403189	0.9769426032999577	0.1344719594959075	0.9630569656286546
25	0.08415179287150824	0.9763079958495965	0.12593373369259547	0.9655950359550494
26	0.0815730672946956	0.9770836269396549	0.12755631192367223	0.9647490122663861
27	0.07712722230745192	0.9789874486687187	0.13117347020199926	0.9633389735248757
28	0.07661902220708798	0.9794810320927215	0.12629064485573593	0.9664410603833078
29	0.07190394728320927	0.9808912704229994	0.12385050413706715	0.9664410596437126
30	0.07117650890309155	0.9806092229670857	0.12558921912734414	0.9658770445908655
31	0.06737850331838587	0.9818079255478218	0.13159020170485375	0.9630569656286546
32	0.0669928547570188	0.9818079253376799	0.12387497438190351	0.9670050761757499
33	0.06488968012506409	0.9816669014962465	0.1255310474481545	0.9661590524870867
34	0.0653101411494297	0.982583556621069	0.12604723085774855	0.9644670051097601
35	0.06379900525080151	0.9825835566294746	0.12186369973928728	0.9689791314492976
36	0.06259297388875674	0.9830066281201523	0.1231010701492622	0.9684151156568555
37	0.06220155213715882	0.9823720208799329	0.12594884773532483	0.9678510998644132
38	0.05936081743543171	0.9850514736990551	0.13292492367222158	0.9630569656286546
39	0.05898513379314355	0.9844873783753497	0.11727704551098243	0.9701071622945868
40	0.058625499478198125	0.985192497321941	0.12496734933073549	0.9684151156568555
41	0.05682275635734707	0.9858271045705661	0.12287925126202283	0.9689791314492976
42	0.05745019987075806	0.9850514736990551	0.12142006665661519	0.9692611393455187
43	0.054363279359000406	0.9861091524467634	0.12075026838862149	0.9703891709304031
44	0.05603766879175836	0.9871668312028775	0.11890766086992878	0.9706711788266241
45	0.05398209607999595	0.9856860807375383	0.12144022399861128	0.9698251551379609
46	0.05290816105957882	0.9866732477872803	0.12008197683141317	0.9703891709304031
47	0.05276628792445627	0.9867437594936523	0.12169428709715824	0.9692611393455187
48	0.05362514567017312	0.9870963192779579	0.11845313636633345	0.9703891709304031
49	0.04967184206979128	0.9876604146184748	0.11722316386811624	0.970107163034182
50	0.05021613366621335	0.9882950218586941	0.11591476320934645	0.9712351946190664
51	0.05068354753055285	0.9878719501494689	0.11661083407351275	0.9706711788266241
52	0.04913734509004825	0.9881539978155245	0.11774185314791322	0.9706711788266241
53	0.047621986615844415	0.9869552952347883	0.12208298240350722	0.9706711788266241
54	0.0493425365210109	0.9880834858990105	0.11231930288751449	0.9712351938794712
55	0.045365843023017875	0.9887180933661831	0.11616019069417277	0.9717992104115085
56	0.04570887504667443	0.98843604548158	0.11562354626103571	0.9717992104115085
57	0.04810225223591009	0.9886475814412635	0.11770463033300366	0.9712351946190664
58	0.046854358432023034	0.9890706529403469	0.11991717104337274	0.9689791314492976
59	0.043558106507237584	0.9905514031955444	0.11707603820697843	0.9706711788266241
60	0.043391664932870576	0.989705260188972	0.11545588393804386	0.9723632262039508
61	0.04299114643476726	0.9893527003962606	0.12112239507660984	0.9689791314492976
62	0.04197008000454821	0.990410379143969	0.11946686093778981	0.970107163034182
63	0.0426782866840873	0.9899873078634331	0.11644982945781203	0.9709531867228453
64	0.04296303715621479	0.9893527003962606	0.12088618824206969	0.9692611393455187
65	0.04310729012088704	0.9901283314779133	0.12432581191967587	0.9689791306760845
66	0.039519820857213624	0.9910449866027359	0.11466266828795577	0.9723632254643556
67	0.04136623945121343	0.9900578197715414	0.11745738960462174	0.9717992096719134
68	0.04050799680603456	0.9900578195698052	0.12106780949675358	0.9695431464685267
69	0.040101364393645124	0.9902693555210831	0.11362047121979325	0.9729272412567977
70	0.03909706356438086	0.9918911296093083	0.1158678931616419	0.9709531859832501
71	0.03841603970035076	0.9912565223606832	0.1188960939591138	0.9712351938458532
72	0.037678529267799424	0.9908334508531942	0.11504217958339379	0.9715172017756923
73	0.03667930409022253	0.9905514029769967	0.1171712006699111	0.9715172017756923
74	0.03795366781548205	0.9910449866027359	0.11503216368763446	0.9709531859832501
75	0.037776273294512094	0.9906219148935106	0.120008161933373	0.9706711780870291
76	0.03608591765472136	0.9911860102256218	0.11606914357182943	0.9723632254643556
77	0.03766473430623761	0.9913975459751634	0.11803012294826101	0.9715172017756923
78	0.03435799221640463	0.9921731770568162	0.12413544081744002	0.9689791314492976
79	0.03807074179316782	0.990339867227455	0.11979922475540161	0.9712351946190664
80	0.03488872942051486	0.9914680578916774	0.1165635736645512	0.970389170190808
81	0.03505939385913992	0.9913270340586495	0.11875056305630222	0.9706711780870291
82	0.034603293067333715	0.9913975459751634	0.11681076864519162	0.9715172017756923
83	0.03425558065127951	0.9907629389366803	0.12285212503018113	0.9681331077606343
84	0.03444058143895867	0.9919616415258221	0.12190802391141535	0.9698251551379609
85	0.031584065367587615	0.9919616413072746	0.11674714791055325	0.9715172017756923
86	0.03208029659197287	0.9917501057762804	0.11679658320198204	0.9726452333605767
87	0.03301373551025863	0.9923142010999859	0.1191002339044837	0.9712351946190664
88	0.03404704946223418	0.9923847130164998	0.12124063789390671	0.9709531867228453
89	0.030154203372991583	0.9926667606825553	0.11806671280210057	0.9712351938794712
90	0.03202966944501172	0.9913270340586495	0.11985755409862588	0.9715172025152874
91	0.029292996417499367	0.9928077845239888	0.12225441659448245	0.9706711788266241
92	0.03139709946576639	0.9924552249414194	0.11888940150766002	0.9720812175681345
93	0.030063556992394887	0.9932308560230722	0.11981200420933798	0.9712351938794712
94	0.030363314956197564	0.9930898321900443	0.12278081022845912	0.9706711780870291
95	0.02835327985786724	0.9933718798476943	0.12531454150564444	0.970107163034182
96	0.02986547996150415	0.9925962487744472	0.12038487653593122	0.970389170190808
97	0.028167023514048737	0.9934423915540662	0.12221154889529934	0.970389170190808
98	0.029268972128587655	0.9924552247228718	0.12533964264194508	0.9689791314492976
99	0.029231580469965886	0.9932308558045246	0.12049361133030828	0.9701071622945868

The optimal condition:
	epoch: 69
	train_acc: 0.9902693555210831
	val_acc: 0.972927241257
	using time: 1164.31211591
