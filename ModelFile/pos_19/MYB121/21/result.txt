The number of train datas: 1624
The number of test datas: 408
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7072443181070788	0.516009851335892	0.69953604889851	0.495098038631327
1	0.6995338747654055	0.5240147774442664	0.6964447837249905	0.4828431384236205
2	0.694348926908277	0.5264778322186964	0.6953188683472428	0.5122549007920658
3	0.686691496172562	0.5369458139823575	0.6941317635423997	0.5147058811842227
4	0.6946011764075368	0.5289408881676021	0.6931250609603583	0.5318627462667578
5	0.6866407268153035	0.5597290649202656	0.6923001829315635	0.5318627462667578
6	0.6896454474608886	0.543719212409898	0.6915376478550481	0.5392156851057913
7	0.6825533109932698	0.5578817748671094	0.6905730296583736	0.5539215674587324
8	0.6892455499160466	0.5332512321143315	0.6899429290902381	0.5514705870665756
9	0.6889493233464622	0.5363300501419406	0.6891917621388155	0.544117645890105
10	0.6817998492659019	0.5634236450265782	0.6881984624208188	0.5514705870665756
11	0.6829589702225671	0.5541871935863213	0.6873958017311844	0.5563725490196079
12	0.6798435211768878	0.5621921167585063	0.6865262599552379	0.5686274498116737
13	0.6840742013137329	0.5597290643330278	0.6857354512401655	0.5686274498116737
14	0.6801699916717454	0.5554187203862985	0.6850695948974759	0.5686274509803921
15	0.676114071472525	0.5917487687665254	0.6840641171324486	0.5710784302038305
16	0.6742812897184213	0.5880541863112614	0.6829172816931033	0.5661764717569538
17	0.6727353313873554	0.5806650243369229	0.6817275776582605	0.5784313737177381
18	0.6736617032530272	0.5917487675920495	0.6808239057952282	0.5759803933255813
19	0.6739415268005409	0.5812807872964831	0.6797562124682408	0.580882351772458
20	0.6697747451918465	0.6046798044237597	0.6784640889541775	0.5882352941176471
21	0.6694779445972349	0.5843596056177112	0.6766265829404196	0.5931372549019608
22	0.6631364026680369	0.6114532025576812	0.6750652170648762	0.5980392168549931
23	0.6643230829920087	0.602832512021652	0.673153232125675	0.6053921568627451
24	0.6704882301133255	0.5886699522070109	0.6714407825002483	0.6102941176470589
25	0.6661190155691701	0.6052955662088441	0.6694942595911961	0.6446078443059734
26	0.6595624694096044	0.6225369464000458	0.6674384322820925	0.6274509803921569
27	0.6579394713411191	0.6262315259191203	0.6653900684094897	0.6176470588235294
28	0.651190507881747	0.6231527105340817	0.6629191251362071	0.6421568627450981
29	0.6585239779773017	0.5985221677813036	0.6604989054156285	0.6348039215686274
30	0.6466929281286418	0.6403940901380455	0.6580225474694196	0.6544117658746009
31	0.6505689794206854	0.6293103451212051	0.6551972873070661	0.6666666654979482
32	0.6439692654045932	0.6613300495547026	0.6520601359068179	0.6470588235294118
33	0.637379595505193	0.653325124620804	0.6488165890469271	0.6568627462667578
34	0.64316969992492	0.6354679788274719	0.6458170332160651	0.6617647047136345
35	0.6324118008754523	0.6551724123250088	0.6428345862556907	0.6764705882352942
36	0.6239383070926948	0.6644088672886929	0.638865563214994	0.6838235294117647
37	0.6334474647573649	0.6533251243271851	0.6351549520212061	0.6862745098039216
38	0.6299088987810858	0.6699507380353993	0.6314246888254204	0.6911764717569538
39	0.6203538878210659	0.6754926123055331	0.6281949199882209	0.7034313737177381
40	0.627772516217725	0.6582512306462368	0.6235584382917366	0.6985294129334244
41	0.6081982169832502	0.6933497525201056	0.6190239202742484	0.7058823529411765
42	0.6069254349605203	0.6853448267053501	0.6145732601483663	0.7083333345020518
43	0.6082432766266057	0.6871921188138389	0.60965108053357	0.7205882352941176
44	0.5968854932362223	0.7062807870028641	0.6040473159621743	0.7254901960784313
45	0.5856367740137823	0.7229064048217435	0.5975423046186858	0.7279411764705882
46	0.58916193364289	0.7247536934068051	0.593414867625517	0.7230392168549931
47	0.5748599107042321	0.7161330049261084	0.5875261811649098	0.7205882352941176
48	0.5830028415313495	0.7112068974325809	0.5808206358376671	0.7303921568627451
49	0.5589000124649461	0.7395320197044335	0.5751357481760138	0.7303921568627451
50	0.5604438171010887	0.7235221671940658	0.5706145009573769	0.7279411764705882
51	0.549984077514686	0.7481527096532249	0.5649418299104653	0.7426470576548109
52	0.5447964415761638	0.7512315265063582	0.5559731581631828	0.7450980392156863
53	0.5396743217125315	0.7512315256255013	0.5529728198752684	0.7475490196078431
54	0.5282069870403835	0.7684729078720356	0.5415663251689836	0.7450980403844047
55	0.5284799971603995	0.7610837432551266	0.5403227245106417	0.7524509803921569
56	0.5176553667472501	0.7653940880827128	0.5278867927252078	0.7549019619530323
57	0.5146135928595594	0.7666256145890711	0.5262981016261905	0.7598039215686274
58	0.5004186700717569	0.7894088684631686	0.5187479467952952	0.7598039215686274
59	0.4912185419369214	0.7937192106481843	0.5078415222027722	0.7598039215686274
60	0.4910920915638872	0.7770935963527322	0.49983805125834896	0.7769607843137255
61	0.4792308706074513	0.7801724146739603	0.4908976969765682	0.7843137243214775
62	0.47758067579104985	0.7924876838482072	0.4849471023269728	0.7892156851057913
63	0.47177461156704154	0.7961822651289954	0.48497040832743926	0.7745098039215687
64	0.46305167616294524	0.8066502465990376	0.47497619542421077	0.7916666666666666
65	0.4386470237095368	0.8232758635370602	0.4715372727197759	0.7843137254901961
66	0.44103148946621146	0.8232758617753466	0.4661109611099842	0.7843137254901961
67	0.43491521888765794	0.8103448267053501	0.4590982514269212	0.7892156862745098
68	0.43251766403907627	0.8146551709456984	0.4450865253513935	0.8112745098039216
69	0.4133783612638859	0.8294334978305647	0.4303206263803968	0.830882351772458
70	0.41979150055664516	0.8275862060156949	0.43341849101524726	0.8235294117647058
71	0.39483603365315595	0.8479064036472678	0.4172375266458474	0.8382352941176471
72	0.39455247512591884	0.836822661272998	0.4222852739633298	0.8235294117647058
73	0.38004432919577424	0.8620689666917172	0.4179164778952505	0.8259803921568627
74	0.37892696510982044	0.8466748768472906	0.3924211123410393	0.848039214517556
75	0.3583894418965419	0.8528325117280331	0.4037071749860165	0.8333333333333334
76	0.3677400714658164	0.8491379310344828	0.38360561079838695	0.8529411764705882
77	0.34438357564616084	0.8762315256255013	0.37731421957997713	0.8529411764705882
78	0.3495362762159902	0.8657635456235538	0.38237563973548366	0.8504901960784313
79	0.3343499319013116	0.8762315259191203	0.3573215787901598	0.865196077262654
80	0.3283078993482543	0.8830049261083743	0.35811996693704645	0.8553921568627451
81	0.3167882216681401	0.8830049261083743	0.36184049558405784	0.8700980392156863
82	0.3162809826176742	0.8780788162658955	0.340721672948669	0.8700980392156863
83	0.311832482444829	0.8836206881870777	0.3377089547175987	0.8700980392156863
84	0.3052249631564605	0.8860837447232214	0.3388398578938316	0.8725490196078431
85	0.301444130724874	0.8922413804848206	0.31676491013928953	0.8725490196078431
86	0.2885467163447676	0.8922413781358691	0.3253114807839487	0.8774509803921569
87	0.29020167263270596	0.890394087495475	0.3083985833560719	0.8921568627450981
88	0.27205081878624526	0.9088669947802727	0.3024130440225788	0.8921568627450981
89	0.2753525153169491	0.9014778339804099	0.31050411042045145	0.8823529411764706
90	0.2801520257013772	0.8947044349656317	0.29977867956839355	0.8897058823529411
91	0.2571252812012076	0.9150246311291098	0.2886682722498389	0.8946078431372549
92	0.26659572425440614	0.9051724146739603	0.30295465039271935	0.875
93	0.25398429890571556	0.9076354682739145	0.2903704292633954	0.8946078431372549
94	0.2480008085373	0.9174876861971587	0.2836065287975704	0.8921568627450981
95	0.24562954631051406	0.9119458139823575	0.2708977992628135	0.9019607843137255
96	0.22964751191914376	0.9187192127035169	0.26477011263954875	0.9019607843137255
97	0.2252005132401518	0.9230295557693895	0.2625536312367402	0.9019607843137255
98	0.2116208789237027	0.9378078808925422	0.2552277689763144	0.9019607843137255
99	0.21543534606548365	0.9261083755587122	0.2575135919101098	0.9044117647058824

The optimal condition:
	epoch: 99
	train_acc: 0.9261083755587122
	val_acc: 0.904411764706
	using time: 166.327728987
