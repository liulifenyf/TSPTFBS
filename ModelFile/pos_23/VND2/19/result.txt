The number of train datas: 5550
The number of test datas: 1388
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7074705707275115	0.5163963961816049	0.6955037977578661	0.5100864546443269
1	0.695321001748781	0.5286486485305133	0.6918636881652415	0.5302593666813216
2	0.6904173950032071	0.5374774773056442	0.6894044029266072	0.5425072051262649
3	0.684618017329826	0.549369369251234	0.6866025356119579	0.5533141208656926
4	0.6823077297210693	0.5545945946375529	0.684266658097248	0.5590778109147844
5	0.6785240109761556	0.55837837833542	0.6813455691255135	0.5814121046052543
6	0.6723421353477615	0.582162161990329	0.6775380543054697	0.5842939493292003
7	0.6663675286318804	0.5998198198198198	0.6729785461590682	0.5914985582189533
8	0.6646714710115312	0.5940540539681375	0.6691931517048597	0.5994236305227197
9	0.6616370170395653	0.6077477476618312	0.6631114656368662	0.6116714709430332
10	0.6457440915408436	0.631891891913371	0.6576165349064368	0.6203170020229878
11	0.6419658666688043	0.6354954953666205	0.6508808575720884	0.6289625372254539
12	0.6343979901880832	0.6491891889743977	0.6444970869193503	0.6397694546825947
13	0.6273852093799694	0.6479279277131365	0.6393176219305319	0.6383285306029086
14	0.6133428898802749	0.6581981984344689	0.6332231076375209	0.6426512945969441
15	0.6045082893027915	0.6760360361004735	0.628740018485946	0.6376080695078078
16	0.598626871001613	0.677297297404693	0.623658221461931	0.6469740649465182
17	0.590926295572573	0.6825225224151268	0.6193353130082232	0.6476945222626502
18	0.5849605349807052	0.6926126125052169	0.6150617518754788	0.6527377526766972
19	0.5775639403940321	0.7050450450235659	0.6137592129473728	0.6671469754375711
20	0.5682675886798549	0.71423423434163	0.6065838549941005	0.6700288170696336
21	0.5581137434426728	0.7239639640713598	0.5994652586986421	0.6793948133672005
22	0.5597801232015764	0.7144144143070187	0.5951116040391949	0.6743515858732658
23	0.5426868323592452	0.7300900900686109	0.5883296262633904	0.687319882664969
24	0.5404053485071337	0.7311711711926503	0.5823670984688685	0.6865994244899805
25	0.5336056327605033	0.7365765765550975	0.5776529160975036	0.6988472603583542
26	0.5240551670392354	0.7473873874518249	0.5691154070134121	0.7031700286466724
27	0.516227178079588	0.7562162162376954	0.5615594727161638	0.7067723351528047
28	0.5071043033213228	0.760900901051255	0.5542243768914632	0.7154178664045306
29	0.4991712868106258	0.7659459458815084	0.5470304219454785	0.7226224792450237
30	0.4869302274300171	0.7706306307809847	0.5449091209801885	0.7219020152298106
31	0.479982767878352	0.7789189188115232	0.5335431506035995	0.7305475494016488
32	0.4837067063005121	0.7735135132772428	0.5278161652493546	0.739193083573487
33	0.46717877715557543	0.786126125975772	0.5238159707712509	0.7370316992575566
34	0.4582063581385054	0.7926126125911335	0.5162756424987694	0.7514409232208296
35	0.45717271261387044	0.7906306306521098	0.5127314928629213	0.7427953890489913
36	0.44984321390186344	0.7951351350706977	0.5121209216049151	0.7435158491134644
37	0.44002829479741623	0.8045045044830254	0.5031839244132084	0.7564841508865356
38	0.43729524221506205	0.8014414412481291	0.5074139632477884	0.7536023063343609
39	0.4268758471699448	0.809549549764341	0.49491423918122174	0.7687319867549094
40	0.42617097521687414	0.8113513512009973	0.49178545000917284	0.7701729091168824
41	0.4176666998970616	0.8163963962890006	0.4886725638544869	0.7716138331965685
42	0.4070787058757232	0.8232432430069726	0.48354611985965146	0.7737752145923867
43	0.4082327819514919	0.8243243243887618	0.48203726400559505	0.7788184424298641
44	0.4040037417411804	0.8261261260616887	0.4743360022474778	0.7766570589727902
45	0.3920025910557927	0.8297297295793756	0.47202809674595547	0.7845821320495275
46	0.38932414985991814	0.834594594358324	0.470229209929447	0.7896253616047181
47	0.38753909210901005	0.8338738737664781	0.4726560181087307	0.7752161366108171
48	0.3792864419318534	0.8376576575502619	0.48109847023782537	0.7867435137888884
49	0.3697401535833204	0.8418018016084894	0.46004875455191224	0.7925072051262649
50	0.3647818212680988	0.847387387194075	0.4557344667849692	0.7896253624635746
51	0.3629948539669449	0.8446846848994762	0.45311748955710135	0.797550432791971
52	0.3547778694049732	0.8535135132772429	0.4498029150262003	0.7975504345096841
53	0.34831353819048083	0.8542342340838802	0.4476122402663877	0.7975504326201996
54	0.34132812364144366	0.8598198199486947	0.4443782292284952	0.795389047617184
55	0.33694848230293206	0.8569369368724995	0.4422759807934335	0.8018731991908049
56	0.3318368736151102	0.8627027029174942	0.43800965131875075	0.8047550427123518
57	0.32935912987133403	0.8618018016514477	0.43512255649058207	0.8061959676508945
58	0.32266069201735764	0.8684684685973434	0.43456921943326504	0.8033141206939214
59	0.32074910172471055	0.8679279277775739	0.4319371076069923	0.8112391953166005
60	0.3177597416413797	0.8677477475544354	0.436156743198032	0.8054755031203674
61	0.3017380648690301	0.8781981983700314	0.4263867490229758	0.8105187314731587
62	0.30024058846740037	0.8742342340838801	0.4242276077827047	0.8126801166479457
63	0.2961300142283912	0.8799999997637293	0.4231688391406529	0.8097982705498291
64	0.294856265933664	0.8814414412051708	0.4214683455074211	0.81628242212345
65	0.28850953346437164	0.8848648649507814	0.4227093134816167	0.817723341737082
66	0.2813413940464054	0.8877477478766227	0.42557463213071356	0.8097982720957709
67	0.2857473234442977	0.8863063060700357	0.41662524490260255	0.8170028823596943
68	0.2771903394041835	0.8859459457955919	0.41674994649392383	0.8162824229823066
69	0.2709362294061764	0.8917117119265032	0.419453156612792	0.8227665694027881
70	0.2673138496038076	0.89243243223912	0.4133973241882984	0.8198847284578109
71	0.2698137820196581	0.8911711710208171	0.41279824387271397	0.8220461110560282
72	0.25829371979644705	0.8976576577865326	0.423268070396154	0.8242074907341334
73	0.25923006677412774	0.897477477692269	0.4105517442099299	0.8220461072770594
74	0.26022644340455	0.9030630632348963	0.4237663779804961	0.8220461074488308
75	0.2482872721901885	0.9046846848135596	0.41687518955135894	0.8227665694027881
76	0.2428151727367092	0.9063063064781395	0.4097483677719787	0.8220461089947725
77	0.2403821445263184	0.9048648649507814	0.4095726501872972	0.8278097987862073
78	0.24271194932965545	0.909009009009009	0.40699282340082726	0.8278097960378663
79	0.2375714955512468	0.9063063063492646	0.40520248173464957	0.8249279516574629
80	0.23136361044806403	0.9095495496354662	0.405423889371435	0.8328530274825412
81	0.22448841508981343	0.9055855858003771	0.4080216369728534	0.8328530274825412
82	0.2230089421315236	0.9129729730588896	0.41054043852286654	0.8263688755653777
83	0.2301725353743579	0.907567567782359	0.40329360790142754	0.8263688765960056
84	0.2248638221755758	0.9115315315744899	0.40329805123874707	0.8299711793231689
85	0.2231147608456311	0.9158558559847307	0.41418868002699155	0.8278097962096377
86	0.2180517801239684	0.9162162163450911	0.40828597519858084	0.8299711803537968
87	0.21659045280636968	0.9136936937796103	0.40464963873456467	0.834293946924402
88	0.20645633785574286	0.9189189190907522	0.4075663535498748	0.834293946924402
89	0.2082855217574953	0.920000000128875	0.4045892269364008	0.8335734885776421
90	0.2039863675993842	0.9232432433291599	0.4053180805200802	0.8350144088783594
91	0.20001605798532296	0.9245045045904211	0.4168026156143771	0.8292507202893238
92	0.2046710597878104	0.9205405405405406	0.4054623636113807	0.8321325663874404
93	0.1969181047903525	0.9237837839985753	0.4093834026488516	0.8306916414488976
94	0.19369271632787344	0.9270270271559019	0.4153814996010288	0.8278097977555794
95	0.1961196771344623	0.9248648649507815	0.4070836740199702	0.8350144088783594
96	0.19134814043839773	0.9270270271559019	0.4165685856634327	0.8270893378628777
97	0.18770937603873175	0.9295495496354661	0.40681365170980394	0.8314121052923394
98	0.18625570543714473	0.9295495496784244	0.4120565004840021	0.8357348710040882
99	0.17919440913844753	0.9320720721579887	0.4077249971521691	0.8306916414488976

The optimal condition:
	epoch: 98
	train_acc: 0.9295495496784244
	val_acc: 0.835734871004
	using time: 463.725850105
