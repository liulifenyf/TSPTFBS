The number of train datas: 5648
The number of test datas: 1412
epoch	train_loss	train_acc	val_loss	val_acc
0	0.702329794340701	0.5060198300283286	0.6830073380605357	0.5835694050991501
1	0.6916739093007852	0.5385977337110481	0.6730672438489141	0.6458923512747875
2	0.6751641960387189	0.5775495750708215	0.6638088791971504	0.6777620396600567
3	0.6657254776941143	0.5987960339943342	0.6509976682514375	0.7188385269121813
4	0.6512722224419245	0.6315509915014165	0.6360255950908823	0.7769121813031161
5	0.6342441380530511	0.6655453257790368	0.6150363634733573	0.8059490084985835
6	0.6129643564183719	0.6947592067988668	0.5872265411166226	0.8307365439093485
7	0.5797186644151596	0.7310552407932012	0.5477077508445501	0.8562322946175638
8	0.5426034349895401	0.7710694050991501	0.5027160445286262	0.8774787535410765
9	0.4910873639009492	0.7999291784702549	0.44652400948845966	0.8980169971671388
10	0.4432327338723893	0.8330382436260623	0.39013099383362293	0.9143059490084986
11	0.39139844844429084	0.8601274787535411	0.3456821960025063	0.9128895184135978
12	0.34052642960386303	0.87907223796034	0.30313508925964744	0.9171388101983002
13	0.30105389160745205	0.8951841359773371	0.27808330197509895	0.9171388101983002
14	0.2638302385469334	0.9081090651558074	0.24194431072760575	0.9348441926345609
15	0.23937074810519773	0.9194405099150141	0.221078554395238	0.9376770538243626
16	0.22199346424837627	0.9249291784702549	0.20700296966448722	0.9376770538243626
17	0.19680369980949855	0.9327195467422096	0.18894763240226606	0.9426345609065155
18	0.18644972757644762	0.9426345609065155	0.17313312770793526	0.9468838526912181
19	0.16772197837025857	0.9413951841359773	0.1631565378931359	0.9511331444759207
20	0.15848294014464695	0.9470609065155807	0.15065139103628084	0.9553824362606232
21	0.14743386466509897	0.9481232294617564	0.14384651112320065	0.9575070821529745
22	0.1416315873689084	0.9548512747875354	0.14482399362215914	0.9518413597733711
23	0.1356963491853506	0.9564447592067988	0.1340740663091792	0.9596317280453258
24	0.1262737554379293	0.9569759206798867	0.12900714853794312	0.9603399433427762
25	0.11771840118821553	0.9631728045325779	0.13699673643868637	0.953257790368272
26	0.1117526592512644	0.9644121813031161	0.13092378250431408	0.9553824362606232
27	0.10881433637005411	0.9675991501416431	0.11932350360595809	0.9610481586402266
28	0.10276566103902822	0.9681303116147308	0.1103406068328082	0.96671388101983
29	0.09239600961843226	0.97078611898017	0.12509049319532878	0.9553824362606232
30	0.09713390003098307	0.9704320113314447	0.10503840972023037	0.9681303116147308
31	0.09038974484033017	0.9739730878186968	0.10470300964567884	0.9681303116147308
32	0.08961126482689347	0.9727337110481586	0.11394952319129753	0.9589235127478754
33	0.0887849491205668	0.9729107648725213	0.11429540273171478	0.9582152974504249
34	0.08310702537046613	0.9771600566572238	0.10455500823907322	0.96671388101983
35	0.08321474682508041	0.9745042492917847	0.10312741738941954	0.9674220963172805
36	0.07729044417315097	0.9792847025495751	0.10635548105553089	0.9638810198300283
37	0.0774572150407111	0.9773371104815864	0.10494436304646916	0.9645892351274787
38	0.06871446433131485	0.9791076487252125	0.09894576712799055	0.9681303116147308
39	0.07348059315667105	0.9785764872521246	0.10484986427232158	0.9645892351274787
40	0.07375401194093922	0.9785764872521246	0.10480651271822349	0.9638810198300283
41	0.06795158686786468	0.9808781869688386	0.09243919594851836	0.9723796033994334
42	0.06919341190340836	0.9812322946175638	0.09290980720739526	0.9702549575070821
43	0.06930127693999759	0.9799929178470255	0.0976303102073943	0.9660056657223796
44	0.06522460349389582	0.9822946175637394	0.08978371870131482	0.9723796033994334
45	0.06691665230609117	0.9837110481586402	0.09795494261923281	0.9674220963172805
46	0.06264641739575788	0.9803470254957507	0.09486738060503438	0.9709631728045326
47	0.06262404716470761	0.9822946175637394	0.09290063997503718	0.9716713881019831
48	0.05808071146795669	0.9831798866855525	0.09864392883880407	0.9660056657223796
49	0.05975052939131645	0.9847733711048159	0.10360167015518033	0.9645892351274787
50	0.05895780120308777	0.9845963172804533	0.09092889376322372	0.9716713881019831
51	0.05691644581029503	0.9851274787535411	0.0912123979399081	0.9695467422096318
52	0.055310232232380185	0.9851274787535411	0.08937787639357087	0.9716713881019831
53	0.05455744517676891	0.9849504249291785	0.08656282362029505	0.9730878186968839
54	0.053449872174107654	0.9865439093484419	0.08645817216105822	0.9730878186968839
55	0.05232750259804152	0.9863668555240793	0.0895092764806013	0.9716713881019831
56	0.055065331062455015	0.9861898016997167	0.09036901786728174	0.9709631728045326
57	0.05002003656594721	0.9884915014164306	0.08587160324493144	0.9723796033994334
58	0.04794381261821678	0.9879603399433428	0.08793548988864332	0.9730878186968839
59	0.05035133157505867	0.9868980169971672	0.08713490597998708	0.9737960339943342
60	0.052115270472197626	0.9870750708215298	0.08245300944556849	0.9737960339943342
61	0.0460641771744905	0.9879603399433428	0.08199743453476567	0.9745042492917847
62	0.04613254993900699	0.9877832861189801	0.08310660488887693	0.9745042492917847
63	0.05053793185155723	0.9868980169971672	0.09708116903885271	0.9681303116147308
64	0.048698256831753356	0.9872521246458924	0.08558372145112361	0.9730878186968839
65	0.04631559466336334	0.9895538243626062	0.08334910484273567	0.9745042492917847
66	0.04088925110128716	0.9911473087818697	0.08477087584047159	0.9745042492917847
67	0.042223179108719144	0.9891997167138811	0.09197429145446243	0.9695467422096318
68	0.044925207193022745	0.9879603399433428	0.09494334430613215	0.9695467422096318
69	0.04471398282680059	0.9884915014164306	0.09049942881850362	0.9716713881019831
70	0.043170991577946766	0.9897308781869688	0.0827402471889222	0.9730878186968839
71	0.04397124552270846	0.9891997167138811	0.08055755835839101	0.976628895184136
72	0.04387919628786889	0.9893767705382436	0.08995706922171516	0.9716713881019831
73	0.03937777019931642	0.9911473087818697	0.08200910414909422	0.9745042492917847
74	0.04142487462789411	0.9904390934844193	0.08755024330474162	0.9709631728045326
75	0.04316035763653412	0.9904390934844193	0.08724149981666642	0.9709631728045326
76	0.03796625296419048	0.9909702549575071	0.09354157350421817	0.9702549575070821
77	0.040017777721452985	0.9895538243626062	0.08062511745170181	0.976628895184136
78	0.04005242152820228	0.9904390934844193	0.08545143523704651	0.9730878186968839
79	0.03827465760387037	0.9902620396600567	0.09015040942823921	0.9716713881019831
80	0.034773593145836855	0.9915014164305949	0.08829206385499357	0.9716713881019831
81	0.0348807302944721	0.9930949008498584	0.08306615315140264	0.9745042492917847
82	0.032969623970305784	0.9909702549575071	0.09714555214343872	0.9688385269121813
83	0.03891918933277596	0.9897308781869688	0.0884525896598804	0.9716713881019831
84	0.03435693949819793	0.9911473087818697	0.08183880614792195	0.976628895184136
85	0.03679276144833808	0.9923866855524079	0.08842245322815737	0.9730878186968839
86	0.03171673343548546	0.9913243626062322	0.0848102069317387	0.9737960339943342
87	0.03794144136203247	0.9916784702549575	0.08769645196024234	0.9723796033994334
88	0.03093263435127377	0.9925637393767706	0.08520938946124135	0.9745042492917847
89	0.03325245450263996	0.9929178470254958	0.088590365091191	0.9709631728045326
90	0.033085358421458065	0.9916784702549575	0.08094441294986703	0.976628895184136
91	0.031452716373054905	0.9929178470254958	0.08796974640832976	0.9709631728045326
92	0.031805786496772306	0.9918555240793201	0.08396796623268626	0.9737960339943342
93	0.03145965270001557	0.9918555240793201	0.09063904410262431	0.9716713881019831
94	0.035382891553994954	0.9909702549575071	0.08155582566737664	0.9759206798866855
95	0.034873572365504826	0.9904390934844193	0.0884509030907618	0.9716713881019831
96	0.028605097625140765	0.9932719546742209	0.08434256715317476	0.9737960339943342
97	0.03178150142297655	0.9927407932011332	0.08601387931632865	0.9730878186968839
98	0.03164411203608592	0.9922096317280453	0.09012956265030328	0.9716713881019831
99	0.027681296918192936	0.9938031161473088	0.08823217994272287	0.9723796033994334

The optimal condition:
	epoch: 90
	train_acc: 0.9916784702549575
	val_acc: 0.976628895184
	using time: 460.77876687
