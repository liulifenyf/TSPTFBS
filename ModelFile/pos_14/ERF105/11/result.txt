The number of train datas: 8884
The number of test datas: 2222
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6863119055536726	0.5552678975045601	0.6258257772340955	0.7817281733001277
1	0.5673072981786105	0.7557406574957332	0.4582599063481864	0.9068406835855609
2	0.37896390368626065	0.8813597479686711	0.2738746885616	0.9144914495741109
3	0.23169029199127034	0.9255965780642912	0.20333466843159537	0.9207920796371172
4	0.17738344013449417	0.9413552454117986	0.18108243223625084	0.9270927097001235
5	0.152407452725763	0.9496848267620075	0.1694639305291575	0.9306930697361271
6	0.14254261626921114	0.9494597028365601	0.14808508788648755	0.9414941498441378
7	0.1283155008043485	0.9579018460421452	0.1621039373033976	0.9342934295575325
8	0.11335562543590452	0.962291760387747	0.17907005710767046	0.9293429345080275
9	0.11202692947627617	0.961728951030355	0.15296303650530257	0.9383438345980365
10	0.10466348160123674	0.9653309321199544	0.14388552898898196	0.9423942396385405
11	0.096321834007237	0.9678072938506853	0.13387682455869326	0.9482448246970464
12	0.09410048106778371	0.9690454751186036	0.14742327891927276	0.9410441046250392
13	0.08985512066617414	0.971972084753903	0.14532538777021112	0.9441944195492433
14	0.08675833414268891	0.9726474561008555	0.12014080106568271	0.957695769898855
15	0.08010367211835012	0.9751238180462812	0.1295345216841981	0.9522952297375504
16	0.08109868675108055	0.9744484465651445	0.14667966620850734	0.9473447345807464
17	0.07786683981272885	0.9753489419180549	0.12390827728916566	0.9563456346707554
18	0.07778849926739864	0.9750112560298839	0.12644520494500117	0.9567956796752559
19	0.07450744974645394	0.9780504275742333	0.12634192429261631	0.9572457246797563
20	0.0728401950812525	0.9786132372805043	0.13454387366476625	0.954995499657254
21	0.07227398118675962	0.9788383610986042	0.133052700857232	0.954995499657254
22	0.06893575755071661	0.9789509228466331	0.12744814107860133	0.9567956796752559
23	0.0684246225722842	0.979626294461954	0.1299223107839897	0.9572457246797563
24	0.06642963336290056	0.9816524088248537	0.13574382190992443	0.954995499657254
25	0.06718985910138693	0.9816524088248537	0.12525127978339912	0.9590459046977582
26	0.06609761756951747	0.9807519135524538	0.12309808497636518	0.9594959497022586
27	0.06552615142496573	0.9807519133914328	0.12032225785037615	0.959945994706759
28	0.06550751793550941	0.9813147229366826	0.13386763762397663	0.9576957696842567
29	0.06296291906606341	0.9827780279153534	0.13472686946043338	0.9567956796752559
30	0.06469992840413519	0.9816524086638325	0.12328750531848866	0.959945994706759
31	0.05935090874187155	0.982665465925793	0.11451600590581619	0.9630963097382622
32	0.06304060884628516	0.9826654660063034	0.12382232723380401	0.9608460847157599
33	0.06070434516283211	0.9828905898244035	0.11491081748630526	0.9635463547427626
34	0.057425784654093454	0.9836785231072427	0.11870132238142239	0.9621962197292613
35	0.05907117060474961	0.9833408372995822	0.11941158642420674	0.9626462647337617
36	0.058253830187240736	0.9837910850968032	0.12809427039283658	0.959945994706759
37	0.056919926033598085	0.9849167041067924	0.11856757728072784	0.9630963097382622
38	0.05667999278433631	0.9840162088343927	0.12065107327769406	0.9626462647337617
39	0.053922041987296644	0.9851418279248925	0.11589672249129074	0.9626462647337617
40	0.056844549443956865	0.9844664564705926	0.1273768745550532	0.9608460847157599
41	0.05625158900924225	0.9853669517429924	0.12679171830107241	0.9608460847157599
42	0.056771784423708324	0.9837910849357822	0.11858514793599435	0.9630963097382622
43	0.0538079780448884	0.984916704187303	0.11424429043725093	0.963996399747263
44	0.05540244480555576	0.9863800089244422	0.12469074525388375	0.9617461747247609
45	0.0541719187337038	0.984916704187303	0.12152123768435846	0.9630963097382622
46	0.050334332712944005	0.9862674470153922	0.11725792532215024	0.9635463547427626
47	0.05492509096585808	0.9857046374701423	0.11698259048425433	0.9630963097382622
48	0.050483358557638365	0.987618189923992	0.11529718818600708	0.964896489756264
49	0.053197673978581723	0.9854795137325529	0.11665877440657624	0.9635463547427626
50	0.05343548734980572	0.984579018460153	0.11783330692070546	0.9635463547427626
51	0.0489973537472925	0.986830256560642	0.12623283369625934	0.9621962197292613
52	0.05162265084856657	0.9864925709140027	0.11681413453015307	0.964896489756264
53	0.050698858160795605	0.9871679423683025	0.11879898917221679	0.9630963097382622
54	0.052148271670740286	0.9858171993791923	0.11170186920881164	0.9662466247697653
55	0.05120995659540495	0.9864925708334922	0.1274652494290302	0.959945994706759
56	0.04814104310235613	0.9870553804592526	0.11627151658146581	0.9653465347607645
57	0.04888674194091333	0.9859297613687528	0.12892180312723323	0.9603960397112595
58	0.04822716763505577	0.9866051328230527	0.10851684619079936	0.9662466247697653
59	0.04688605572902528	0.9869428183891815	0.12170763300693217	0.9621962197292613
60	0.04722134661363863	0.9877307518330419	0.11919989016721852	0.9644464447517636
61	0.047287340254557664	0.9871679423683025	0.1177390538102383	0.964896489756264
62	0.04523749495212799	0.9870553803787421	0.12295470120507677	0.9626462647337617
63	0.0503614575596663	0.9870553802982315	0.11931766367757997	0.9630963097382622
64	0.04532680380376595	0.9880684374796813	0.12017663326164713	0.9626462647337617
65	0.04743120278777342	0.9876181900045025	0.12059736952292929	0.9621962197292613
66	0.048087005155435264	0.9870553804592526	0.11081030411255134	0.9657965797652649
67	0.04460212572208132	0.9880684375601918	0.12515095718587227	0.9621962197292613
68	0.045293789600994554	0.9887438090950023	0.12462427784981328	0.9621962197292613
69	0.04578726383773983	0.9872805041163314	0.11495249399883484	0.964896489756264
70	0.044784801049792836	0.9877307517525313	0.11925274622563732	0.9635463547427626
71	0.043980467391948025	0.9886312471859523	0.11773321460714542	0.9635463547427626
72	0.04392951787967287	0.9889689327520811	0.11523549966882951	0.964896489756264
73	0.043591889853428635	0.9886312471054417	0.1129748151812813	0.9653465347607645
74	0.044170044966374146	0.9893066185597416	0.1172591626416124	0.9635463547427626
75	0.04204261375155899	0.9886312471859523	0.11491673655345244	0.9657965797652649
76	0.04388341137896997	0.9886312471054417	0.1206162557756976	0.9617461747247609
77	0.0431045795573221	0.9886312471054417	0.10962218385857038	0.9666966697742658
78	0.04160774768804414	0.9889689329131022	0.11930938358447983	0.9626462647337617
79	0.04189739734368824	0.9885186852769023	0.12901437636649254	0.9603960397112595
80	0.04280338087486072	0.9887438089339812	0.11534868076470497	0.963996399747263
81	0.043533485958948966	0.9891940567312022	0.11818629522362772	0.9626462647337617
82	0.042526122643866016	0.9884061232873418	0.12387549990501412	0.9608460847157599
83	0.039893685244208305	0.9895317424583521	0.11646187752418213	0.9635463547427626
84	0.041775739366395795	0.9895317424583521	0.11672031065628509	0.9635463547427626
85	0.03889338212496174	0.989644304367402	0.12361215736673395	0.9617461747247609
86	0.04114510985770636	0.9890814948221521	0.12218239625478305	0.9621962197292613
87	0.03881198494036366	0.9903196758217019	0.11635097856260333	0.9635463547427626
88	0.039430141871655	0.989869428024481	0.12307492201991922	0.9612961297202604
89	0.03833407961009913	0.9893066185597416	0.11574085890026269	0.9630963097382622
90	0.03945801238529804	0.9902071138321414	0.12163562652538426	0.9617461747247609
91	0.03960845618098236	0.9897568661154309	0.11238426539098004	0.9666966697742658
92	0.039911069623364465	0.9900945519230915	0.11421066381432901	0.9635463547427626
93	0.04001805325697492	0.9897568662764521	0.11279897834069551	0.9657965797652649
94	0.03837647171500686	0.989981990094552	0.11268877550879113	0.9666966697742658
95	0.03816773405299429	0.989419180388281	0.12157630327917991	0.9621962197292613
96	0.03714427209800157	0.9903196758217019	0.11885216809024583	0.9621962197292613
97	0.03790601197326575	0.9902071138321414	0.11412337867997446	0.9657965797652649
98	0.039776329781385435	0.9900945519230915	0.11658355848851985	0.9621962197292613
99	0.035728627842260156	0.9907699234579018	0.11374570764299452	0.9662466247697653

The optimal condition:
	epoch: 94
	train_acc: 0.989981990094552
	val_acc: 0.966696669774
	using time: 558.957566023
