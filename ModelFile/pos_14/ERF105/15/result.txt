The number of train datas: 8884
The number of test datas: 2222
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6789948393342088	0.5678748312376469	0.6067044916290297	0.8177317736601636
1	0.531139489566888	0.7863574964889585	0.4084151070414096	0.9027902794570991
2	0.3365265985213653	0.8939666817017581	0.2545886998719508	0.9117911795471082
3	0.22290049065935993	0.9258217018823911	0.20904637406421717	0.9189918996191153
4	0.17912083207380122	0.9385411977660597	0.1940054382213486	0.9239423945613212
5	0.16044055598375767	0.9447321026832979	0.178537117198284	0.9275427545973248
6	0.150645485157059	0.9494597028365601	0.16468670545774575	0.9374437446963347
7	0.13867036844630973	0.9524988744077464	0.17358080238023393	0.9315931596378288
8	0.12248996357051492	0.9585772173085871	0.18719325918104068	0.9243924394585226
9	0.12271882878437819	0.9559882934004377	0.1627795146551892	0.9374437445890357
10	0.1140621261438879	0.961954074848455	0.15430089093000368	0.9410441046250392
11	0.10537170707669574	0.9633048174886862	0.14737738499251923	0.9441944196565424
12	0.1013324484866463	0.966794236937604	0.14928392433535398	0.9455445546700437
13	0.09942788430453957	0.9675821703009538	0.15253105203677253	0.9446444646610428
14	0.0958273907849135	0.9690454749307457	0.12728757584261316	0.9531953197465514
15	0.08710211195397194	0.9727600179562318	0.13497536450383044	0.9522952297375504
16	0.08608660420578162	0.9736605132017947	0.1575002081450796	0.9387938794952378
17	0.08260111225444365	0.9752363800090049	0.13200882497695413	0.9531953197465514
18	0.08114610384950119	0.9736605131212842	0.13549305214928037	0.9513951397285496
19	0.07776822808262787	0.9759117513022837	0.1320446836623815	0.9531953197465514
20	0.0755206710134391	0.9787257991090437	0.13580960098027003	0.9527452746347518
21	0.07585941577554152	0.9777127419275939	0.12850907652845905	0.9549954997645532
22	0.07279211353847756	0.9785006754788017	0.1280790059135692	0.9549954997645532
23	0.07197032910710865	0.9790634849167041	0.1266579192691725	0.9563456346707554
24	0.06560045441898582	0.9819900945520036	0.13550849719615157	0.9545454546527536
25	0.06714129487689097	0.9825529040972535	0.11565312675454399	0.960846084823059
26	0.06750734275536513	0.9800765420176434	0.11955669065593708	0.9585958598005567
27	0.06599956993743247	0.9809770372095327	0.11755648969557776	0.9594959498095577
28	0.06517733435596447	0.9812021610276327	0.12793514827261307	0.9590459046977582
29	0.06444087784732316	0.9826654660063034	0.13077968166861095	0.9576957696842567
30	0.06242835616968817	0.982215218289593	0.122545834499957	0.9590459046977582
31	0.06052400863141103	0.9812021611081432	0.11182164355884469	0.9626462648410609
32	0.05984546243221923	0.9827780279153534	0.1241129499958186	0.9594959497022586
33	0.06063254256697119	0.9836785231877533	0.11499534989937697	0.9630963097382622
34	0.057429982958976236	0.9844664564705926	0.11229731183428683	0.963996399747263
35	0.05984482169151306	0.9841287707434426	0.11657152036883936	0.9617461747247609
36	0.057777237225926065	0.984579018460153	0.12304088682553234	0.9612961297202604
37	0.056577688727975695	0.9852543898339424	0.11515306407111277	0.9621962197292613
38	0.056172345720905806	0.9850292660158424	0.11616915901980349	0.9626462647337617
39	0.052695808299841884	0.9852543899144529	0.11570293727246198	0.963996399747263
40	0.05703552604687745	0.9842413326524926	0.12649513930954126	0.9594959497022586
41	0.05400199397814698	0.9867176946515921	0.12216218561939995	0.9612961297202604
42	0.057416645737045365	0.9851418278443819	0.1181780601961456	0.9626462647337617
43	0.053275720360162614	0.9857046375506529	0.11235648873794411	0.9653465347607645
44	0.053375452948094274	0.9866051327425421	0.12313509985643609	0.9617461747247609
45	0.0528894623104971	0.9857046375506529	0.1181952300792498	0.9635463547427626
46	0.05015913568494128	0.987280504196842	0.11443455452577259	0.9653465347607645
47	0.051954621481820305	0.986830256560642	0.11642919590446887	0.9644464447517636
48	0.04999259658214854	0.9871679423683025	0.11046404119926354	0.9653465347607645
49	0.052386560625338384	0.9877307519135524	0.11249763054167977	0.9653465347607645
50	0.05158098288910285	0.9861548851063422	0.11480121865439372	0.9653465347607645
51	0.04694453497383306	0.9877307518330419	0.12089682917649633	0.9630963097382622
52	0.050444965043223856	0.9871679423683025	0.11633804644366624	0.964896489756264
53	0.04949287000711452	0.9871679423683025	0.11782836892267372	0.9635463547427626
54	0.05074488666145075	0.987167942287792	0.10856597915519797	0.9666966698815649
55	0.049710165513012654	0.9861548851063422	0.12208012679573332	0.9612961297202604
56	0.04659113619235025	0.9878433138226025	0.11439750715084274	0.9653465347607645
57	0.04799599137714066	0.9869428185502026	0.12397240958336664	0.9617461747247609
58	0.046341037903549646	0.9873930661864025	0.1080992405581968	0.9666966698815649
59	0.04445119624146466	0.9882935612977812	0.11395298826074836	0.9657965797652649
60	0.045609069888331986	0.9881809995497524	0.11555532937740336	0.964896489756264
61	0.044962208567104166	0.9881809995497524	0.11697460812265867	0.9644464447517636
62	0.04313777484425764	0.9884061232873418	0.11741259384608613	0.9644464447517636
63	0.047069567259449725	0.9885186851158811	0.11265431474609272	0.9653465347607645
64	0.04367418330580412	0.9887438089339812	0.11373197269549679	0.9653465347607645
65	0.04464341246240757	0.9889689329131022	0.1147678198710312	0.9644464447517636
66	0.044644373078243066	0.9880684376407024	0.1103646846154485	0.965796579872564
67	0.04300776297769156	0.9887438090144917	0.12279966289159094	0.963996399747263
68	0.04366947122158056	0.9889689329131022	0.11885202522485992	0.963996399747263
69	0.042839946202641935	0.9880684375601918	0.11396592874901451	0.9653465347607645
70	0.041375881256363725	0.9900945518425809	0.11791301300727387	0.9644464447517636
71	0.041192139016874456	0.9887438090950023	0.12337474509885889	0.963996399747263
72	0.0423638426549045	0.9893066184792311	0.11080886035299216	0.965796579872564
73	0.04300185519059678	0.9887438090144917	0.11154253081721191	0.964896489863563
74	0.04187455362078844	0.9893066185597416	0.11596658208569248	0.9644464447517636
75	0.040314238511347945	0.989981990094552	0.11363954620450922	0.9644464447517636
76	0.04012716127972998	0.9896443042868915	0.11988487467840381	0.9644464447517636
77	0.04133885888360149	0.9888563710040522	0.10868348451507295	0.9675967598905658
78	0.03819056423041317	0.9907699234579018	0.11927908538940465	0.9644464447517636
79	0.04020082004467266	0.9895317424583521	0.12557987097573645	0.9644464447517636
80	0.03902800513019652	0.9888563708430311	0.11119848251020877	0.9644464448590626
81	0.04035038686114649	0.9895317423778416	0.11724154902982561	0.963996399747263
82	0.039966513509688106	0.9900945519230915	0.12506940664805666	0.9644464447517636
83	0.037213292556996416	0.9906573615488519	0.11542827930405374	0.9653465347607645
84	0.038197279072466034	0.9907699234579018	0.11420449664485981	0.9662466248770645
85	0.037692118122127916	0.9902071139126519	0.12446213715133851	0.963996399747263
86	0.0377726952387259	0.990094552003602	0.11929023469706895	0.9644464447517636
87	0.03670421271102284	0.9903196758217019	0.1194815023472779	0.9644464447517636
88	0.03625437946053359	0.9908824853669518	0.12597274948598886	0.9644464447517636
89	0.03627176114761819	0.989981990094552	0.11621797785270224	0.9657965797652649
90	0.03666222864700727	0.9906573613878308	0.12157167254550623	0.963996399747263
91	0.03749117929989934	0.989869428024481	0.11096833871960854	0.9675967598905658
92	0.03654206468346741	0.9906573614683413	0.11277594084035802	0.9684968498995666
93	0.03832533759077972	0.9895317424583521	0.10970660272573265	0.9671467148860653
94	0.03629906668517703	0.9903196758217019	0.11266644745662768	0.9671467148860653
95	0.03451503166498659	0.9907699232968807	0.11949384332534754	0.963996399747263
96	0.0351745694144413	0.990432237730752	0.1143468790172082	0.9662466248770645
97	0.034986464015700054	0.9908824852864413	0.11491089101300703	0.9662466248770645
98	0.03712014854625236	0.9908824853669518	0.11446041084698574	0.9653465347607645
99	0.03247307029056695	0.9915578568212516	0.11490790856437143	0.9662466247697653

The optimal condition:
	epoch: 92
	train_acc: 0.9906573614683413
	val_acc: 0.9684968499
	using time: 647.094779015
