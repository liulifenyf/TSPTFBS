The number of train datas: 3092
The number of test datas: 774
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7087433088334689	0.48609314363493183	0.6976216706502654	0.4832041344439337
1	0.6986516962384499	0.5161707633371341	0.6931040045210866	0.5051679587333393
2	0.6979303509575275	0.5126131953428201	0.6891777979003059	0.5348837210072411
3	0.690900655181411	0.5365459248905503	0.6856420526824872	0.5503875969762334
4	0.6878702752340349	0.5423673997412678	0.6831330462943676	0.5710594316015564
5	0.6847138976218012	0.5514230270126659	0.6795320216691463	0.58656330749354
6	0.6809678559624054	0.5517464424320828	0.6763927864165885	0.6059431524547804
7	0.6777944588722881	0.5721216039854989	0.6717681122380633	0.6214470284237726
8	0.6718435897401511	0.5866752911508469	0.6669650988061299	0.6395348837209303
9	0.6703563303256559	0.5886157825107253	0.6607422568385299	0.6576227390180879
10	0.6636528689679322	0.6112548513060863	0.6532057167947755	0.6821705426356589
11	0.653248953557107	0.6374514876331118	0.6444698153232111	0.7028423774149991
12	0.6443176854011466	0.643596377826138	0.6337648791860241	0.7157622740558259
13	0.6348305154124331	0.6620310480196757	0.6220677322503516	0.7325581393808666
14	0.6214726298160725	0.6791720569210866	0.6072682190003013	0.7571059431524548
15	0.6108609268304447	0.6921086674519992	0.5908229823876413	0.7764857881136951
16	0.5977508778097096	0.7040750322644184	0.5722322308431916	0.7945736434108527
17	0.577317030278708	0.732858991098589	0.5538901343980193	0.8062015503875969
18	0.5571815132092381	0.7529107375410211	0.5277864340817897	0.813953488372093
19	0.5446990624282215	0.7525873221216042	0.5068239314765585	0.8320413436692506
20	0.511394061446961	0.7913971540227744	0.478828797429723	0.838501291989664
21	0.49518450045955753	0.7865459248134421	0.4540863392118952	0.851421188630491
22	0.4752845549799338	0.7981888743606607	0.4326097318368365	0.8669250645994832
23	0.4615296746133062	0.8023932728082674	0.41215118658018973	0.872093023255814
24	0.44242586872093426	0.8124191460294835	0.39325182320843677	0.8837209302325582
25	0.4144455970952921	0.8405562741790367	0.369840761333781	0.8811369509043928
26	0.39630684965949164	0.8382923675539576	0.35348892754824585	0.8824289405684754
27	0.3727768817663501	0.8599611900139595	0.33497572380288937	0.8875968992248062
28	0.36521114445596276	0.8651358344113842	0.3285294643360207	0.8927648578811369
29	0.3527928357907748	0.8648124190690755	0.31838105873082034	0.8940568475452196
30	0.3303815248635577	0.8716041395611781	0.29530976612592547	0.8927648578811369
31	0.32060375913765576	0.8793661060030987	0.2870673738824305	0.8953488372093024
32	0.3099361752939409	0.8809831824833178	0.2752475708684564	0.896640826873385
33	0.30206579374773534	0.890362225251241	0.26782796485710514	0.900516795865633
34	0.2900485961973899	0.8965071150587262	0.2646357433855996	0.9108527131782945
35	0.2812387750882843	0.9013583439596258	0.25342798631551655	0.9069767441860465
36	0.2720364333741261	0.902975420516953	0.24907828434262164	0.9108527131782945
37	0.26958351941805764	0.9117076325231506	0.24206461199109253	0.9082687338501292
38	0.25602056988229416	0.9120310478654593	0.23584046590235808	0.9082687338501292
39	0.2466328169904736	0.9159120309707572	0.22927401480517645	0.9198966408268734
40	0.2445584764802903	0.9175291072967598	0.2254100693750751	0.9211886304909561
41	0.23694219911545708	0.9236739972584614	0.22184757724673865	0.91343669250646
42	0.23620610538614675	0.9217335057443665	0.21674248789863068	0.9211886304909561
43	0.22837482092065922	0.9210866751368573	0.2162929020379249	0.9147286821705426
44	0.21961094253969995	0.924644243054063	0.21307607675669113	0.9263565891472868
45	0.21878001417718915	0.9259379041919733	0.2061072765664229	0.9263565891472868
46	0.2161643161579369	0.9314359637003821	0.2176169753074646	0.9263565891472868
47	0.21220010102643386	0.9336998704796775	0.2020235003889069	0.9250645994832042
48	0.20965349290611518	0.9336998705567857	0.19915407077825656	0.9250645994832042
49	0.19441337465160413	0.9333764552915852	0.1986036638245564	0.9289405684754521
50	0.20170351524595148	0.9336998706338939	0.19548410030914523	0.9276485788113695
51	0.19231029197014626	0.9404915912031048	0.19166421282853574	0.9302325581395349
52	0.19238937383018828	0.9349935315404796	0.19187683158720187	0.9341085271317829
53	0.19628496948065763	0.9346701163523873	0.1881630439070614	0.9302325581395349
54	0.18549233957411865	0.9459896506344053	0.1898290299995771	0.9289405684754521
55	0.1864179800352489	0.940168175860796	0.18506838933827033	0.9302325581395349
56	0.17344342777445276	0.9424320827171997	0.18305537536817312	0.9315245478036176
57	0.17980695584304582	0.9372574384739915	0.18211061193653472	0.9328165374677002
58	0.17262390406289044	0.9414618368444899	0.18069807103129937	0.9341085271317829
59	0.17599241682274067	0.9404915911259966	0.18459944025606148	0.9341085271317829
60	0.16851264226791313	0.9427554979824002	0.1784933254758055	0.9328165374677002
61	0.16495044095704348	0.9518111253309065	0.1775327979055178	0.9366925064599483
62	0.1615622736426868	0.9495472185516111	0.17635683833744176	0.9366925064599483
63	0.1622838861806581	0.9472833116952074	0.17646998459670588	0.9366925064599483
64	0.16414667039454214	0.9501940490049039	0.17749297525493057	0.9405684754521964
65	0.16302728776327235	0.9489003879441018	0.17603015783182718	0.9392764857881137
66	0.1568911764843035	0.953104786545925	0.1740865731366383	0.9418604651162791
67	0.15587217303867637	0.9508408796124131	0.17518166996519388	0.9392764857881137
68	0.15311081740248558	0.9466364810876982	0.17375251141590972	0.9354005167958657
69	0.1518526581558188	0.9521345406732152	0.17407292991068013	0.9392764857881137
70	0.14942573337667509	0.9569857697283312	0.1705435424350029	0.9418604651162791
71	0.14653151263067207	0.9518111254851229	0.16969046723434475	0.9392764857881137
72	0.1475178621237059	0.9566623544631306	0.16895194583661488	0.9431524547803618
73	0.1446411919817425	0.9589262612424261	0.1712415367846187	0.937984496124031
74	0.14343026766184847	0.9566623543860224	0.1684828194517652	0.9431524547803618
75	0.13916629288745574	0.9569857697283312	0.17099900806481524	0.9392764857881137
76	0.14065774087764005	0.9569857695741147	0.16758375313585427	0.9470284237726099
77	0.14098937283203797	0.9563389391208219	0.17276574382967574	0.9431524547803618
78	0.13963432480878693	0.9527813712036163	0.168688598269409	0.9418604651162791
79	0.13164753787807473	0.958279430712025	0.1665232929398693	0.9470284237726099
80	0.13322093799459672	0.9579560154468245	0.17036255342688517	0.9444444444444444
81	0.12619620073890317	0.9592496765076266	0.16572193190147402	0.9483204134366925
82	0.13370120920539674	0.9550452780600198	0.16621516378312456	0.9418604651162791
83	0.13198729580386337	0.9582794307891332	0.166983041873813	0.9444444444444444
84	0.12510499419381826	0.9657179818887451	0.16874796591545108	0.9457364341085271
85	0.12706689827654988	0.9595730917728271	0.1652737902405188	0.9483204134366925
86	0.12587330414206369	0.9605433375684287	0.16493805180224339	0.9470284237726099
87	0.12745351558322277	0.9595730917728271	0.1681213912190701	0.9405684754521964
88	0.11917815645638598	0.9637774902204338	0.17236227359747855	0.9444444444444444
89	0.12165811287304254	0.963130659767141	0.1640670542780897	0.9470284237726099
90	0.12152143853100891	0.9634540749552333	0.1659946072827399	0.9457364341085271
91	0.12220397393037245	0.9644243207508348	0.166618040211749	0.9431524547803618
92	0.11784163448974047	0.9608667528336292	0.1642558904754561	0.9496124031007752
93	0.11085962649690226	0.9637774902204338	0.17277913692212382	0.9431524547803618
94	0.11414938447527095	0.964424320827943	0.16430310332228354	0.9457364341085271
95	0.12090183983413554	0.9608667528336292	0.1648189877797621	0.9496124031007752
96	0.1152203651711364	0.9663648122649298	0.16607887683874262	0.9431524547803618
97	0.11088468237053531	0.9676584734799483	0.16495580042806246	0.9483204134366925
98	0.10806985350776305	0.9621604138944313	0.16451616747935305	0.9509043927648578
99	0.10825743120438377	0.9653945666235446	0.16455489330629045	0.9457364341085271

The optimal condition:
	epoch: 98
	train_acc: 0.9621604138944313
	val_acc: 0.950904392765
	using time: 224.66139698
