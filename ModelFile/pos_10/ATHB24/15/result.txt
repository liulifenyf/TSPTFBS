The number of train datas: 3092
The number of test datas: 774
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7055296995044525	0.5077619664419206	0.6961557885165054	0.4999999998459828
1	0.6976378017995521	0.5145536869340233	0.6902849606457299	0.5361757104402981
2	0.6941093283513847	0.5181112547741208	0.6852188176578946	0.5555555554015383
3	0.6876170918981594	0.5433376455368694	0.6801207909596366	0.5891472869757226
4	0.6829373498783383	0.5617723156918529	0.67538581646074	0.6149870802573764
5	0.6771388209652623	0.57503234152652	0.6706593626537373	0.6356589148826993
6	0.6748314088868292	0.5756791719027047	0.6656148601564018	0.6666666668206839
7	0.6667938693528959	0.5996119016817594	0.6589957276980082	0.6873385014460068
8	0.662740925767906	0.6086675289531575	0.6524421905362329	0.6976744187586683
9	0.6604142595386135	0.6067270373619543	0.6446379095084908	0.7144702843917433
10	0.6516555765930462	0.6364812418375102	0.6353810888544226	0.7260981913684874
11	0.6424356754507778	0.6520051746442432	0.6250067984718993	0.7558139536423892
12	0.629334796986327	0.6701164294954722	0.6125937841967403	0.7803617572599604
13	0.6181877603968858	0.6891979301423027	0.5990595803704373	0.7855297157622739
14	0.6006964916245287	0.6976067271146243	0.581234764529137	0.7971576225850009
15	0.5874643375926	0.7183053040874575	0.5629422706997056	0.8139534882180759
16	0.5772627431701719	0.7289780077619664	0.5426907345306041	0.8281653745229854
17	0.5501012739666375	0.7519404916683113	0.5243881901567297	0.8152454780361758
18	0.5366743156857509	0.7609961190168176	0.4984885923160139	0.834625322997416
19	0.5216295012064461	0.7642302716688227	0.4806858704687705	0.8423772609819121
20	0.49076086560319654	0.7910737386033575	0.45456322750379874	0.8488372093023255
21	0.4725278491036241	0.8069210865210746	0.4329753856942327	0.8552971576227391
22	0.458817396018977	0.8117723157304071	0.416708286649497	0.8591731266149871
23	0.4476780842840286	0.8108020697034809	0.3994212710426143	0.8656330749354005
24	0.43425132532785965	0.8120957310727158	0.38644128221566054	0.8617571059431525
25	0.41207883637133425	0.8305304008807124	0.3656885698245169	0.875968992248062
26	0.38908859512938565	0.842820181266765	0.351795458092862	0.8772609819121447
27	0.3703067897208141	0.849611901527543	0.33606385541670697	0.8824289405684754
28	0.368502134840362	0.8589909442954662	0.3349999008791699	0.8824289405684754
29	0.35521894797470716	0.8564036220967538	0.32335395117600757	0.8824289405684754
30	0.33504770593994804	0.8696636481241915	0.3018851503922342	0.8901808785529716
31	0.32540152789627286	0.8806597670639008	0.29843541188526523	0.900516795865633
32	0.3184796490382408	0.8780724450965132	0.2853162993679367	0.8979328165374677
33	0.3139823676697804	0.8819534283560275	0.27828227410944856	0.9031007751937985
34	0.29641174845985424	0.8890685638820061	0.27732109299617835	0.9095607235142119
35	0.2871016604780071	0.8923027167653359	0.26171235782539504	0.9056847545219638
36	0.2826289411581195	0.8968305302468185	0.25866731148434546	0.91343669250646
37	0.2790808579745916	0.9062095730918499	0.2496635567502766	0.9121447028423773
38	0.2640286088375348	0.9055627424843407	0.24549890427010312	0.9160206718346253
39	0.2568746470348647	0.9133247088491531	0.2419786768212183	0.9186046511627907
40	0.2572345210463387	0.9065329884341586	0.23923363721416901	0.9224806201550387
41	0.2468228530027888	0.9149417850980475	0.2298945082828056	0.917312661498708
42	0.24712646287055096	0.915912030893649	0.22612844642434626	0.9211886304909561
43	0.2421472542575846	0.9130012935068443	0.22292623693936864	0.9224806201550387
44	0.23006969485986126	0.9149417851751557	0.2206745508105256	0.9263565891472868
45	0.22741141845923962	0.919469598887963	0.21368858659067202	0.9276485788113695
46	0.2288429065864114	0.9197930140760553	0.2332134362820353	0.9160206718346253
47	0.22370201555522878	0.9256144888496646	0.21016431875161115	0.9276485788113695
48	0.22029552334030417	0.9262613194571738	0.20566741779485107	0.9302325581395349
49	0.20343025861474243	0.9294954720320707	0.20905243603450074	0.9315245478036176
50	0.20659565539093253	0.9314359637003821	0.20179737925298455	0.9302325581395349
51	0.200508922068607	0.9340232858219862	0.2012675662719926	0.9328165374677002
52	0.19977983689709128	0.9333764555229098	0.19687714058068373	0.9328165374677002
53	0.20206130832857797	0.9343467010871868	0.2000969130478472	0.9302325581395349
54	0.19297730481254483	0.9379042690815006	0.19960537315069551	0.9302325581395349
55	0.1964972907578498	0.934993531694696	0.19110163135661018	0.9315245478036176
56	0.181860637984794	0.939521345330395	0.1893328995821704	0.9341085271317829
57	0.18506569449065727	0.9349935315404796	0.1880362615836375	0.9341085271317829
58	0.17845572723993816	0.9463130658224976	0.1889115990228585	0.9341085271317829
59	0.18445642104548285	0.9404915911259966	0.19112520663005128	0.9315245478036176
60	0.17674053995297767	0.9391979299880863	0.1854866371906389	0.937984496124031
61	0.17207125022062816	0.9446959895736033	0.18450718925596823	0.9366925064599483
62	0.16950256708060013	0.9430789132476007	0.18331577221668044	0.9354005167958657
63	0.17153159749692964	0.9456662352920967	0.18344694109349596	0.9354005167958657
64	0.16946873435073498	0.9430789134018172	0.18221602351127977	0.9366925064599483
65	0.16354761919413932	0.9476067271917326	0.18447874997590863	0.9341085271317829
66	0.16470712818504152	0.94890038802121	0.17990419691192702	0.9418604651162791
67	0.159009246630317	0.94890038802121	0.18388795332853183	0.9366925064599483
68	0.15606743667906037	0.9495472184745029	0.1792096913592452	0.9444444444444444
69	0.15795913058180086	0.9495472186287193	0.17925916799856711	0.937984496124031
70	0.15460390887701497	0.9508408796895214	0.1772535142876227	0.9366925064599483
71	0.15212031913846538	0.952457956015524	0.1753345253162606	0.9418604651162791
72	0.15157158054980086	0.9511642949547219	0.17510095508215656	0.9431524547803618
73	0.1485874380863345	0.9498706338168116	0.17592884095756275	0.9444444444444444
74	0.14278747097024017	0.9540750322644184	0.17626866936029081	0.9431524547803618
75	0.14763555937430992	0.9501940491591203	0.17826050327421775	0.9431524547803618
76	0.1425767901798115	0.9531047867001414	0.17204605466481634	0.9470284237726099
77	0.14721639251955732	0.9534282017340173	0.18225324350272037	0.9418604651162791
78	0.13959910122034314	0.9560155238556214	0.1706559738331987	0.9444444444444444
79	0.1351345736837017	0.9566623543860224	0.17123540687237598	0.9470284237726099
80	0.13425258403453605	0.9550452780600198	0.17863916901231428	0.9444444444444444
81	0.12974637793075838	0.958279430712025	0.16995858922793267	0.9470284237726099
82	0.13380775881152876	0.9556921086675291	0.16927128423785054	0.9483204134366925
83	0.13532966295833113	0.9534282018111255	0.17717741161238315	0.9444444444444444
84	0.129217848904614	0.9611901681759379	0.17552453704005064	0.9457364341085271
85	0.13172858240225027	0.9586028459772256	0.16866685555963862	0.9470284237726099
86	0.13092233090243396	0.9605433375684287	0.1688205414386683	0.9483204134366925
87	0.13012853970830685	0.9589262613195343	0.16980992607984124	0.9496124031007752
88	0.11844487688751147	0.9634540749552333	0.17996096839160883	0.9444444444444444
89	0.12493501707217518	0.9573091849935317	0.16875587900479636	0.9483204134366925
90	0.12609029327065022	0.9598965071151359	0.16987111039209427	0.9457364341085271
91	0.1203811461103533	0.9637774902204338	0.1709281142213856	0.9457364341085271
92	0.11836018302462234	0.964424320827943	0.16799170614366998	0.9444444444444444
93	0.11444103906719065	0.9650711513583441	0.17630022709337315	0.9444444444444444
94	0.11270704500155491	0.964424320827943	0.16757060818431913	0.9470284237726099
95	0.11973207200097853	0.9592496765076266	0.1689637249542607	0.9418604651162791
96	0.11611499395438339	0.9621604138944313	0.17490740355287104	0.9431524547803618
97	0.11258182604526101	0.9647477360931436	0.16742869233592228	0.9483204134366925
98	0.10867379050109087	0.9647477360931436	0.1704930836281881	0.9470284237726099
99	0.11140896005972854	0.9673350582147477	0.16830588436326932	0.9483204134366925

The optimal condition:
	epoch: 87
	train_acc: 0.9589262613195343
	val_acc: 0.949612403101
	using time: 233.167123795
