The number of train datas: 2850
The number of test datas: 714
epoch	train_loss	train_acc	val_loss	val_acc
0	0.718956261224914	0.5056140350040637	0.6902725402714491	0.5406162460812
1	0.6964296049402471	0.5178947368002774	0.6842863330987989	0.5490196071752981
2	0.6857304795583089	0.5512280701963526	0.6793868222824332	0.5826330517186504
3	0.6853585832160816	0.5456140349622358	0.6734393833398151	0.6106442580370008
4	0.6760260285410965	0.585263157852909	0.6668000930831546	0.642857143524982
5	0.6703841537341737	0.5870175438178213	0.6594158444417959	0.6680672258889976
6	0.6633451272730242	0.6112280700917829	0.6495748380986917	0.7058823519394177
7	0.6521451370757922	0.6371929826652795	0.638303940703555	0.7282913171944498
8	0.6412694984569884	0.6389473686720195	0.6239589531214631	0.7464986021111325
9	0.6282415215592635	0.6670175440269605	0.6061071245944133	0.7787114855955962
10	0.6101436053660878	0.7021052629487556	0.5851372799285653	0.8039215679596118
11	0.5813788563326785	0.7242105261484781	0.5589050386800152	0.8235294139351832
12	0.5614517563686037	0.7357894735168993	0.5300654122809402	0.8361344567867888
13	0.5357847278996518	0.7533333335006446	0.5043532223928542	0.8207282901478081
14	0.5111384406006128	0.7859649125316687	0.4739407200773223	0.840336134119862
15	0.47017147344455384	0.7996491226815341	0.4443600279610364	0.8585434187026251
16	0.4540435535656778	0.8108771931497675	0.4209375424044473	0.8599439780919158
17	0.4251909885071872	0.8242105264412729	0.40098023656703513	0.8585434178678262
18	0.40413838466008506	0.8357894737678662	0.38635561796797424	0.8501400556884894
19	0.3910457876899786	0.8463157895573399	0.365293867447797	0.8683473394364536
20	0.3575305453936259	0.8635087716788576	0.3577629221754582	0.85994397475272
21	0.3483712985431939	0.8621052631997226	0.33959903353068677	0.8725490184391246
22	0.3449555047562248	0.862105263325206	0.3317781935552923	0.8753501372177059
23	0.31973076780637105	0.8754385965748838	0.31266159353469936	0.8739495794980132
24	0.31508432927884555	0.8768421049285353	0.3107612517033638	0.8893557448013156
25	0.3001591854346426	0.889122806766577	0.2940814798118688	0.8907563050254053
26	0.2848446348257232	0.8905263155385068	0.2838274428323537	0.899159666369943
27	0.2778037308391772	0.8919298243104365	0.2710652065043356	0.901960783979806
28	0.27733030994733177	0.8954385965330559	0.2645982180823799	0.9089635879385705
29	0.26046871927746557	0.9028070172510649	0.2585017811350462	0.9089635879385705
30	0.24465454508338058	0.9091228067247491	0.24287213159709417	0.918767509507198
31	0.24293594950123837	0.9115789471174541	0.2365156064848272	0.9215686299553772
32	0.23906009814195467	0.9126315786545737	0.22688055748031252	0.9187675041644847
33	0.2341210506568875	0.9150877193819013	0.2197830771782151	0.9243697504035565
34	0.22497985335818507	0.9157894733914158	0.21185954595480314	0.9243697504035565
35	0.21722376489848422	0.9200000000418278	0.21036719532907844	0.9327731109132954
36	0.2072447725555353	0.9217543856721175	0.1977754215649864	0.9257703106276461
37	0.2055410132910076	0.9235087719716524	0.1918416373035153	0.9313725506892058
38	0.1967773219577053	0.929824561110714	0.1886703884568201	0.9369747915855643
39	0.1960259063463462	0.9280701754385965	0.1805621158091628	0.9369747915855643
40	0.18825930819176792	0.934385964619486	0.18164628428988763	0.9397759120337436
41	0.1888306519023159	0.934385964619486	0.17189862401712508	0.9397759120337436
42	0.191448736049627	0.931929824226781	0.17056865174145924	0.9439775927060124
43	0.18090667881463704	0.9333333333751611	0.1679840758234179	0.9425770324819228
44	0.17013616290008812	0.9414035084373072	0.1606808922120503	0.9383753518096539
45	0.17295953435855999	0.9347368417706405	0.157102370253798	0.9397759120337436
46	0.1722302672110106	0.9361403509190208	0.15874928626276197	0.9467787131541917
47	0.16690063232392596	0.9403508772348103	0.15343507834258868	0.9453781529301021
48	0.16039137039268225	0.9435087716370298	0.15315481797069394	0.9467787131541917
49	0.15718251929471366	0.9452631575601143	0.14599628235195197	0.9453781529301021
50	0.1594218956692177	0.9421052628651	0.14319268954234296	0.9439775927060124
51	0.1491290262393784	0.945964911987907	0.14267512300268276	0.9425770324819228
52	0.15275556370354534	0.9431578947368421	0.14252396314000548	0.9453781529301021
53	0.14518556042721398	0.9491228066829213	0.13830829290699223	0.9453781529301021
54	0.15036725124246195	0.9445614035505997	0.13822691434738682	0.9481792733782813
55	0.14107459906161876	0.9508771929824561	0.13261556314403602	0.9467787131541917
56	0.13260436705329962	0.950526315496679	0.13128985679533636	0.9481792733782813
57	0.14040658847281806	0.9466666663320441	0.13096708136529817	0.9523809540505502
58	0.136109752257665	0.950877193024284	0.12758888767546966	0.9495798327675721
59	0.13164383314680636	0.952280701754386	0.12675674457927377	0.949579833602371
60	0.130684092293183	0.9550877192982457	0.12474461327664324	0.9509803929916617
61	0.12693377813749146	0.9501754386383191	0.12260804817873557	0.9453781529301021
62	0.13082881242559669	0.9554385961566055	0.12246798402538486	0.9523809532157513
63	0.1270826141823802	0.9540350877192982	0.12417821429607247	0.9509803929916617
64	0.12159379934009752	0.9564912281120033	0.1190271063470373	0.953781513439841
65	0.1179907865064186	0.958596491269898	0.11836236026607641	0.9537815142746399
66	0.11533190742396472	0.9592982456558629	0.11704376920097682	0.9565826338880202
67	0.11194120348022696	0.9631578944022195	0.1156714306909497	0.9537815142746399
68	0.10947576380612557	0.960701754385965	0.1147428515161119	0.9537815142746399
69	0.11096222857634226	0.9635087719716524	0.11352644518476908	0.9537815142746399
70	0.10476713838284475	0.9628070172092371	0.11223393071348928	0.9565826347228192
71	0.11118347973154302	0.9596491225142229	0.11155359522134316	0.9579831941121099
72	0.11012613038221995	0.9614035084373073	0.11090576657060147	0.9565826338880202
73	0.10246577981271242	0.9666666666666667	0.11733115925675347	0.953781513439841
74	0.1039184298013386	0.9645614031741494	0.10972224182191015	0.9593837543361995
75	0.10508858673143805	0.9656140350877193	0.10907762370356659	0.9565826338880202
76	0.10048567512579132	0.9645614035924276	0.10849100186460826	0.9579831941121099
77	0.09527924976850811	0.9673684211362872	0.106580503431021	0.9593837543361995
78	0.09407146106425085	0.9680701754385965	0.10802176335946519	0.9565826355576181
79	0.09331800753610175	0.9670175435250266	0.10562038194148146	0.9593837543361995
80	0.09482360494241379	0.9659649119460791	0.10851041104446273	0.9593837560057974
81	0.0975725491828563	0.9680701754385965	0.11033272735920607	0.9607843145602891
82	0.090039597945778	0.9715789473684211	0.10428526173202264	0.9635854350084684
83	0.09375706649140307	0.968070175103974	0.10363741392264512	0.9635854350084684
84	0.0925188656229722	0.9680701754804243	0.11060435831004164	0.9607843145602891
85	0.0898019002717838	0.9673684207598369	0.10227057141583173	0.9607843145602891
86	0.08899418207375627	0.9708771929824561	0.10175290864472296	0.9607843145602891
87	0.08658336848804825	0.971228069840816	0.10164239455838832	0.9635854350084684
88	0.08240645202628354	0.9712280701754386	0.10115287179539517	0.9593837543361995
89	0.08289068870377123	0.9747368417706406	0.10093358952124246	0.9607843145602891
90	0.08367343577245871	0.9736842105263158	0.10081029963009164	0.9635854350084684
91	0.0842261482017082	0.9726315789891963	0.10105067036565946	0.9607843153950881
92	0.07666176701193315	0.9743859649122807	0.10003734402963761	0.964985995232558
93	0.07812070716891373	0.9733333333751611	0.09896985339183434	0.9635854350084684
94	0.08004257042549158	0.9733333333333334	0.09993456516947065	0.960784316229887
95	0.0727999161314546	0.976140350877193	0.09991940322752092	0.964985995232558
96	0.0761629000410699	0.9743859649541086	0.10265936687880871	0.9621848747843788
97	0.07519997113629391	0.9754385964912281	0.09850052833891049	0.964985995232558
98	0.07814645727344773	0.9733333333333334	0.0979263988279161	0.9635854350084684
99	0.07804814813691273	0.9743859649122807	0.09758222040508975	0.964985995232558

The optimal condition:
	epoch: 99
	train_acc: 0.9743859649122807
	val_acc: 0.964985995233
	using time: 117.502475977
