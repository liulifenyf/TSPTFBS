The number of train datas: 13440
The number of test datas: 3360
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6991442663328988	0.5024553571428572	0.6901262095996312	0.537797619047619
1	0.6919293835049584	0.528720238095238	0.6873465498288472	0.5574404761904762
2	0.6906405829247975	0.5344494047619047	0.6841998281933013	0.5857142857142857
3	0.6871384047326587	0.546577380952381	0.6810771743456523	0.6026785714285714
4	0.6830853422482809	0.5588541666666667	0.6763047820045834	0.6235119047619048
5	0.6796175758043925	0.5684523809523809	0.6685349941253662	0.6452380952380953
6	0.6697931624594189	0.5892857142857143	0.6559156361080352	0.6741071428571429
7	0.6594874961035592	0.614657738095238	0.6386071261905488	0.7071428571428572
8	0.6418539194833665	0.6451636904761905	0.6128268537067232	0.7291666666666666
9	0.6147950887680054	0.6744791666666666	0.5733388650984991	0.7642857142857142
10	0.5773835948535374	0.7168898809523809	0.5239095449447632	0.787797619047619
11	0.5342366573356446	0.7508184523809524	0.4691654091789609	0.8211309523809524
12	0.4877688092844827	0.7821428571428571	0.4156716749781654	0.8449404761904762
13	0.4411110940433684	0.8080357142857143	0.3736517412321908	0.8577380952380952
14	0.408364143541881	0.8274553571428571	0.3335495437894549	0.8776785714285714
15	0.3739505620229812	0.8526785714285714	0.3043453449294681	0.8928571428571429
16	0.34187799834069754	0.8667410714285714	0.27850181659062706	0.9029761904761905
17	0.3229831895657948	0.8761160714285714	0.26149752026512507	0.9080357142857143
18	0.3011145259652819	0.8881696428571428	0.24790867084548587	0.9148809523809524
19	0.2825849213770458	0.8951636904761905	0.23399982225327265	0.9151785714285714
20	0.2751867958477565	0.8965773809523809	0.22644244886579967	0.9181547619047619
21	0.25993787334078833	0.9049107142857142	0.2222163370677403	0.9205357142857142
22	0.26150205036004387	0.9055059523809523	0.21587667635508945	0.9199404761904761
23	0.24719034475939614	0.9104910714285714	0.21207942579473768	0.9229166666666667
24	0.23788044083686102	0.9119047619047619	0.20670824476650784	0.9202380952380952
25	0.24055838556516737	0.9123511904761905	0.2076753903002966	0.9255952380952381
26	0.23024268803142367	0.91875	0.2030659896986825	0.9252976190476191
27	0.2295353828441529	0.9166666666666666	0.20113401696795508	0.9270833333333334
28	0.21971614289851416	0.9209077380952381	0.19670743630045937	0.9255952380952381
29	0.21937237758012046	0.920610119047619	0.19718485375245412	0.9264880952380953
30	0.21593396365642548	0.9211309523809523	0.19506490670499346	0.9261904761904762
31	0.20959246768837883	0.9244791666666666	0.1947575929619017	0.925
32	0.20781050203811555	0.9238839285714285	0.193906231153579	0.9276785714285715
33	0.20267468591531118	0.9269345238095238	0.19302827971322195	0.9279761904761905
34	0.2006821156257675	0.9273809523809524	0.19295006905283246	0.9264880952380953
35	0.19897475824469613	0.9270089285714286	0.19154729999247053	0.9282738095238096
36	0.19434056040786563	0.929985119047619	0.19091850859778267	0.9300595238095238
37	0.19373252476964678	0.9291666666666667	0.19085268974304198	0.9252976190476191
38	0.1886172442209153	0.9299107142857143	0.19788260005769276	0.9267857142857143
39	0.19028037084000451	0.93125	0.19046440997294017	0.9282738095238096
40	0.18553031846171333	0.9321428571428572	0.19568390690145038	0.9261904761904762
41	0.18334977598417374	0.9327380952380953	0.1869226552191235	0.9273809523809524
42	0.18126878298464275	0.9308779761904762	0.18627178612209502	0.9276785714285715
43	0.1801745307587442	0.9336309523809524	0.18588129991576785	0.9276785714285715
44	0.1786420131013507	0.9354166666666667	0.18568984298478988	0.9273809523809524
45	0.1755526970539774	0.9369791666666667	0.18540686482474916	0.9264880952380953
46	0.17208549025512876	0.9375	0.18706703874326888	0.9294642857142857
47	0.17485888781292097	0.9368303571428571	0.18500173120271593	0.9255952380952381
48	0.1698416116691771	0.9386160714285714	0.18765503664811453	0.9273809523809524
49	0.16974794822079795	0.9379464285714286	0.1865193450734729	0.9267857142857143
50	0.1654438520471255	0.9390625	0.18712791914031618	0.9270833333333334
51	0.1610916780573981	0.9415922619047619	0.18373391500541142	0.9267857142857143
52	0.1654783552601224	0.9404761904761905	0.19445374061663945	0.925
53	0.15990722200700214	0.9418154761904762	0.18316050682749066	0.9264880952380953
54	0.15761492727767853	0.9421130952380953	0.18330731888612112	0.9255952380952381
55	0.15716298712151391	0.9438244047619048	0.18449781196457998	0.9270833333333334
56	0.1581229091400192	0.9415922619047619	0.18248388171195984	0.924404761904762
57	0.15293294276509967	0.9436755952380952	0.2037557805577914	0.9217261904761904
58	0.1545878312417439	0.9447916666666667	0.18446942823273796	0.9258928571428572
59	0.15302519195136569	0.9445684523809523	0.1845043128445035	0.9252976190476191
60	0.14894332417419978	0.9469494047619048	0.1842110961675644	0.9264880952380953
61	0.14831383909497942	0.9461309523809524	0.18120363567556655	0.9288690476190476
62	0.14595348302807126	0.9453869047619048	0.18092098463149298	0.9282738095238096
63	0.14469934155543646	0.9472470238095239	0.18825252538635617	0.9235119047619048
64	0.1434545530804566	0.9473214285714285	0.18103688345068977	0.9279761904761905
65	0.1405520884763627	0.9510416666666667	0.1822493858280636	0.9255952380952381
66	0.14177423999423072	0.9482142857142857	0.1912063689458938	0.9238095238095239
67	0.14012321411144166	0.9512648809523809	0.17931308547655742	0.9270833333333334
68	0.13773749605530783	0.9496279761904762	0.18277938039529892	0.9252976190476191
69	0.1364552164006801	0.9519345238095238	0.1834135488385246	0.9238095238095239
70	0.1362689026764461	0.9515625	0.17990937573569163	0.9261904761904762
71	0.13082917084296544	0.9523809523809523	0.18658003090392974	0.925
72	0.13019540405699184	0.9529017857142857	0.18644868717307136	0.9252976190476191
73	0.13146135232278278	0.9535714285714286	0.18060162166754404	0.924702380952381
74	0.1227171428501606	0.9551339285714285	0.19847630084980103	0.9226190476190477
75	0.12515122691790262	0.9568452380952381	0.17974310105755215	0.925
76	0.1245683576024714	0.9555059523809524	0.1829385186944689	0.924702380952381
77	0.12555273207170622	0.9546130952380952	0.18829282947949	0.9252976190476191
78	0.12293744810989925	0.9570684523809524	0.18069320633297875	0.9264880952380953
79	0.12168627714826948	0.9561011904761905	0.17923014674867901	0.9270833333333334
80	0.11924431153706141	0.9577380952380953	0.18521897338685536	0.9258928571428572
81	0.11640912613698415	0.9588541666666667	0.18477567987782614	0.9241071428571429
82	0.11660188890638806	0.9591517857142857	0.18075539015588307	0.9273809523809524
83	0.11565687851536842	0.9591517857142857	0.18215049107869466	0.9252976190476191
84	0.1169748434708232	0.9590029761904761	0.18188055186044602	0.9261904761904762
85	0.1132677708353315	0.9585565476190476	0.18655867434683301	0.925
86	0.11460329886703265	0.958110119047619	0.1801798587753659	0.9267857142857143
87	0.11029665157908485	0.9614583333333333	0.18401223648162116	0.924404761904762
88	0.11134126512777237	0.960639880952381	0.1819516970997765	0.9235119047619048
89	0.11048363049825033	0.961235119047619	0.1919607868506795	0.9255952380952381
90	0.11063297060983522	0.9609375	0.18078483485040212	0.924404761904762
91	0.10814242898708298	0.9613095238095238	0.1886440090480305	0.9241071428571429
92	0.1047455448834669	0.9628720238095239	0.19054064083667027	0.9255952380952381
93	0.10438434818670864	0.9630208333333333	0.19597501116139548	0.9255952380952381
94	0.10414498036816007	0.9632440476190476	0.19797797614619844	0.925
95	0.10146416024792762	0.9631696428571429	0.19534151248988652	0.9273809523809524
96	0.1004973937358175	0.9646577380952381	0.18596343908991134	0.925
97	0.10118450692721775	0.9647321428571428	0.18201531512396676	0.9241071428571429
98	0.09910020916944458	0.9664434523809524	0.18252240461962563	0.924404761904762
99	0.09921876106943403	0.9645089285714286	0.18368291088512967	0.9238095238095239

The optimal condition:
	epoch: 36
	train_acc: 0.929985119047619
	val_acc: 0.93005952381
	using time: 922.736257076
