The number of train datas: 13440
The number of test datas: 3360
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6993969502903167	0.505282738095238	0.6898073219117664	0.5276785714285714
1	0.6929156910805475	0.5194940476190476	0.6845810697192237	0.5604166666666667
2	0.688157590230306	0.5429315476190476	0.67975830804734	0.5883928571428572
3	0.6855727479571387	0.5454613095238096	0.673435758409046	0.6142857142857143
4	0.6789498482431684	0.567782738095238	0.6644070755867731	0.643452380952381
5	0.6703052912439619	0.5901041666666667	0.65140411286127	0.6758928571428572
6	0.6588135089193071	0.6140625	0.6339548769451323	0.7041666666666667
7	0.6427437101091658	0.6329613095238096	0.6106401085853577	0.7375
8	0.6199283401171366	0.6680059523809524	0.5770396266664778	0.7625
9	0.5876939166159857	0.6994047619047619	0.5353744926906767	0.7880952380952381
10	0.5510719304993039	0.731845238095238	0.49049219290415447	0.8086309523809524
11	0.5087736476035345	0.7659970238095238	0.4375276945886158	0.8389880952380953
12	0.46113483678726924	0.7979166666666667	0.38610711211249943	0.8598214285714286
13	0.4143315528120313	0.8246279761904762	0.35041209516071137	0.8744047619047619
14	0.38162749466441925	0.8458333333333333	0.3120863431975955	0.8857142857142857
15	0.34726795355478923	0.8631696428571428	0.28827535935810633	0.8898809523809523
16	0.32345622650214606	0.8753720238095238	0.2728850671223232	0.8952380952380953
17	0.30852542845975783	0.8824404761904762	0.2578963339328766	0.9026785714285714
18	0.28622326496101563	0.8960565476190476	0.24848504492214749	0.9098214285714286
19	0.27660298092024665	0.8990327380952381	0.23937029583113534	0.9130952380952381
20	0.26772468941552297	0.9008184523809524	0.2325333195073264	0.9160714285714285
21	0.25413057804107664	0.9042410714285715	0.22965051219576882	0.9166666666666666
22	0.250493266752788	0.9092261904761905	0.22366168924740382	0.9181547619047619
23	0.23988680555706932	0.9116815476190476	0.2242535698981512	0.9199404761904761
24	0.23522400444462185	0.9156994047619048	0.21585560270718165	0.9226190476190477
25	0.23273014639105116	0.9168154761904762	0.21801829664480118	0.9235119047619048
26	0.22163766807033902	0.9206845238095238	0.20962841170174734	0.9223214285714286
27	0.22182864539680028	0.9197916666666667	0.21544179916381836	0.925
28	0.21602145014774232	0.920610119047619	0.2052616406054724	0.9235119047619048
29	0.21228634771846588	0.9249255952380953	0.20464279211702802	0.9252976190476191
30	0.2095937294619424	0.9239583333333333	0.20315337010792323	0.9223214285714286
31	0.20428049465020498	0.9260416666666667	0.20241165189515978	0.9226190476190477
32	0.20046960158007485	0.9273065476190476	0.19873958542233422	0.9255952380952381
33	0.19574005986963	0.9286458333333333	0.20017210741837818	0.9255952380952381
34	0.1919515880800429	0.9314732142857143	0.19810507411048525	0.9220238095238096
35	0.1889886050706818	0.9328869047619047	0.195119166799954	0.9255952380952381
36	0.18437352492695763	0.9338541666666667	0.1957585857028053	0.9273809523809524
37	0.18148876499562036	0.9356398809523809	0.19360515163058326	0.9273809523809524
38	0.17901505820807956	0.9331101190476191	0.1951032022635142	0.9288690476190476
39	0.17597797825222924	0.9359375	0.19490826711768194	0.9273809523809524
40	0.17605496247609456	0.9364583333333333	0.2036680668592453	0.9258928571428572
41	0.17055983053786414	0.9381696428571429	0.1922653255008516	0.9267857142857143
42	0.17147243100972404	0.9375	0.19102738556407747	0.9297619047619048
43	0.1676094046660832	0.940327380952381	0.1887293375673748	0.9297619047619048
44	0.16451779355605442	0.938764880952381	0.1888261758145832	0.9297619047619048
45	0.16308071599120186	0.9401785714285714	0.19077935176236288	0.9300595238095238
46	0.1586160340479442	0.9438244047619048	0.19326573127791996	0.9288690476190476
47	0.16011670260202318	0.9415178571428572	0.19111148104781195	0.9282738095238096
48	0.15649458255086626	0.9429315476190476	0.18994443672043937	0.9282738095238096
49	0.15150976869322005	0.9453869047619048	0.18781364815575735	0.93125
50	0.15193072894499415	0.9450892857142857	0.19326190877528418	0.9282738095238096
51	0.14788959210827238	0.9466517857142858	0.1871532122294108	0.9303571428571429
52	0.1486609175091698	0.9453869047619048	0.21893788533551353	0.9178571428571428
53	0.1462043370164576	0.947842261904762	0.18732923070589702	0.9297619047619048
54	0.13968142427149274	0.9500744047619047	0.18591469810122535	0.9297619047619048
55	0.1385128053171294	0.9494791666666667	0.19084072936148871	0.93125
56	0.13848928284077416	0.9491815476190476	0.18528991029376074	0.9300595238095238
57	0.13703302056306885	0.9511160714285715	0.18534717048917498	0.9300595238095238
58	0.13534546608016604	0.9514880952380952	0.19630184528373537	0.9297619047619048
59	0.13540852346590587	0.9525297619047619	0.18698247358912512	0.93125
60	0.1309198199283509	0.9526785714285714	0.18579084603559404	0.9297619047619048
61	0.133425634318874	0.9523809523809523	0.18591639825275966	0.9300595238095238
62	0.12798614640321052	0.9561755952380953	0.18487608830134075	0.9288690476190476
63	0.126886786591439	0.9535714285714286	0.18944689219906216	0.93125
64	0.1257614225503944	0.9541666666666667	0.1843053048565274	0.9291666666666667
65	0.12111024281808308	0.9583333333333334	0.1850036348615374	0.9306547619047619
66	0.12491465867275284	0.9563988095238095	0.18898734535489764	0.9300595238095238
67	0.1211270816269375	0.9575892857142857	0.18656145220711118	0.9273809523809524
68	0.12526403083687737	0.9544642857142858	0.19877565673419406	0.9267857142857143
69	0.12133747981417747	0.9572916666666667	0.19989136060078938	0.9261904761904762
70	0.12020481856805938	0.9544642857142858	0.18355216355550857	0.93125
71	0.11771227430020059	0.9572916666666667	0.1903054193371818	0.9306547619047619
72	0.11285111304549944	0.9607886904761904	0.18577197988828023	0.9315476190476191
73	0.11476491891912051	0.9597470238095238	0.20829345044635592	0.925
74	0.11418758449809892	0.959672619047619	0.1994595970426287	0.9282738095238096
75	0.10941860331665902	0.9602678571428571	0.18283538080397108	0.9303571428571429
76	0.11038040401680128	0.9615327380952381	0.18696416985420955	0.9306547619047619
77	0.11046038007452375	0.9619791666666667	0.2017652398064023	0.9285714285714286
78	0.10748999686468215	0.9626488095238095	0.18816125109082177	0.9303571428571429
79	0.10647160286704699	0.9633184523809524	0.18457947572072347	0.9318452380952381
80	0.10335961303540639	0.963764880952381	0.18872464639799935	0.9315476190476191
81	0.10357484760738554	0.9640625	0.19056521100657328	0.9306547619047619
82	0.1015245626370112	0.9646577380952381	0.18548697971162342	0.9315476190476191
83	0.10324670214738164	0.9633928571428572	0.1896212943962642	0.9303571428571429
84	0.10289280971600896	0.9623511904761904	0.18930316241014572	0.9315476190476191
85	0.09876776220543045	0.9646577380952381	0.19284396441209883	0.9294642857142857
86	0.09801820296616781	0.9664434523809524	0.18534651796023052	0.9297619047619048
87	0.09862351268529893	0.9650297619047619	0.19454788182462965	0.930952380952381
88	0.09264605506545022	0.9683779761904762	0.1941214667899268	0.930952380952381
89	0.09635480656510308	0.9657738095238095	0.18649611047336034	0.9330357142857143
90	0.0968337795209317	0.9660714285714286	0.1840569564274379	0.9330357142857143
91	0.09413615355179424	0.96875	0.1949433732600439	0.9306547619047619
92	0.0919838785415604	0.969047619047619	0.198222289057005	0.9306547619047619
93	0.09253577075543858	0.9671130952380952	0.1987279542854854	0.9291666666666667
94	0.09059890494460152	0.9686011904761904	0.20043532649676005	0.9297619047619048
95	0.08760875028868516	0.9713541666666666	0.20480610515390124	0.9270833333333334
96	0.08786617224769933	0.9702380952380952	0.19263845866634732	0.9336309523809524
97	0.08848737719513121	0.9701636904761904	0.1861925871599288	0.9315476190476191
98	0.08429617275084768	0.9695684523809524	0.19923929345040095	0.9315476190476191
99	0.08783791113112654	0.9697172619047619	0.19009331776982263	0.9318452380952381

The optimal condition:
	epoch: 96
	train_acc: 0.9702380952380952
	val_acc: 0.933630952381
	using time: 1071.30282807
