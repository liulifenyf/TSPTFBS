The number of train datas: 13440
The number of test datas: 3360
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6986825568335396	0.5110119047619047	0.6900290046419416	0.5363095238095238
1	0.6927581770079476	0.5220238095238096	0.6858880247388567	0.5681547619047619
2	0.6882515623455956	0.5396577380952381	0.6815468351046244	0.5863095238095238
3	0.6850271009263538	0.5466517857142857	0.6760125182923816	0.6211309523809524
4	0.6794353638376508	0.5699404761904762	0.6678081943875267	0.6473214285714286
5	0.6723965315591721	0.5903273809523809	0.6548557729948135	0.6788690476190476
6	0.657265781788599	0.6162202380952381	0.6343089966546922	0.705952380952381
7	0.641163166364034	0.6395089285714286	0.6070442120234172	0.7392857142857143
8	0.6139772505987258	0.6786458333333333	0.567744121097383	0.7782738095238095
9	0.575634127003806	0.7170386904761905	0.5176888375055222	0.80625
10	0.5343284984429677	0.7506696428571429	0.4676867899440584	0.8205357142857143
11	0.48523158601352145	0.7806547619047619	0.40927136966160366	0.8577380952380952
12	0.43723736235073635	0.8149553571428572	0.3589015279497419	0.8720238095238095
13	0.3953970506077721	0.8395833333333333	0.32504279102597916	0.8869047619047619
14	0.36498306620688664	0.8551339285714286	0.2939738653955005	0.8979166666666667
15	0.33834450727417353	0.870014880952381	0.2732805334386371	0.9026785714285714
16	0.31651449033192225	0.8803571428571428	0.25961225770768664	0.9089285714285714
17	0.3029753988697415	0.8844494047619048	0.24967584411303204	0.912797619047619
18	0.2867156343800681	0.8951636904761905	0.23859480505897884	0.9148809523809524
19	0.27715924240293954	0.8976190476190476	0.2315046503430321	0.9154761904761904
20	0.268902127515702	0.9024553571428572	0.2262766882067635	0.91875
21	0.25667366002287184	0.9069940476190477	0.22634716885430473	0.9214285714285714
22	0.2537280353761855	0.9078869047619048	0.22000650877044314	0.9178571428571428
23	0.24380609747909365	0.9123511904761905	0.21756650450683776	0.924702380952381
24	0.2359038714851652	0.914360119047619	0.21263523073423476	0.9211309523809523
25	0.23638424298592975	0.913764880952381	0.2105022993825731	0.9258928571428572
26	0.2226675815525509	0.9184523809523809	0.20682958023888723	0.924702380952381
27	0.22640186690148853	0.9191964285714286	0.21111810845988138	0.9264880952380953
28	0.2169671681665239	0.9226934523809524	0.20286179667427426	0.9282738095238096
29	0.216715584056718	0.9228422619047619	0.20468409487179348	0.9261904761904762
30	0.21039918277944838	0.9238095238095239	0.20154201019377935	0.9241071428571429
31	0.20530212684756233	0.9267113095238095	0.19932591489383153	0.9264880952380953
32	0.20505816787481307	0.9244791666666666	0.19825175865775063	0.9276785714285715
33	0.19703918411618188	0.9293154761904762	0.19596782397656215	0.9285714285714286
34	0.19632967717590785	0.9292410714285714	0.1971273239169802	0.9229166666666667
35	0.19203309842518398	0.9303571428571429	0.1931095160189129	0.9270833333333334
36	0.18689507515657516	0.9321428571428572	0.19267299104304542	0.9270833333333334
37	0.1857850947550365	0.9321428571428572	0.19631864726543427	0.9208333333333333
38	0.18199942665440696	0.9329613095238095	0.19640994306121554	0.9276785714285715
39	0.18033964648133233	0.9348214285714286	0.1953186293443044	0.9276785714285715
40	0.1769686024103846	0.9357142857142857	0.19488196330411092	0.9270833333333334
41	0.1756099066564015	0.9369047619047619	0.18916347708020892	0.9258928571428572
42	0.17295065429948625	0.9371279761904762	0.18806584179401398	0.9267857142857143
43	0.1703208401799202	0.9398065476190476	0.18797730860256012	0.9261904761904762
44	0.1692357926141648	0.9390625	0.18805772889228095	0.9255952380952381
45	0.1671541344551813	0.9384672619047619	0.18817741700581142	0.9261904761904762
46	0.1634381719997951	0.9406994047619047	0.1905126900899978	0.9294642857142857
47	0.1644184381124519	0.9415178571428572	0.18812731752792994	0.9273809523809524
48	0.1606871723419144	0.9427083333333334	0.1877247670576686	0.9279761904761905
49	0.15880778758298783	0.9450892857142857	0.18951523928415206	0.9279761904761905
50	0.155709346419289	0.9428571428571428	0.18890468251137507	0.9285714285714286
51	0.15340622855084282	0.9443452380952381	0.18657745236442203	0.925
52	0.15563979290780566	0.9436755952380952	0.20177826349224362	0.9270833333333334
53	0.1517623843181701	0.9449404761904762	0.18529420849822817	0.9252976190476191
54	0.14649800218286968	0.9485119047619047	0.18675529332388016	0.9252976190476191
55	0.14503678565933592	0.9473214285714285	0.18684112472193581	0.9258928571428572
56	0.1448529369774319	0.9471726190476191	0.18670818862460908	0.9270833333333334
57	0.14403434175820579	0.9470238095238095	0.1890550738998822	0.9273809523809524
58	0.14407190283139545	0.9485863095238095	0.18607695869037083	0.9264880952380953
59	0.14208267160824367	0.9494791666666667	0.18592271010080974	0.9261904761904762
60	0.1389347622791926	0.9497023809523809	0.1876261652935119	0.9252976190476191
61	0.13571041467643918	0.9511160714285715	0.18768520795163654	0.9261904761904762
62	0.13527588979119345	0.9513392857142857	0.18656418976329622	0.9267857142857143
63	0.1365014981301058	0.9511904761904761	0.1940473667212895	0.9267857142857143
64	0.13405954330450012	0.9520833333333333	0.18646022719996316	0.9264880952380953
65	0.12801130818469184	0.955654761904762	0.18791782820508593	0.9255952380952381
66	0.1299876060514223	0.9543154761904762	0.1958000136273248	0.9258928571428572
67	0.12923039481753396	0.9546875	0.1872838033097131	0.9264880952380953
68	0.1301964687094802	0.954389880952381	0.1921029949472064	0.9264880952380953
69	0.12613844431581953	0.9538690476190477	0.2047032783428828	0.9235119047619048
70	0.12488263036523546	0.9552083333333333	0.18949110422815596	0.9258928571428572
71	0.12371430212543125	0.9549851190476191	0.18987265470482054	0.9258928571428572
72	0.12099218808469318	0.9575148809523809	0.19158648813054674	0.9273809523809524
73	0.12139840807233537	0.9560267857142857	0.19361173248007185	0.9282738095238096
74	0.11847326092067219	0.9563988095238095	0.19769529714470818	0.9291666666666667
75	0.1168153563780444	0.9580357142857143	0.18787880284445627	0.9273809523809524
76	0.11633996697408812	0.9581845238095238	0.19355475285223553	0.9264880952380953
77	0.11768861906159492	0.9588541666666667	0.2020387663727715	0.9252976190476191
78	0.1137616740096183	0.9605654761904762	0.1951996528676578	0.9276785714285715
79	0.11466085091233254	0.9610119047619048	0.18895778173492067	0.9267857142857143
80	0.11336189047211692	0.9581845238095238	0.19725720314752487	0.9276785714285715
81	0.10748432832104819	0.9630952380952381	0.1979999100168546	0.9276785714285715
82	0.1087029459575812	0.9615327380952381	0.1915434391725631	0.9270833333333334
83	0.1095193325763657	0.9594494047619048	0.19282789350975127	0.9270833333333334
84	0.1090242899954319	0.9597470238095238	0.19522289307344529	0.9279761904761905
85	0.10653595502177875	0.9616815476190477	0.20450591168233326	0.9255952380952381
86	0.10612080629382814	0.9626488095238095	0.1932489275932312	0.9252976190476191
87	0.1052197132437002	0.9619791666666667	0.19427354271922792	0.9273809523809524
88	0.10178434220807893	0.9633184523809524	0.20340985879302026	0.9273809523809524
89	0.10313452457388242	0.9641369047619047	0.20039951929024288	0.9285714285714286
90	0.10285806528159551	0.9638392857142857	0.19321158790872212	0.9282738095238096
91	0.10026720733869643	0.9642857142857143	0.2010067859575862	0.9273809523809524
92	0.0972179287601085	0.9652529761904762	0.20558855122043973	0.9279761904761905
93	0.09647548855060623	0.9655505952380953	0.20495259754714512	0.9270833333333334
94	0.09406939195025535	0.9686011904761904	0.21089700772648767	0.925
95	0.09134367395724569	0.9676339285714286	0.20651326644278709	0.9267857142857143
96	0.09332940142069544	0.9671875	0.2011881248581977	0.9285714285714286
97	0.09377164304966018	0.9652529761904762	0.2011777882065092	0.9282738095238096
98	0.09477307072707584	0.9650297619047619	0.19650038583647636	0.9288690476190476
99	0.09109767207077571	0.9673363095238096	0.19696064988772075	0.924404761904762

The optimal condition:
	epoch: 46
	train_acc: 0.9406994047619047
	val_acc: 0.929464285714
	using time: 1009.38570309
