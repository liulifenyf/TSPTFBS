The number of train datas: 13440
The number of test datas: 3360
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7005363816306704	0.5016369047619048	0.6895637444087437	0.5386904761904762
1	0.6923600117365519	0.5200892857142857	0.685766019139971	0.5681547619047619
2	0.6896163804190499	0.531547619047619	0.6805655791645958	0.6053571428571428
3	0.6831313184329442	0.5565476190476191	0.6725525492713564	0.6389880952380952
4	0.6763703896885827	0.5758184523809524	0.6600172689982823	0.6619047619047619
5	0.664471469606672	0.6029017857142858	0.6396207077162607	0.7044642857142858
6	0.6426873967761085	0.638095238095238	0.6075131291434879	0.7354166666666667
7	0.615404958952041	0.6774553571428571	0.5676867240951174	0.7770833333333333
8	0.5720783835365659	0.7216517857142857	0.5114998079481579	0.8116071428571429
9	0.5191532291117169	0.763095238095238	0.4520436911355881	0.8360119047619048
10	0.46315949644361226	0.8029761904761905	0.3960994527453468	0.8547619047619047
11	0.4167554985909235	0.8252232142857143	0.35443873150008065	0.8705357142857143
12	0.3727646373567127	0.8491815476190476	0.31818126014300757	0.8842261904761904
13	0.34384400844573976	0.8626488095238095	0.30402002050763083	0.8851190476190476
14	0.32691478374458494	0.8734375	0.2801845544860477	0.9014880952380953
15	0.30950063921156384	0.8827380952380952	0.2691938604627337	0.9026785714285714
16	0.28951947532948996	0.8888392857142857	0.2590358149437677	0.9056547619047619
17	0.2839913505883444	0.8924851190476191	0.25376870405106317	0.9074404761904762
18	0.2705713622626804	0.8982142857142857	0.2484336041268848	0.912797619047619
19	0.26053608031499953	0.9020833333333333	0.24143437516121638	0.9116071428571428
20	0.2577185515846525	0.9051339285714286	0.23688120529765175	0.9133928571428571
21	0.24501987028689612	0.9093005952380953	0.23478236425490606	0.9148809523809524
22	0.2486723936739422	0.9103422619047619	0.23118349853016082	0.9139880952380952
23	0.23473389546076456	0.9145089285714286	0.2275349974632263	0.9184523809523809
24	0.22832559233620053	0.9132440476190476	0.22364388477234615	0.9157738095238095
25	0.23096272164867038	0.9171875	0.22396608874911353	0.9184523809523809
26	0.22024801565068108	0.9218005952380952	0.21992406845092774	0.9181547619047619
27	0.22052463789780935	0.9200892857142857	0.22168903350830077	0.9202380952380952
28	0.21359174691495442	0.9220238095238096	0.2148588294074649	0.9205357142857142
29	0.21295711994171143	0.9225446428571429	0.2130501219204494	0.9214285714285714
30	0.2063517344139871	0.9244791666666666	0.21129328693662372	0.9196428571428571
31	0.20450072047256287	0.9264136904761905	0.21194086500576564	0.9223214285714286
32	0.1996704821785291	0.9269345238095238	0.20845612173988706	0.9226190476190477
33	0.19511861020610446	0.9306547619047619	0.20799694047087713	0.9229166666666667
34	0.1964890548161098	0.9286458333333333	0.20681952039400736	0.9226190476190477
35	0.19023732393980025	0.9315476190476191	0.20455996096134185	0.9229166666666667
36	0.1889885915177209	0.9317708333333333	0.20292534005074275	0.9241071428571429
37	0.18535561178411755	0.9337053571428572	0.2030232105936323	0.9232142857142858
38	0.18235066227969668	0.9333333333333333	0.21275823442708877	0.9208333333333333
39	0.1832226118871144	0.9333333333333333	0.20791050252460297	0.9232142857142858
40	0.176229351687999	0.9356398809523809	0.20290983177366712	0.9232142857142858
41	0.17376820139941715	0.9354910714285715	0.19747019693965004	0.9267857142857143
42	0.1734633757244973	0.9353422619047619	0.19523148990812755	0.9255952380952381
43	0.16996709527004333	0.9377232142857143	0.19786923627058664	0.9241071428571429
44	0.1683813798285666	0.9390625	0.19278015636262438	0.9267857142857143
45	0.16737328036910012	0.9383928571428571	0.1926271291006179	0.9261904761904762
46	0.16143291521640052	0.9409226190476191	0.19451991958277567	0.9264880952380953
47	0.1669370035685244	0.9413690476190476	0.19593868213040488	0.9261904761904762
48	0.16058614495254697	0.9409226190476191	0.19237428179809024	0.9261904761904762
49	0.15849640355223701	0.9420386904761905	0.20256689701761518	0.9229166666666667
50	0.15603010406096776	0.9425595238095238	0.1960398915268126	0.9261904761904762
51	0.15225134527399425	0.9445684523809523	0.18784087896347046	0.9291666666666667
52	0.15926494910603478	0.9432291666666667	0.20237557696444647	0.9241071428571429
53	0.15027702408177512	0.9455357142857143	0.1859937669265838	0.9306547619047619
54	0.14941334508004642	0.9458333333333333	0.18804877272674014	0.9267857142857143
55	0.14482034742832184	0.9468005952380952	0.1882481682868231	0.9276785714285715
56	0.147209037343661	0.9462053571428571	0.18479535622256144	0.9306547619047619
57	0.14475329369306564	0.9467261904761904	0.19138448451246534	0.9276785714285715
58	0.14458011062372297	0.9479910714285714	0.1892849507785979	0.9288690476190476
59	0.13983327675433385	0.95	0.1852038379226412	0.9303571428571429
60	0.13704735888611702	0.9497767857142857	0.1876937366667248	0.930952380952381
61	0.13424096632571447	0.9511904761904761	0.18477162151109605	0.9324404761904762
62	0.13492773955776577	0.9515625	0.18274068860780626	0.9324404761904762
63	0.1338333134140287	0.9519345238095238	0.18845253544194357	0.9303571428571429
64	0.13234064522243683	0.9520833333333333	0.18174214022500174	0.9336309523809524
65	0.13055992995699248	0.9543154761904762	0.1826794405778249	0.9327380952380953
66	0.1304234229737804	0.9546130952380952	0.1929943988720576	0.9267857142857143
67	0.12905857509800367	0.9555803571428572	0.18088313724313462	0.9330357142857143
68	0.1276941726250308	0.9526785714285714	0.18784446716308595	0.9297619047619048
69	0.1232627326533908	0.9561755952380953	0.18575960312570844	0.9291666666666667
70	0.12652422214547793	0.953422619047619	0.18161614182449523	0.9342261904761905
71	0.12229482797639711	0.95625	0.1944907865353993	0.9270833333333334
72	0.12058402413413638	0.9560267857142857	0.18791780784016565	0.9303571428571429
73	0.12017827910326775	0.955654761904762	0.18322755424749285	0.9339285714285714
74	0.11720519839298157	0.9583333333333334	0.20293245556808653	0.9235119047619048
75	0.11602570797715868	0.9584821428571428	0.1858883948553176	0.930952380952381
76	0.11378867267852738	0.9592261904761905	0.19092286995479038	0.9288690476190476
77	0.11679569057055882	0.9598958333333333	0.19249780419326964	0.9267857142857143
78	0.11035992077418737	0.9607886904761904	0.19882475967918123	0.9261904761904762
79	0.11443482548708007	0.9594494047619048	0.18339059423832665	0.9348214285714286
80	0.1100590739931379	0.9613839285714286	0.19472441935823076	0.9267857142857143
81	0.10978407015403112	0.9633184523809524	0.18872472026518414	0.93125
82	0.10763121250839461	0.9624255952380952	0.18387072937829155	0.9342261904761905
83	0.10920076544086138	0.9614583333333333	0.18761207241387595	0.9327380952380953
84	0.10785319652585756	0.9624255952380952	0.18962141616003855	0.9315476190476191
85	0.10579295534463155	0.9617559523809524	0.19940936934380304	0.9258928571428572
86	0.10653788752499081	0.9633184523809524	0.18659616325582776	0.9330357142857143
87	0.10180335866198653	0.9636904761904762	0.18765481156962258	0.9324404761904762
88	0.10075623591740926	0.9644345238095238	0.18976328138794218	0.9330357142857143
89	0.10128584706357548	0.9643601190476191	0.19793373126359212	0.9285714285714286
90	0.10402888861440476	0.963467261904762	0.18334347364448367	0.9324404761904762
91	0.1019267536699772	0.9639136904761905	0.193988484782832	0.9318452380952381
92	0.09613289666317758	0.9676339285714286	0.19529539531185514	0.9330357142857143
93	0.09626456105283328	0.9665922619047619	0.20024497693493254	0.9264880952380953
94	0.0953645717175234	0.9657738095238095	0.2099769712204025	0.9220238095238096
95	0.0941874623298645	0.9668154761904761	0.19632892154511952	0.9318452380952381
96	0.09234011744459471	0.9686755952380952	0.1940093912539028	0.9327380952380953
97	0.09316782454649607	0.9682291666666667	0.19738495009286064	0.9318452380952381
98	0.09399813814532189	0.967485119047619	0.19010684809514455	0.9339285714285714
99	0.09387260001330149	0.9671130952380952	0.1915849262759799	0.9342261904761905

The optimal condition:
	epoch: 79
	train_acc: 0.9594494047619048
	val_acc: 0.934821428571
	using time: 853.512525082
