The number of train datas: 2148
The number of test datas: 538
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7202295118204042	0.5162942275765666	0.6943874893135298	0.5334572484058961
1	0.7029211843035963	0.5246741154562383	0.6870850971640264	0.5724907067628598
2	0.6880711066212291	0.5446927369306873	0.6782647566281287	0.5762081779955045
3	0.6820499296516902	0.5633147123583646	0.6713631122085685	0.6263940529309241
4	0.6753970748663393	0.5763500937758433	0.6659117666762114	0.6431226774662401
5	0.6654437711562968	0.605679700938461	0.6605470333400713	0.6542750936015388
6	0.6664091986872852	0.5996275596334504	0.6533133316660459	0.6747211902558139
7	0.6588278972236804	0.6135940420782988	0.6453684803278473	0.7100371753859254
8	0.6451564228068517	0.6340782126234896	0.6378521152588514	0.7156133835643641
9	0.6338159293213814	0.6578212292722706	0.6281081389317282	0.7323420080996801
10	0.6180554034545657	0.6876163882250227	0.6166722716895178	0.7490706326349961
11	0.6122207966818712	0.6983240227903512	0.6040268733155771	0.7583643129323938
12	0.605742572628142	0.6969273751896409	0.5901213813448484	0.7695167292892712
13	0.5886533109391424	0.7146182489794726	0.5763949395112389	0.7713754653487507
14	0.563749905627089	0.7430167592215582	0.5629632672412688	0.7750929359166595
15	0.5422729585645807	0.7597765368678272	0.5453020899269218	0.7806691440950982
16	0.532436725591592	0.763500930099736	0.5306255970302568	0.7788104080356186
17	0.5167060615408132	0.7802607086339698	0.5134826750117164	0.7881040883330165
18	0.49156042567178526	0.7993482320224329	0.5013054138444171	0.7955390325709346
19	0.4700247523282937	0.8049348227582608	0.48341886870923095	0.7992565046898937
20	0.4648283984186041	0.803072625698324	0.4678994512469352	0.7973977686304142
21	0.44756077338197375	0.8175046550494999	0.45815485671550366	0.7955390325709346
22	0.4313643685155297	0.8114525126345331	0.4421403190903504	0.7955390341219849
23	0.4089375020072447	0.8314711356074228	0.4439712708545883	0.7918215604519755
24	0.40713807896084847	0.8347299825989778	0.42076154856433656	0.8029739783599031
25	0.39425574412337006	0.8361266286457495	0.42304950442899114	0.7973977686304142
26	0.3802771856886937	0.844506517468884	0.4010952331098039	0.8178438668357395
27	0.3678983962180672	0.8533519564172187	0.4050376200321439	0.7936802965114551
28	0.36276304649685126	0.8533519550852714	0.3967331103897449	0.8048327144193826
29	0.3492757298426921	0.8626629433818369	0.39608371302097706	0.804832714197804
30	0.34760366310842433	0.8575418983313846	0.38411365000731884	0.8104089225978213
31	0.33471670130777625	0.8705772823017625	0.3850910838651834	0.8159851290036312
32	0.32536027201727113	0.8682495332297	0.37216716428671626	0.823420073463128
33	0.31583716688431396	0.8775605216372613	0.3745988413525337	0.8252788106305006
34	0.31036621315519236	0.8724394779187563	0.368679201735883	0.8327137535389472
35	0.30607757513416545	0.876629421608852	0.3657389040551664	0.8345724909278983
36	0.30270559677864584	0.881750464772379	0.36045568195417466	0.8327137548684187
37	0.2878685808381555	0.8873370566181631	0.36075190512885835	0.834572489376848
38	0.2885031871622501	0.8859404107933826	0.35026912634922225	0.8364312269873778
39	0.2882371404983478	0.886405959697631	0.3407674208006451	0.8457249072847757
40	0.28058653370628145	0.8891992544550692	0.330188043720217	0.8531598501932223
41	0.26771772657026793	0.9008379881608419	0.3462290169470372	0.8438661710037175
42	0.2607868680074894	0.9013035378420597	0.3235923304433716	0.8568773236416529
43	0.26116824821608914	0.908752328079728	0.3136093676311819	0.86245353049062
44	0.25146819071174775	0.8999068900193582	0.3129414406961668	0.8624535318200917
45	0.25478039082535153	0.9050279341818456	0.32838371091394175	0.8587360581500822
46	0.24179360808828912	0.9045623848336147	0.3138921388241438	0.8605947942095619
47	0.24842051262629097	0.9050279341818456	0.291822347166813	0.8717472107880178
48	0.23034439462079237	0.9175977661400978	0.2970734803650016	0.8698884745069596
49	0.21597500722612525	0.9273743006770171	0.29341336979520366	0.8717472105664391
50	0.2140154430930619	0.9199255119932874	0.28110643667359336	0.8791821563554076
51	0.2130856091083761	0.9250465548238275	0.28472472101339175	0.8754646826853982
52	0.20752782400981895	0.9259776544082542	0.2773035580230025	0.8754646842364485
53	0.20380816204920826	0.9310986972387942	0.2962003887585991	0.8754646826853982
54	0.2071891796378006	0.9236499067791347	0.27384355542385	0.8773234187448778
55	0.20004384694152705	0.9278398504692305	0.27259227799660213	0.8773234187448778
56	0.18293842959115403	0.9348230915806591	0.26315660132129837	0.8847583645338463
57	0.1890357408943123	0.9315642470310076	0.2681846979271524	0.884758362982796
58	0.17705706472281416	0.938547485034559	0.27743742085965595	0.881040890863837
59	0.17831437062173805	0.9343575407894852	0.27058001228203116	0.8866170990422756
60	0.1743214606295307	0.9338919933281797	0.25349120696016403	0.8884758351017551
61	0.17511908363141604	0.9390130357147373	0.23880612124519277	0.9014869890691622
62	0.16981769643127365	0.9432029802927979	0.2448012773432253	0.8921933072207142
63	0.15462988282049167	0.9469273733027155	0.2396386190417974	0.8959107793396733
64	0.1636097805238081	0.9418063313601404	0.24974973965090003	0.8921933072207142
65	0.15401109184521758	0.945996274495258	0.22377535329653872	0.9163568775449987
66	0.15770865513403767	0.9418063313601404	0.2389294966556769	0.901486987518112
67	0.15255514053659067	0.9483240213474082	0.24429618930063282	0.8959107793396733
68	0.1412091991921377	0.953910615857087	0.2353805440398397	0.901486987518112
69	0.13866112205014328	0.9534450650659131	0.2223245102122814	0.9107806678155098
70	0.14234454438673053	0.9553072633468017	0.21886217959751428	0.9107806678155098
71	0.1298898301422041	0.9571694607397253	0.22966333575629833	0.9052044596370711
72	0.13068392116652744	0.95670391150249	0.226858011547296	0.9052044596370711
73	0.13704944857061463	0.9506517704194707	0.21797832342550214	0.9163568759939484
74	0.12275800774883291	0.9567039105035295	0.2194013677011192	0.9126394038749893
75	0.11957382387178127	0.9571694602957429	0.21161878685082644	0.9182156120534279
76	0.12488255548521571	0.9576350087560089	0.21132987438524523	0.9182156120534279
77	0.11432423048567728	0.962290503681261	0.20438754137563883	0.9237918202318667
78	0.108329386295997	0.9660148979121302	0.2238236596482394	0.9089219317560302
79	0.11162247948584388	0.9636871517259538	0.20818057944340335	0.9200743481129076
80	0.10820724489080617	0.9674115460678185	0.21360478251064577	0.9163568759939484
81	0.10086243897953957	0.9674115450688581	0.20794237959008235	0.9237918202318667
82	0.10690537824866048	0.9641527010741846	0.20819376517073374	0.9256505562913462
83	0.10587777932706936	0.9664804468163787	0.2227390374725193	0.9126394038749893
84	0.10417628231383791	0.9697392913660302	0.20859457109275803	0.9200743481129076
85	0.10095120135354818	0.9664804482593217	0.19937363291872479	0.9293680284103053
86	0.09952435729889897	0.9688081936685289	0.2042800453681928	0.9200743481129076
87	0.095703769731899	0.9706703919494174	0.20320835152855593	0.9237918202318667
88	0.08962180210863634	0.9729981382465895	0.19245356781110445	0.9312267644697849
89	0.0913884960239826	0.9692737439047246	0.18578359927829757	0.9368029726482235
90	0.08561553328091649	0.9739292369430513	0.1904375067320012	0.9293680284103053
91	0.08968852499232834	0.9739292355001083	0.20662357367325893	0.9219330841723871
92	0.0858497507800825	0.9734636865958599	0.19321347684443663	0.9293680284103053
93	0.08427723408355837	0.9739292373870339	0.1832282763653085	0.9368029726482235
94	0.07391428090007611	0.975791434335975	0.19243491465939022	0.9293680284103053
95	0.08137853551843313	0.9711359394107228	0.1859669265472313	0.9330855005292644
96	0.07939466939514132	0.9776536326168636	0.19113420149429136	0.9293680284103053
97	0.07601839358080699	0.9771880809377248	0.18321305923302378	0.934944236588744
98	0.07374749318791946	0.9785847313133254	0.18477070733184708	0.9330855005292644
99	0.06922545775188414	0.9790502806615563	0.18385631488601514	0.9330855005292644

The optimal condition:
	epoch: 93
	train_acc: 0.9739292373870339
	val_acc: 0.936802972648
	using time: 67.6705908775
