The number of train datas: 8936
The number of test datas: 2236
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7116429861251435	0.4944046552200454	0.6953737709091473	0.5008944537430629
1	0.6995424066896191	0.5074977615953239	0.6915786490244175	0.52146690540109
2	0.694464614429747	0.518352730741646	0.689705699628922	0.5415921290146857
3	0.6918757505041206	0.5334601611459265	0.6881970222606215	0.544275491310147
4	0.6905773801257169	0.528648164993754	0.6860192286946906	0.5576923074790532
5	0.6883556021572547	0.5377126232043056	0.683719363003596	0.5769230762833133
6	0.6860153354377542	0.545881826427224	0.6815721423553439	0.584078712518825
7	0.6848175371450939	0.5513652643670754	0.6791439285645118	0.6015205731971959
8	0.682467145746909	0.5616606984590993	0.6761961630503905	0.6064400708099598
9	0.6790878743386844	0.5660250672508588	0.6727861587178089	0.6247763859777843
10	0.6766352549448756	0.5738585499001062	0.6678712388270657	0.6274597502991637
11	0.6713706593270161	0.5839301697783099	0.6622994953703155	0.643559927910513
12	0.664723980021242	0.606647269258354	0.6540595847506856	0.6623434708028871
13	0.6610417665918704	0.6073187107258645	0.6446469296069819	0.6923076926275741
14	0.6505218472668606	0.6305953447265933	0.6326704833503273	0.7093023254747681
15	0.639194858106205	0.6459265892379713	0.6185801915277949	0.7169051871956568
16	0.6240322582403677	0.6626007161507568	0.5975158610156269	0.7468694094468528
17	0.6115717949777602	0.6787153087563033	0.5764503264683091	0.7674418598253526
18	0.5816855870834289	0.7062444044952427	0.5439433321116862	0.7956171740572866
19	0.5549634905830493	0.731423455791593	0.5101522744661581	0.8161896240092774
20	0.5225373783758313	0.7610787821328309	0.4668395779427134	0.8394454379627657
21	0.47968091819045156	0.7889435989790552	0.42323197762953363	0.858676207193535
22	0.4354265455753545	0.8182632048533447	0.3819846916603914	0.8725402501273454
23	0.3945918800901278	0.8399731423989298	0.33723580538693393	0.8908765658283063
24	0.3560717946306978	0.8650402862148404	0.30379814317379955	0.9060822890568291
25	0.31498381025895755	0.8901074308311715	0.27393375907579776	0.911449015780297
26	0.2878304438710533	0.8978290064802315	0.2546886953130391	0.9168157416507469
27	0.2672790762240479	0.9075649060515708	0.23567581166095086	0.9244186039047719
28	0.24723670428206906	0.9148388537532427	0.2263546631886409	0.9284436486274911
29	0.23041794896659407	0.9228961504028648	0.21083982742003338	0.9333631477330366
30	0.2166239213842095	0.9294986573307239	0.20697614351997223	0.9347048293072764
31	0.20478247267493416	0.9334153986019862	0.19417533892904923	0.9391771012214087
32	0.19509968298988462	0.9405774395169162	0.1901452697293703	0.935599284116612
33	0.1890120300978769	0.9403536259434323	0.18404627604699944	0.9449910547097808
34	0.18106380321132146	0.9401298116762508	0.1798030127619588	0.9418604647963973
35	0.1743353749879685	0.9466204118707293	0.17748233169477187	0.9405187832221575
36	0.16885655398014515	0.9450537154155858	0.174642748450977	0.9445438279448767
37	0.16263929099484864	0.9497538049411005	0.16962881226339152	0.9454382823277031
38	0.1544255913104345	0.9517681291301867	0.16860814744436678	0.9440966007534635
39	0.15753300426629577	0.9507609669289209	0.16703104410380498	0.9476744182847694
40	0.15028962903825321	0.9540062668393954	0.16285986819826	0.9485688726675958
41	0.14485380328331232	0.9565801250155525	0.163559653744608	0.9485688726675958
42	0.1426854887268537	0.9571396597496825	0.1722743212910159	0.9449910547097808
43	0.14491534247767637	0.9562444044952427	0.16267612140645707	0.9463327367105296
44	0.1379096572326568	0.9583706355244321	0.15615668578309963	0.950805008624662
45	0.13408421760386618	0.9581468217908642	0.15840572926460736	0.949016099859009
46	0.12997524396932433	0.9602730526599697	0.1537982683382222	0.9512522358160752
47	0.1311891027321854	0.9622873770091399	0.15185743626307077	0.950805008624662
48	0.12575509457206127	0.9627350043161916	0.151494371763069	0.9499105542418356
49	0.12409855010473206	0.9646374216118132	0.1507084082298927	0.9499105542418356
50	0.12227260504141384	0.9621754701156753	0.1498169672937001	0.9512522358160752
51	0.12469620226266241	0.9636302598907996	0.14859079533591465	0.9512522358160752
52	0.11643881970414544	0.9640778868776831	0.14719789361911084	0.9503577814332488
53	0.11939655209665546	0.9626230976895338	0.14674920107576203	0.9530411445817282
54	0.11581932063962373	0.9646374215050905	0.14503953791155158	0.9530411445817282
55	0.10970762013495235	0.9666517455874539	0.144657644608153	0.952593917390315
56	0.10982675684971156	0.9679946283090296	0.1452482468540212	0.9521466901989017
57	0.11081940173142278	0.967435094215236	0.14247151825423743	0.9539355989645547
58	0.10658212130157245	0.9696732318177219	0.14398610072080478	0.9530411445817282
59	0.10579602918591793	0.9658683971731173	0.1417250096371434	0.9530411445817282
60	0.10095830859354595	0.9704565800719743	0.14703267202287754	0.9539355989645547
61	0.10549847855030049	0.9666517456941767	0.144942682789562	0.9557245077302077
62	0.10142655494550348	0.9691136971903146	0.16213740073877497	0.9521466897723927
63	0.09745647404726425	0.9686660699366243	0.14013540952704673	0.9575134164958606
64	0.09890601978759843	0.9697851386044638	0.13895388704612985	0.9552772805387943
65	0.09760796583541932	0.970568486965439	0.14391447449093	0.9566189621130341
66	0.09535630196733141	0.9706803937521808	0.14994573391880672	0.9534883717731415
67	0.09617133103744623	0.9707923010191751	0.1416026854184531	0.9566189621130341
68	0.0895712820407847	0.9742614146098562	0.14167863189214458	0.9561717349216209
69	0.09043950176628551	0.9726947181013512	0.13754280876494904	0.9561717349216209
70	0.0887786225084759	0.9733661590352481	0.13706741211452722	0.9561717353481299
71	0.0884918998576694	0.9722470906875768	0.1434050400696415	0.9552772805387943
72	0.08807780531601064	0.9722470905274927	0.17678916189079846	0.9432021459441279
73	0.08633903642464345	0.9747090420769919	0.13951270863387155	0.9566189621130341
74	0.0858944256255535	0.9757162043849805	0.14253336918908496	0.9566189621130341
75	0.08329639535800837	0.9740376003960359	0.14759407641636024	0.9539355989645547
76	0.08062977314448933	0.9750447625973018	0.14083689488537196	0.9570661893044473
77	0.07992018647858791	0.9747090419169079	0.13838338665330985	0.9579606436872738
78	0.08075457036281763	0.9742614143430492	0.13751836294351621	0.9548300542003993
79	0.07772762535828613	0.9754923904379671	0.14599398623532175	0.952593917390315
80	0.07708839677280897	0.975492390117799	0.1448598230834084	0.9530411445817282
81	0.07698314986462666	0.9764995524791489	0.14263126254081726	0.9557245077302077
82	0.07577452202300035	0.9764995523190648	0.13859642962117102	0.9575134164958606
83	0.0735746417711543	0.9778424347738336	0.1428569027477599	0.9552772805387943
84	0.07250534211458003	0.9785138762947055	0.139217088708724	0.9570661897309565
85	0.07180860271092067	0.9788495968150154	0.14144835435853662	0.9552772805387943
86	0.07292174160373777	0.9780662489876538	0.13718658653696023	0.9575134169223697
87	0.07171587057698488	0.9762757384254128	0.13663526601782852	0.9566189625395431
88	0.06876254560644325	0.97896150370848	0.13973829848608518	0.9552772809653035
89	0.06790698216285894	0.9799686661765526	0.14909267036347568	0.9539355989645547
90	0.06679831997507261	0.9795210387627782	0.13849456872197938	0.9557245081567167
91	0.0651427954768857	0.9787376903484416	0.13919401006216653	0.9557245085832258
92	0.06370531665553125	0.9799686657496617	0.14688403120727572	0.952593917390315
93	0.06843238703126125	0.9795210387627782	0.13902599325866732	0.9548300537738902
94	0.06465464869752566	0.9796329452293518	0.13759399278752493	0.9543828270089861
95	0.06275670806357876	0.9815353628451416	0.1565918669717683	0.9521466897723927
96	0.06214958707649418	0.9816472697386063	0.13905019828906426	0.9566189629660523
97	0.06147318909023101	0.9807520143240823	0.14065494155094746	0.9539355998175728
98	0.06220863922269833	0.9820948973124648	0.14166662427521776	0.9543828270089861
99	0.05774176908505208	0.9818710832587287	0.14371227892865435	0.9548300542003993

The optimal condition:
	epoch: 77
	train_acc: 0.9747090419169079
	val_acc: 0.957960643687
	using time: 778.394269943
