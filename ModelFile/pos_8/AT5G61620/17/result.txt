The number of train datas: 4330
The number of test datas: 1084
epoch	train_loss	train_acc	val_loss	val_acc
0	0.700721063597373	0.5180138564550298	0.686138544795258	0.5525830247305417
1	0.693828362900996	0.5212471129574897	0.6817245058907794	0.5968634699543464
2	0.6865478627676226	0.5510392604468877	0.67906405784987	0.5940959409594095
3	0.6847935296922028	0.5448036955355496	0.6759874774521127	0.619003690476787
4	0.677203205055783	0.5812933020173264	0.6723180325268819	0.6208487091469149
5	0.6754925206131528	0.5787528866708417	0.6676723600753559	0.6420664204442633
6	0.6675663128736112	0.6002309474603684	0.6628126011563403	0.6549815511351582
7	0.668152429820759	0.5956120091002203	0.6593027704316312	0.6457564566848023
8	0.6617804903356362	0.6103926090114937	0.6510056065897221	0.6835793366731313
9	0.6545986307961286	0.6189376436810571	0.6443824988009745	0.6964944645047628
10	0.6468190106728886	0.6369515008243622	0.6358579863481416	0.7140221404413456
11	0.6384121076339387	0.6561200917180086	0.6279004592297261	0.7158671573519266
12	0.6274028379977713	0.6579676676842687	0.6151248869860744	0.7333948330685661
13	0.6236777884304936	0.6674364891118321	0.6047031355959903	0.7527675283351067
14	0.6086503727056137	0.6866050814370911	0.5899268153408797	0.7693726950465973
15	0.5939703435325182	0.6983833717143563	0.5757703875703565	0.7684501836220716
16	0.5799473009814291	0.7286374138629464	0.5553378797105317	0.7998154970552649
17	0.5610441436393157	0.7323325634002685	0.534154072678837	0.8108856101757486
18	0.5417839293391821	0.7496535801447016	0.5105039249706972	0.8219557182375355
19	0.5236977661454375	0.7621247110410871	0.4924100432888608	0.8311808129078347
20	0.4981497389064375	0.7831408773228423	0.46181126373280457	0.8487084866449842
21	0.4772489625366951	0.7953810628236855	0.442846239822817	0.8523985253048999
22	0.4573236717638188	0.8101616633131102	0.4113451407404403	0.8726937256176094
23	0.430665320598501	0.8295612008687255	0.38509599144168444	0.8874538740988587
24	0.4111103262554415	0.8383371831363123	0.36338752101268273	0.8939114386745045
25	0.3943301813707065	0.8436489604912509	0.34363682958472697	0.895756457784519
26	0.3660235724603331	0.8644341806341264	0.3221475988956395	0.9031365324650303
27	0.3513146218746969	0.869053117920565	0.3052355185206086	0.9059040577209304
28	0.33169855279955524	0.8849884529587303	0.29011894350122264	0.9123616247159528
29	0.3226418746949343	0.8806004623893227	0.27956760204586156	0.9086715853962072
30	0.3116931223291172	0.893071592955336	0.2691680880270321	0.9132841315216684
31	0.2966614794786202	0.8965357965464955	0.25675276482677106	0.9151291523912296
32	0.29580151716776315	0.8930715936711424	0.25183982756744894	0.9160516616163219
33	0.2767332396799092	0.903233255938074	0.2433531187007348	0.9197416985166909
34	0.27528628324250976	0.9113163972011064	0.23776268084770638	0.9197416985166909
35	0.25918784696290453	0.9131639726167463	0.23195245411123297	0.9188191892915986
36	0.25707888868196455	0.9108545036293894	0.22522363539551457	0.9197416985166909
37	0.2495119641752221	0.9150115471238628	0.22256113280889292	0.9225092253121943
38	0.2391214312499445	0.9193995380787046	0.2167383991044386	0.9234317345372866
39	0.23533818273015716	0.923094688194178	0.21687362318329265	0.9243542437623787
40	0.23814277695728506	0.922632794622461	0.2111120115676929	0.9261992630923366
41	0.22178756991104495	0.9254041577596863	0.2088739848334851	0.9271217714376555
42	0.2215853784706521	0.9293302534634191	0.2089929560893576	0.925276752987471
43	0.21905387111403926	0.932563510915699	0.2028728040052076	0.9298892991129323
44	0.2112096888088464	0.9325635100071755	0.20303989891856358	0.9298892991129323
45	0.21012448799252234	0.9330254043222299	0.19936521323844517	0.9317343175631168
46	0.2077624053382433	0.9330254039367958	0.2017303562252284	0.9308118074582512
47	0.19776684904759256	0.9357967663582147	0.19520006617496813	0.9317343175631168
48	0.19237297550359994	0.9376443419665718	0.19255645551144857	0.932656826788209
49	0.20127061823636774	0.9341801383754123	0.19351942111425294	0.932656826788209
50	0.19752236835262793	0.9411085451998281	0.18903578603399634	0.9354243544634858
51	0.18249014503135416	0.9431870669470648	0.1878902617965677	0.9354243544634858
52	0.1860970399671559	0.939260969398754	0.18693925412818516	0.936346863688578
53	0.17895377956279154	0.9443418021014877	0.18494500610221357	0.9372693729136703
54	0.1837361874467506	0.9457274822935496	0.18553029204206714	0.9409594089342659
55	0.17395194534892022	0.9452655894376389	0.1832295997666257	0.9381918821387625
56	0.16906809859820932	0.948960738837306	0.1821318187946763	0.9381918821387625
57	0.1709367405322077	0.9459584300842901	0.1829162996083608	0.9409594089342659
58	0.16872140568343377	0.9498845261734573	0.18020273503122294	0.9391143913638548
59	0.16612444775346796	0.9505773673707288	0.1861233545185455	0.9391143904840814
60	0.16157627517301545	0.9533487295994307	0.17877165940194992	0.9400369005889471
61	0.1624365008317846	0.9528868365508029	0.17900895379566178	0.9409594106938126
62	0.15181320773536558	0.9551963050150706	0.18127893719725943	0.9455719550597271
63	0.15501211885423088	0.95658198595047	0.17694033022516328	0.9437269366095427
64	0.15454022512011936	0.9542725174862022	0.1781573900437443	0.9428044291439971
65	0.15084349778039902	0.9558891456617219	0.17605629101450593	0.9455719550597271
66	0.14439178337332284	0.9556581993301251	0.17562996615342988	0.9437269366095427
67	0.14350055617562066	0.9531177828823997	0.17477416348853234	0.9437269366095427
68	0.14836540834733025	0.9554272513466674	0.174814572468455	0.9464944642848194
69	0.1398087590795191	0.9577367210773617	0.17297268887067632	0.9464944642848194
70	0.14335131405682816	0.9605080834987808	0.17348106551874168	0.9474169735099117
71	0.13847839512946147	0.9570438797149041	0.1735814325373991	0.9455719568192739
72	0.12971539117447498	0.9612009235948118	0.17252869249709857	0.9474169735099117
73	0.13453704262578184	0.9605080833060636	0.17343276744619066	0.9464944660443662
74	0.1309568420086942	0.9586605086062301	0.173376003369634	0.9464944642848194
75	0.1301659063296285	0.9614318702843118	0.17261424875127435	0.9483394836147773
76	0.1273294472219487	0.9607390298303776	0.17127530595693202	0.9492619919600962
77	0.12309501451240125	0.9655889147148397	0.17076613690800332	0.9501845011851884
78	0.11900157357198261	0.9630484986525485	0.17049677367579893	0.9511070104102807
79	0.1220982752172556	0.9614318710276492	0.1702692868854727	0.951107011290054
80	0.12341565739268794	0.9577367207194586	0.17184640791583325	0.9492619919600962
81	0.1190026946400247	0.9625866045302112	0.1703821066010922	0.9501845020649617
82	0.11304650222043792	0.9669745962008593	0.17030920896582938	0.951107011290054
83	0.12107137656377039	0.9628175521282346	0.1730671290212012	0.9501845020649617
84	0.11298873476838955	0.9648960742609055	0.17000295370267327	0.952029519635373
85	0.11441997490633993	0.9632794455347656	0.16955400469998153	0.9501845011851884
86	0.10602992076177245	0.9648960737102852	0.16967937476740552	0.9511070104102807
87	0.09930170484695919	0.9704387988834954	0.16984567705995482	0.9511070104102807
88	0.10934538520511249	0.9660508090298942	0.1703913994270937	0.9501845020649617
89	0.10986615767311003	0.9662817559121112	0.16955441643391148	0.9501845011851884
90	0.09887150458251631	0.9685912243763789	0.16965701114867446	0.951107011290054
91	0.10510792458993458	0.9678983833442935	0.16959953363091304	0.9501845020649617
92	0.10021459773079627	0.9685912247342822	0.16949004468222825	0.9492619928398696
93	0.09787481714891781	0.9688221710658789	0.17426627995343225	0.9501845020649617
94	0.09904203768690518	0.9690531173974757	0.17458860878574892	0.9483394836147773
95	0.09624665660340571	0.9688221716164992	0.1695971948084356	0.9492619928398696
96	0.09002590356330123	0.9732101620207207	0.1694783793274327	0.9529520297402385
97	0.09254010001726569	0.9674364892219561	0.1693929778583815	0.9511070104102807
98	0.08476177176619787	0.9729792142299802	0.17159351057671973	0.9501845020649617
99	0.0889810323577555	0.9711316404386701	0.1711611447519042	0.9538745380855574

The optimal condition:
	epoch: 99
	train_acc: 0.9711316404386701
	val_acc: 0.953874538086
	using time: 387.868129969
