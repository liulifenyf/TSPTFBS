The number of train datas: 2078
The number of test datas: 520
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6896990667293574	0.5360923968793339	0.6837007761001587	0.5865384615384616
1	0.6836896014397137	0.559672762672986	0.6771130690207848	0.6192307692307693
2	0.6777448786119639	0.5745909531261051	0.6695650458335877	0.6480769230769231
3	0.6659024223556188	0.5957651586918101	0.6593742233056289	0.6961538461538461
4	0.6565915900313934	0.6361886428111556	0.6455225055034344	0.7384615384615385
5	0.6376679781196896	0.6871992302583432	0.6252687289164617	0.7634615384615384
6	0.619666362233295	0.6987487971495848	0.5976286264566275	0.8115384615384615
7	0.5883187706133169	0.7406159771303354	0.5571095255705026	0.85
8	0.5431830514727933	0.8022136667580186	0.5024270873803359	0.8865384615384615
9	0.4874331746053191	0.8580365733416523	0.4368562698364258	0.9019230769230769
10	0.4337918409312196	0.8642925890852787	0.369291745699369	0.926923076923077
11	0.367126942541418	0.9027911449878462	0.305388480424881	0.9326923076923077
12	0.3121624398506869	0.9071222329736329	0.26274807911652787	0.9211538461538461
13	0.27285122636192916	0.9191530313597377	0.22382310445492085	0.9346153846153846
14	0.23550225986495857	0.9287776704357724	0.20181385645499597	0.9403846153846154
15	0.22843809017805783	0.9302213666987488	0.1882345410493704	0.9384615384615385
16	0.20303571261501405	0.9364773816966001	0.17566577104421763	0.9423076923076923
17	0.19628295824433659	0.9350336858351949	0.17448411446351272	0.9346153846153846
18	0.1890834549135377	0.9359961498001657	0.16653914268200215	0.9384615384615385
19	0.17688078564502965	0.9432146290498243	0.16371669127390934	0.9384615384615385
20	0.17850964766666222	0.9408084697397542	0.15827596691938547	0.9423076923076923
21	0.1687829972632925	0.9417709331884191	0.16096309423446656	0.9384615384615385
22	0.1641418450692161	0.9412897012346174	0.15733319520950317	0.9403846153846154
23	0.15931262732039747	0.9446583249112296	0.14814571417295017	0.9461538461538461
24	0.1714422828423736	0.9427333975549611	0.1571829066826747	0.9442307692307692
25	0.168069574928146	0.9384023095691744	0.14690004266225376	0.9442307692307692
26	0.15961774539012422	0.9461020212315733	0.15187739500632652	0.948076923076923
27	0.15844904808497864	0.9461020207726347	0.1494281420340905	0.9461538461538461
28	0.14551207449025438	0.9509143407695906	0.14594390850800734	0.9461538461538461
29	0.15644081103632493	0.9427333974975939	0.1457023038313939	0.948076923076923
30	0.14663397032441258	0.9499518768619871	0.14604162986461933	0.95
31	0.1367867305745748	0.953801732492401	0.14453788904043344	0.95
32	0.1458501202539255	0.9538017320334624	0.14220262444936313	0.95
33	0.14587449524784685	0.9542829639872642	0.14057818880447975	0.9519230769230769
34	0.1396882106783989	0.9513955727233924	0.14133163598867562	0.9519230769230769
35	0.13622633778670296	0.9528392685847975	0.1371678311091203	0.95
36	0.14387273475800258	0.9528392681832263	0.1380324588372157	0.9519230769230769
37	0.1303788309520661	0.9518768042756228	0.1388687340112833	0.9519230769230769
38	0.13197170370065672	0.9533205000796607	0.1350097614985246	0.9519230769230769
39	0.13258205523447306	0.9470644851391767	0.13877513408660888	0.9519230769230769
40	0.13041327830629926	0.9576515881228148	0.13731059707128085	0.9519230769230769
41	0.12783404327104364	0.9566891242725787	0.13890222952916073	0.9519230769230769
42	0.12766715722146002	0.9595765159380218	0.13637876510620117	0.9519230769230769
43	0.13110603190621467	0.9557266603076079	0.14126717218985924	0.9519230769230769
44	0.12884724928967878	0.9562078918024711	0.1310944419640761	0.9557692307692308
45	0.1260889840381322	0.9562078918024711	0.13584229854437022	0.9538461538461539
46	0.11920444683832429	0.9615014436958614	0.1290464304960691	0.9557692307692308
47	0.12150378158823358	0.9552454278948677	0.13268387546906105	0.9538461538461539
48	0.11690092132685848	0.9595765155364505	0.13092992718403157	0.9538461538461539
49	0.12896476911884644	0.9552454283538062	0.13163822614229642	0.9557692307692308
50	0.12058271043884627	0.9557266598486693	0.13097836008438699	0.9557692307692308
51	0.11614830718089802	0.9605389793866868	0.13268985427342928	0.9557692307692308
52	0.11920064055254187	0.9615014432942902	0.12749699033223666	0.9557692307692308
53	0.11802099504050036	0.9615014436958614	0.1254062139070951	0.9538461538461539
54	0.11258976903669643	0.96390760346487	0.13201652260927055	0.9557692307692308
55	0.10895057739663055	0.9586140515714798	0.12667569242990934	0.9538461538461539
56	0.10656687465637091	0.9663137628323075	0.12754266262054442	0.9557692307692308
57	0.11203095366366214	0.9677574591526512	0.12557481481478763	0.9538461538461539
58	0.11013427124330927	0.9653512993836426	0.13138387340765734	0.9557692307692308
59	0.11181686014740139	0.9663137632338787	0.12368203264016371	0.9557692307692308
60	0.11194508174959573	0.96535129944101	0.12520744983966534	0.9538461538461539
61	0.10864847426637075	0.9639076030632988	0.12852671054693368	0.9557692307692308
62	0.1036360868440154	0.9658325308785057	0.11962944544278659	0.9557692307692308
63	0.10159063726462804	0.9663137633486134	0.12581338653197655	0.9538461538461539
64	0.10084799737369246	0.9672762271414822	0.12461234422830435	0.9538461538461539
65	0.10454961367819146	0.9643888354760392	0.1253401008936075	0.9538461538461539
66	0.10432733471314418	0.9663137632912461	0.12201489897874686	0.9557692307692308
67	0.10656588956986171	0.9653512993262753	0.11897570215738737	0.9557692307692308
68	0.10367418898769705	0.9629451391556954	0.11928007923639737	0.9557692307692308
69	0.10017787165315939	0.9672762271988495	0.11708585207278911	0.9576923076923077
70	0.09931191519849339	0.9701636188642926	0.1229953775039086	0.9538461538461539
71	0.09562978476888291	0.9687199230028873	0.11805749489710882	0.9557692307692308
72	0.09895147910992382	0.9687199230602547	0.12610260935930107	0.9538461538461539
73	0.09671515428583936	0.9735322425982721	0.11639635792145363	0.9576923076923077
74	0.09325261822076114	0.9696823865089196	0.11925762479121868	0.9538461538461539
75	0.09728274401008394	0.9692011549566891	0.11728793749442468	0.9557692307692308
76	0.08853543093705889	0.9711260823703248	0.11856141411341153	0.9557692307692308
77	0.09066444344969181	0.9692011545551179	0.11690723987726065	0.9557692307692308
78	0.09980211378979614	0.9716073144388612	0.1114755800137153	0.9576923076923077
79	0.09027628736127674	0.9701636188642926	0.11665444098986112	0.9557692307692308
80	0.09098631445465465	0.9711260823703248	0.1118159803060385	0.9576923076923077
81	0.09811847138508108	0.9682386906475144	0.11275964425160334	0.9576923076923077
82	0.09506739231043418	0.9706448508180944	0.11755888599615831	0.9557692307692308
83	0.08914350176855736	0.9687199230028873	0.11116400498610277	0.9576923076923077
84	0.09131564912713412	0.9735322421393334	0.11111622911233168	0.9576923076923077
85	0.08722885404251825	0.9720885466794995	0.11510053001917325	0.9557692307692308
86	0.08080378090165004	0.97256977823173	0.11545825187976544	0.9557692307692308
87	0.08086581974934798	0.9764196342637151	0.11706140408149132	0.9538461538461539
88	0.08363030518156847	0.9749759380007387	0.11105195421438951	0.9596153846153846
89	0.08222871040701292	0.9769008662748841	0.11129703338329609	0.9596153846153846
90	0.08402283852193881	0.973051010587103	0.11886500762059138	0.9538461538461539
91	0.07512284988847573	0.974494706046937	0.11097413714115437	0.9576923076923077
92	0.08207269738983144	0.9749759380007387	0.10955051825596736	0.9576923076923077
93	0.08287275953288258	0.9701636184627214	0.11522038854085483	0.9538461538461539
94	0.08361453233829935	0.9735322421393334	0.11100128293037415	0.9576923076923077
95	0.07366557817285857	0.9754571699545405	0.10644659675084628	0.9596153846153846
96	0.08412789665987219	0.9740134740931352	0.10730247818506682	0.9576923076923077
97	0.07492467848524896	0.9754571699545405	0.10814345203913175	0.9576923076923077
98	0.06842560622988124	0.9788257940327237	0.10524088052602915	0.9596153846153846
99	0.07632483004863957	0.9749759380007387	0.10586307553144601	0.9596153846153846

The optimal condition:
	epoch: 99
	train_acc: 0.9749759380007387
	val_acc: 0.959615384615
	using time: 182.624136209
