The number of train datas: 2078
The number of test datas: 520
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6924165973190624	0.529836381164391	0.6858592840341421	0.5461538461538461
1	0.6829009498967014	0.5514918189420507	0.6790754254047687	0.5942307692307692
2	0.6736548627306339	0.5861405201320813	0.6713725401804997	0.6384615384615384
3	0.6641860499304	0.6116458136262058	0.661145202930157	0.6788461538461539
4	0.6541202056281721	0.6434071220608143	0.6463974961867699	0.7230769230769231
5	0.6338792046293602	0.6698748795199095	0.6254488193071805	0.75
6	0.6125360052670505	0.7069297399052756	0.5973964581122765	0.7903846153846154
7	0.5825495635006035	0.7526467759180114	0.5606016452495869	0.8403846153846154
8	0.5393849610708675	0.8007699713555521	0.5131947829173161	0.8923076923076924
9	0.49563919419388686	0.8339749756515658	0.45867093251301694	0.9
10	0.45082581877937905	0.8575553417894218	0.39962702164283165	0.9192307692307692
11	0.39964451060717326	0.8840230988469459	0.34176613275821394	0.9307692307692308
12	0.3446354940892184	0.9051973047568548	0.2936905975525196	0.9326923076923077
13	0.3029787978005019	0.9124157840065135	0.25234428002284126	0.9423076923076923
14	0.26251367794365926	0.9186717998075072	0.2231098697735713	0.9403846153846154
15	0.24735176282163074	0.9196342633135395	0.2069269434763835	0.9384615384615385
16	0.21914280576701342	0.9307025982509793	0.1878825334402231	0.9423076923076923
17	0.21013876939187037	0.9331087584789265	0.17732459077468285	0.9442307692307692
18	0.1970057673071071	0.9307025987099179	0.1729070381476329	0.9423076923076923
19	0.1848323559594682	0.9441770929574278	0.16772162180680494	0.9423076923076923
20	0.18608031600455577	0.9379210780169438	0.16154348712701064	0.9442307692307692
21	0.17253202157627515	0.9408084692808156	0.16060107144025657	0.9423076923076923
22	0.16598361344063248	0.9436958610036261	0.1593857554289011	0.9423076923076923
23	0.16849778218264758	0.9441770934163664	0.1535981801839975	0.9461538461538461
24	0.17476317266412833	0.9456207892777716	0.15407045758687532	0.9423076923076923
25	0.1697591770659053	0.9388835419245473	0.14830891398283153	0.948076923076923
26	0.1596754774006659	0.9446583253701681	0.14914058401034427	0.9442307692307692
27	0.16218407375377686	0.9465832527264365	0.14569095831650955	0.948076923076923
28	0.1485471766768337	0.9552454283538062	0.14430592151788565	0.95
29	0.15946958116161583	0.9436958614051973	0.14293735715059133	0.95
30	0.1501755888526318	0.9485081810579493	0.14613890785437364	0.9461538461538461
31	0.14150406621016484	0.9499518768619871	0.14071808044727033	0.95
32	0.14738951839284328	0.9499518764030486	0.13962579965591432	0.95
33	0.14744049796872236	0.9504331083568504	0.13895455873929538	0.95
34	0.14475915337893916	0.9533205000796607	0.13990713403775143	0.95
35	0.13659598937220477	0.9552454278948677	0.13653937440652114	0.95
36	0.1473185885858949	0.9499518768619871	0.1372013353384458	0.9519230769230769
37	0.12768578070419356	0.9600577478918235	0.1370985971047328	0.9519230769230769
38	0.13741409665294516	0.9557266598486693	0.13495787657224215	0.9519230769230769
39	0.13264748199526455	0.952839268125859	0.1346144777077895	0.9519230769230769
40	0.1370645192549479	0.9557266598486693	0.13699553379645715	0.9538461538461539
41	0.13113003108682714	0.9581328196750454	0.137174686560264	0.9538461538461539
42	0.12821692984131694	0.9581328200766166	0.13374549929912274	0.9557692307692308
43	0.12963302766221205	0.9581328200766166	0.13678166407805223	0.9538461538461539
44	0.13137504875774678	0.9615014432942902	0.1297293314566979	0.9557692307692308
45	0.12571363911190436	0.9576515876638763	0.1355126394675328	0.9538461538461539
46	0.12070784309773175	0.9571703561690131	0.12577685392819918	0.9538461538461539
47	0.12510231511956	0.9562078922040423	0.1313448415352748	0.9557692307692308
48	0.11764186726841822	0.9619826753054592	0.13002395171385545	0.9557692307692308
49	0.13005617076640408	0.9542829639872642	0.13101428563778217	0.9557692307692308
50	0.12197217293607145	0.9557266598486693	0.12660132646560668	0.9576923076923077
51	0.11360323905973507	0.9634263711094971	0.12871102140499996	0.9576923076923077
52	0.12281857208636543	0.9615014437532288	0.12713147539358874	0.9576923076923077
53	0.11883883176441372	0.9629451395572666	0.12399871899531438	0.9538461538461539
54	0.11480252702179955	0.9615014436958614	0.12946482071509727	0.9576923076923077
55	0.11169365577622029	0.9605389798456253	0.12711101953799908	0.9576923076923077
56	0.10795642624145751	0.9653512989247041	0.12780628066796523	0.9596153846153846
57	0.11424970411703607	0.9653512989247041	0.12647135578669033	0.9576923076923077
58	0.10685677186758961	0.9672762267972783	0.1294056548522069	0.9596153846153846
59	0.10586992755560948	0.9667949951876804	0.12302043667206397	0.9557692307692308
60	0.11126959206280052	0.963426371625803	0.12473540856288029	0.9615384615384616
61	0.10757743301904465	0.967276226739911	0.13141077848581167	0.9557692307692308
62	0.10591786743443786	0.9677574590952839	0.11928146664912884	0.9576923076923077
63	0.10575425458482186	0.9634263711668645	0.12539009360166697	0.9615384615384616
64	0.10091010412995464	0.9672762271414822	0.12357249993544359	0.9596153846153846
65	0.10081987035630183	0.968238691106453	0.12795274762006906	0.9576923076923077
66	0.10733444719818261	0.9663137628323075	0.12440103384164664	0.9615384615384616
67	0.10720834896843288	0.9667949951876804	0.11926956956203168	0.9576923076923077
68	0.1040269691672775	0.9619826752480919	0.12014754918905404	0.9596153846153846
69	0.10115498192500792	0.9672762271988495	0.11825947853235098	0.9576923076923077
70	0.10097225856204464	0.9692011549566891	0.12197275620240432	0.9596153846153846
71	0.09454272027352432	0.9677574590952839	0.1205560890527872	0.9596153846153846
72	0.10433520174462481	0.9692011550140565	0.12666963568100562	0.9576923076923077
73	0.09758901545872932	0.9696823865089196	0.11980164096905635	0.9596153846153846
74	0.09476734377278859	0.9735322421393334	0.12028451011731074	0.9576923076923077
75	0.09507913619308545	0.9716073147256978	0.11872335901627173	0.9596153846153846
76	0.08737850607273324	0.9720885462779283	0.12113823340489314	0.9557692307692308
77	0.08830038602244292	0.9687199226013161	0.11844372015732985	0.9596153846153846
78	0.10106117175793396	0.9696823866236542	0.11334176934682406	0.9634615384615385
79	0.08953699533387488	0.9677574586937127	0.11784769204946664	0.9576923076923077
80	0.09190567254417785	0.9716073143241265	0.11312734805620633	0.9634615384615385
81	0.10033477642739244	0.9667949947861092	0.11612425263111407	0.9596153846153846
82	0.0935094812929745	0.971126082771896	0.12047782219373263	0.9538461538461539
83	0.08938164205162197	0.9696823865089196	0.11354024777045617	0.9634615384615385
84	0.0909052270825834	0.9716073143241265	0.11485628393980173	0.9615384615384616
85	0.08641695302549868	0.9701636188642926	0.11676163765100332	0.9596153846153846
86	0.08283090764966805	0.974494706046937	0.12037920172397908	0.9538461538461539
87	0.08000909395809926	0.97256977823173	0.12106351944116446	0.9538461538461539
88	0.08450006541578212	0.97256977823173	0.11300474130190336	0.9653846153846154
89	0.08108459625310686	0.9720885467368668	0.11608328406627362	0.9615384615384616
90	0.08563819088766045	0.973051010587103	0.12090443372726441	0.9538461538461539
91	0.08066947091661243	0.9764196342637151	0.11484193343382615	0.9596153846153846
92	0.08539815346734586	0.9754571699545405	0.11419855723014245	0.9596153846153846
93	0.08156376296190027	0.9716073143241265	0.11419478975809537	0.9576923076923077
94	0.08506973457089746	0.9740134740931352	0.11475773545411917	0.9576923076923077
95	0.0756026671713539	0.9778633297235491	0.11150590639847975	0.9634615384615385
96	0.08191668757087801	0.9725697786906685	0.10824083823424119	0.9653846153846154
97	0.07226851261987263	0.9773820982286859	0.1123793322306413	0.9596153846153846
98	0.0746920364079737	0.9769008662175168	0.10735480326872605	0.9653846153846154
99	0.07551328958342922	0.9773820977697474	0.10887003449293284	0.9615384615384616

The optimal condition:
	epoch: 98
	train_acc: 0.9769008662175168
	val_acc: 0.965384615385
	using time: 166.228419065
