The number of train datas: 2078
The number of test datas: 520
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6841685750716231	0.5486044273626587	0.6792223453521729	0.6134615384615385
1	0.6743082315217312	0.5822906644443001	0.6701096965716435	0.6634615384615384
2	0.6656118286585326	0.6005774781724601	0.6588857925855196	0.7038461538461539
3	0.6516709206079037	0.6482194417135663	0.643452641597161	0.7480769230769231
4	0.6369587220287415	0.6819056783649529	0.6235149236825797	0.7769230769230769
5	0.6149320128562935	0.7117420599022315	0.5971565374961266	0.7923076923076923
6	0.5856974911414395	0.7468719920134521	0.5635558926142179	0.8576923076923076
7	0.554030875785633	0.7844080844099873	0.5228557201532217	0.8788461538461538
8	0.5099504129374911	0.82242540927663	0.47412745035611664	0.9
9	0.4663204732884342	0.8614051974198357	0.42500994618122395	0.9057692307692308
10	0.4232383085857571	0.8700673725882668	0.3712249985108009	0.9230769230769231
11	0.37566270586730655	0.8888354183275959	0.32519341707229615	0.9230769230769231
12	0.3287651033442794	0.9051973047568548	0.2844136701180385	0.9230769230769231
13	0.29073746618568264	0.9205967272211429	0.2482711645273062	0.9307692307692308
14	0.2622266133836649	0.9230028869901515	0.22298056712517372	0.9346153846153846
15	0.24456018068907465	0.9215591915303176	0.20712007926060602	0.926923076923077
16	0.2196406543369587	0.9292589028485126	0.1879989280150487	0.9326923076923077
17	0.21369642845361247	0.928777670894711	0.17904299887327046	0.9346153846153846
18	0.19440628536569027	0.9379210780169438	0.17164972126483918	0.9384615384615385
19	0.18686762267115944	0.9398460053732122	0.1658356950833247	0.9423076923076923
20	0.1915634740879033	0.9355149182479352	0.1597811485712345	0.9442307692307692
21	0.16942693846689266	0.944177093358999	0.16052334010601044	0.9365384615384615
22	0.16765154196134086	0.9417709335899904	0.1542760505126073	0.9442307692307692
23	0.16820909797112682	0.9412897012346174	0.1466688816363995	0.9461538461538461
24	0.1707887911704782	0.9436958610609933	0.1504885359452321	0.9461538461538461
25	0.16836638215129712	0.9465832531853751	0.14293482647492337	0.948076923076923
26	0.15199488950705045	0.9542829644462028	0.14442753562560448	0.948076923076923
27	0.16138234520841951	0.9494706449081854	0.13792062676869907	0.95
28	0.14513967098010286	0.9547641964000044	0.13729986731822674	0.95
29	0.1539724482953032	0.9446583253128008	0.13577201801996966	0.95
30	0.14350665068832927	0.951876804677194	0.1375778269309264	0.9538461538461539
31	0.13864087836173317	0.9533205005385993	0.13262920654737032	0.9519230769230769
32	0.14314921487112017	0.9547641959410659	0.13143419348276578	0.9538461538461539
33	0.14776228619981432	0.9494706444492469	0.12937313753824967	0.9519230769230769
34	0.1380950918957175	0.9494706449081854	0.1345818755718378	0.9557692307692308
35	0.13459137126559587	0.953801732492401	0.1251716959934968	0.9557692307692308
36	0.14288803522006266	0.9528392685847975	0.12711630967947152	0.9576923076923077
37	0.1274485141182313	0.9562078918598385	0.12603735098472008	0.9576923076923077
38	0.1254054966514448	0.9576515876638763	0.12373316746491653	0.9576923076923077
39	0.13267914113284765	0.9552454278948677	0.12478174498448005	0.9596153846153846
40	0.13115273237486547	0.9542829639872642	0.12691621940869552	0.9596153846153846
41	0.12297883099151186	0.9600577474902523	0.12555864545015188	0.9596153846153846
42	0.12422577808750031	0.958614051973051	0.12095306125970987	0.9615384615384616
43	0.12694872806746874	0.9581328200192493	0.12921046041525328	0.9576923076923077
44	0.12398315738094208	0.9643888350171006	0.11831461626749773	0.9596153846153846
45	0.12035175524759568	0.958132819617678	0.12730149833055643	0.9596153846153846
46	0.11668542840655201	0.960057747432885	0.11533770148570721	0.9596153846153846
47	0.11835878348843884	0.9586140520304184	0.11919527902052952	0.9615384615384616
48	0.10923524982546017	0.9653512993836426	0.11796614413078015	0.9615384615384616
49	0.12417635546066763	0.9605389793866868	0.11800451714258928	0.9615384615384616
50	0.11692423562772923	0.9586140520304184	0.1178950188251642	0.9615384615384616
51	0.1073869469578273	0.9653512993836426	0.1165760494195498	0.9615384615384616
52	0.12173676707345323	0.9605389798456253	0.11483813317922445	0.9615384615384616
53	0.10818647357874529	0.9653512993262753	0.11271820664405822	0.9615384615384616
54	0.10952832834495732	0.9634263715110684	0.12358169280565702	0.9576923076923077
55	0.10626009990092765	0.9648700669709023	0.11274537558739002	0.9615384615384616
56	0.10536537162020186	0.9653512989247041	0.11397460676156558	0.9615384615384616
57	0.10633767779138481	0.967276226739911	0.11365867027869592	0.9615384615384616
58	0.09888150395253625	0.9677574591526512	0.11535811745203459	0.9615384615384616
59	0.10297500833696878	0.9687199230028873	0.1104935503922976	0.9615384615384616
60	0.10562086251633344	0.9667949949008439	0.11184046451862041	0.9615384615384616
61	0.10089159841515676	0.9682386906475144	0.11426318196149973	0.9615384615384616
62	0.10004447213050491	0.9677574590952839	0.10718219967988821	0.9596153846153846
63	0.09976927657845619	0.9682386906475144	0.1105375010233659	0.9596153846153846
64	0.09658989801830804	0.9672762271414822	0.1105769056540269	0.9596153846153846
65	0.10259741540420962	0.9648700669709023	0.11341731479534736	0.9615384615384616
66	0.10495410120980572	0.9672762271988495	0.10971378454795251	0.9596153846153846
67	0.09905859421045879	0.9667949951876804	0.10601937495745145	0.9596153846153846
68	0.10030929047589238	0.9634263715110684	0.10957076091032762	0.9596153846153846
69	0.09541709785626644	0.9687199230602547	0.1039438417324653	0.9596153846153846
70	0.09597060606564835	0.9682386910490857	0.10976705230199374	0.9596153846153846
71	0.09123431644523454	0.9706448508180944	0.10886379044789535	0.9596153846153846
72	0.09915695747466358	0.9677574591526512	0.10633810804440424	0.9596153846153846
73	0.09324246574698788	0.9730510101855318	0.10576749489857601	0.9596153846153846
74	0.089373775722891	0.974494706046937	0.10729921872799213	0.9596153846153846
75	0.09302430993611131	0.9754571703561117	0.10558127623337965	0.9596153846153846
76	0.08804029230247104	0.973051010587103	0.1031844987319066	0.9596153846153846
77	0.0806671730005133	0.9716073143241265	0.10474627659871028	0.9596153846153846
78	0.09423731965899353	0.9720885467942342	0.09916706039355351	0.9615384615384616
79	0.08546884230286944	0.970644850416523	0.1014496610714839	0.9596153846153846
80	0.08767183932464093	0.9720885462779283	0.09942269371106074	0.9596153846153846
81	0.0960784318271569	0.9711260823703248	0.10333138612600473	0.9615384615384616
82	0.09258715272007136	0.9740134744947064	0.10501624941825867	0.9615384615384616
83	0.08682859625893218	0.9701636184627214	0.09911495309609633	0.9596153846153846
84	0.0922405463217599	0.9725697786333013	0.09997712648831882	0.9596153846153846
85	0.08816056385191733	0.9735322425409048	0.10055138789690458	0.9596153846153846
86	0.08034595636304924	0.9735322421393334	0.10264707253529476	0.9615384615384616
87	0.0762726726643275	0.9778633297235491	0.10247800992085383	0.9615384615384616
88	0.08146075350774723	0.974494706046937	0.10017940860528213	0.9615384615384616
89	0.0787593968162408	0.9783445616773508	0.10093339681625366	0.9615384615384616
90	0.08354454608571368	0.9744947064485082	0.10376204022994408	0.9596153846153846
91	0.07551584505010844	0.9783445620789221	0.09944266355954684	0.9615384615384616
92	0.0834598109714106	0.9769008658159456	0.09879731214963473	0.9615384615384616
93	0.08060574522950077	0.9735322421393334	0.09773519405951867	0.9615384615384616
94	0.08040216770220307	0.9735322421393334	0.1014961614058568	0.9596153846153846
95	0.07310392455887176	0.9773820977697474	0.09611434936523437	0.9653846153846154
96	0.08125270786224591	0.9730510101855318	0.09458540173677298	0.9653846153846154
97	0.07296756774732077	0.9826756492615664	0.09620227125974802	0.9634615384615385
98	0.0742373641766787	0.9817131857555341	0.09358025055665237	0.9653846153846154
99	0.07300594042631671	0.980269489894129	0.09511875968713027	0.9653846153846154

The optimal condition:
	epoch: 99
	train_acc: 0.980269489894129
	val_acc: 0.965384615385
	using time: 134.091025114
