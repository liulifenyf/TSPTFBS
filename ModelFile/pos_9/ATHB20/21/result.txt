The number of train datas: 4096
The number of test datas: 1026
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7084920350462198	0.51513671875	0.69491840384857	0.5019493177387915
1	0.6996181085705757	0.513916015625	0.6917476607577377	0.5165692007797271
2	0.6930972523987293	0.5283203125	0.6889566575806972	0.550682261208577
3	0.6902798227965832	0.53076171875	0.686805650504709	0.5477582846003899
4	0.6862836685031652	0.552978515625	0.6836195784470259	0.5896686159844055
5	0.6840709391981363	0.5556640625	0.6808729234494661	0.5994152046783626
6	0.6815273761749268	0.56591796875	0.6771329105713679	0.6042884990253411
7	0.6732155382633209	0.58349609375	0.6730217905769571	0.6101364522417154
8	0.6728186551481485	0.590576171875	0.6677657396007932	0.6374269005847953
9	0.6711020264774561	0.5927734375	0.6630933677476284	0.6491228070175439
10	0.6609837431460619	0.611083984375	0.6580094667206033	0.672514619883041
11	0.6593294702470303	0.617431640625	0.6508793770453618	0.6851851851851852
12	0.6507919635623693	0.629638671875	0.6418327527668973	0.6929824561403509
13	0.6360858231782913	0.66162109375	0.6303056638840346	0.6998050682261209
14	0.6306774523109198	0.661865234375	0.6191516859024822	0.7134502923976608
15	0.6205285899341106	0.662353515625	0.60565397393169	0.7348927875243665
16	0.6058715488761663	0.685546875	0.5896796186765035	0.7504873294346979
17	0.5904698204249144	0.703857421875	0.5730718453260425	0.7641325536062378
18	0.5803691204637289	0.720947265625	0.5552523804222167	0.7709551656920078
19	0.5529631488025188	0.738037109375	0.5319641908706977	0.7914230019493177
20	0.5325827533379197	0.74853515625	0.509790873666953	0.7943469785575049
21	0.5152677716687322	0.767822265625	0.48616040148000733	0.8216374269005848
22	0.48941896855831146	0.785400390625	0.4606865088493503	0.8401559454191033
23	0.4704681020230055	0.795654296875	0.4347647297219691	0.8508771929824561
24	0.44080572482198477	0.81689453125	0.4080674218968806	0.8576998050682261
25	0.41779025457799435	0.830810546875	0.38390538003477204	0.8674463937621832
26	0.3907866086810827	0.84423828125	0.3584888423511624	0.8869395711500975
27	0.3670144099742174	0.85888671875	0.3360479322441837	0.8927875243664717
28	0.3440616885200143	0.869873046875	0.31245841623282106	0.898635477582846
29	0.32657250203192234	0.873779296875	0.2972361114870967	0.9093567251461988
30	0.30641055246815085	0.88671875	0.2757899370226014	0.9181286549707602
31	0.28366595041006804	0.899169921875	0.2612466896951315	0.9210526315789473
32	0.27241214783862233	0.9013671875	0.2456371178868686	0.9239766081871345
33	0.2543994844891131	0.9150390625	0.2344569276880335	0.9278752436647173
34	0.24108500126749277	0.9169921875	0.2232619174855959	0.9298245614035088
35	0.2270976286381483	0.9189453125	0.21247218768557144	0.9317738791423001
36	0.21812429931014776	0.927001953125	0.20340330163870174	0.9346978557504874
37	0.2065274710766971	0.928466796875	0.19610763280189525	0.935672514619883
38	0.195780529640615	0.9365234375	0.18914758618812114	0.9385964912280702
39	0.19065458816476166	0.9384765625	0.18490374671407842	0.9395711500974658
40	0.1790798914153129	0.944091796875	0.17966318872646514	0.9444444444444444
41	0.16768059879541397	0.943359375	0.17190339631940188	0.942495126705653
42	0.17067584791220725	0.946533203125	0.16878222734404122	0.9434697855750487
43	0.15791259915567935	0.94970703125	0.16416205073657789	0.949317738791423
44	0.1589972444344312	0.9501953125	0.15987958361124202	0.9454191033138402
45	0.14494108129292727	0.95263671875	0.1572561387415634	0.9532163742690059
46	0.1436454439535737	0.956298828125	0.15410371098602027	0.9532163742690059
47	0.13574105012230575	0.960693359375	0.1506172545820649	0.9502923976608187
48	0.1398354284465313	0.95654296875	0.14886019189005126	0.9502923976608187
49	0.1304337156470865	0.960205078125	0.14619837496901697	0.9551656920077972
50	0.12642983929254115	0.963623046875	0.14383973308691853	0.956140350877193
51	0.1242068293504417	0.96630859375	0.1419274087116616	0.956140350877193
52	0.1182953326497227	0.966064453125	0.14589130169880843	0.9551656920077972
53	0.1185418744571507	0.966796875	0.13832275839213856	0.956140350877193
54	0.11413164436817169	0.9658203125	0.13768289105868653	0.956140350877193
55	0.11692959303036332	0.96484375	0.13742734314093175	0.9580896686159844
56	0.10929143987596035	0.9677734375	0.1343191767322012	0.9590643274853801
57	0.1122565483674407	0.96923828125	0.14012006303516977	0.9590643274853801
58	0.10731097287498415	0.972412109375	0.13203911387977021	0.9590643274853801
59	0.09582224360201508	0.970947265625	0.1320005568692036	0.9600389863547758
60	0.10015749384183437	0.96923828125	0.13074199493691238	0.9571150097465887
61	0.10060407721903175	0.97216796875	0.12993015909520272	0.9590643274853801
62	0.09436370572075248	0.973876953125	0.12905854601993955	0.9580896686159844
63	0.09451616229489446	0.9716796875	0.12977793598166334	0.9619883040935673
64	0.09189983794931322	0.978271484375	0.12685717957831383	0.9619883040935673
65	0.09265232365578413	0.97265625	0.1271158594903164	0.9619883040935673
66	0.0931589303072542	0.970703125	0.12927679791792385	0.9649122807017544
67	0.08763220813125372	0.975830078125	0.1250944427644823	0.9629629629629629
68	0.0893858103081584	0.972900390625	0.12463379265344747	0.9619883040935673
69	0.08798734762240201	0.975830078125	0.12821966073281527	0.9658869395711501
70	0.08599503530422226	0.97705078125	0.12666416096865957	0.9649122807017544
71	0.08456289349123836	0.977783203125	0.12572458066267722	0.9639376218323586
72	0.08370804536389187	0.97412109375	0.12275376329724959	0.9639376218323586
73	0.07936172804329544	0.978515625	0.12490901012848664	0.9649122807017544
74	0.08256702346261591	0.978515625	0.12263935102698108	0.9668615984405458
75	0.07789415773004293	0.97802734375	0.1208957627608094	0.9668615984405458
76	0.07613165734801441	0.978759765625	0.1208116900426341	0.9668615984405458
77	0.0758672917727381	0.98046875	0.12478358639934287	0.9629629629629629
78	0.0698967925272882	0.98193359375	0.12504522721818695	0.9668615984405458
79	0.0725639684824273	0.97900390625	0.12679257754555978	0.9639376218323586
80	0.07110298477346078	0.9814453125	0.12294507990491378	0.9658869395711501
81	0.06777480675373226	0.983642578125	0.12273974150880358	0.9678362573099415
82	0.06541532586561516	0.985107421875	0.12456101896586241	0.9658869395711501
83	0.07245033932849765	0.978271484375	0.1260460652574374	0.9658869395711501
84	0.06371682829922065	0.983642578125	0.11881248684069887	0.9668615984405458
85	0.07067958393599838	0.983642578125	0.11997042457004882	0.9688109161793372
86	0.07201248040655628	0.97998046875	0.11934719952894465	0.9678362573099415
87	0.06832638423657045	0.980224609375	0.11826299318088832	0.9678362573099415
88	0.06256214750465006	0.985595703125	0.11803337999349042	0.9678362573099415
89	0.06206892296904698	0.982666015625	0.11830102724747525	0.9678362573099415
90	0.06553851149510592	0.981689453125	0.12003096521670474	0.9688109161793372
91	0.06369710282888263	0.98193359375	0.12077191256015737	0.9707602339181286
92	0.06454966106684878	0.983642578125	0.12348285121716138	0.9668615984405458
93	0.05733373016119003	0.984130859375	0.11822628470311998	0.9668615984405458
94	0.053566482674796134	0.986572265625	0.11991488202620247	0.9717348927875243
95	0.06160612992243841	0.984375	0.11689575127331399	0.9688109161793372
96	0.05638167686993256	0.985107421875	0.1192680405258595	0.9707602339181286
97	0.058116206782869995	0.984619140625	0.11778325057855388	0.9678362573099415
98	0.05123433127300814	0.986083984375	0.12031863141599788	0.9717348927875243
99	0.06010980834253132	0.984130859375	0.11807203393876117	0.9668615984405458

The optimal condition:
	epoch: 98
	train_acc: 0.986083984375
	val_acc: 0.971734892788
	using time: 403.822422028
