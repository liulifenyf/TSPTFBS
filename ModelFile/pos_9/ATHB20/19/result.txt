The number of train datas: 4096
The number of test datas: 1026
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7125512287020683	0.5068359375	0.699022816984277	0.4775828460038986
1	0.7030831575393677	0.503662109375	0.6953632708413792	0.5077972709551657
2	0.695478105917573	0.515625	0.6924312519051178	0.5253411306042886
3	0.692851023748517	0.525634765625	0.6907634921008848	0.5380116959064327
4	0.6893148012459278	0.53857421875	0.6881086962264881	0.5399610136452242
5	0.6880174484103918	0.540771484375	0.6858147453611125	0.5477582846003899
6	0.6859018243849277	0.552490234375	0.6824521056392736	0.5740740740740741
7	0.6798930447548628	0.563720703125	0.6796981353044045	0.5740740740740741
8	0.6783030927181244	0.572998046875	0.676005338367663	0.594541910331384
9	0.6780481971800327	0.56982421875	0.673051881511309	0.6081871345029239
10	0.6693880371749401	0.60302734375	0.6688803692310177	0.6345029239766082
11	0.6689534969627857	0.598876953125	0.6641387048288163	0.6364522417153996
12	0.6632262319326401	0.611328125	0.6578767966573467	0.6549707602339181
13	0.6533694863319397	0.6259765625	0.6496561449638352	0.6832358674463938
14	0.6486845947802067	0.63818359375	0.6409768883944952	0.7037037037037037
15	0.6399202309548855	0.64306640625	0.6300634575633742	0.716374269005848
16	0.6294607371091843	0.661865234375	0.6181454839762192	0.7270955165692008
17	0.6153671201318502	0.673095703125	0.6050200254364088	0.7348927875243665
18	0.6075197048485279	0.691650390625	0.5898837282178927	0.7514619883040936
19	0.5894228741526604	0.7060546875	0.5718207602147702	0.7660818713450293
20	0.5732771381735802	0.7177734375	0.5525702037076968	0.776803118908382
21	0.5572201497852802	0.7265625	0.5319529468553108	0.7933723196881092
22	0.5377926900982857	0.74462890625	0.5089983219756485	0.8118908382066277
23	0.5191475860774517	0.765625	0.48521493041259733	0.8284600389863548
24	0.49684333615005016	0.777099609375	0.4604199065102471	0.8362573099415205
25	0.4674576809629798	0.80029296875	0.4328603272201025	0.847953216374269
26	0.442309970036149	0.822021484375	0.4084870688050811	0.8606237816764133
27	0.41675910726189613	0.833984375	0.38392981120020325	0.8703703703703703
28	0.39686269313097	0.84130859375	0.3576786257834927	0.8830409356725146
29	0.37806743662804365	0.8505859375	0.3388032385131769	0.8869395711500975
30	0.3515170542523265	0.86865234375	0.3122915405976145	0.898635477582846
31	0.32810466457158327	0.874267578125	0.2953686624997773	0.9005847953216374
32	0.31328366277739406	0.887939453125	0.275967727162917	0.9122807017543859
33	0.2938113193958998	0.8955078125	0.25932223946727506	0.9122807017543859
34	0.27630000095814466	0.8984375	0.2466222913118831	0.9210526315789473
35	0.2611048799008131	0.911376953125	0.23230987520013405	0.9307992202729045
36	0.251111735124141	0.914794921875	0.22212071480051584	0.9346978557504874
37	0.23542744247242808	0.915771484375	0.21143006707666911	0.9337231968810916
38	0.22629018453881145	0.925048828125	0.20185117451129136	0.9376218323586745
39	0.21192894876003265	0.930419921875	0.19371664801478153	0.942495126705653
40	0.1997871370986104	0.9365234375	0.1892403252568045	0.9405458089668616
41	0.19465922168456018	0.933349609375	0.17942476177453762	0.9454191033138402
42	0.18815889535471797	0.9384765625	0.17472391954639502	0.9463937621832359
43	0.17872474435716867	0.940673828125	0.16826392892479433	0.9463937621832359
44	0.17360877059400082	0.9423828125	0.16234358884466787	0.9512670565302144
45	0.1581254960037768	0.949462890625	0.1585287556277323	0.9522417153996101
46	0.16059752786532044	0.94970703125	0.1542587182856733	0.9541910331384016
47	0.14976214873604476	0.953125	0.15079434388489635	0.956140350877193
48	0.15180674172006547	0.954833984375	0.14853567418008753	0.9571150097465887
49	0.14419884071685374	0.95751953125	0.14521138317026125	0.9590643274853801
50	0.1411569935735315	0.95849609375	0.14334244689891446	0.9571150097465887
51	0.13211526442319155	0.963134765625	0.1400872864206748	0.9571150097465887
52	0.12671250011771917	0.96435546875	0.1429426854977395	0.9571150097465887
53	0.13047809898853302	0.9619140625	0.135865285311831	0.9600389863547758
54	0.1265470338985324	0.962646484375	0.1359241705888893	0.9610136452241715
55	0.12288023624569178	0.966796875	0.13293919651850797	0.9600389863547758
56	0.12235582852736115	0.965087890625	0.13060476844603847	0.9639376218323586
57	0.11738774448167533	0.968017578125	0.13305260030803276	0.9629629629629629
58	0.11524532246403396	0.968994140625	0.1278089514387078	0.9658869395711501
59	0.1050593153340742	0.968505859375	0.12693203352645882	0.9668615984405458
60	0.10888582991901785	0.9658203125	0.12545606732680725	0.9688109161793372
61	0.10635492973960936	0.9716796875	0.12464946108646908	0.9678362573099415
62	0.10830832412466407	0.966552734375	0.12302614418793376	0.9678362573099415
63	0.09986506402492523	0.9716796875	0.12429010757965854	0.9668615984405458
64	0.10074370820075274	0.97705078125	0.1210804109880973	0.9688109161793372
65	0.09985993115697056	0.97509765625	0.12129892090509771	0.9668615984405458
66	0.09841779025737196	0.969482421875	0.1200447284805336	0.9707602339181286
67	0.09807797474786639	0.97265625	0.11977685509126118	0.9678362573099415
68	0.09662951179780066	0.972900390625	0.11844515070123107	0.9688109161793372
69	0.09504315571393818	0.97412109375	0.12102707552670938	0.9658869395711501
70	0.09572553681209683	0.974365234375	0.11880944883287475	0.9688109161793372
71	0.08933727664407343	0.976318359375	0.11890899543296436	0.9678362573099415
72	0.08924239291809499	0.977294921875	0.11664002345871274	0.9678362573099415
73	0.0837072676513344	0.978515625	0.11794239077825992	0.9688109161793372
74	0.09039131517056376	0.97607421875	0.1148363429395805	0.9717348927875243
75	0.0862426336389035	0.97705078125	0.11451287443802255	0.9688109161793372
76	0.0866620778106153	0.9765625	0.11464487048788233	0.9688109161793372
77	0.0857252172427252	0.97705078125	0.11973927752886396	0.9658869395711501
78	0.07609633984975517	0.9814453125	0.12346713356383246	0.9629629629629629
79	0.07666740717831999	0.978759765625	0.11718789509862487	0.9668615984405458
80	0.07739583600778133	0.97900390625	0.11434751631125634	0.9678362573099415
81	0.07657516747713089	0.979248046875	0.11548742054749214	0.9658869395711501
82	0.07349664747016504	0.9833984375	0.11477056225366004	0.9668615984405458
83	0.07532825804082677	0.981201171875	0.1128519733425513	0.9707602339181286
84	0.0716630591196008	0.981689453125	0.11184465467791867	0.9707602339181286
85	0.07416151789948344	0.983642578125	0.11205406476276951	0.9707602339181286
86	0.07631626486545429	0.979248046875	0.11266999138559107	0.9678362573099415
87	0.07183637353591621	0.98095703125	0.11303504967070811	0.9668615984405458
88	0.0666303327307105	0.982666015625	0.11165610749408834	0.9717348927875243
89	0.06976080895401537	0.98046875	0.11241497879586461	0.9707602339181286
90	0.06798137538135052	0.982666015625	0.11253903955484415	0.9688109161793372
91	0.06974929489661008	0.9814453125	0.11893908993103205	0.9639376218323586
92	0.06759556184988469	0.984130859375	0.11399963588615404	0.9668615984405458
93	0.06401291314978153	0.982666015625	0.11665355415196026	0.9649122807017544
94	0.060261956008616835	0.984375	0.1130890518596639	0.9688109161793372
95	0.06295286258682609	0.986083984375	0.111690082860526	0.969785575048733
96	0.06146526260999963	0.984619140625	0.1151761537722764	0.9649122807017544
97	0.060247045184951276	0.98388671875	0.11119680106821406	0.969785575048733
98	0.055236998945474625	0.98681640625	0.11406267249773368	0.9668615984405458
99	0.06527878867927939	0.98291015625	0.11102642158552874	0.969785575048733

The optimal condition:
	epoch: 88
	train_acc: 0.982666015625
	val_acc: 0.971734892788
	using time: 374.224379063
