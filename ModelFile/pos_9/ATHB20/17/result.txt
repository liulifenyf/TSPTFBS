The number of train datas: 4096
The number of test datas: 1026
epoch	train_loss	train_acc	val_loss	val_acc
0	0.716076523065567	0.505126953125	0.6941942545870359	0.5263157894736842
1	0.7042524572461843	0.4970703125	0.6913411126964041	0.52046783625731
2	0.6983877718448639	0.515380859375	0.6894191302518863	0.5428849902534113
3	0.6933408156037331	0.51708984375	0.6874152140775387	0.5623781676413255
4	0.6928978394716978	0.52783203125	0.6857305152839155	0.5750487329434698
5	0.68950330093503	0.54052734375	0.6838524455447875	0.5828460038986355
6	0.688753167167306	0.526123046875	0.6810250629690888	0.6033138401559455
7	0.682797783985734	0.5615234375	0.6778317893225315	0.6169590643274854
8	0.6809651646763086	0.564208984375	0.6748396569525289	0.6237816764132553
9	0.6784535739570856	0.564697265625	0.6719294328670985	0.6325536062378168
10	0.672972034662962	0.578857421875	0.6685060820384332	0.6471734892787524
11	0.673142010346055	0.58544921875	0.6640244139100608	0.6530214424951267
12	0.6687139887362719	0.601806640625	0.6583067232172857	0.6695906432748538
13	0.6582842525094748	0.62158203125	0.6518260556587234	0.6744639376218323
14	0.6573637314140797	0.62744140625	0.6465495376326652	0.695906432748538
15	0.651483241468668	0.6220703125	0.6380231069077757	0.7017543859649122
16	0.6397975571453571	0.644287109375	0.6281391224201195	0.7241715399610137
17	0.6302270740270615	0.656982421875	0.6175701086051748	0.7251461988304093
18	0.6239390950649977	0.672607421875	0.6055276348576908	0.7358674463937622
19	0.6064431481063366	0.692626953125	0.5922286582504332	0.7514619883040936
20	0.6015907656401396	0.690185546875	0.5780217107276471	0.7582846003898636
21	0.5909013450145721	0.694091796875	0.5641380511296887	0.767056530214425
22	0.574142986908555	0.72021484375	0.5466715894479733	0.7797270955165692
23	0.5582648757845163	0.726806640625	0.5281592070707801	0.7875243664717348
24	0.5434426767751575	0.742919921875	0.5109446146334821	0.8001949317738791
25	0.5194665528833866	0.760009765625	0.48951359984935144	0.8148148148148148
26	0.5073147807270288	0.778564453125	0.4697139683755053	0.8226120857699805
27	0.4818566394969821	0.783935546875	0.4503752832059507	0.8284600389863548
28	0.46198421344161034	0.799072265625	0.4247286576509011	0.8391812865497076
29	0.44020018726587296	0.8095703125	0.40672014069836043	0.847953216374269
30	0.4186831582337618	0.825439453125	0.3829092098723146	0.8586744639376218
31	0.395525892265141	0.83544921875	0.3630119971713128	0.8674463937621832
32	0.3819943843409419	0.846923828125	0.3422273147640637	0.8742690058479532
33	0.36189696937799454	0.861328125	0.32191498313266165	0.8888888888888888
34	0.3384264940395951	0.875	0.30679988163953636	0.8888888888888888
35	0.3248561918735504	0.8779296875	0.28763546238401017	0.9025341130604289
36	0.30674710497260094	0.88623046875	0.27046769561126216	0.905458089668616
37	0.289394891820848	0.890625	0.2580489244958346	0.9132553606237817
38	0.27542546996846795	0.904052734375	0.24182654525104322	0.9200779727095516
39	0.2585628875531256	0.9052734375	0.23010773968394505	0.9249512670565302
40	0.2479790230281651	0.913330078125	0.2188970418410924	0.9327485380116959
41	0.2251101308502257	0.925048828125	0.2080375596038547	0.935672514619883
42	0.2223878400400281	0.92578125	0.2001895246769485	0.9385964912280702
43	0.2096702284179628	0.931640625	0.19207139660333797	0.942495126705653
44	0.20340662077069283	0.935791015625	0.18344091770709375	0.9434697855750487
45	0.18935927748680115	0.940673828125	0.17836281464055734	0.9463937621832359
46	0.18731937813572586	0.9384765625	0.1723844295995742	0.9483430799220273
47	0.1757430713623762	0.9443359375	0.1667845034082266	0.9502923976608187
48	0.17155700759030879	0.947265625	0.16338618818605155	0.956140350877193
49	0.17118221684359014	0.9462890625	0.15959711762083437	0.9532163742690059
50	0.1606808139476925	0.949951171875	0.15641425528198655	0.9512670565302144
51	0.1562165308278054	0.955078125	0.15321296258860398	0.9580896686159844
52	0.15107659855857491	0.952880859375	0.1531541213378688	0.9580896686159844
53	0.14898104406893253	0.95703125	0.14805047503049842	0.9619883040935673
54	0.14118760055862367	0.95751953125	0.1502195239379334	0.9610136452241715
55	0.1378670963458717	0.959228515625	0.14508230238063644	0.9629629629629629
56	0.13890962954610586	0.9599609375	0.14081590181873788	0.9590643274853801
57	0.13703445275314152	0.958984375	0.14450213064386946	0.9619883040935673
58	0.13300161669030786	0.961669921875	0.13692204862629692	0.9600389863547758
59	0.11827345134224743	0.963623046875	0.13602365948782677	0.9668615984405458
60	0.12135593150742352	0.963623046875	0.13399626974009166	0.9580896686159844
61	0.11393552040681243	0.966796875	0.13372134957934564	0.9678362573099415
62	0.11874817218631506	0.964599609375	0.13084756014378449	0.9649122807017544
63	0.10705035296268761	0.969970703125	0.12972433184642077	0.9678362573099415
64	0.11058208346366882	0.96728515625	0.1284393721839257	0.9668615984405458
65	0.10977484576869756	0.969970703125	0.1365348667933898	0.9639376218323586
66	0.10733569134026766	0.968994140625	0.1273976073838175	0.9668615984405458
67	0.10170625906903297	0.97216796875	0.12682348282800782	0.9678362573099415
68	0.10927334649022669	0.968017578125	0.1259248615415008	0.9678362573099415
69	0.10492151300422847	0.970947265625	0.12715662724645282	0.9668615984405458
70	0.09953619271982461	0.97119140625	0.12826361034072747	0.9649122807017544
71	0.10219168558251113	0.97412109375	0.12806860732230527	0.9658869395711501
72	0.09825232881121337	0.973388671875	0.12341476863224721	0.9678362573099415
73	0.09616661758627743	0.973876953125	0.12702415957974295	0.9649122807017544
74	0.09749262710101902	0.974609375	0.12394999959605944	0.9668615984405458
75	0.09098497510422021	0.97412109375	0.12270240986004442	0.9668615984405458
76	0.09215021319687366	0.97314453125	0.12217866534232862	0.9678362573099415
77	0.09101436636410654	0.9736328125	0.12717506691239788	0.9639376218323586
78	0.08336043718736619	0.9775390625	0.12358963705207172	0.9678362573099415
79	0.08286111196503043	0.977294921875	0.12685161094829353	0.9639376218323586
80	0.08332321961643174	0.97802734375	0.12126364743747325	0.9678362573099415
81	0.08452512556686997	0.974853515625	0.12422020961013105	0.9658869395711501
82	0.07462173770181835	0.983154296875	0.12209291869799876	0.9668615984405458
83	0.0812365198507905	0.979248046875	0.12050071642979195	0.9668615984405458
84	0.07301678176736459	0.979736328125	0.12046975221985962	0.9668615984405458
85	0.07751906401244923	0.979736328125	0.1196053724329316	0.9668615984405458
86	0.07621508988086134	0.979248046875	0.12472506664279434	0.9658869395711501
87	0.0709770949324593	0.9814453125	0.12105844631703974	0.9668615984405458
88	0.06958756182575598	0.982421875	0.12002864920445237	0.9678362573099415
89	0.07178324752021581	0.97998046875	0.11981020815539778	0.9678362573099415
90	0.07008340884931386	0.98095703125	0.12085432675077087	0.9658869395711501
91	0.06842219142708927	0.984619140625	0.11965439654523634	0.9658869395711501
92	0.07053196476772428	0.981201171875	0.11902266276045384	0.9678362573099415
93	0.0657249633804895	0.98193359375	0.12413323098942493	0.9668615984405458
94	0.06248581601539627	0.984130859375	0.1197562020228446	0.9688109161793372
95	0.07038982131052762	0.98291015625	0.11898841053886489	0.9668615984405458
96	0.06724430475151166	0.983154296875	0.11896075753106593	0.9678362573099415
97	0.06207873910898343	0.982666015625	0.11934209100495421	0.9678362573099415
98	0.062155835796147585	0.984130859375	0.12002339752365565	0.9658869395711501
99	0.0647054731962271	0.9833984375	0.11916915249609575	0.9678362573099415

The optimal condition:
	epoch: 94
	train_acc: 0.984130859375
	val_acc: 0.968810916179
	using time: 354.544137955
