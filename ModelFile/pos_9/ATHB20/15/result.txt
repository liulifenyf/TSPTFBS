The number of train datas: 4096
The number of test datas: 1026
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7157414648681879	0.501953125	0.6921397930929768	0.5048732943469786
1	0.7020342238247395	0.508544921875	0.6898673319677163	0.5282651072124757
2	0.6983546055853367	0.505859375	0.6874567279574002	0.5536062378167641
3	0.6911839880049229	0.52734375	0.6861248399779113	0.5701754385964912
4	0.6921273823827505	0.521728515625	0.6843068384752403	0.5740740740740741
5	0.688599506393075	0.5341796875	0.6825306536393788	0.5925925925925926
6	0.6884462591260672	0.539306640625	0.6800914240627028	0.6062378167641326
7	0.6820534858852625	0.565673828125	0.6778094631421868	0.6179337231968811
8	0.6823593527078629	0.55615234375	0.6746258024583783	0.6413255360623782
9	0.6802990213036537	0.566162109375	0.6716790737232037	0.6510721247563352
10	0.6751882713288069	0.5869140625	0.668291091221815	0.6598440545808967
11	0.6755173876881599	0.5830078125	0.6644589598880641	0.6637426900584795
12	0.6704281102865934	0.595703125	0.6597420182841564	0.6842105263157895
13	0.6606031507253647	0.611083984375	0.6540428743957312	0.6949317738791423
14	0.6615998037159443	0.6201171875	0.6494176187942832	0.6968810916179338
15	0.6536888591945171	0.63671875	0.642373059576715	0.7115009746588694
16	0.644180154427886	0.649658203125	0.6340654157755667	0.7387914230019493
17	0.6350100375711918	0.6552734375	0.6246996155956335	0.7290448343079922
18	0.6297168806195259	0.66650390625	0.6134890815203186	0.7573099415204678
19	0.6147809959948063	0.6875	0.6008819708814863	0.7621832358674464
20	0.607694286853075	0.6884765625	0.58787565133725	0.7826510721247564
21	0.5983046591281891	0.694580078125	0.5726549386048643	0.7914230019493177
22	0.5822117440402508	0.71630859375	0.5561243897525423	0.7982456140350878
23	0.5637455582618713	0.727294921875	0.5361014567388196	0.8070175438596491
24	0.5461634248495102	0.73876953125	0.5165991223114044	0.817738791423002
25	0.5231782598420978	0.760498046875	0.4925017554392824	0.8235867446393762
26	0.5056302472949028	0.77734375	0.4691768082958913	0.834307992202729
27	0.47926232870668173	0.7900390625	0.4457581754316363	0.8382066276803118
28	0.45562623906880617	0.8076171875	0.41912603424771255	0.8508771929824561
29	0.4309748709201813	0.82275390625	0.3959821212826184	0.8596491228070176
30	0.4078806173056364	0.835693359375	0.3708023213968407	0.8742690058479532
31	0.3809213787317276	0.854248046875	0.34848294353392156	0.8859649122807017
32	0.3643855908885598	0.855224609375	0.32649227256430985	0.8918128654970761
33	0.34759052470326424	0.86376953125	0.3068337894787333	0.9035087719298246
34	0.3193125845864415	0.88916015625	0.288633788247787	0.9103313840155945
35	0.30326702538877726	0.887451171875	0.2707861936696556	0.9132553606237817
36	0.29249137872830033	0.894287109375	0.2566104083381898	0.9210526315789473
37	0.27103667380288243	0.902587890625	0.24466979858006185	0.9249512670565302
38	0.2645398019813001	0.90478515625	0.23176618329962792	0.9317738791423001
39	0.24558606185019016	0.912353515625	0.2215616141843517	0.9327485380116959
40	0.2338732574135065	0.91455078125	0.21210102513287268	0.9337231968810916
41	0.22043451620265841	0.924072265625	0.20169699534802873	0.9385964912280702
42	0.21813996136188507	0.925537109375	0.19764380708888726	0.9337231968810916
43	0.20588240819051862	0.93212890625	0.18853794215483044	0.9415204678362573
44	0.1979437975678593	0.936279296875	0.18201143028791886	0.9444444444444444
45	0.18714273441582918	0.93798828125	0.17864314013580132	0.9405458089668616
46	0.18532999278977513	0.9375	0.17372428285971023	0.9463937621832359
47	0.17361649894155562	0.946533203125	0.16919822494188944	0.9473684210526315
48	0.17329539405182004	0.947021484375	0.16456262732458393	0.949317738791423
49	0.1689932628069073	0.94384765625	0.1616459256637166	0.9522417153996101
50	0.159567020367831	0.95068359375	0.15921108861822367	0.9502923976608187
51	0.15646485053002834	0.9541015625	0.157182537977807	0.9522417153996101
52	0.1506705260835588	0.95263671875	0.15914476062325475	0.9512670565302144
53	0.1498781975824386	0.953369140625	0.15236163283126397	0.9551656920077972
54	0.14577347063459456	0.951171875	0.1548484833602436	0.9532163742690059
55	0.14488349319435656	0.95556640625	0.14976745063972752	0.9541910331384016
56	0.1386642255820334	0.95751953125	0.14605274193032444	0.9551656920077972
57	0.1351583742070943	0.9599609375	0.1488555777549279	0.9571150097465887
58	0.13500100234523416	0.96044921875	0.14347406569686783	0.9571150097465887
59	0.12410066602751613	0.962646484375	0.1436438989221004	0.9571150097465887
60	0.12430800264701247	0.963134765625	0.139871126952169	0.9590643274853801
61	0.1199088313151151	0.965087890625	0.1382493189232856	0.9610136452241715
62	0.12394114094786346	0.962890625	0.13760484786264846	0.9600389863547758
63	0.11428268859162927	0.96435546875	0.13632865699614466	0.9610136452241715
64	0.11217432469129562	0.966796875	0.13597657952682782	0.9610136452241715
65	0.11401275428943336	0.965576171875	0.13839606507581462	0.9610136452241715
66	0.11249432095792145	0.96875	0.13558682835285077	0.9619883040935673
67	0.10972927126567811	0.97021484375	0.1353992327837161	0.9619883040935673
68	0.11774918425362557	0.967041015625	0.1332748358557273	0.9619883040935673
69	0.10769196134060621	0.969970703125	0.13270495321100567	0.9619883040935673
70	0.1064304318279028	0.9697265625	0.1349815554394011	0.9629629629629629
71	0.10730601358227432	0.969482421875	0.13627509343606686	0.9610136452241715
72	0.10659782926086336	0.966064453125	0.13071613739195623	0.9639376218323586
73	0.10155484545975924	0.974365234375	0.13296133315746198	0.9619883040935673
74	0.1057868879288435	0.969482421875	0.12923228846350956	0.9658869395711501
75	0.09780372225213796	0.974365234375	0.12828323866293329	0.9658869395711501
76	0.10211632342543453	0.970947265625	0.12936548117119784	0.9658869395711501
77	0.10027322778478265	0.970703125	0.13268478151200228	0.9619883040935673
78	0.09145487612113357	0.974853515625	0.13658008412194764	0.9610136452241715
79	0.09110230964142829	0.973388671875	0.12974126132288638	0.9639376218323586
80	0.09004169167019427	0.978515625	0.12761879332915502	0.9658869395711501
81	0.0965922650648281	0.972412109375	0.13110743295292407	0.9639376218323586
82	0.08793247130233794	0.97607421875	0.12702351939259915	0.9678362573099415
83	0.09261883655562997	0.97607421875	0.1253486487353638	0.9678362573099415
84	0.08451780886389315	0.977783203125	0.13109181026908157	0.9619883040935673
85	0.08871873433236033	0.974853515625	0.1256338231352686	0.9678362573099415
86	0.08996770327212289	0.97705078125	0.13071527894128832	0.9619883040935673
87	0.08377993840258569	0.974365234375	0.1249670636300978	0.9678362573099415
88	0.07884033909067512	0.979736328125	0.12445003036082837	0.9668615984405458
89	0.08550428575836122	0.97509765625	0.1239084274331961	0.9658869395711501
90	0.07916859106626362	0.978515625	0.1256266291422105	0.9688109161793372
91	0.07889211492147297	0.978759765625	0.12440157117282148	0.969785575048733
92	0.07979501318186522	0.97900390625	0.1249488204369071	0.969785575048733
93	0.07440502289682627	0.98046875	0.12451390375621021	0.969785575048733
94	0.07048107858281583	0.980224609375	0.12369838017846874	0.9688109161793372
95	0.0767237392719835	0.97998046875	0.12393615307326321	0.969785575048733
96	0.077869035420008	0.98046875	0.12207248833095818	0.9668615984405458
97	0.07247987389564514	0.97998046875	0.12252648947778617	0.969785575048733
98	0.07082120340783149	0.981201171875	0.12411361946007254	0.9688109161793372
99	0.07493026106385514	0.979736328125	0.12186399567509197	0.9658869395711501

The optimal condition:
	epoch: 97
	train_acc: 0.97998046875
	val_acc: 0.969785575049
	using time: 317.520369053
