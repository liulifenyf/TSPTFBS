The number of train datas: 5216
The number of test datas: 1304
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7064886096796376	0.5021088957055214	0.688630637581363	0.5375766871165644
1	0.7003732736856659	0.5080521476049364	0.6865595889969106	0.547546011904266
2	0.6968687776407582	0.5176380371754886	0.6858405522042257	0.566717791411043
3	0.691487043547484	0.5356595095681267	0.6847690713186205	0.5690184045423028
4	0.6902100235406606	0.5293328220858896	0.6832637892910308	0.5743865030674846
5	0.6847625905019374	0.5542561349693251	0.6816948941148864	0.5812883437411186
6	0.6846577751855909	0.5592407979116849	0.679989193480439	0.5805214723926381
7	0.679705597505979	0.5663343554625482	0.6782690458502506	0.5820552149067627
8	0.6796587650761282	0.5646088960711941	0.6758011802573877	0.6004601228822228
9	0.6738640219887342	0.5833972396294763	0.6730373622449629	0.5973926384024825
10	0.670176624154752	0.5943251533742331	0.6694458843740217	0.6250000003656727
11	0.6650599230286534	0.5991180981595092	0.6654267921769546	0.6365030678503353
12	0.6618103001015317	0.6071702457644457	0.6610162843224461	0.639570552512912
13	0.6561520026505359	0.6156058282208589	0.6554576794794	0.63420245398773
14	0.6509437250213389	0.6286426380368099	0.6488844445146666	0.6733128838012555
15	0.6443834136600143	0.63554447889328	0.6409244405711355	0.6779141107951205
16	0.6358025830947548	0.6503067484662577	0.6314155806793026	0.6886503067484663
17	0.6265171886953108	0.6618098163165929	0.6205704325547248	0.700920245398773
18	0.6188590837402578	0.6752300609840206	0.6080121419912466	0.7154907979116849
19	0.596531496457527	0.6936349689594807	0.5921706513393145	0.7285276077276358
20	0.5882239093078426	0.6972776069962905	0.5746286006792922	0.7515337419656157
21	0.5645801644383764	0.7266104290821801	0.5528191755885726	0.7707055214723927
22	0.5541953437167443	0.7308282208588958	0.531548963002632	0.7776073615975175
23	0.5293835966499305	0.7509585885913825	0.504151985689175	0.7944785279730346
24	0.4980615838173708	0.7754984662576687	0.4746505380408164	0.8151840494454272
25	0.46971071918317875	0.796395705887145	0.44192114984330955	0.8312883431926096
26	0.44650212899307534	0.8159509202453987	0.4095549274441655	0.852760736196319
27	0.4174294098754602	0.8238113496932515	0.37932076337147347	0.8680981595092024
28	0.381282599608591	0.8493098159509203	0.3492303084742072	0.8803680981595092
29	0.3626166057367266	0.8535276077276358	0.32551246278125084	0.8957055214723927
30	0.32628056900632896	0.8736579758257954	0.29980834440950965	0.901840490797546
31	0.31393218460989875	0.8751917181570837	0.2814031927132168	0.9072085889570553
32	0.2921706187578798	0.8930214720269654	0.2614044415438833	0.9156441717791411
33	0.27407254863736086	0.8981978531264089	0.24948014830884757	0.921012270304323
34	0.2586027524588298	0.901457055214724	0.23408416672352633	0.9233128838012555
35	0.2435493001177267	0.9102760736196319	0.22374691526216964	0.9279141107951205
36	0.22974953942137993	0.9198619631901841	0.21145106385821946	0.9271472396294763
37	0.22475374549444468	0.9190950923902126	0.21109981839459366	0.9263803680981595
38	0.2107353559666616	0.9246549079754601	0.20780144106208182	0.9248466257668712
39	0.19573195790586295	0.932898773006135	0.18690769762897785	0.9355828220858896
40	0.19098496766178155	0.9305981595092024	0.18230131149657666	0.9363496932515337
41	0.184580187856054	0.9374999996343273	0.17691644491410694	0.9386503067484663
42	0.16879343090613194	0.9440184045423028	0.17175393030504507	0.941717791411043
43	0.16597688536336816	0.9411426380368099	0.17242072147825743	0.9371165644171779
44	0.1579305695975485	0.9461273006134969	0.16344576767800045	0.941717791411043
45	0.14895847613460447	0.9530291414699672	0.16238121386685986	0.9394171779141104
46	0.15326658869447884	0.9445935586478813	0.15943666888069521	0.9394171779141104
47	0.15154283310920913	0.9518788343558282	0.1532226313202659	0.9455521472392638
48	0.13772985298026558	0.9547546008613212	0.15251881560664968	0.9394171779141104
49	0.13302193463214337	0.9553297542355543	0.14725333356235656	0.9447852760736196
50	0.12930068780490958	0.956671779506777	0.14477374233259746	0.9447852760736196
51	0.12472789236372965	0.958588956689542	0.1453155645289304	0.9432515337423313
52	0.12647165760306492	0.9587806752122985	0.14121169345510518	0.9486196319018405
53	0.11921182009705737	0.9635736196319018	0.13867097279411153	0.9478527607361963
54	0.11878304133203132	0.9606978527607362	0.1407884277083391	0.9455521472392638
55	0.11574605413558293	0.961464724292053	0.13634544188168152	0.9478527607361963
56	0.11389924832648295	0.9593558285865316	0.13486482132157665	0.9493865030674846
57	0.1102280139557423	0.9624233132491082	0.13857347693042887	0.946319018404908
58	0.10576315459572465	0.9639570555803966	0.1353174070342004	0.9455521472392638
59	0.10220296114134642	0.9668328224515622	0.13248094597522833	0.9486196319018405
60	0.09716459139724451	0.9679831284686832	0.1405078311753602	0.9470858895705522
61	0.09620645050347948	0.9697085893227279	0.12871089309134	0.9547546012269938
62	0.09509794889417894	0.9700920245398773	0.12680964452997306	0.9555214723926381
63	0.09676901278503101	0.9687500003656727	0.12752953108880052	0.9539877300613497
64	0.09101718623031137	0.9722009202453987	0.13229387271806506	0.9493865030674846
65	0.0891185155584037	0.9727760736196319	0.13305834081435314	0.9486196319018405
66	0.08801454563905126	0.9722009202453987	0.12510256254417032	0.9555214723926381
67	0.08790403092565711	0.9733512266281924	0.13314081011397158	0.9493865030674846
68	0.08569926889670407	0.9741180981595092	0.12596843185966	0.9539877300613497
69	0.08759935675588854	0.9702837423312883	0.12173250828372555	0.9593558282208589
70	0.08117560964603365	0.974884969690826	0.12232337602945559	0.9562883435582822
71	0.0835462515613784	0.9756518404907976	0.1269885311131737	0.950920245398773
72	0.07358286250954026	0.9783358892048795	0.12164837152817132	0.9578220858895705
73	0.07501319597012426	0.9764187112907691	0.12446588631490806	0.9547546012269938
74	0.07275769217339761	0.9787193247877015	0.12255104662610526	0.9578220858895705
75	0.075073606580313	0.9773773009791696	0.11969657873083478	0.9608895705521472
76	0.07360579123709099	0.9773773002478242	0.12513664467088834	0.9532208588957055
77	0.07227489612768033	0.9762269938650306	0.12782551245363943	0.9516871165644172
78	0.07032651993577466	0.97929447889328	0.11842155499966597	0.9593558282208589
79	0.06855982619743406	0.9792944785276073	0.1181190006286363	0.9601226993865031
80	0.06833710674585008	0.9792944785276073	0.11974424645990316	0.9593558282208589
81	0.06973561230886934	0.9796779137447568	0.1229358495047396	0.9570552147239264
82	0.06125966182972756	0.98025306711899	0.12075365373030579	0.9593558282208589
83	0.06577403075490261	0.9815950916588672	0.12122070880183962	0.9601226993865031
84	0.06341707231076948	0.9804447856417463	0.1174285308017961	0.9601226993865031
85	0.06298237545358623	0.9806365030674846	0.11897566011232649	0.9601226993865031
86	0.06194127122500191	0.9814033742331288	0.12120811869476013	0.9593558282208589
87	0.06011749111527314	0.9815950923902126	0.11784494456840805	0.9608895705521472
88	0.0613385406922709	0.9815950923902126	0.11642330960924822	0.9601226993865031
89	0.05255487492662266	0.9846625770527893	0.11852834201446431	0.9601226993865031
90	0.054480463586336264	0.9833205521472392	0.11845749684329504	0.9601226993865031
91	0.05664583965221797	0.9831288347215009	0.11976775412442037	0.9593558282208589
92	0.05384319339610316	0.982170245398773	0.1183270214988273	0.9593558282208589
93	0.05503029785364683	0.9840874229472107	0.12465533086504399	0.9562883435582822
94	0.05221312977602145	0.9856211656441718	0.11857164971404738	0.9601226993865031
95	0.05124873169726389	0.9856211656441718	0.1165679326806606	0.9601226993865031
96	0.050697567707007646	0.985237729695677	0.12808170740812605	0.9547546012269938
97	0.048379042122993	0.983512270304323	0.11833351210582475	0.9616564417177914
98	0.04972354720340916	0.9846625763214439	0.11661093346088942	0.9601226993865031
99	0.04595963111821493	0.9869631901840491	0.11760658270856537	0.9593558282208589

The optimal condition:
	epoch: 97
	train_acc: 0.983512270304323
	val_acc: 0.961656441718
	using time: 92.1633658409
