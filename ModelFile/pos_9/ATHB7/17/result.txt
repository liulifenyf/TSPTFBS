The number of train datas: 6136
The number of test datas: 1536
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7035971495287671	0.496251629726206	0.6946495721737543	0.517578125
1	0.6958905198894237	0.5174380704430278	0.6906849145889282	0.5286458333333334
2	0.6916068995169897	0.5265645371966132	0.6875487913688024	0.5703125
3	0.6902799347544276	0.5355280315238774	0.6840893924236298	0.576171875
4	0.6830556008775356	0.5545958279786241	0.6805027822653452	0.58984375
5	0.6789112421337908	0.5739895700631272	0.6758799105882645	0.6119791666666666
6	0.6731481994301897	0.5803455021110943	0.6700016111135483	0.64453125
7	0.6658800771991774	0.6100065185939784	0.6623901675144831	0.6516927083333334
8	0.6608726954211468	0.6103324640683121	0.6529560585816702	0.68359375
9	0.6501139229093101	0.6334745757272067	0.6416503091653188	0.7141927083333334
10	0.6360585149450438	0.6533572363729117	0.6249741117159525	0.744140625
11	0.6244336567148858	0.6707953066993724	0.6053066899379095	0.7701822916666666
12	0.6050606677709378	0.6947522810727086	0.5811526527007421	0.7994791666666666
13	0.5787344550060636	0.7299543673553864	0.5496702591578165	0.82421875
14	0.5430333674187144	0.7530964794805495	0.5101038590073586	0.845703125
15	0.5101373086075117	0.7819426338706831	0.4654240806897481	0.873046875
16	0.46976915821724485	0.8088331161142173	0.4190493697921435	0.888671875
17	0.42111599946581557	0.8394719683206998	0.3714335535963376	0.9036458333333334
18	0.38956074414694636	0.8494132984104181	0.33448781818151474	0.9134114583333334
19	0.3420057171637574	0.8805410693335254	0.3042282164096832	0.919921875
20	0.3084712334686339	0.8885267273543556	0.26782555257280666	0.9251302083333334
21	0.29356811064473964	0.8974902214873413	0.24849203725655875	0.9322916666666666
22	0.26762339274606617	0.911994784720718	0.23501456280549368	0.9368489583333334
23	0.24617737164475617	0.9232398961637912	0.21982205162445703	0.9401041666666666
24	0.23132580240904274	0.9258474575494072	0.2072774109741052	0.9375
25	0.22243193650649765	0.9279661019280494	0.20027771716316542	0.9446614583333334
26	0.20926327822727517	0.9369295963718807	0.19220093948145708	0.9466145833333334
27	0.1966142942339687	0.9388852677413662	0.19780446899433932	0.9446614583333334
28	0.19303592996771363	0.9401890484730299	0.1816923183699449	0.9485677083333334
29	0.18569123987812727	0.9450782267801765	0.17820833685497442	0.9524739583333334
30	0.18010193993479517	0.948663625055062	0.17473307314018408	0.9537760416666666
31	0.17671662219344714	0.949804433166126	0.17149130379160246	0.9544270833333334
32	0.16781029518999674	0.9511082134315212	0.17016060029466948	0.95703125
33	0.16514879082374498	0.9537157752056943	0.17305542590717474	0.9544270833333334
34	0.16050964341325274	0.954041721068585	0.16562456885973612	0.9583333333333334
35	0.15573733912919305	0.9566492823764896	0.1623770004759232	0.9576822916666666
36	0.15452865605404045	0.9564863100667355	0.17034245717028776	0.9576822916666666
37	0.1526991849500477	0.9599087347884844	0.15972556670506796	0.9576822916666666
38	0.14547355541039012	0.9617014336150814	0.15810355357825756	0.9576822916666666
39	0.14290586337350028	0.9608865709783512	0.15862995572388172	0.95703125
40	0.14772328841251064	0.9610495441429308	0.1559025483826796	0.9576822916666666
41	0.14191377188189555	0.9590938725403111	0.15878518298268318	0.9596354166666666
42	0.14266809110069523	0.9595827897027076	0.15425925763944784	0.9563802083333334
43	0.1395311406394649	0.9634941334519268	0.1541642565280199	0.9576822916666666
44	0.13484856884591429	0.9647979142613019	0.15386511757969856	0.9583333333333334
45	0.13337964600503366	0.9630052145798794	0.15588309646894535	0.958984375
46	0.12641568483864934	0.9657757491300749	0.15338518284261227	0.9602864583333334
47	0.12261656921410342	0.9657757494409206	0.16535991430282593	0.962890625
48	0.12533260874129648	0.9654498038888755	0.15435650882621607	0.9596354166666666
49	0.12467137270520844	0.9657757495963434	0.14970374231537184	0.9576822916666666
50	0.12477517378609992	0.9659387219060975	0.14872822972635427	0.9596354166666666
51	0.12125644932902932	0.9677314205772718	0.1477299171189467	0.9583333333333334
52	0.11964362630477318	0.9662646673027198	0.14819833201666674	0.9602864583333334
53	0.1170247590565153	0.969361146938692	0.1476751690109571	0.958984375
54	0.12022324173554604	0.9675684489669203	0.15133076254278421	0.958984375
55	0.11721799679032516	0.9690352025523179	0.14735280474027	0.958984375
56	0.11482829618057651	0.9705019559822928	0.14651438407599926	0.9596354166666666
57	0.1120345559180016	0.9708279013789151	0.14721083485831818	0.958984375
58	0.11131424971672826	0.9709908739995148	0.14609158101181188	0.958984375
59	0.1117445901230541	0.9709908729892666	0.1449823056658109	0.9583333333333334
60	0.10737380874980693	0.9716427640933568	0.14512168616056442	0.958984375
61	0.1058859886574854	0.9732724902216427	0.14466223741571108	0.958984375
62	0.11050443028766453	0.9719687094122677	0.14446092459062734	0.9596354166666666
63	0.10627529184386192	0.9724576275849125	0.1457924166073402	0.9596354166666666
64	0.10459418297105383	0.9711538463092689	0.1478961423660318	0.9602864583333334
65	0.10352743302400295	0.9721316813334647	0.14649476731816927	0.9596354166666666
66	0.10490860958065172	0.9722946548088899	0.14361328755815825	0.9596354166666666
67	0.10259736373029756	0.9731095172124861	0.1433550634731849	0.958984375
68	0.10205534390007502	0.9734354631530882	0.14345170060793558	0.958984375
69	0.09894031858389817	0.9742503254012614	0.14640042992929617	0.9596354166666666
70	0.09642236688534937	0.9735984359291107	0.14494846699138483	0.958984375
71	0.09438609975879475	0.9740873529360845	0.146735278579096	0.9602864583333334
72	0.10210748388877593	0.971968708712865	0.1471382873132825	0.9609375
73	0.09638175585900945	0.97506518850426	0.14306618149081865	0.9602864583333334
74	0.09448113281770355	0.9739243808594645	0.1481181476265192	0.9622395833333334
75	0.09394004379521759	0.9740873537909098	0.1425647223368287	0.9615885416666666
76	0.09310993278275258	0.9749022168939085	0.14386213415612778	0.9596354166666666
77	0.09130724230987619	0.975717078986659	0.1430303935582439	0.9596354166666666
78	0.0924148618436699	0.974413298177284	0.1446811929345131	0.9609375
79	0.09462780991600732	0.9747392438070405	0.14506091177463531	0.9609375
80	0.09114334742008008	0.9752281612802827	0.14234667364507914	0.9615885416666666
81	0.0916842185495108	0.976531943099906	0.14332468310991922	0.9602864583333334
82	0.08647735110414852	0.9762059975478609	0.14384212096532187	0.9596354166666666
83	0.09074959634879733	0.9752281611248598	0.1439875795816382	0.9602864583333334
84	0.0849999293218691	0.975228162135108	0.14731380126128593	0.962890625
85	0.08641692871686843	0.9744132980218612	0.14330637361854315	0.9622395833333334
86	0.08614396168868575	0.9762059968484582	0.14379497027645508	0.9615885416666666
87	0.08476958532648882	0.9766949147102575	0.14310864048699537	0.9609375
88	0.08352497643566505	0.9778357239092811	0.1426650257781148	0.9622395833333334
89	0.0819374361989784	0.9760430242278585	0.1431976261859139	0.9615885416666666
90	0.08510850199936577	0.9762059977032836	0.14681637597580752	0.9635416666666666
91	0.08350396697862363	0.9781616689950577	0.1444279352823893	0.9583333333333334
92	0.08150008028904959	0.9768578881856826	0.1452885220448176	0.9602864583333334
93	0.0797917996830704	0.9779986966853036	0.14786991011351347	0.9609375
94	0.08322934063231618	0.9765319420896578	0.14321006617198387	0.9622395833333334
95	0.07801787952517282	0.9779986962190352	0.14516375058641037	0.9641927083333334
96	0.07802730726838267	0.976531943099906	0.14557258629550537	0.9635416666666666
97	0.07867570194225113	0.9786505861574544	0.1474004021535317	0.9635416666666666
98	0.07790106277538869	0.9784876135368547	0.14420069692035517	0.962890625
99	0.07592827893764441	0.9789765315540766	0.1471920938541492	0.9596354166666666

The optimal condition:
	epoch: 95
	train_acc: 0.9779986962190352
	val_acc: 0.964192708333
	using time: 106.271500826
