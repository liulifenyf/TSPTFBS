The number of train datas: 6136
The number of test datas: 1536
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7019675105926733	0.5045632331436585	0.6919980893532435	0.5234375
1	0.6918807411287101	0.5281942631306207	0.687253788113594	0.5475260416666666
2	0.6909911919292913	0.5337353319978776	0.6836391190687815	0.5703125
3	0.6864280335440007	0.552151239058185	0.6796247363090515	0.5813802083333334
4	0.6789748361710619	0.5730117337178375	0.674844687183698	0.6041666666666666
5	0.6729147638615605	0.5757822687343016	0.6690803815921148	0.6184895833333334
6	0.6687666134231249	0.5909387221392317	0.6618742992480596	0.6380208333333334
7	0.6598147578158621	0.6186440674080531	0.6527980168660482	0.6627604166666666
8	0.6537040352355081	0.6127770530664626	0.6418352325757345	0.6901041666666666
9	0.64092263241324	0.6390156450607319	0.629037156701088	0.705078125
10	0.6259190110681576	0.6676988268302659	0.609997366865476	0.734375
11	0.610878706056105	0.681877444589309	0.588878000775973	0.7727864583333334
12	0.5919353379886184	0.7094198178592219	0.5622830390930176	0.8040364583333334
13	0.5624830751562057	0.7451108216928535	0.5288945287466049	0.8333333333333334
14	0.5303083120844044	0.7612451110545162	0.49213486164808273	0.84375
15	0.49749026133774776	0.7860169492302538	0.44747870912154514	0.8684895833333334
16	0.4556857635409145	0.8184485005741791	0.4066395163536072	0.87890625
17	0.41248048214433713	0.8357235985131742	0.3602769871552785	0.8990885416666666
18	0.3810727717901302	0.8554432851394743	0.32671360671520233	0.90625
19	0.33509437753448584	0.877770534627907	0.30168720955650014	0.9075520833333334
20	0.30329779859005707	0.8908083443535975	0.26614513993263245	0.923828125
21	0.2865943692653711	0.899119947382493	0.24974726513028145	0.927734375
22	0.2619697298888588	0.9180247713720627	0.23673907543222109	0.9270833333333334
23	0.24073394526869563	0.9240547584119645	0.2209824062883854	0.9283854166666666
24	0.23053277294592253	0.9264993484980746	0.20731896782914797	0.9407552083333334
25	0.21689080999680885	0.9299217727535551	0.20165505322317281	0.9381510416666666
26	0.2038067752177277	0.9370925683707892	0.19552774416903654	0.9401041666666666
27	0.18987747537266011	0.9398631027655621	0.1951373169819514	0.943359375
28	0.18898184587778294	0.939863103542676	0.18407898272077242	0.947265625
29	0.18331923154140234	0.944426336764046	0.18130704698463282	0.951171875
30	0.17733948074543493	0.9499674055535915	0.17879514334102473	0.9518229166666666
31	0.17044654147604765	0.949804433166126	0.173931193848451	0.951171875
32	0.1651871379421152	0.9530638850341409	0.17231977234284082	0.9524739583333334
33	0.15989954118778374	0.9553455017225373	0.17563082153598467	0.9518229166666666
34	0.15522145492545628	0.9573011731697341	0.1696707879503568	0.9537760416666666
35	0.1490768232277195	0.9564863100667355	0.16808007719616094	0.9537760416666666
36	0.14901468701748058	0.9573011731697341	0.17549081332981586	0.9524739583333334
37	0.14688647185808054	0.9569752279285346	0.16488320815066496	0.955078125
38	0.14328028634676257	0.9586049548339346	0.1633884534239769	0.9557291666666666
39	0.13997989368407637	0.9595827900135533	0.16503947600722313	0.955078125
40	0.1429565201915383	0.9610495441429308	0.16048469332357249	0.9563802083333334
41	0.13720801547461103	0.9630052147353022	0.1654650972535213	0.9544270833333334
42	0.14110043013499954	0.9605606257371517	0.15831785835325718	0.95703125
43	0.13595184042680683	0.9639830513137261	0.159912982955575	0.9557291666666666
44	0.13006817370730864	0.9626792703489281	0.15862791240215302	0.9563802083333334
45	0.13037634270831536	0.965123858647676	0.1580002699047327	0.9557291666666666
46	0.1288906575084665	0.9652868321231012	0.15765765495598316	0.9563802083333334
47	0.12412869759302252	0.9664276400787423	0.17083941213786602	0.9537760416666666
48	0.12381799301470119	0.9674054756469179	0.15810958171884218	0.9563802083333334
49	0.12352722945393609	0.9656127775974348	0.1535942181944847	0.9583333333333334
50	0.11978101990679874	0.9662646680021224	0.1549022098382314	0.9583333333333334
51	0.11616661606509496	0.9685462836802705	0.1531760717431704	0.9583333333333334
52	0.11731491747859871	0.9677314207326946	0.15369300295909247	0.9583333333333334
53	0.11333843875273265	0.9682203385944939	0.15420915186405182	0.9583333333333334
54	0.11636686194906645	0.9664276406227221	0.1545166876167059	0.95703125
55	0.1146910428670581	0.9665906122330736	0.15153956227004528	0.958984375
56	0.11402555955318926	0.9695241204141172	0.15186745362977186	0.958984375
57	0.10933897180927157	0.9705019559822928	0.1529462772111098	0.958984375
58	0.10937796117351761	0.9703389826622905	0.15276608554025492	0.9596354166666666
59	0.10687563922911922	0.9722946539540646	0.15028283248345056	0.9596354166666666
60	0.10578063021582762	0.970990873455535	0.1498522274196148	0.958984375
61	0.10554077246528716	0.9721316818774446	0.14947547825674215	0.958984375
62	0.1079349693644311	0.9706649284474698	0.14867685455828905	0.9609375
63	0.10457423894703777	0.9705019551274674	0.14920026529580355	0.9602864583333334
64	0.10101693478137294	0.9719687094122677	0.15363534136364856	0.9557291666666666
65	0.10041359644941743	0.9708279012234923	0.15013879941155514	0.958984375
66	0.1016899874382877	0.9729465454467117	0.14857202333708605	0.9609375
67	0.09832761253107636	0.974413298177284	0.1481893596549829	0.9609375
68	0.09863857727745522	0.9724576275849125	0.15066847701867422	0.9596354166666666
69	0.09675202408934198	0.9745762714972863	0.15004021022468805	0.9596354166666666
70	0.09401506041765524	0.9740873537909098	0.15107254777103662	0.9596354166666666
71	0.0932385588484917	0.9731095172124861	0.1533124546209971	0.9583333333333334
72	0.09566967053317028	0.9714797911619114	0.15421358806391558	0.9563802083333334
73	0.09498736773273936	0.9755541073763075	0.14746113245685896	0.9602864583333334
74	0.09366652128593862	0.9729465454467117	0.1522337794303894	0.958984375
75	0.09128417856651304	0.9750651895145083	0.14770167879760265	0.9596354166666666
76	0.09387147640311579	0.9735984350742852	0.14802118887503943	0.958984375
77	0.09086495266821736	0.9747392442733088	0.1471683932468295	0.9602864583333334
78	0.08728282779183195	0.9755541068323277	0.14680369446674982	0.9602864583333334
79	0.08780676421054882	0.9765319426336375	0.15170914183060327	0.9596354166666666
80	0.08882757459889801	0.9763689701684606	0.14746044327815375	0.9609375
81	0.09112744779851788	0.9752281619796852	0.14805619853238264	0.9602864583333334
82	0.08103551721926462	0.9768578878748371	0.1489541775857409	0.9596354166666666
83	0.08931233319107837	0.9749022160390831	0.14777441509068012	0.9615885416666666
84	0.08088439305688132	0.9768578873308572	0.1499914616967241	0.9609375
85	0.08259689106546449	0.9765319429444832	0.14802968284736076	0.9622395833333334
86	0.08062448883927008	0.9766949157205057	0.14856631867587566	0.9622395833333334
87	0.08167675766982187	0.9763689696244808	0.14958442002534866	0.9609375
88	0.0803944731065627	0.9771838335823049	0.14753283032526573	0.9615885416666666
89	0.08167154729521725	0.9778357237538583	0.1491170016427835	0.9602864583333334
90	0.0827860756737157	0.9776727504338559	0.14911753746370474	0.9609375
91	0.08082336816339325	0.97848761439168	0.14639595616608858	0.9622395833333334
92	0.07564677515660924	0.978324641926503	0.15237968197713295	0.9596354166666666
93	0.07600073700933443	0.9781616693059033	0.14904848548273245	0.9602864583333334
94	0.07697603298834436	0.9783246417710803	0.1476402822881937	0.9615885416666666
95	0.07606615574430611	0.9778357237538583	0.1520765027962625	0.9583333333333334
96	0.07555721827443918	0.9779986966853036	0.14805135627587637	0.9622395833333334
97	0.07583668560877617	0.9794654501152784	0.14777083757023016	0.9615885416666666
98	0.07546854805992977	0.9802803130628543	0.14916510165979466	0.9609375
99	0.07300429390998366	0.9820730122002971	0.15155768766999245	0.962890625

The optimal condition:
	epoch: 99
	train_acc: 0.9820730122002971
	val_acc: 0.962890625
	using time: 115.339568853
