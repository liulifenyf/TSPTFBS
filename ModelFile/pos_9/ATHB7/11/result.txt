The number of train datas: 6136
The number of test datas: 1536
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6987029621001173	0.5110821378122252	0.6918227275212606	0.5305989583333334
1	0.6934863910992112	0.5242829203139383	0.6870922992626826	0.5540364583333334
2	0.6885794384849429	0.5394393741851369	0.683155337969462	0.5755208333333334
3	0.6843147144945535	0.5558996083994422	0.6789083133141199	0.6041666666666666
4	0.6776544084138634	0.5769230765345199	0.673661877711614	0.626953125
5	0.6728199384669437	0.5860495438320851	0.6668424258629481	0.6438802083333334
6	0.6639722682040238	0.6052803127520088	0.6583117296298345	0.6783854166666666
7	0.6547295376561301	0.6236962189574907	0.6472275406122208	0.7122395833333334
8	0.6464562395094582	0.6383637552777356	0.6340255935986837	0.7252604166666666
9	0.6327868753648332	0.6577574961965678	0.6180114448070526	0.7428385416666666
10	0.6163675084107858	0.680247718072466	0.5950147360563278	0.7825520833333334
11	0.5937097414531484	0.710234681039932	0.5686119347810745	0.8125
12	0.5692117546030564	0.7281616686065008	0.5356847246487936	0.841796875
13	0.5351602930910739	0.7684159064386161	0.4955448980132739	0.8678385416666666
14	0.4977702848525837	0.7899282925132045	0.45263927926619846	0.884765625
15	0.4606416868495195	0.816818774057336	0.40764377017815906	0.8990885416666666
16	0.4146792599554945	0.8371903524871289	0.3616554066538811	0.9127604166666666
17	0.374383219994964	0.8583767922325581	0.3204262355963389	0.923828125
18	0.34628193878909913	0.8740221638101332	0.29129668573538464	0.9231770833333334
19	0.3064577447583187	0.8958604958253237	0.264785702029864	0.9296875
20	0.27482615619159584	0.9084093870675237	0.23533650860190392	0.939453125
21	0.263301588138359	0.9090612775499227	0.22004363934199014	0.9440104166666666
22	0.2389371276989754	0.9247066488166521	0.20823304417232671	0.9446614583333334
23	0.22592321549198618	0.9256844847733847	0.19746215206881365	0.9485677083333334
24	0.20989540098854273	0.9361147331134593	0.18743682838976383	0.9498697916666666
25	0.20217402302690404	0.9388852673528092	0.18353707840045294	0.9518229166666666
26	0.19299674714093412	0.940514994025075	0.1767273172736168	0.9524739583333334
27	0.17796818610897586	0.9452411997893332	0.17815432666490474	0.9518229166666666
28	0.1779610624602441	0.9455671452636669	0.16901253970960775	0.9544270833333334
29	0.17120801015347825	0.9506192958805676	0.16905110577742258	0.955078125
30	0.16838175347839837	0.9501303781741912	0.16742287141581377	0.9557291666666666
31	0.16520691063677628	0.9501303777079227	0.16179205973943075	0.955078125
32	0.15550593742335792	0.9542046936891847	0.16000903149445853	0.9557291666666666
33	0.15290008800048405	0.9559973922049362	0.1625732152412335	0.95703125
34	0.15038610901562144	0.9579530633412875	0.15865764332314333	0.9563802083333334
35	0.14473641427741368	0.9576271182555108	0.15567311458289623	0.9557291666666666
36	0.1458027714856134	0.9584419812030867	0.16102245977769294	0.95703125
37	0.14393273658438488	0.9603976526502835	0.15386297336469093	0.955078125
38	0.14124238702821917	0.9607235989017312	0.15242340043187141	0.9583333333333334
39	0.13663867115974426	0.9626792699603711	0.15271098787585893	0.9583333333333334
40	0.14158122091902592	0.960723597891483	0.15175276746352515	0.95703125
41	0.13727393127599005	0.9617014344699069	0.15324464812874794	0.9602864583333334
42	0.13734871937833834	0.9636571052177011	0.14972745316723982	0.9583333333333334
43	0.13380049091352167	0.9657757491300749	0.15003488399088383	0.958984375
44	0.13079993822156527	0.966101695070677	0.1495770417774717	0.9596354166666666
45	0.12746248342767066	0.9661016943712745	0.14870499540120363	0.9583333333333334
46	0.12579909066100164	0.9661016943712745	0.1488560875877738	0.9609375
47	0.12021175021065261	0.9682203385944939	0.1599344303831458	0.95703125
48	0.12374122798287418	0.9665906132433219	0.1493066002925237	0.9622395833333334
49	0.12453686627601862	0.9662646680798338	0.14692473380515972	0.958984375
50	0.12098627978501139	0.9682203387499166	0.14746984653174877	0.9615885416666666
51	0.11743956124300751	0.9688722299317182	0.14683841976026693	0.9615885416666666
52	0.11843067566916404	0.9687092567671387	0.14689459962149462	0.9615885416666666
53	0.11826270119307716	0.9675684484229405	0.14622407872229815	0.9615885416666666
54	0.11601071733850232	0.9705019552828902	0.14734831048796573	0.9615885416666666
55	0.11724381999754999	0.96773142158752	0.14545857595900694	0.9583333333333334
56	0.11493977463307561	0.9691981741626695	0.1466912136723598	0.9622395833333334
57	0.11260436289740977	0.970013037421091	0.14530025329440832	0.958984375
58	0.1097436098301737	0.9709908731446895	0.14643053027490774	0.9615885416666666
59	0.11306924658500853	0.9696870920244687	0.14481716696172953	0.958984375
60	0.10770672161467228	0.9690352020083381	0.14491142984479666	0.9596354166666666
61	0.1078706214731411	0.9735984354628422	0.1447819611057639	0.958984375
62	0.10970607769069647	0.9726205998946666	0.1453336322059234	0.9596354166666666
63	0.10605979999320914	0.9691981741626695	0.146117669219772	0.9615885416666666
64	0.1051332908530745	0.9711538466201146	0.14785876063009104	0.9622395833333334
65	0.10477396338750673	0.9726205993506868	0.14524292511244616	0.9609375
66	0.10381479134887574	0.9719687095676904	0.14549066281567016	0.9609375
67	0.10386180022860132	0.9722946541094873	0.1451878339673082	0.9583333333333334
68	0.10331418171932986	0.9724576272740668	0.14546582692613205	0.958984375
69	0.10214222366332697	0.9721316820328674	0.14604810687402883	0.9615885416666666
70	0.09815081935545923	0.9735984357736879	0.14586993182698885	0.9609375
71	0.09845991063537622	0.9731095172124861	0.1454931345457832	0.9609375
72	0.09709464498301373	0.973272489677663	0.14568085751185814	0.9609375
73	0.09782681380054942	0.9742503255566842	0.14752631448209286	0.962890625
74	0.09778670589724918	0.9745762716527091	0.14614374206090966	0.9615885416666666
75	0.098605889181037	0.9737614075394622	0.1447541161129872	0.9596354166666666
76	0.09868347909996066	0.9745762714972863	0.14665173708150783	0.9622395833333334
77	0.09486109168891646	0.9752281611248598	0.14561483853807053	0.9609375
78	0.09370292898029517	0.974250325712107	0.1458468372002244	0.9615885416666666
79	0.09548758427858975	0.9755541070654619	0.14566473538676897	0.9602864583333334
80	0.09432862832112604	0.9729465454467117	0.14547830075025558	0.9602864583333334
81	0.09767006074395299	0.971642764326491	0.14537212004264197	0.9609375
82	0.09149455695839251	0.9747392442733088	0.14551661008348069	0.958984375
83	0.09371082541062903	0.9729465444364634	0.14495726053913435	0.9602864583333334
84	0.09111124158604982	0.9735984349188624	0.14529013633728027	0.9596354166666666
85	0.08671893172616908	0.9762059978587064	0.14649312943220139	0.958984375
86	0.08775089455785465	0.9773468062029047	0.1465860487272342	0.9596354166666666
87	0.08822684436842236	0.9737614075394622	0.1464507932153841	0.9609375
88	0.08833611576855571	0.9744132988766866	0.14644751170029244	0.9596354166666666
89	0.0888926152679025	0.9750651892036627	0.14626906843235096	0.958984375
90	0.0920439676091444	0.9752281619796852	0.1485530181477467	0.9609375
91	0.08887318457626146	0.9755541073763075	0.14521292938540378	0.9583333333333334
92	0.08488346683893552	0.9762059977032836	0.14596756532167396	0.9615885416666666
93	0.0842982587711752	0.9768578883411054	0.14712001274650297	0.9609375
94	0.08692838770314332	0.9779986966853036	0.14684518023083606	0.9596354166666666
95	0.08466821108523373	0.9752281619796852	0.14796950838839015	0.9596354166666666
96	0.08010005669223905	0.9786505871677026	0.14810236264020205	0.958984375
97	0.08252867195643533	0.9755541063660593	0.1491389077467223	0.9596354166666666
98	0.08307372421181652	0.9778357230544557	0.1472433709229032	0.9596354166666666
99	0.0835777430502501	0.9770208601068797	0.14966671541333199	0.9576822916666666

The optimal condition:
	epoch: 73
	train_acc: 0.9742503255566842
	val_acc: 0.962890625
	using time: 76.5151789188
