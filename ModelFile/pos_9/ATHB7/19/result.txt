The number of train datas: 6136
The number of test datas: 1536
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6995503252767988	0.5105932205721172	0.6947042047977448	0.5071614583333334
1	0.6920653818639037	0.5288461536907311	0.6904710878928503	0.5260416666666666
2	0.6889815299420811	0.5347131683431673	0.6871740172306696	0.5416666666666666
3	0.6854018430666321	0.546773141878991	0.6833771963914236	0.5677083333333334
4	0.6775853879448643	0.5767601039139202	0.678972507516543	0.5846354166666666
5	0.674445330863515	0.5743155144495012	0.6736525992552439	0.6048177083333334
6	0.6696257201136324	0.6015319424782147	0.6665747662385305	0.6243489583333334
7	0.6586827042827084	0.6284224248771717	0.6572064707676569	0.654296875
8	0.6496244431163684	0.6328226858664989	0.643281469742457	0.6946614583333334
9	0.636401196269044	0.6517275101669142	0.6259710838397344	0.728515625
10	0.6161989179552767	0.684485005974925	0.6015758713086446	0.76171875
11	0.5959445067925434	0.7092568452386222	0.5705277373393377	0.796875
12	0.5640725574250949	0.73761408029044	0.5314079423745474	0.8287760416666666
13	0.5255863973494459	0.7775423734253357	0.485490250090758	0.8645833333333334
14	0.4806472452010139	0.8044328548917559	0.43840622653563815	0.875
15	0.4380035715898914	0.8270860496990995	0.386594499150912	0.8971354166666666
16	0.39416300345119937	0.8507170792197932	0.3457464650273323	0.90625
17	0.3496251728730531	0.8751629729314453	0.30415696154038113	0.9153645833333334
18	0.322150965674138	0.8862451103551136	0.27566280712683994	0.9225260416666666
19	0.2831726225755982	0.9054758799744398	0.2619154577453931	0.91796875
20	0.25542757311420616	0.9118318119446954	0.2322974738975366	0.9309895833333334
21	0.24991901283003048	0.9181877439926625	0.2209648663798968	0.9342447916666666
22	0.23044524228168747	0.928455019090446	0.214851476252079	0.9368489583333334
23	0.216100189723123	0.9336701428719263	0.20506390184164047	0.939453125
24	0.2083079493768523	0.9346479789063704	0.19448627531528473	0.9427083333333334
25	0.1978433635741511	0.9392112127494314	0.1913311711202065	0.9466145833333334
26	0.18857869348516676	0.9441003913674236	0.18601416051387787	0.9459635416666666
27	0.17723690805837725	0.9485006523567509	0.18825363305707773	0.9453125
28	0.173323363920545	0.9485006524344622	0.17781919799745083	0.9466145833333334
29	0.16773116141751973	0.9525749673277645	0.17716492029527822	0.9479166666666666
30	0.1691309004400358	0.9525749671723417	0.175181420519948	0.9485677083333334
31	0.1621959501442729	0.9537157760605196	0.17090838278333345	0.9485677083333334
32	0.15581176217251994	0.9577900911869561	0.16989459407826266	0.9479166666666666
33	0.1547646742056681	0.9576271182555108	0.17484688137968382	0.9518229166666666
34	0.1489986093445272	0.95713820085998	0.16671020475526652	0.951171875
35	0.1447916182226743	0.9600717074090841	0.16439898374179998	0.9505208333333334
36	0.14570338375176725	0.9595827895472848	0.16950200870633125	0.9518229166666666
37	0.14423414029307285	0.9621903516323035	0.16186328480641046	0.9518229166666666
38	0.13739263752992648	0.9631681882107274	0.16170196297268072	0.953125
39	0.13573932678789638	0.9613754889955732	0.16057723760604858	0.9537760416666666
40	0.13912452912781353	0.961864406391104	0.15915644044677416	0.9537760416666666
41	0.13383613870694086	0.9634941324416786	0.16172394901514053	0.955078125
42	0.1365956048222533	0.9628422422701253	0.15702445122102895	0.953125
43	0.13144541577456673	0.965123858647676	0.15699119927982488	0.9544270833333334
44	0.12867765666763972	0.9654498047437009	0.15809632961948714	0.9557291666666666
45	0.12519631529957873	0.9661016945266973	0.15678432770073414	0.9537760416666666
46	0.12506743365075473	0.9665906123884964	0.15599555956820646	0.9537760416666666
47	0.12166850218328379	0.9682203389053394	0.1682027600084742	0.9544270833333334
48	0.12217276486066672	0.966916557629696	0.1553969494998455	0.9557291666666666
49	0.1228248737315311	0.9669165582513871	0.15397964914639792	0.9524739583333334
50	0.12270237091622732	0.9665906122330736	0.1535511246571938	0.955078125
51	0.11796221702397258	0.9680573659738941	0.1523190513253212	0.953125
52	0.11651843508421364	0.9705019559822928	0.1514240608861049	0.9557291666666666
53	0.11331594658643979	0.9698500649559141	0.15179070830345154	0.9563802083333334
54	0.11604706738071305	0.9680573659738941	0.15650420635938644	0.9576822916666666
55	0.11414000488128002	0.9705019559822928	0.15037881210446358	0.95703125
56	0.11408063401182751	0.9705019559822928	0.15021240897476673	0.9563802083333334
57	0.10943520552875788	0.9703389825068677	0.15149538405239582	0.9557291666666666
58	0.10998941456712054	0.970176009886268	0.149699991568923	0.9557291666666666
59	0.10776882431186939	0.9706649277480671	0.14866432609657446	0.9557291666666666
60	0.10668434012278118	0.970501955438313	0.14943701525529227	0.9563802083333334
61	0.1058092947121627	0.9726206000500894	0.1481243638942639	0.9563802083333334
62	0.10890649191092948	0.9713168189298687	0.14801277096072832	0.9557291666666666
63	0.10456134295370308	0.9701760108965162	0.14757142712672552	0.9557291666666666
64	0.10213387125648918	0.9737614083942876	0.1515524753679832	0.9583333333333334
65	0.10076964229850446	0.9718057362476881	0.15001644225170216	0.95703125
66	0.10127026853886235	0.9731095172124861	0.14681154458473125	0.9563802083333334
67	0.10003430123357139	0.9729465449027319	0.14702562180658182	0.9583333333333334
68	0.10114276799648961	0.9734354631530882	0.14737138090034327	0.9557291666666666
69	0.09756880231211362	0.9735984357736879	0.15000378992408514	0.95703125
70	0.0957926630565831	0.974250326100664	0.14636412356048822	0.9557291666666666
71	0.09542527225601938	0.9719687088682878	0.14863820187747478	0.9576822916666666
72	0.0995075878586421	0.9713168192407143	0.150414171628654	0.9583333333333334
73	0.09598305615483549	0.9753911340563052	0.1461731120944023	0.9563802083333334
74	0.09554356981598258	0.9731095179118886	0.15076736453920603	0.958984375
75	0.0917510989436581	0.9755541073763075	0.1457484137887756	0.9576822916666666
76	0.0941465525527277	0.9739243810148873	0.14840917382389307	0.9583333333333334
77	0.09011896603499119	0.975717078986659	0.14542253936330476	0.9576822916666666
78	0.09011274352766856	0.9760430245387042	0.1460524688785275	0.9576822916666666
79	0.09096501075518178	0.9760430247718384	0.148684143088758	0.958984375
80	0.09198942131604489	0.9752281611248598	0.1457415803646048	0.9576822916666666
81	0.09224389747970263	0.974087353635487	0.1459800877297918	0.95703125
82	0.08568843250130115	0.9753911344448621	0.14806588056186834	0.95703125
83	0.09036945880935898	0.9752281611248598	0.14669836685061455	0.9576822916666666
84	0.08534082022375358	0.9742503262560868	0.14937706074366966	0.958984375
85	0.08519476173248876	0.9755541073763075	0.14674273071189722	0.9576822916666666
86	0.08500902872469465	0.9771838327274796	0.14775141639014086	0.9576822916666666
87	0.08510176351748047	0.975717078986659	0.14696823060512543	0.9576822916666666
88	0.08383955083292031	0.9773468060474818	0.1466605675717195	0.9583333333333334
89	0.08273473589388457	0.9766949155650829	0.14688112183163562	0.958984375
90	0.08542575587116599	0.9778357239092811	0.14862523041665554	0.9583333333333334
91	0.08528590582146017	0.9765319429444832	0.146116033817331	0.9596354166666666
92	0.0796699466856471	0.977346805892059	0.14878297162552676	0.9583333333333334
93	0.07949409776669593	0.9783246417710803	0.1490065654118856	0.9583333333333334
94	0.08223468226512999	0.9770208599514569	0.1475036802391211	0.958984375
95	0.07855717390969959	0.9791395050295018	0.15006377951552471	0.9583333333333334
96	0.07955552346159302	0.9765319429444832	0.1484553155799707	0.9596354166666666
97	0.08002738720668186	0.9794654492604531	0.15021242449680963	0.9583333333333334
98	0.07788409604514904	0.9788135596328795	0.14746894128620625	0.9602864583333334
99	0.07795767715344062	0.9779986966853036	0.1483344758550326	0.9583333333333334

The optimal condition:
	epoch: 98
	train_acc: 0.9788135596328795
	val_acc: 0.960286458333
	using time: 109.666398048
