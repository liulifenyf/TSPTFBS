The number of train datas: 1864
The number of test datas: 468
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7435543583186399	0.4935622321433775	0.7000621944411188	0.49572649580609596
1	0.6974474007479623	0.525214592786306	0.6929831102363064	0.523504270447625
2	0.6868388788382894	0.5472103009408124	0.6897526230567541	0.5405982926360562
3	0.6894947651118168	0.5434549351106898	0.6852524621873839	0.5598290577912942
4	0.6867174948745531	0.5450643780661243	0.6808476830140139	0.5705128215317034
5	0.6806643684534556	0.5552575111133347	0.6770735321900784	0.5833333343522161
6	0.6747142334864374	0.5954935627433875	0.6727386896426861	0.6388888873605647
7	0.6696824132117078	0.6003218894352729	0.6682089409257612	0.6367521403182266
8	0.6685122783603586	0.592811159565725	0.6636399428049723	0.6452991407141726
9	0.6713715001237239	0.5912017164823835	0.659424856177762	0.6581196535346855
10	0.6594064788245336	0.6105150209475996	0.6541666413983728	0.6709401689024053
11	0.6604351158305811	0.6062231754540374	0.6493774601536938	0.6816239290767245
12	0.650465723526836	0.6378755369923146	0.643647838352073	0.7008547008547008
13	0.6525219527948568	0.6341201726970754	0.6378065368049165	0.7200854700854701
14	0.6482389075561654	0.6298283256686297	0.6317998552933718	0.7329059798493345
15	0.6352429522976855	0.6722102994059288	0.6239859222346901	0.7499999969433515
16	0.6264013942219157	0.6824034334763949	0.6154916342507061	0.7649572644478235
17	0.6222453245277568	0.6807939903930533	0.6069068226039919	0.7692307712685349
18	0.6208334583069633	0.673819743512526	0.5987522887368487	0.7884615404993041
19	0.6143466096067633	0.6877682408549755	0.589850249962929	0.7970085490463127
20	0.6075573167064159	0.7001072958815251	0.5817081291451414	0.7970085434424572
21	0.5995162589867228	0.7011802580223575	0.5720326880104522	0.8205128169467306
22	0.5873366225942521	0.7049356233408522	0.5620509920976101	0.8162393152204335
23	0.5775946703591572	0.7231759654094221	0.5519214669863383	0.8141025656308883
24	0.5668270240014203	0.7274678103913566	0.540190246879545	0.8290598280409462
25	0.5609725529543832	0.7344420605974648	0.5312235151600634	0.8290598331353604
26	0.5565653622406235	0.7285407722763749	0.5213239712592883	0.8311965801776984
27	0.5446122552192262	0.7403433484069267	0.5118329889244504	0.824786326314649
28	0.5401378424894144	0.7440987129579798	0.5008205934467479	0.8333333297672435
29	0.5267637320854122	0.7591201716738197	0.49237109707970905	0.8269230784514011
30	0.5198601428019642	0.7741416314129154	0.48187361084497893	0.8354700844512026
31	0.5123348635153709	0.7730686705511527	0.4715631453909426	0.8269230764136355
32	0.5049676400141655	0.7703862660944206	0.4679036171008379	0.831196582215464
33	0.4882351643537759	0.7800429192223775	0.4506951132391253	0.8376068421918103
34	0.47722931634714677	0.7902360515021459	0.4433938787024245	0.8461538420783149
35	0.46739671145897566	0.8025751065286956	0.4298751443369776	0.8482905947245084
36	0.46398308604571953	0.7902360517579599	0.42061476294810957	0.8525641015452198
37	0.4507420028483919	0.8068669517664439	0.41571075743080205	0.8525641035829854
38	0.4484719549637496	0.8084763956172272	0.4039967798779153	0.8611111121299939
39	0.43369002685014785	0.8159871234402636	0.39616400334570145	0.8589743599932418
40	0.4120814426774119	0.8288626601767642	0.38437493489338803	0.8611111121299939
41	0.41727226524905586	0.820815450132149	0.3809470544513474	0.8675213685402503
42	0.4072535431947831	0.8320815450643777	0.3634407988980285	0.8717948702665476
43	0.3929765571084657	0.8395922744222977	0.354219949653006	0.8760683770872589
44	0.38804248397442404	0.8433476384617228	0.3490902333178072	0.8846153881814744
45	0.38130142299914055	0.8476394839552851	0.3337552537266006	0.8803418788135561
46	0.3540201673180249	0.8589055804223973	0.32602442253349173	0.8910256445917308
47	0.3531440106328465	0.8605150209475996	0.3140665173021137	0.8952991488652352
48	0.3410187228043192	0.865343347639485	0.3042771798423213	0.8910256445917308
49	0.32049825595683806	0.8792918449819344	0.30591298257693267	0.8952991458085867
50	0.3131797349504135	0.8798283256686297	0.2896750895386068	0.9017093996716361
51	0.3139187226735471	0.8798283269476993	0.27489444511568445	0.9059829013979334
52	0.3015611811257227	0.885193134070466	0.2689553277614789	0.9059829039451404
53	0.29016333562621743	0.8927038624051303	0.2596844493323921	0.9188034172750946
54	0.2847115021406837	0.8986051502145923	0.2628657973220206	0.9123931654498109
55	0.2636775737028777	0.9082618018076655	0.2449660136913642	0.9166666697233151
56	0.26169274728185626	0.907188840434275	0.24797662977988905	0.9123931654498109
57	0.2598282634060782	0.9039699581048007	0.2302130314274731	0.9294871825438279
58	0.24340134622457202	0.9211373398232358	0.2230914754745288	0.931623932133373
59	0.23501374889085222	0.9173819732256714	0.2238450324178761	0.9188034218600672
60	0.2333544024582073	0.9136266102095019	0.21752028689425215	0.9230769261335715
61	0.21783177030188844	0.9259656662593072	0.21068473886220884	0.9337606868173323
62	0.22563782558164883	0.9168454943296735	0.20718695134179205	0.93162393468058
63	0.21188269178243155	0.9286480681579	0.2068333444941757	0.9209401739968194
64	0.20252027154736252	0.9334763940823436	0.1965934190994654	0.9423076953643408
65	0.20582421232702394	0.9291845503794789	0.194323442175857	0.9337606868173323
66	0.19760364569052094	0.9297210305545464	0.20196076972871765	0.9273504222560133
67	0.19314085413969637	0.9329399133956483	0.186786028309765	0.9401709406803815
68	0.19022323958607704	0.9415236056618425	0.18838089596257251	0.9358974308030218
69	0.17665203567993998	0.9431330461870447	0.18915960944106436	0.9358974308030218
70	0.17521234106096586	0.9452789709803372	0.17965440668611446	0.9423076953643408
71	0.17743878897935025	0.9490343342523206	0.17707707268050593	0.9423076928171337
72	0.17302062071444138	0.9431330482335561	0.1798439558245178	0.9444444393500303
73	0.17501166693130787	0.9377682393200919	0.17779356425898707	0.9444444393500303
74	0.17247825202256314	0.942596567035233	0.17576108057784218	0.9444444393500303
75	0.16422329990137288	0.9484978543330671	0.17809409418931374	0.9465811914867825
76	0.16280413921043085	0.9458154511554047	0.17524638969419348	0.9465811914867825
77	0.15095553249760246	0.9511802585339854	0.17347874237686142	0.9444444393500303
78	0.15087097179736192	0.9490343342523206	0.16952187007563746	0.9465811914867825
79	0.15475623501472718	0.951180256487474	0.1736426980704324	0.9465811914867825
80	0.14563376107952625	0.9560085826677314	0.17113105819011346	0.9465811914867825
81	0.1523987957847988	0.9501072971605947	0.165987962586248	0.946581199637845
82	0.13824742549606658	0.9549356215501548	0.16655336466864643	0.9465811914867825
83	0.1456918108552822	0.951180256487474	0.16753937845301425	0.9465811914867825
84	0.13855417398935735	0.9586909863570218	0.1650223064626384	0.9487179436235347
85	0.14036022299349052	0.9581545069493961	0.16327437000651646	0.946581199637845
86	0.13244682946941883	0.9565450636102406	0.17439760516087213	0.940170935076526
87	0.1303428783053492	0.9576180249836311	0.16321909714203614	0.9487179436235347
88	0.1222996324172859	0.9597639492652958	0.1662619024133071	0.9465811914867825
89	0.126184672277117	0.9603004286729215	0.16240837979011047	0.946581199637845
90	0.1251830203466661	0.9597639492652958	0.16782579838465422	0.9465811914867825
91	0.12986500922574507	0.9613733900463121	0.1672963119852237	0.9465811914867825
92	0.12244532612260318	0.9586909878919053	0.162490225627891	0.9508546957602868
93	0.12440162794784415	0.959227467043717	0.16518645459770137	0.9465811914867825
94	0.12322992466933738	0.9603004289287355	0.16209135338281974	0.9508546957602868
95	0.11871931967305523	0.9597639490094819	0.16586101418122268	0.9444444393500303
96	0.11473594784992447	0.9613733895346842	0.16028152412583685	0.946581199637845
97	0.11408064050735833	0.9635193122814654	0.16252642971837622	0.9508546957602868
98	0.12258116514002304	0.9565450641218685	0.16405971220925322	0.9508546957602868
99	0.11501269493363958	0.968884119660046	0.16039645576324219	0.946581199637845

The optimal condition:
	epoch: 98
	train_acc: 0.9565450641218685
	val_acc: 0.95085469576
	using time: 166.214949131
