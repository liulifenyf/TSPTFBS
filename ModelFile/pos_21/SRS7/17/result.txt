The number of train datas: 4752
The number of test datas: 1188
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7218189078950722	0.49726430976430974	0.6927816446381386	0.5143097643097643
1	0.6976526718749743	0.5067340067340067	0.6907141836805376	0.5361952857939081
2	0.6946473816027143	0.5178872053872053	0.6898711149138633	0.5269360270363714
3	0.6892533802022838	0.5349326599326599	0.6881088106720535	0.5521885525899303
4	0.6870211170177267	0.5418771043771043	0.6868352940186908	0.5547138048141492
5	0.6893105585165699	0.5326178451178452	0.6854380439427565	0.5479797980801425
6	0.686232045242682	0.5536616161616161	0.6837921285067343	0.5648148144134367
7	0.6840708024975427	0.5517676767676768	0.681635385811931	0.5942760940754053
8	0.6842759960026853	0.547979797979798	0.6790125420197894	0.6018518516511628
9	0.6788856116208163	0.5730218855218855	0.6760907213294546	0.6119528617521729
10	0.6774465327311043	0.5747053872053872	0.6715088627153776	0.6186868684861796
11	0.6753413211617004	0.5757575757575758	0.6672745096161711	0.6346801348808238
12	0.6726304059879546	0.5858585858585859	0.6632009471707071	0.6708754208754208
13	0.6654924587769941	0.6071127946127947	0.6572474971764818	0.6700336708364262
14	0.6610291710606327	0.6066919191919192	0.6506292081441141	0.6885521891542556
15	0.6508951877504086	0.6317340067340067	0.6426004795514373	0.7129629629629629
16	0.6477108455266214	0.623526936026936	0.6337259193060776	0.7188552180524627
17	0.6339068515132172	0.6557239057239057	0.6212959508301834	0.7382154878141102
18	0.6254991672255776	0.6624579124579124	0.6085973424140854	0.7398989890962338
19	0.6173279112838335	0.6757154882154882	0.59599743828629	0.7508417500389947
20	0.6044598936231851	0.6923400673400674	0.581922157846316	0.7592592596606373
21	0.583979419987611	0.7085437710437711	0.5613985416865108	0.7676767668740115
22	0.5632949864824212	0.7270622895622896	0.5417498980307017	0.7760942764956542
23	0.5485170232727873	0.7409511784511784	0.5210865926662278	0.7920875420875421
24	0.5321867391717956	0.7556818181818182	0.5038788163100028	0.7904040408054185
25	0.5111986741875157	0.7628367003367004	0.48068020279560025	0.8097643101656878
26	0.49466984992476826	0.7781986531986532	0.4627197457082344	0.8148148152161929
27	0.4695194144843002	0.7910353535353535	0.44224606800561	0.8232323236337014
28	0.44570659918817207	0.8122895622895623	0.4239704828671735	0.8291245795259572
29	0.43048181106345823	0.8179713804713805	0.40657210560760115	0.8400673404687181
30	0.4154548127241809	0.8263888888888888	0.39501035654986344	0.8425925923919035
31	0.40264291514451256	0.8352272727272727	0.3892924119326402	0.8383838385845275
32	0.3918218118975861	0.8390151515151515	0.3698332800407602	0.8594276098289875
33	0.37546577166627954	0.8493265993265994	0.3519637371955897	0.8644781138760473
34	0.36168881187133917	0.8552188552188552	0.3424407413310876	0.871212120610054
35	0.35699860184682336	0.8606902356902357	0.3330139395363804	0.8737373731353066
36	0.33453176659767075	0.868476430976431	0.32366134151063786	0.8821548823555712
37	0.33139837871898303	0.872895622895623	0.31491847853066546	0.8905723903717015
38	0.30713299408504857	0.8806818181818182	0.3182661071770922	0.8695286203313757
39	0.30348525083426275	0.8878367003367004	0.3201553166314006	0.878787879389946
40	0.2986896028020968	0.8914141414141414	0.2948679297861427	0.8981481483488372
41	0.28562877615694243	0.8964646464646465	0.28547527623497676	0.8964646466653355
42	0.27651177251379094	0.8954124579124579	0.2845976169061179	0.8989898995919661
43	0.2688374262466174	0.9027777777777778	0.2767601154669367	0.9015151521172187
44	0.2595780714593752	0.9040404040404041	0.26876645266809046	0.9057239059245947
45	0.25675518655215046	0.9118265993265994	0.2678308439776552	0.9065656571677236
46	0.24856953909902862	0.9107744107744108	0.25934237241744995	0.9141414143421032
47	0.24920965605713302	0.9090909090909091	0.2628930338003017	0.9074074080094745
48	0.23861665501939727	0.9143518518518519	0.2581065990005679	0.9099326605347271
49	0.23342114097441888	0.9143518518518519	0.24763755294610354	0.914983165183854
50	0.22546872265812523	0.9227693602693603	0.24887273538393606	0.9141414147434812
51	0.21935860707302285	0.9231902356902357	0.24258891781572542	0.9065656567663456
52	0.21661301042495754	0.9223484848484849	0.23692037029699844	0.9132996639017305
53	0.2136810551388095	0.9223484848484849	0.23873640511573765	0.9200336706357372
54	0.2036830906815802	0.9307659932659933	0.25216237668838565	0.9057239063259729
55	0.20399195176583748	0.9288720538720538	0.22779645773296806	0.9149831655852321
56	0.1945167174092447	0.9328703703703703	0.22510208851761287	0.9183501689522354
57	0.18812085938975465	0.9341329966329966	0.22249998608823576	0.9166666672687338
58	0.19107549544737396	0.9328703703703703	0.22179116037758914	0.9175084181104847
59	0.18406407931436994	0.9358164983164983	0.21888827379504439	0.9183501689522354
60	0.180583921646831	0.9368686868686869	0.21557025726796802	0.9183501689522354
61	0.16830913286016444	0.9436026936026936	0.21491600964406524	0.9183501689522354
62	0.1690533505533179	0.9431818181818182	0.21119694050514337	0.9191919197939863
63	0.16805415026065879	0.944023569023569	0.20991684100041888	0.9191919197939863
64	0.16681675944063398	0.9438131313131313	0.22358768400720475	0.9175084181104847
65	0.1634414012383933	0.9408670033670034	0.21252631609287326	0.9166666672687338
66	0.1551904099105986	0.9484427609427609	0.2220741434631123	0.9191919197939863
67	0.1514195715538179	0.9488636363636364	0.20536600931324941	0.9225589231609896
68	0.15078446991515881	0.9480218855218855	0.20054436527719402	0.9225589231609896
69	0.14946354940684156	0.9499158249158249	0.2054707407951355	0.920875421477488
70	0.14353614006981705	0.9503367003367004	0.19864549540510082	0.9250841756862422
71	0.1430371550824305	0.9524410774410774	0.1997210635279967	0.9217171723192389
72	0.1394547487950887	0.9528619528619529	0.19623907873726854	0.9225589231609896
73	0.14091847997522514	0.9524410774410774	0.19509917311997527	0.9234006740027405
74	0.14006012076079244	0.9526515151515151	0.192983940243721	0.9250841756862422
75	0.13447213504049513	0.9545454545454546	0.19324839646968778	0.9250841756862422
76	0.13518430458174813	0.9526515151515151	0.22777823516816803	0.9166666658639105
77	0.12729377347210843	0.9551767676767676	0.1906325084091437	0.925925926527993
78	0.12747073569883802	0.9558080808080808	0.18921626923662244	0.9267676773697439
79	0.12226397978135632	0.9581228956228957	0.18926897599841608	0.9276094282114947
80	0.12436275369791872	0.9587542087542088	0.203508404042785	0.9200336706357372
81	0.122428461884208	0.9608585858585859	0.1876423987575653	0.9267676773697439
82	0.11419713953729431	0.9629629629629629	0.21019170829643705	0.9175084181104847
83	0.1174755310169374	0.9593855218855218	0.20796422805850354	0.9292929298949965
84	0.1178637857890691	0.9589646464646465	0.1878852251202169	0.9267676773697439
85	0.10990761680785655	0.9640151515151515	0.18368699559659668	0.9292929298949965
86	0.10591134363754029	0.9648569023569024	0.1961581834689134	0.9242424248444914
87	0.10912873568358245	0.9627525252525253	0.19028489246512903	0.9276094282114947
88	0.10442091509549305	0.9646464646464646	0.18405277419973304	0.9318181824202489
89	0.10594256237299755	0.9652777777777778	0.18870443208550763	0.9250841756862422
90	0.10339602641761303	0.9627525252525253	0.18365418369119818	0.9284511790532456
91	0.10236457624293939	0.9659090909090909	0.18116156174879683	0.9301346807367472
92	0.09853754847495494	0.9656986531986532	0.19514581147167417	0.9284511776484223
93	0.09818627727954878	0.9669612794612794	0.18093390266100565	0.9318181824202489
94	0.09476608379119976	0.969486531986532	0.18156842897436032	0.9318181824202489
95	0.09409514455883591	0.969486531986532	0.2028401942064465	0.925084174281419
96	0.09496419387634354	0.9671717171717171	0.19808382254959356	0.9276094272080495
97	0.09151729028232973	0.9696969696969697	0.18085387845834097	0.9318181824202489
98	0.09434322491037324	0.969486531986532	0.18034784179745297	0.9318181824202489
99	0.08742473463869657	0.9726430976430976	0.20094518393579155	0.9259259255245479

The optimal condition:
	epoch: 98
	train_acc: 0.969486531986532
	val_acc: 0.93181818242
	using time: 144.846081018
