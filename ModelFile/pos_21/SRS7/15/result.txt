The number of train datas: 4752
The number of test datas: 1188
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7197526924136511	0.4989478114478115	0.6896570473407655	0.5446127947131392
1	0.6964583121967637	0.5157828282828283	0.6879355564261928	0.5572390572390572
2	0.6931906980697555	0.5155723905723906	0.6865800958289843	0.564814815617571
3	0.6879791804034301	0.5431397306397306	0.6849144596844812	0.5782828280821393
4	0.6865626607679759	0.5534511784511784	0.6833027681517682	0.5892255896269672
5	0.6862229710877544	0.5433501683501684	0.6811322465488806	0.6119528613507949
6	0.684951754330786	0.5469276094276094	0.6791168947011132	0.606902357705113
7	0.6792052811645097	0.5717592592592593	0.6761916125262225	0.6338383844404509
8	0.6794592366876827	0.5643939393939394	0.6733760376169224	0.6506734012754678
9	0.6761161574610958	0.5845959595959596	0.6706740111614318	0.6473063979084644
10	0.6709720165239842	0.5906986531986532	0.6664827993823221	0.6675084175084175
11	0.6702910918579359	0.5934343434343434	0.662046654055817	0.670875421477488
12	0.6656826016076085	0.6098484848484849	0.6572975867525094	0.6717171711151046
13	0.6583042215016555	0.6199494949494949	0.6502833123560305	0.6835016833009945
14	0.6550858012754909	0.6165824915824916	0.6426896693730595	0.6994949496956385
15	0.6444456388653328	0.6367845117845118	0.633907321326259	0.7121212129239682
16	0.6427080095416368	0.6435185185185185	0.6246402675053889	0.7222222226236003
17	0.6226543316536078	0.6683501683501684	0.6114478990285084	0.7365319873347427
18	0.6159934283105613	0.6841329966329966	0.5978756137568542	0.7356902348874795
19	0.6066567076978459	0.6917087542087542	0.5826988430938336	0.7567340067340067
20	0.5920314313185335	0.7018097643097643	0.5715852652735983	0.7508417506410618
21	0.5761101685389124	0.7148569023569024	0.5481193178029172	0.7744107740093963
22	0.5509597059050795	0.7365319865319865	0.5266998954092212	0.7803030311057865
23	0.5383056466426913	0.7447390572390572	0.5062441067262129	0.7946127946127947
24	0.5181098951635136	0.7615740740740741	0.4871629464505899	0.802188551586485
25	0.49913631785999646	0.7742003367003367	0.46436930505514945	0.8190235684215019
26	0.47874117529753485	0.7889309764309764	0.445388556028456	0.8249158247151359
27	0.45997178875637373	0.8047138047138047	0.42324298188742565	0.8400673394652729
28	0.4335790415002842	0.8162878787878788	0.40293491368341927	0.8484848482841595
29	0.41892862400221903	0.82996632996633	0.38322509990798104	0.8543771041764153
30	0.39941991569618585	0.8373316498316499	0.36957886122693917	0.8661616163623052
31	0.3864134719676843	0.8440656565656566	0.37018534220027605	0.8552188558209224
32	0.38175642640903745	0.8409090909090909	0.33904666150057755	0.8787878789885678
33	0.36129109305564805	0.8529040404040404	0.32396683528367115	0.8838383840390729
34	0.3477987324950671	0.8634259259259259	0.3140174551844998	0.8897306399313287
35	0.34497591592246035	0.8661616161616161	0.307893199651731	0.8855218853211965
36	0.3227221201164554	0.8798400673400674	0.3003776703619395	0.8930976436997102
37	0.32083493029629745	0.8792087542087542	0.28533772276306796	0.8981481487502153
38	0.2995717162235016	0.8905723905723906	0.2860411094495343	0.8922558920552032
39	0.2949870007507729	0.8943602693602694	0.29202306436167824	0.8905723911744577
40	0.2881316001768465	0.8914141414141414	0.2623603131233241	0.9107744113764779
41	0.2796157343620403	0.8977272727272727	0.2568091770213862	0.9124579130599796
42	0.26736864979419644	0.9044612794612794	0.25320413176860873	0.9158249164269829
43	0.25921574746719517	0.9029882154882155	0.24510926690567222	0.9200336706357372
44	0.2513440161040335	0.9147727272727273	0.2382467244610642	0.9175084181104847
45	0.25094565397962576	0.9099326599326599	0.23769340787070367	0.9217171723192389
46	0.23931738463315097	0.9124579124579124	0.23084313610587456	0.9234006740027405
47	0.23731710694052957	0.9158249158249159	0.23307717072241235	0.9183501689522354
48	0.22919937019998377	0.9223484848484849	0.22762863709268344	0.9191919197939863
49	0.23534863168743725	0.913510101010101	0.22467266650312276	0.9225589231609896
50	0.226213531963753	0.9255050505050505	0.22074799766444198	0.9242424248444914
51	0.21183843122989643	0.9252946127946128	0.21558686047290712	0.9234006740027405
52	0.213733502811053	0.9242424242424242	0.2126950204171717	0.925925926527993
53	0.2071951793299781	0.92739898989899	0.21135875020765696	0.9276094282114947
54	0.20516642275884095	0.929503367003367	0.22740483785719182	0.9225589217561664
55	0.203405046402806	0.9318181818181818	0.20488393999109364	0.9276094282114947
56	0.19555366169723998	0.9343434343434344	0.21020855385847767	0.9292929298949965
57	0.18863179339001876	0.9345538720538721	0.20146282855107728	0.9276094282114947
58	0.18603917390660005	0.9341329966329966	0.20614004421113719	0.9301346807367472
59	0.18831016757973917	0.9341329966329966	0.19768857233452075	0.9284511790532456
60	0.17993361214395323	0.9375	0.2000312616528084	0.9234006740027405
61	0.18105098680414336	0.938973063973064	0.19793323735998133	0.9318181824202489
62	0.17260155387799747	0.9393939393939394	0.19381900287236428	0.9292929298949965
63	0.16562179516160527	0.9431818181818182	0.19201741651051776	0.9318181824202489
64	0.17151352637745315	0.9421296296296297	0.21695423276737483	0.9259259251231697
65	0.1602792673640781	0.9427609427609428	0.1938839437383594	0.9326599332619998
66	0.1617744396180416	0.9446548821548821	0.1937400138237661	0.9326599332619998
67	0.15386459497289626	0.952020202020202	0.18674089380787678	0.9301346807367472
68	0.15546923302590646	0.9461279461279462	0.1876650017620337	0.9351851857872523
69	0.1481310683067399	0.9480218855218855	0.20636973778406778	0.9284511776484223
70	0.14846597797541505	0.9480218855218855	0.18406237165133157	0.9318181824202489
71	0.1451084837192036	0.9480218855218855	0.19272902442349327	0.9309764315784981
72	0.14061864182001813	0.9524410774410774	0.18382415361075288	0.9335016841037507
73	0.14125419636366746	0.9501262626262627	0.182937244975607	0.9343434349455014
74	0.13963574622616623	0.9507575757575758	0.18084527200922018	0.9326599332619998
75	0.13495097858737212	0.9541245791245792	0.18108245344073684	0.9343434349455014
76	0.13950839959812486	0.9501262626262627	0.18412588250757467	0.936868687470754
77	0.1342430454914016	0.9545454545454546	0.18917889943227223	0.9351851857872523
78	0.12911721607450685	0.9572811447811448	0.17821795295183906	0.9335016841037507
79	0.12824946009751523	0.9564393939393939	0.17672752922632878	0.9377104383125048
80	0.12785631633968866	0.9558080808080808	0.19175916348242197	0.9335016841037507
81	0.12035879381126427	0.960016835016835	0.17587126003772724	0.9377104383125048
82	0.11548981828119619	0.9612794612794613	0.18205332088751425	0.9385521891542556
83	0.12034135234074962	0.9568602693602694	0.17422508235130246	0.9309764315784981
84	0.11618178159700901	0.9617003367003367	0.1734214239951336	0.9385521891542556
85	0.10967589684006342	0.9671717171717171	0.1730046069581902	0.9351851857872523
86	0.10709633906481643	0.9635942760942761	0.19074824743399316	0.9385521877494324
87	0.11571251653661632	0.961489898989899	0.18048865159954688	0.9402356908377574
88	0.10514569663840914	0.9635942760942761	0.17748815744412869	0.936868687470754
89	0.10725592877025958	0.9654882154882155	0.17147643668483	0.9393939399960065
90	0.10732355295846659	0.9629629629629629	0.1696074965726647	0.9393939399960065
91	0.10282687678531766	0.9667508417508418	0.17078149780279858	0.9385521891542556
92	0.09784196886651042	0.9661195286195287	0.17553545348973387	0.9410774402746849
93	0.10025817757905131	0.9682239057239057	0.175611374805672	0.9410774402746849
94	0.09970023069116804	0.9667508417508418	0.1702269212364749	0.9402356908377574
95	0.09358433119777075	0.9673821548821548	0.1933065171946179	0.9368686860659307
96	0.09517204235323551	0.9669612794612794	0.18042521705531112	0.9402356894329341
97	0.09563281372039005	0.9656986531986532	0.1724684836487176	0.9402356908377574
98	0.09382462475185442	0.9667508417508418	0.17097597566718606	0.9427609419581866
99	0.09726192097270529	0.9671717171717171	0.1802060634198815	0.9419191911164357

The optimal condition:
	epoch: 98
	train_acc: 0.9667508417508418
	val_acc: 0.942760941958
	using time: 126.249012947
