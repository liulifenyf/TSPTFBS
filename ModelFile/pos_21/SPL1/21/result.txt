The number of train datas: 3202
The number of test datas: 802
epoch	train_loss	train_acc	val_loss	val_acc
0	0.721906613067565	0.49750156152404745	0.6861174062005897	0.571072319647915
1	0.7048797773093748	0.523422860712055	0.6809887997527372	0.5835411462403295
2	0.6943041092898233	0.537788881948782	0.6769307637749765	0.6047381555053064
3	0.687226396959175	0.5608994378513429	0.67285156235136	0.6234413974005683
4	0.6829541535916588	0.5571517801374141	0.6687241441888405	0.6384039907681377
5	0.6768499262477368	0.5652717051842598	0.6647951562802987	0.6371571063400802
6	0.6766256950260474	0.5752654590880699	0.6600526951792234	0.6521196998562896
7	0.665868251678126	0.6002498438475953	0.6544512902709314	0.6733167086753464
8	0.6616873445174308	0.6114928169893816	0.6481482938043495	0.6770573561625588
9	0.655134335262637	0.6114928169893816	0.6404199896013351	0.6845386529206635
10	0.6472111152046401	0.6292941911305434	0.6289107139568376	0.71571072363794
11	0.6359089169928165	0.6533416614615865	0.6180965068037075	0.7107231912767501
12	0.6327342699647769	0.6489693941286696	0.6065241536891965	0.7468827921256163
13	0.6221896015726575	0.6620861961274204	0.6058792300949667	0.6758104750045815
14	0.6145574855178986	0.6692692067457839	0.5849665135814067	0.7518703244868062
15	0.5989482663036658	0.6848844472204872	0.5734079362745594	0.7394014965566317
16	0.5837936225643313	0.6992504684572143	0.5611090457944798	0.745635910670359
17	0.5721035450045426	0.7129918800749532	0.5491241777032391	0.7518703231490461
18	0.5581917750842864	0.7273579013116802	0.5364913802937676	0.7394014952188716
19	0.5506107105008518	0.7386008744534666	0.5218704210552492	0.7593516200557908
20	0.5376371816405648	0.7342286071205496	0.507142573892327	0.7755610975541378
21	0.5210435178635792	0.7420362273579013	0.4927561914088423	0.7805486287262077
22	0.5218683137586905	0.749843847595253	0.49191798637632717	0.7743142137206404
23	0.5057646490349612	0.7610868207370394	0.4756050704423329	0.7905236898812272
24	0.49654764104529814	0.7713928794503435	0.46045049787162246	0.8117206985516441
25	0.48660341789393335	0.7707682698313554	0.4480203176079843	0.8067331672309342
26	0.47204404540690387	0.7873204247345409	0.4388087009848502	0.8167082298723539
27	0.4558304462635391	0.7957526545908807	0.430322640331606	0.8154613470793365
28	0.4531952370560817	0.7998126171143035	0.4080890077456572	0.8379052370563707
29	0.4510480734164234	0.7979387882573392	0.40291307862857334	0.8416458854354231
30	0.42683490904177224	0.8173016864459712	0.38185048081036516	0.8566084789516325
31	0.4181678895463354	0.8157401623985009	0.3791773979949238	0.8566084780597925
32	0.4066955671226286	0.8316677076826983	0.3594196368185362	0.871571072467842
33	0.39152270559219177	0.8385384134915678	0.3478547430915428	0.8740648367161168
34	0.3942894836204786	0.8326046221111805	0.3390275665798092	0.8778054850951692
35	0.36962320105051116	0.8500936914428482	0.32052791594269864	0.8865336646462914
36	0.363359725099292	0.8479075577763897	0.3101972046487052	0.8915211958183612
37	0.357173888081409	0.8572767020612118	0.3065281106795456	0.8877805487770689
38	0.3439758440094542	0.8647720174890693	0.2946590939513466	0.9002493753694834
39	0.33884140030061505	0.8600874453466584	0.2843334915632024	0.9089775549206056
40	0.33361200251145934	0.8616489693941287	0.2817307337932753	0.9014962595002609
41	0.33349426347601796	0.868207370393504	0.2737971781718166	0.9064837893345706
42	0.32314297307903955	0.8663335415365396	0.26598176282094305	0.9152119688856929
43	0.3097833634786387	0.8803872579637726	0.2616294588605662	0.9127182032996579
44	0.30739012876203253	0.8819487820112429	0.28333643963212085	0.8802992521676042
45	0.30748833567927886	0.8782011242973142	0.25434165475820364	0.9064837906723308
46	0.3012022400445896	0.8813241723922548	0.24718114150283937	0.9164588516787103
47	0.2934567951024286	0.886945658963148	0.2478307006216406	0.9089775549206056
48	0.28379352227886495	0.8885071830106184	0.23999173418988015	0.9177057344717278
49	0.28425340254853326	0.8903810118675828	0.25193783785785523	0.9039900250862959
50	0.28027965754810386	0.8906933166770769	0.23656299624805735	0.9152119688856929
51	0.26917250414403954	0.8941286695815116	0.23048145712313806	0.9164588516787103
52	0.2698136412731717	0.8941286695815116	0.24753900292211042	0.9027431422932785
53	0.26159342336029207	0.8928794503435353	0.22539472932976082	0.9189526172647452
54	0.262288085029674	0.9013116801998751	0.22684055321531701	0.9139650874304355
55	0.2579677327583165	0.9006870705808869	0.28461478126613876	0.8703241886343445
56	0.2664792267402063	0.8935040599625235	0.22388525509700513	0.9276807980049875
57	0.2638000588466196	0.8997501561524047	0.22418367517113388	0.9201995000577627
58	0.24976883762557384	0.9091193004372268	0.30043919269283514	0.8603491262902048
59	0.2631363080748165	0.8935040599625235	0.22326429912871554	0.9201995000577627
60	0.24563920334083897	0.9072454715802624	0.26565189113343446	0.8915211961156412
61	0.24193906240039584	0.9044347282948157	0.22008688157038794	0.9226932656437976
62	0.23993078056143494	0.910368519675203	0.2270115441886564	0.9102244392000232
63	0.23054039737047963	0.9119300437226733	0.21779400229156762	0.9201995002064027
64	0.22563923602408353	0.9156777014366021	0.20861709541513437	0.9201995002064027
65	0.22219504141420368	0.9134915677701436	0.20407839583934395	0.9226932656437976
66	0.2219733499144108	0.9144284821986258	0.20271388424602232	0.923940148436815
67	0.21848109802190474	0.9119300437226733	0.20279605192436542	0.9201995002064027
68	0.21030806088767745	0.9184884447220487	0.21942762967357018	0.9102244392000232
69	0.2069327828662236	0.924422236102436	0.20918101235815414	0.9164588518273503
70	0.20860238303474007	0.9184884447220487	0.19801833501034544	0.9251870325675926
71	0.19869757063458815	0.9237976264834479	0.19963670861988592	0.9339152107809547
72	0.21320641706979773	0.9184884447220487	0.19973060105952836	0.9177057346203678
73	0.1948765621268697	0.9297314178638351	0.2266745253691352	0.9077306736139883
74	0.1941155888824296	0.9272329793878826	0.201387919522729	0.9326683279879373
75	0.20117362023684324	0.9209868831980013	0.2149432487321316	0.9114713219930406
76	0.1930492203508147	0.9234853216739538	0.19324049643447572	0.9326683293256973
77	0.19225278737106077	0.924422236102436	0.1911868464917019	0.9301745637396625
78	0.1820572839629866	0.9303560274828232	0.1938633978218212	0.9239401499232152
79	0.17752506461071269	0.9344159900062461	0.19982464147030266	0.9164588531651104
80	0.17264321914814101	0.9375390381011868	0.1947652004900716	0.9189526187511453
81	0.17262271049896083	0.9366021236727046	0.1992637351564041	0.9164588531651104
82	0.17114825978605244	0.9375390381011868	0.18703985459489417	0.928927680946645
83	0.16962731410536933	0.9362898188632105	0.1945515989588383	0.9189526187511453
84	0.16214265131265354	0.9406620861961275	0.187266693411028	0.9251870327162326
85	0.16402436263724315	0.9412866958151156	0.19295705301208688	0.9226932671301977
86	0.16080618067077365	0.943785134291068	0.186502430950317	0.9326683293256973
87	0.1607502143059873	0.9419113054341037	0.31654419313345167	0.8566084780597925
88	0.1736602784040792	0.9284821986258588	0.19715211887906614	0.9339152121187149
89	0.16234754047808536	0.9397251717676453	0.18643096810267157	0.9239401499232152
90	0.15517507692558144	0.9425359150530919	0.18778029641605673	0.9239401499232152
91	0.15017677463828438	0.9447220487195502	0.18671092814638132	0.9251870327162326
92	0.150480000407322	0.9456589631480324	0.20059829177404578	0.9139650875790756
93	0.1464177024402981	0.9472204871955028	0.19844921486930656	0.915211970372093
94	0.14114289319399817	0.948157401623985	0.1837693264805468	0.9276807983022676
95	0.13818824797086907	0.9512804497189257	0.18320042002676729	0.9276807983022676
96	0.13465114025344407	0.9522173641474079	0.215180491921759	0.9326683293256973
97	0.15030799106200884	0.9450343535290443	0.19288101353847475	0.9226932671301977
98	0.13207601022317325	0.948469706433479	0.18033946233051376	0.9339152122673549
99	0.12624748850629305	0.9562773266708308	0.1848476303188581	0.9264339155092501

The optimal condition:
	epoch: 98
	train_acc: 0.948469706433479
	val_acc: 0.933915212267
	using time: 319.258251905
