The number of train datas: 3202
The number of test datas: 802
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7141381554272977	0.5112429731417863	0.6830232235558907	0.5660847877326451
1	0.7015275762722986	0.5274828232354778	0.6798437252603564	0.5785536153655397
2	0.6923622754050522	0.5509056839475328	0.6761693133974908	0.5960099749137041
3	0.6870331538609606	0.5505933791380387	0.6732376308512509	0.6059850385956039
4	0.6839782319762869	0.5602748282323547	0.6682591802461486	0.6296758100278954
5	0.6759867565398064	0.5668332292317302	0.6632927042290457	0.6433915217915676
6	0.6762071541515757	0.570580886945659	0.6584911677902774	0.6496259360539348
7	0.6649618023153695	0.5971267957526546	0.6531891207445292	0.6596009972089544
8	0.6582621834860378	0.6105559025608994	0.6463739027703492	0.6670822941156992
9	0.6496688440805074	0.6255465334166146	0.6371759295166282	0.6907730683721509
10	0.6478288385512158	0.6258588382261087	0.6277369115120752	0.6870324196958185
11	0.634221127188109	0.6530293566520925	0.6179513592375186	0.7032418963023255
12	0.6275951697780221	0.6592754528419738	0.6070052932325444	0.7069825428976977
13	0.6240255382565838	0.6570893191755153	0.6050125867351333	0.699501246734153
14	0.6173983501837002	0.6574016239850093	0.5886221077674048	0.7281795515681145
15	0.6044151369740559	0.6830106183635228	0.5785480593505345	0.7244389034863422
16	0.594614553049458	0.6861336664584634	0.5668523751589426	0.7306733161136694
17	0.5842159932885298	0.7051842598376015	0.555818759889674	0.7431421452329641
18	0.5731291209884467	0.7070580886945659	0.5496404801223641	0.7194513717197123
19	0.5692546666971525	0.7064334790755777	0.5336747451910652	0.7630922687321232
20	0.5570838261514363	0.712054965646471	0.5207748668746758	0.7568578558075161
21	0.5394509706476344	0.7276702061211743	0.5098336725460918	0.7705735666793481
22	0.5409197079844954	0.7286071205496565	0.5100561802523986	0.7693266841836106
23	0.5261815230895548	0.7454715802623361	0.48986503400112924	0.7855361588577975
24	0.5168627048193999	0.750468457214241	0.4771544398215049	0.7780548619510527
25	0.5088863961961699	0.7570268582136165	0.46474911075577774	0.7855361587091574
26	0.4953777541747918	0.7738913179262961	0.4548906359886588	0.8067331663390942
27	0.4798606668391278	0.7757651467832605	0.44051677189265703	0.8079800491321116
28	0.46854408754548904	0.7907557776389756	0.42827820681277057	0.8104738145695065
29	0.4797039532162561	0.7801374141161774	0.42245298572014695	0.8179551125167314
30	0.4520742070071776	0.7973141786383511	0.40228859429942104	0.8329177048438208
31	0.4430689142690012	0.801998750780762	0.38876729609068494	0.8503740639460652
32	0.42930057657874426	0.8129294191130544	0.37387058317215366	0.855361595118135
33	0.4120989708808122	0.8188632104934416	0.3686042348494256	0.8416458854354231
34	0.41792202740442297	0.8222985633978763	0.3606202016001628	0.8441396510214579
35	0.39577284667508295	0.834790755777639	0.3360783784020869	0.8765586024507918
36	0.3851004056376565	0.8379138038725796	0.3216071794009268	0.8940149615530362
37	0.38021303364061176	0.8460337289194254	0.31259976873671325	0.8890274305296063
38	0.3698961111919944	0.8497813866333541	0.3011080969004262	0.8952618443460536
39	0.35892685173750666	0.84946908182386	0.2911347817824666	0.9002493767072435
40	0.35889401940685894	0.853841349156777	0.285405832633116	0.9039900238971758
41	0.34984683640519953	0.8529044347282948	0.2746644876990235	0.910224437862263
42	0.3353016309295871	0.8697688944409744	0.26484847882590684	0.912718203448298
43	0.3239477108547384	0.8760149906308557	0.25654309791073837	0.912718203448298
44	0.32306582528602173	0.8722673329169269	0.27367637772809833	0.8915211961156412
45	0.32106882931291125	0.868207370393504	0.24568095119516747	0.9152119690343329
46	0.30946333238216284	0.8753903810118676	0.23961222814651498	0.9189526174133853
47	0.30912983268127076	0.8700811992504685	0.23509801467160632	0.9189526186025053
48	0.2919794266006859	0.8891317926296065	0.2320006710855741	0.9201995013955228
49	0.28786897246052817	0.8816364772017489	0.24388111135608834	0.9052369068388333
50	0.2947816225530802	0.8800749531542785	0.22438770450856027	0.9201995002064027
51	0.274620748698004	0.891317926296065	0.21695638713693977	0.9251870325675926
52	0.27826056734942073	0.891317926296065	0.22906610756146342	0.9139650863899554
53	0.27060012200115474	0.8950655840099938	0.21104878291227575	0.9239401496259352
54	0.27674855512429	0.8944409743910057	0.20894496529328258	0.9226932669815577
55	0.26507036254824434	0.8947532792004997	0.28520641422033904	0.8778054855410892
56	0.2788300116236399	0.8881948782011243	0.20762679746323393	0.928927680798005
57	0.2687680881184239	0.8972517176764522	0.206806805440018	0.9214463829994202
58	0.2573124212745128	0.8985009369144284	0.24247844416898978	0.9027431412527983
59	0.2594847865286356	0.8941286695815116	0.20231035619305257	0.9276807981536276
60	0.252570446508516	0.9047470331043098	0.21757722049579953	0.9177057359581279
61	0.23509719652088265	0.905371642723298	0.19564222661485695	0.92643391536061
62	0.24289928770378036	0.9038101186758276	0.2040066923063592	0.9226932671301977
63	0.23220793041007956	0.9106808244846971	0.1890041084955458	0.92643391536061
64	0.23240934867763208	0.9106808244846971	0.1866583323612475	0.92643391536061
65	0.22824197086150166	0.9113054341036851	0.18421649609569302	0.9276807981536276
66	0.22445037926568753	0.9131792629606496	0.18252092726212785	0.9301745637396625
67	0.2200101622421618	0.915053091817614	0.18075976753026768	0.9301745637396625
68	0.2212292759735684	0.9141161773891318	0.1871749022580739	0.92643391417149
69	0.2052299909428609	0.9225484072454716	0.18036788378719082	0.928927680946645
70	0.21095057562002906	0.9144284821986258	0.1781492231418367	0.928927680946645
71	0.20171152856631402	0.9225484072454716	0.1744000293370197	0.9339152121187149
72	0.21669774645384515	0.9163023110555902	0.1736759190770456	0.9351620949117323
73	0.2003673667519782	0.9209868831980013	0.18500017324587947	0.9301745638883024
74	0.19300609089894863	0.9262960649594004	0.17138203904218507	0.9339152121187149
75	0.194296040136523	0.9266083697688945	0.18037547877155932	0.9276807983022676
76	0.19588031629559996	0.9231730168644597	0.16937486344293465	0.9364089777047497
77	0.1909288670716436	0.9256714553404123	0.16964896257381487	0.9314214465326799
78	0.18922537985926194	0.9262960649594004	0.16990938489127932	0.9376558604977672
79	0.1827039538261985	0.9287945034353529	0.17284674243885384	0.9326683294743374
80	0.17915367672707347	0.9325421611492817	0.1687499952509516	0.9351620950603723
81	0.17569458452306413	0.9356652092442224	0.17208612481703484	0.9326683294743374
82	0.17410817622747515	0.9344159900062461	0.16417859189974102	0.9351620949117323
83	0.17280743446091723	0.9334790755777639	0.1676957182158853	0.9351620950603723
84	0.16566624806066516	0.9400374765771393	0.16438954280796195	0.9364089778533897
85	0.1658638446783178	0.9331667707682698	0.16774271584657066	0.9326683294743374
86	0.16890939430733312	0.9306683322923173	0.16107820654450508	0.9413965088768196
87	0.16756478660297275	0.9366021236727046	0.16310490422563959	0.9351620950603723
88	0.15483161509223167	0.9450343535290443	0.1844973936305379	0.9276807981536276
89	0.17016847820244008	0.9350405996252342	0.15857089832982518	0.9389027421016646
90	0.15445219792849119	0.9397251717676453	0.15704201830741474	0.942643391669837
91	0.15454216551286942	0.9375390381011868	0.15695607368636905	0.940149624894682
92	0.15104433203593137	0.9456589631480324	0.17631872410786123	0.9314214466813199
93	0.15313153836384896	0.9447220487195502	0.16735562511215782	0.9339152122673549
94	0.14790901972119377	0.9469081823860087	0.15508500830342348	0.9389027421016646
95	0.14513428911315435	0.9450343535290443	0.1552836923230616	0.9413965088768196
96	0.14189083828619314	0.9453466583385384	0.2520025636527009	0.9114713216957606
97	0.19340888733308365	0.9281698938163647	0.16232461621636465	0.9413965090254596
98	0.14689553817088422	0.9478450968144909	0.1551910664821206	0.9376558604977672
99	0.1332141081079223	0.9512804497189257	0.15401784514548475	0.9463840400488894

The optimal condition:
	epoch: 99
	train_acc: 0.9512804497189257
	val_acc: 0.946384040049
	using time: 244.331945896
