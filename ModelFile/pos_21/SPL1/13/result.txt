The number of train datas: 3202
The number of test datas: 802
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7094806294602055	0.514366021236727	0.6829727474888067	0.5623441392049527
1	0.7008931117829198	0.5243597751405371	0.6789295801200772	0.5860349136100446
2	0.6925838077016208	0.5365396627108058	0.6756099750870779	0.6159600998992635
3	0.6855026117940756	0.551842598376015	0.673247167445775	0.6084788031411588
4	0.684219792029174	0.5530918176139913	0.6680354357063027	0.6359102242902628
5	0.6731717824042401	0.5793254216114928	0.6625202338297171	0.6259351616488431
6	0.6752296526085058	0.5718301061836353	0.657841519524629	0.6471321706165399
7	0.6634324986922748	0.5993129294191131	0.6523346581363916	0.6745635907251639
8	0.6594659931431853	0.6127420362273579	0.6458678282704436	0.685785536010961
9	0.6515077867781944	0.627420362273579	0.63774349193026	0.7019950123201879
10	0.6437274025500677	0.6342910680824485	0.6279314081567778	0.688279302488836
11	0.6360334731280096	0.6405371642723298	0.6182402949083475	0.7107231927631502
12	0.627454859401791	0.6639600249843848	0.6089496804294443	0.7082294258393551
13	0.6251830098258191	0.6599000624609619	0.6079861637660096	0.7082294264339152
14	0.6118795358710256	0.6680199875078077	0.589557521509708	0.7306733173027895
15	0.6038287103660103	0.6783260462211118	0.5798677550884256	0.7369077314165168
16	0.593443935286768	0.6898813241723922	0.568535802816215	0.7431421440438439
17	0.5813443485384505	0.7064334790755777	0.5556976190231685	0.7556109719740185
18	0.5660045590719381	0.7161149281698939	0.5487784292186585	0.7306733171541495
19	0.5643632423125677	0.7136164896939413	0.5323845500363376	0.7556109719740185
20	0.5567703270524982	0.7111180512179888	0.5224152701602612	0.7655860341695181
21	0.5366566613046622	0.7345409119300437	0.5105010103109174	0.7693266826972105
22	0.5313266581628264	0.7370393504059962	0.5038402530915125	0.7755610966622978
23	0.5245075984570029	0.7354778263585259	0.48473962271897275	0.7942643397466798
24	0.5167947289982414	0.750468457214241	0.4746130868383774	0.7942643384089196
25	0.5023688627808337	0.7679575265459088	0.4631568910623726	0.7942643395980398
26	0.4960784666952232	0.7707682698313554	0.45206387381898494	0.8167082300209939
27	0.47665165164632994	0.7848219862585883	0.43739499393246717	0.8204488784000463
28	0.4640217050025792	0.7938788257339163	0.42658846492779223	0.8192019953097488
29	0.4725006817840621	0.7888819487820112	0.42265836504332144	0.8229426423510411
30	0.45060523650111595	0.8013741411617739	0.3993695243041117	0.8416458855840631
31	0.4402069440117335	0.8023110555902561	0.3879210369248045	0.8466334169047729
32	0.42523676562800694	0.8148032479700187	0.37136654827065596	0.8541147135142376
33	0.4071939043295823	0.8269831355402874	0.36141236145002886	0.8578553605555299
34	0.4149581258331218	0.8188632104934416	0.3606754380122682	0.8678304227510295
35	0.39134289956256646	0.8366645846346034	0.3359231635965314	0.8765586024507918
36	0.3854441153656908	0.8432229856339788	0.31958795611995117	0.8840398992088965
37	0.37618219958086596	0.8454091193004373	0.3130091341059107	0.8765586037885519
38	0.36442749409806646	0.8500936914428482	0.30234144973635974	0.8865336661326915
39	0.3542949690586474	0.8544659587757651	0.29050584312091743	0.8915211959670012
40	0.35537423295836235	0.8519675202998126	0.2870096551658507	0.8877805489257089
41	0.35048293904503164	0.8591505309181762	0.27786554258660484	0.8940149628907962
42	0.33714108165355866	0.8663335415365396	0.26873279598882965	0.9027431424419184
43	0.3309073426355279	0.8647720174890693	0.2627367127937569	0.901496259648901
44	0.32341529781709677	0.8744534665833854	0.266764760166035	0.8952618456838137
45	0.31741076028399134	0.8753903810118676	0.24899613210685234	0.9077306722762282
46	0.31176026566634696	0.8735165521549032	0.2426259008949237	0.912718203448298
47	0.31056582355763596	0.872579637726421	0.23773139904710716	0.9114713206552805
48	0.29266317308805345	0.8844472204871955	0.2318542368542821	0.9114713205066405
49	0.2983642001959177	0.8778888194878202	0.2417152017875205	0.9027431411041583
50	0.2979543549122102	0.8816364772017489	0.22546729750169484	0.9152119690343329
51	0.28149822155138166	0.8878825733916302	0.22065734618025232	0.9164588518273503
52	0.2853779186469053	0.8828856964397251	0.23458822647532324	0.9039900238971758
53	0.27374449482118984	0.8900687070580887	0.21223218508640726	0.9226932669815577
54	0.27780176492537056	0.8853841349156777	0.21258695523935067	0.9201995002064027
55	0.270795311948644	0.8910056214865709	0.2427473271874121	0.9002493755181235
56	0.2689244609412218	0.8906933166770769	0.20472554684131222	0.9226932656437976
57	0.26533907860387196	0.8938163647720175	0.21008386163788842	0.9164588518273503
58	0.2613922099185541	0.8935040599625235	0.24498333025751565	0.8927680800977787
59	0.26594631377605255	0.8894440974391006	0.2050945394651551	0.92643391536061
60	0.2568366281097193	0.9006870705808869	0.2161222630902716	0.912718203448298
61	0.25049286337568194	0.8972517176764522	0.19871228379650308	0.9301745624019023
62	0.250760238108078	0.9069331667707683	0.20487246690248315	0.9164588518273503
63	0.2416977949398596	0.9034978138663335	0.18859154049149177	0.9364089763669896
64	0.23852080130818148	0.9044347282948157	0.18574737811326386	0.9314214451949198
65	0.23259793625426695	0.9084946908182386	0.18763536616156523	0.928927680946645
66	0.22664041474210256	0.9116177389131792	0.18445929375818543	0.9301745637396625
67	0.2303517561203461	0.9059962523422861	0.17933058263060458	0.9364089763669896
68	0.22352227503474542	0.9138038725796377	0.18089152263138358	0.9326683293256973
69	0.2124676581083574	0.9169269206745784	0.1820366433136481	0.9326683293256973
70	0.2158147295393622	0.915053091817614	0.17656718714724753	0.9314214465326799
71	0.2108875953503358	0.9181761399125546	0.17612735111442884	0.9389027419530246
72	0.2229940227031019	0.9116177389131792	0.17335905744101937	0.9413965075390595
73	0.21305746727068672	0.915365396627108	0.20397297380273777	0.9064837894832107
74	0.19839158060400283	0.9203622735790131	0.1694169210228242	0.9401496260838021
75	0.2019577037140513	0.9216114928169894	0.1800102688130595	0.9276807969645074
76	0.20512353378039164	0.9191130543410369	0.1705181637309733	0.9413965088768196
77	0.1914880660471322	0.9228607120549657	0.1669904316155393	0.9389027419530246
78	0.19337172338100317	0.9259837601499064	0.16661598156217922	0.942643391669837
79	0.18972843026580624	0.9262960649594004	0.1689047146765074	0.9389027432907846
80	0.18553069893324248	0.9306683322923173	0.1689855370884227	0.9389027432907846
81	0.18099897332270767	0.9344159900062461	0.16875323106969087	0.9364089765156296
82	0.1793756596720792	0.9272329793878826	0.1616115761813975	0.9413965088768196
83	0.18330601402683455	0.9237976264834479	0.16237253288824363	0.9476309228419069
84	0.17040081192820167	0.9347282948157402	0.16312898832960915	0.9438902744628545
85	0.17102223606099567	0.9353529044347283	0.16315893301196824	0.942643391669837
86	0.17323683534541182	0.9319175515302935	0.1583027220203395	0.942643391669837
87	0.17422129056514762	0.9353529044347283	0.17843473500147128	0.9251870313784726
88	0.16542665396981654	0.9366021236727046	0.17662856828170526	0.9364089763669896
89	0.17643277902274784	0.9297314178638351	0.15846588234057152	0.9438902744628545
90	0.16322309833059528	0.9400374765771393	0.16043726423583424	0.9426433904807169
91	0.16154560788132036	0.9362898188632105	0.15674806217154363	0.9488778056349243
92	0.15795589681321534	0.9409743910056215	0.17555838726702475	0.9276807969645074
93	0.16456487917543147	0.9406620861961275	0.17187507811032626	0.9339152109295947
94	0.15892858946024627	0.938475952529669	0.15335397463189693	0.9488778056349243
95	0.15106833154111077	0.9453466583385384	0.15355355632572698	0.9451371572558719
96	0.14420128756579126	0.9487820112429731	0.1578560720135149	0.9376558604977672
97	0.15524036831441781	0.9456589631480324	0.1537683667833371	0.9451371560667519
98	0.14594175890181155	0.9450343535290443	0.15124045360712637	0.9463840400488894
99	0.1402359479193856	0.9475327920049968	0.151012659407316	0.9488778056349243

The optimal condition:
	epoch: 99
	train_acc: 0.9475327920049968
	val_acc: 0.948877805635
	using time: 236.630044937
