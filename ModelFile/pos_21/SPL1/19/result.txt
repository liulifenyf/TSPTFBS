The number of train datas: 3202
The number of test datas: 802
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7176151797966537	0.5068707058088695	0.6837353241116626	0.5748129686215274
1	0.6999487021727386	0.5299812617114303	0.6791110713582978	0.5885286791960794
2	0.6918608848933947	0.5312304809494066	0.6743054957758459	0.5985037418374991
3	0.6861059212967576	0.5459088069956277	0.669839346200748	0.6159600997506235
4	0.6809528245544672	0.5652717051842598	0.6651961474941853	0.6558603488299021
5	0.6720402568746253	0.5805746408494691	0.6603597902003072	0.660847880893812
6	0.6707270452933041	0.5915053091817614	0.6543072683555526	0.6733167091212665
7	0.6580195242281931	0.6211742660836976	0.6469730660505129	0.6720698263282491
8	0.6505835726438352	0.6199250468457215	0.6389926636308209	0.6708229424947515
9	0.6449549652724471	0.6277326670830731	0.6274364488083228	0.6795511218972337
10	0.6346048622076248	0.637101811367895	0.6139631037997486	0.6957605990983007
11	0.6195275866560903	0.66052467207995	0.6028737002180105	0.7044887787980629
12	0.6144912399998462	0.6742660836976889	0.5896192112765705	0.7007481289326104
13	0.6014919879286085	0.683635227982511	0.5914592552660707	0.6807980050618512
14	0.5976228539009976	0.6780137414116177	0.5710695042574495	0.726932667585977
15	0.5824817580628737	0.707682698313554	0.558911394597289	0.7344139643440817
16	0.56635462061306	0.7136164896939413	0.5468387489306956	0.7406483794982891
17	0.5579971197915777	0.7214241099312929	0.5348259927031406	0.7531172074284637
18	0.5436825931332843	0.730793254216115	0.5232607183462367	0.7418952608049064
19	0.5327836724462396	0.7373516552154903	0.5050256256748019	0.7655860353586382
20	0.521642800981294	0.73579013116802	0.49202460660006936	0.7793017447440701
21	0.5060143435023711	0.7582760774515928	0.47977856180614364	0.7817955116678652
22	0.5067710226807722	0.7579637726420987	0.47717762810928266	0.7805486290234878
23	0.4897480164372422	0.7695190505933791	0.45664707680890093	0.8054862833974368
24	0.47613041129877687	0.7820112429731418	0.4429773663790743	0.8204488769136462
25	0.4693248225777392	0.7838850718301061	0.4295406071027913	0.8192019939719888
26	0.4606336125362895	0.7898188632104934	0.417085962030953	0.839152118808908
27	0.44188500828180066	0.8041848844472205	0.40445529626789234	0.8453865327739953
28	0.4356553598652029	0.8029356652092442	0.38920181967373796	0.8428927682284405
29	0.43569701403695893	0.8054341036851967	0.38273649999031106	0.8441396510214579
30	0.41057484176738196	0.8226108682073704	0.36472532353793596	0.8628428917275998
31	0.4008090123208443	0.8291692692067458	0.35857768947644125	0.8703241886343445
32	0.38934523595042114	0.8391630231105559	0.34065093720643	0.8740648382025169
33	0.3738079579043284	0.8429106808244847	0.3321706028353246	0.8778054864329293
34	0.37888183765378614	0.844159900062461	0.32251048537709764	0.8865336646462914
35	0.3600130051020754	0.8507183010618363	0.3054593555870793	0.8915211958183612
36	0.3509344611221518	0.8547782635852592	0.2969551883879445	0.8940149614043961
37	0.3444933426321521	0.8594628357276702	0.2941162145494523	0.8877805475879489
38	0.33763256084539234	0.8613366645846346	0.284134691567195	0.8940149627421562
39	0.3278187808210145	0.8741411617738913	0.27518024680174497	0.9039900237485358
40	0.3257738597584024	0.8653966271080574	0.27594668334559014	0.8902743131739838
41	0.3220628749237144	0.868207370393504	0.26770393286559946	0.9002493753694834
42	0.31288348354264245	0.8782011242973142	0.26052289372519066	0.9039900237485358
43	0.30200617984030337	0.8860087445346658	0.25612783788742866	0.9064837893345706
44	0.30385564462160186	0.8835103060587133	0.2851996910096404	0.8790523695232267
45	0.30351211643457265	0.8744534665833854	0.24866109224328972	0.9089775549206056
46	0.29461368669911076	0.8853841349156777	0.2414827985953809	0.9127182032996579
47	0.2905948216038559	0.8838226108682073	0.2447237977734825	0.9089775549206056
48	0.2778155136153074	0.886945658963148	0.23484450679021585	0.9177057344717278
49	0.27691888259136255	0.8910056214865709	0.24844012950126668	0.896508727139071
50	0.275622278098238	0.886633354153654	0.23395520392944688	0.9102244390513832
51	0.2648607369030661	0.8988132417239225	0.22638647347465715	0.9177057344717278
52	0.26430234356872334	0.8938163647720175	0.24156845418592343	0.9039900238971758
53	0.25849094683494067	0.9019362898188632	0.2216324095714122	0.915211970223453
54	0.26108438190745237	0.8969394128669581	0.22053098425900847	0.9201995013955228
55	0.25685757171504575	0.9028732042473454	0.2688565202187422	0.8765586025994317
56	0.2611248068032154	0.8978763272954403	0.21577104548935283	0.9251870324189526
57	0.25652157780548546	0.9066208619612742	0.21548132642992118	0.9177057358094879
58	0.24877007755169936	0.9019362898188632	0.2888090765089763	0.8640897748178972
59	0.2585101172765443	0.8953778888194878	0.21683628095355711	0.9226932669815577
60	0.2409681019598361	0.9084946908182386	0.2677877139569518	0.8802992509784842
61	0.238453045154664	0.9084946908182386	0.21116275780664714	0.9189526174133853
62	0.23632706107012114	0.9047470331043098	0.21703930344070282	0.9089775550692456
63	0.22942290879055383	0.9088069956277327	0.21474801899489024	0.912718203448298
64	0.22179435419708696	0.9138038725796377	0.1997942543609481	0.92643391417149
65	0.22081252117917582	0.915053091817614	0.20652789386579223	0.9201995002064027
66	0.21564654658765514	0.9172392254840724	0.20181884217143356	0.9214463829994202
67	0.2109138972726857	0.915365396627108	0.19343085152252654	0.9314214465326799
68	0.2047789099624498	0.9169269206745784	0.20619671912561927	0.9177057346203678
69	0.20272433403635085	0.920049968769519	0.1912487517865816	0.9326683293256973
70	0.20484784579626997	0.9228607120549657	0.18809510577943855	0.9339152121187149
71	0.197190512350989	0.9247345409119301	0.18515339371123515	0.9314214465326799
72	0.20688236275365546	0.9172392254840724	0.18559613333378647	0.9339152121187149
73	0.19685257549661164	0.9241099312929419	0.241791283251936	0.8890274318673664
74	0.20120482549750754	0.9272329793878826	0.20500213533937187	0.9339152107809547
75	0.213213909524426	0.9178638351030606	0.19266945502704516	0.9226932657924376
76	0.19274497961044906	0.9247345409119301	0.1838570935396185	0.9289276797575249
77	0.18307861401935077	0.9297314178638351	0.17990268882076044	0.9314214453435599
78	0.1863624017352912	0.9284821986258588	0.18020692597749524	0.9314214453435599
79	0.1797903409736146	0.9350405996252342	0.1902560995998525	0.923940148585455
80	0.17556249736334145	0.9331667707682698	0.1870051209171514	0.9251870313784726
81	0.1740444633344201	0.9319175515302935	0.18901987043104862	0.923940148585455
82	0.1716819966722659	0.9334790755777639	0.17511182324844704	0.9364089765156296
83	0.1703657640876024	0.9328544659587757	0.17964091882146802	0.9276807969645074
84	0.16159549988119826	0.938788257339163	0.1745595757726422	0.9326683281365773
85	0.16438344974585023	0.9409743910056215	0.17443912593355201	0.9289276797575249
86	0.1666707070003369	0.9372267332916927	0.18047404608821632	0.9376558604977672
87	0.16855230998203652	0.9400374765771393	0.2440742952122058	0.8940149630394363
88	0.17168770394498	0.9356652092442224	0.17704763127829964	0.9401496260838021
89	0.16358707545512471	0.9381636477201749	0.17245201257398896	0.9314214453435599
90	0.15091996038592026	0.9462835727670206	0.16978419447628934	0.9339152109295947
91	0.1517524522860685	0.9400374765771393	0.17254986177358841	0.9314214453435599
92	0.15090966535472417	0.9453466583385384	0.18538199614111028	0.9276807969645074
93	0.15033030947142437	0.9456589631480324	0.18661794192773148	0.9276807969645074
94	0.14543412370533962	0.948157401623985	0.16949183347070604	0.9314214453435599
95	0.14496012361746963	0.9456589631480324	0.16651960846937802	0.940149624894682
96	0.13728929896007694	0.9487820112429731	0.16719736853739864	0.9413965088768196
97	0.14093751932664783	0.948469706433479	0.16488075709699693	0.940149624894682
98	0.12973822940892535	0.9519050593379138	0.16522157682742264	0.9339152109295947
99	0.12885515672179593	0.9531542785758901	0.16668098897410746	0.9326683281365773

The optimal condition:
	epoch: 96
	train_acc: 0.9487820112429731
	val_acc: 0.941396508877
	using time: 298.491058826
