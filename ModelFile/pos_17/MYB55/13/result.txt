The number of train datas: 4600
The number of test datas: 1152
epoch	train_loss	train_acc	val_loss	val_acc
0	0.706018429942753	0.5073913041405056	0.6882116397221884	0.5364583333333334
1	0.6971231905273769	0.5189130437892416	0.6854472160339355	0.5607638888888888
2	0.6873399552055027	0.5500000003109807	0.6827541059917874	0.5789930555555556
3	0.6833691848879275	0.5573913045551466	0.6797170175446404	0.5868055555555556
4	0.678893941692684	0.5660869563144186	0.6755932768185934	0.6041666666666666
5	0.6757149785497915	0.5784782607659049	0.6699887447886996	0.6328125
6	0.6685140924868377	0.6002173907860465	0.662715322441525	0.6284722222222222
7	0.6633408843952676	0.6054347829196765	0.653426726659139	0.671875
8	0.6521025665946629	0.6278260876821435	0.641644623544481	0.6961805555555556
9	0.6431916238950647	0.6434782608695652	0.627309262752533	0.7126736111111112
10	0.6249033036439315	0.6658695645954298	0.6100565195083618	0.71875
11	0.6011504015715226	0.696956521946451	0.5903305212656657	0.7456597222222222
12	0.5881986700970193	0.6976086962741355	0.5692061450746324	0.7421875
13	0.5717323720973471	0.7171739132507987	0.5505109628041586	0.7517361111111112
14	0.538139490770257	0.7404347830233367	0.5288069049517313	0.7543402777777778
15	0.5257610480681709	0.749782609421274	0.5165062811639574	0.7508680555555556
16	0.5007565879821777	0.7721739128361578	0.4976636204454634	0.7586805555555556
17	0.48631900346797446	0.7776086955485136	0.4851091636551751	0.7630208333333334
18	0.4770041301457778	0.7767391305384429	0.47502536574999493	0.7682291666666666
19	0.450874401382778	0.793043477638908	0.46311529146300423	0.7769097222222222
20	0.4391132304979407	0.7969565223610919	0.4517459173997243	0.7751736111111112
21	0.42732406071994616	0.8104347825050354	0.44059129224883187	0.7829861111111112
22	0.41535524596338685	0.8169565214281497	0.42881740464104545	0.7881944444444444
23	0.401454044321309	0.8334782608695652	0.4141704771253798	0.8046875
24	0.38740821833195893	0.8341304345752882	0.4006561272674137	0.8125
25	0.37172534512436906	0.8395652171839838	0.3877677751912011	0.8229166666666666
26	0.36163754074469856	0.8500000006219615	0.3823316627078586	0.8177083333333334
27	0.3402383077144623	0.8626086963777957	0.35927650332450867	0.8428819444444444
28	0.324875573489977	0.8663043476187664	0.34539153509669834	0.8498263888888888
29	0.31741048978722614	0.8721739128361577	0.3322464923063914	0.8532986111111112
30	0.3028273167040037	0.8786956524848938	0.3200117349624634	0.859375
31	0.2894363928877789	0.8823913037258646	0.3075753152370453	0.8663194444444444
32	0.2712721485936123	0.8934782613878665	0.2964077459441291	0.8689236111111112
33	0.26245079506998475	0.8997826092139535	0.2835290895568	0.8836805555555556
34	0.24762244507022527	0.9047826085919919	0.2727026674482558	0.8862847222222222
35	0.24612652983354485	0.9067391307457634	0.26426537831624347	0.8897569444444444
36	0.22614475815192514	0.9184782604549242	0.25950220889515346	0.8958333333333334
37	0.21873897368493286	0.9269565212208292	0.2494511902332306	0.8975694444444444
38	0.209900521143623	0.9265217394414156	0.23978288306130302	0.9001736111111112
39	0.20253341920997786	0.9269565218427906	0.2376532902320226	0.9027777777777778
40	0.19469974059125653	0.9273913050734478	0.22879320714208815	0.9071180555555556
41	0.1905431348344554	0.9347826093176137	0.22495990991592407	0.9079861111111112
42	0.19161783487900444	0.9313043476187665	0.21936393280824026	0.9140625
43	0.18116209802420244	0.9341304341606472	0.2150366803010305	0.9131944444444444
44	0.17140356284120808	0.9445652172876441	0.2125415090057585	0.9149305555555556
45	0.16659722880176875	0.9423913050734478	0.20691298113928902	0.9140625
46	0.16113546891056973	0.941956522361092	0.20446760621335772	0.9149305555555556
47	0.15810230532418126	0.9463043479297472	0.20108324454890358	0.9149305555555556
48	0.15540361578049866	0.9460869568327199	0.20193401310178968	0.9227430555555556
49	0.15460163992384204	0.951521739648736	0.19801372455226052	0.9227430555555556
50	0.14679542498744053	0.9502173919263094	0.19496199323071373	0.9236111111111112
51	0.14845555157765097	0.9486956518629323	0.1925917069117228	0.9227430555555556
52	0.1395104923196461	0.9517391301238018	0.1901556733581755	0.9244791666666666
53	0.13442504573127498	0.9519565210135087	0.18925594124529097	0.9253472222222222
54	0.139014377542164	0.9534782606622447	0.1861786146958669	0.9262152777777778
55	0.1270616698783377	0.9580434781572094	0.19545300636026594	0.9348958333333334
56	0.12720252166623655	0.960869565113731	0.1831110285388099	0.9270833333333334
57	0.12181001979371776	0.9576086957558342	0.18176365229818556	0.9270833333333334
58	0.11704901506071505	0.9613043484480485	0.18160854279994965	0.9279513888888888
59	0.1182955081825671	0.9606521740167038	0.17967902620633444	0.9279513888888888
60	0.11876643600671187	0.9606521742240243	0.17936025063196817	0.9296875
61	0.1159622792834821	0.9623913049697876	0.17794371644655863	0.9305555555555556
62	0.11316159243169038	0.962826086645541	0.1764522757795122	0.9305555555555556
63	0.11196068628974583	0.9639130442038827	0.17924486100673676	0.9288194444444444
64	0.10993503847847814	0.9634782601439434	0.17471149729357827	0.9288194444444444
65	0.1090668987709543	0.9647826093176137	0.1744452350669437	0.9305555555555556
66	0.10532138256923013	0.9686956527958746	0.17441621753904554	0.9305555555555556
67	0.10165983934765277	0.966521738819454	0.17505845427513123	0.9331597222222222
68	0.1066296119534451	0.9641304354045702	0.17652248425616157	0.9366319444444444
69	0.09810282492119334	0.9691304351972497	0.1746667441394594	0.9340277777777778
70	0.09958704560995102	0.9671739134581193	0.1721968808107906	0.9322916666666666
71	0.09441674386677534	0.9697826091102931	0.17740857601165771	0.9409722222222222
72	0.09294294630703719	0.9710869571437006	0.1801954847243097	0.9427083333333334
73	0.09306310490421627	0.971521738819454	0.1700727923048867	0.9322916666666666
74	0.0863748142382373	0.9699999992743782	0.1720797974202368	0.9314236111111112
75	0.08989489257335663	0.9710869569363801	0.17087289028697544	0.9340277777777778
76	0.0838912213107814	0.9730434775352478	0.17500549223687914	0.9375
77	0.08794991094133128	0.9706521736020627	0.17198939455880058	0.9340277777777778
78	0.08288443413765534	0.9750000002073205	0.16911828186776903	0.9340277777777778
79	0.08322664992964786	0.975217390578726	0.17010955015818277	0.9340277777777778
80	0.07828392229650331	0.9730434775352478	0.1682717485560311	0.9340277777777778
81	0.08347355504398761	0.971956521946451	0.16839374436272514	0.9322916666666666
82	0.07870918801297312	0.97086956469909	0.1685785303513209	0.9348958333333334
83	0.08213229268789292	0.9717391306421032	0.16728657318486106	0.9357638888888888
84	0.07564935300013294	0.9747826091102931	0.1684243314796024	0.9331597222222222
85	0.0767087993544081	0.9763043473077857	0.17104424122307035	0.9383680555555556
86	0.0720862225216368	0.976956522361092	0.17222565081384447	0.9401041666666666
87	0.07096960371603137	0.9765217393377553	0.17615647945139143	0.9409722222222222
88	0.07407125714032546	0.976521738404813	0.17202583369281557	0.9401041666666666
89	0.06889174628516902	0.9793478265015976	0.17062476774056753	0.9401041666666666
90	0.07266710574212282	0.9760869569363801	0.1668797085682551	0.9383680555555556
91	0.06459848625504452	0.980000000414641	0.16745427830351722	0.9348958333333334
92	0.0648782804413982	0.9784782614915267	0.17070000949833128	0.9409722222222222
93	0.06455000233391057	0.9804347826086957	0.16753782166375053	0.9383680555555556
94	0.0640165657452915	0.9832608688395956	0.17149840046962103	0.9418402777777778
95	0.061430607800898346	0.9804347832306571	0.17483030590746138	0.9401041666666666
96	0.06600537602020347	0.9789130438929019	0.17005526274442673	0.9366319444444444
97	0.06318730757288311	0.9813043473077857	0.1701083862119251	0.9383680555555556
98	0.06020004758368368	0.9828260862309	0.1706780360804664	0.9375
99	0.06271573447662851	0.9804347832306571	0.16780184706052145	0.9383680555555556

The optimal condition:
	epoch: 72
	train_acc: 0.9710869571437006
	val_acc: 0.942708333333
	using time: 345.163824081
