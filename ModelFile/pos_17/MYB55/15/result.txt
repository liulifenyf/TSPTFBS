The number of train datas: 4600
The number of test datas: 1152
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7090066678627678	0.49869565175927205	0.6913810637262132	0.5234375
1	0.6999889640186144	0.505869565113731	0.6885078085793389	0.5381944444444444
2	0.6955429507338482	0.518478261180546	0.6855198542277018	0.5642361111111112
3	0.6881883812987286	0.5452173914080081	0.6834874219364591	0.5824652777777778
4	0.6843949298236681	0.5554347830233367	0.6811016201972961	0.5928819444444444
5	0.6859687803102577	0.5484782605585845	0.6781346268124051	0.6128472222222222
6	0.6776392402856246	0.5780434781572094	0.6738163299030728	0.6189236111111112
7	0.6758084851762522	0.5782608697725379	0.6679832140604655	0.640625
8	0.6693509595290474	0.5967391304347827	0.6610134840011597	0.6510416666666666
9	0.662133802641993	0.6095652180132659	0.6516493558883667	0.6701388888888888
10	0.6475715075368467	0.6423913036222043	0.638793925444285	0.6770833333333334
11	0.63138687931973	0.658478260765905	0.6221575207180448	0.7005208333333334
12	0.6161771392822266	0.6706521731874218	0.6020828286806742	0.7126736111111112
13	0.6022214852208676	0.6802173907860466	0.5825428300433688	0.7230902777777778
14	0.5690619191916093	0.7180434787791709	0.5601450271076627	0.7230902777777778
15	0.5529468888821809	0.7280434776389081	0.5455348657237159	0.7256944444444444
16	0.5304326486587524	0.7473913047624671	0.5280850794580247	0.7300347222222222
17	0.5120242368656656	0.7543478261906168	0.5156077775690291	0.734375
18	0.5049702701361283	0.7584782612842063	0.5069000555409325	0.7395833333333334
19	0.4780953019598256	0.7810869564180789	0.4962305757734511	0.7447916666666666
20	0.46719934577527256	0.7797826093176137	0.48839429683155483	0.7456597222222222
21	0.4577257446102474	0.7939130439965622	0.47958503166834515	0.7526041666666666
22	0.44243460556735165	0.7982608696688777	0.47126809424824184	0.7604166666666666
23	0.4295171316810276	0.8110869566253994	0.4573299156294929	0.7699652777777778
24	0.4210314227187115	0.8145652168730031	0.44741980565918815	0.7682291666666666
25	0.4024363416692485	0.8210869562107583	0.43358921342425877	0.78125
26	0.39382089381632596	0.8308695658393528	0.42526649435361225	0.7838541666666666
27	0.3747365112408348	0.8430434780535491	0.4067595601081848	0.8090277777777778
28	0.35707100971885347	0.8563043480334075	0.39273757735888165	0.8203125
29	0.3550759257959283	0.8545652173913043	0.38021181689368355	0.828125
30	0.3355236806558526	0.8595652175986248	0.3673288623491923	0.8342013888888888
31	0.3193652069050333	0.8671739134581192	0.3542810148662991	0.8394097222222222
32	0.30063120209652444	0.8832608693578969	0.34068775839275783	0.8420138888888888
33	0.2965052376104438	0.88413043530091	0.32620171705881756	0.8506944444444444
34	0.2792845610950304	0.8910869563144186	0.31449394424756366	0.8576388888888888
35	0.2693120801967123	0.899782609421274	0.3021155711677339	0.8645833333333334
36	0.25535443793172424	0.9045652173913044	0.2990795804394616	0.8715277777777778
37	0.24336297278818877	0.9113043485517087	0.2833851178487142	0.8758680555555556
38	0.23503199916818868	0.9121739137691001	0.2725238303343455	0.8793402777777778
39	0.2264859484589618	0.9171739135617796	0.2663942128419876	0.8897569444444444
40	0.2156586865497672	0.9250000003109807	0.25746013555261826	0.8932291666666666
41	0.21080579664396204	0.9252173909933671	0.25025879508919185	0.8949652777777778
42	0.20872456949690113	0.9265217389231143	0.2445039384894901	0.8975694444444444
43	0.19558484007482943	0.927608695652174	0.23833258284462822	0.9027777777777778
44	0.1895314912174059	0.9326086961704751	0.23351690669854483	0.9079861111111112
45	0.18189421607100445	0.9380434783645298	0.22972124483850268	0.9097222222222222
46	0.1771687562569328	0.937826086645541	0.22700388729572296	0.9053819444444444
47	0.1773124996734702	0.9360869566253994	0.22140396800306109	0.9131944444444444
48	0.16986083686351777	0.943478260765905	0.21910245716571808	0.9140625
49	0.16661523891531904	0.9454347827123559	0.21413271791405147	0.9192708333333334
50	0.1568396585272706	0.9445652178059454	0.21030140916506448	0.9175347222222222
51	0.16367487104042716	0.942391303933185	0.21052476598156822	0.9175347222222222
52	0.14959719276946523	0.9473913044514863	0.2051210171646542	0.921875
53	0.15202311077843542	0.9441304344716279	0.20825915866427952	0.921875
54	0.14970060581746308	0.9452173905787261	0.20052380445930693	0.9236111111111112
55	0.14397319645985313	0.9517391305384428	0.20009602275159624	0.9236111111111112
56	0.1384987372159958	0.9539130431672801	0.1961770388815138	0.9296875
57	0.13336724939553635	0.9541304346789484	0.19576343894004822	0.9288194444444444
58	0.12752222744019134	0.9569565216354702	0.19406989382372963	0.9348958333333334
59	0.1264739699208218	0.9573913036222044	0.19142522248956892	0.9331597222222222
60	0.13061524642550426	0.9543478257759758	0.19585730714930427	0.9322916666666666
61	0.12557384064664012	0.9560869557961174	0.18832618412044314	0.9357638888888888
62	0.12691619279591934	0.9552173912006876	0.18685591883129543	0.9348958333333334
63	0.12512164727501246	0.9586956526922144	0.18478860374954012	0.9357638888888888
64	0.11568140603925871	0.9597826083846714	0.18418390055497488	0.9392361111111112
65	0.11555496031823366	0.960652174535005	0.18276030321915945	0.9383680555555556
66	0.11248231522414995	0.9634782614915267	0.1823932710621092	0.9409722222222222
67	0.11075478793486306	0.9632608688395956	0.18358918776114783	0.9383680555555556
68	0.11131686807974525	0.9599999996890193	0.1816343350542916	0.9435763888888888
69	0.10520956801331562	0.9671739136654398	0.17955734332402548	0.9418402777777778
70	0.10192849871904953	0.9667391308494236	0.18094399488634533	0.9392361111111112
71	0.10145811929650929	0.9654347832306571	0.18178593615690866	0.9392361111111112
72	0.1042033914120301	0.9676086955485137	0.18112598028447893	0.9375
73	0.0999564783728641	0.9660869562107584	0.17846196641524634	0.9383680555555556
74	0.09154732017413429	0.9678260866455409	0.17935986320177713	0.9375
75	0.09587982553502787	0.966956522361092	0.17608274022738138	0.9427083333333334
76	0.09386527227318806	0.9704347818830739	0.17605365481641558	0.9470486111111112
77	0.08924767765014067	0.9713043471004652	0.1764420916636785	0.9444444444444444
78	0.08864189156371614	0.9739130434782609	0.17350700000921884	0.9470486111111112
79	0.08685395768155223	0.9719565210135087	0.1748591744237476	0.9435763888888888
80	0.08545944629803948	0.9736956514482913	0.17440139419502682	0.9453125
81	0.08713975126328675	0.970652174120364	0.17631219824155173	0.9418402777777778
82	0.0815527125739533	0.9739130438929019	0.17323864003022513	0.9461805555555556
83	0.08504151165485382	0.9726086962741354	0.1747328895661566	0.9427083333333334
84	0.08045223912467127	0.9739130438929019	0.17264595213863584	0.9479166666666666
85	0.08101020934789077	0.9730434775352478	0.17530441366963917	0.9418402777777778
86	0.08208174057628798	0.9732608701871789	0.17191724313629997	0.9470486111111112
87	0.07800178312737009	0.9763043480334075	0.17400082531902525	0.9409722222222222
88	0.07587299407824226	0.974782608177351	0.1731978886657291	0.9453125
89	0.07355829937302548	0.977391304762467	0.17408214757839838	0.9418402777777778
90	0.07620777920536373	0.9747826093176137	0.17436756359206307	0.9461805555555556
91	0.06904904456242271	0.9756521733947422	0.17253570589754316	0.9461805555555556
92	0.06987729321031466	0.9780434782608696	0.1766759604215622	0.9392361111111112
93	0.06982386944734532	0.9786956521739131	0.17084801859325832	0.9487847222222222
94	0.06820533418137094	0.9804347832306571	0.17462405976321962	0.9409722222222222
95	0.06456013715137605	0.9786956523812336	0.17414577222532696	0.9427083333333334
96	0.06597636934855709	0.9789130438929019	0.17278785589668486	0.9479166666666666
97	0.06836090778527053	0.9782608690469161	0.17318835688961876	0.9461805555555556
98	0.06263257901953614	0.9789130438929019	0.18016770564847523	0.9375
99	0.06848019965316939	0.9778260873711627	0.1729232304626041	0.9470486111111112

The optimal condition:
	epoch: 93
	train_acc: 0.9786956521739131
	val_acc: 0.948784722222
	using time: 361.584752083
