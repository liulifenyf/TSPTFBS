The number of train datas: 8186
The number of test datas: 2048
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6957952499156647	0.5131932565177416	0.6867292337119579	0.56298828125
1	0.6919219892006936	0.5318837034478038	0.6807653345167637	0.59814453125
2	0.6843082927096423	0.5528951867734078	0.6737774647772312	0.640625
3	0.6770960811062311	0.5840459321082847	0.6641110330820084	0.67919921875
4	0.6708929209612472	0.5852675295068325	0.6508001163601875	0.701171875
5	0.6562231164848836	0.6246029805968158	0.6319240927696228	0.73681640625
6	0.6432306826799096	0.644148545934494	0.6088662222027779	0.77294921875
7	0.6176992870472242	0.6755436112325581	0.5773643255233765	0.78369140625
8	0.5946668400148177	0.7038846810755857	0.5408979952335358	0.80810546875
9	0.567010363156598	0.7286831172992745	0.49946543015539646	0.82470703125
10	0.5299276940519118	0.7682628880903186	0.4526670537889004	0.849609375
11	0.4903613521451039	0.7915954067483963	0.40596781112253666	0.87646484375
12	0.45018331966830033	0.8150500853079734	0.3604230023920536	0.8818359375
13	0.41447802611385265	0.8449792325016109	0.323775976896286	0.8994140625
14	0.38838792382403864	0.8521866599621646	0.2964442176744342	0.9091796875
15	0.36261896179265857	0.8685560710063751	0.2748191710561514	0.91064453125
16	0.3415770601620454	0.8764964570312956	0.2612253613770008	0.9111328125
17	0.3297787283863731	0.8834595652131034	0.252610320225358	0.91357421875
18	0.31722154386201407	0.8854141217876466	0.242097532376647	0.92822265625
19	0.3089380218846973	0.8951869042817345	0.2358916662633419	0.9287109375
20	0.30242695342116793	0.8955533837823567	0.22959967330098152	0.9287109375
21	0.297346909697703	0.89579770349798	0.22549461666494608	0.92919921875
22	0.2938648144285166	0.8993403369862556	0.22306359186768532	0.9306640625
23	0.2845122415163742	0.9042267282405809	0.2172949407249689	0.93310546875
24	0.2812073317609205	0.907525042435548	0.21500028017908335	0.9326171875
25	0.27314266862451025	0.9069142434959915	0.21238030772656202	0.93359375
26	0.26828089206791905	0.9070364038926186	0.2108873575925827	0.93408203125
27	0.26710274291306463	0.9093574396474071	0.2130012921988964	0.9296875
28	0.263967200352806	0.910579037803209	0.20784230716526508	0.93359375
29	0.2597564661995053	0.9131443932881834	0.20435110293328762	0.93798828125
30	0.25566840986590383	0.9154654291885976	0.2088072942569852	0.9326171875
31	0.25666443237954295	0.9130222329061188	0.20200033113360405	0.93505859375
32	0.2498264273388765	0.9149767899175393	0.1987114166840911	0.9384765625
33	0.2490598135899717	0.9142438310473582	0.19872797466814518	0.939453125
34	0.2439268938878507	0.9187637433981272	0.19836902897804976	0.9365234375
35	0.2449993883925605	0.9174199851660748	0.19765432085841894	0.93896484375
36	0.2444518148615108	0.9170535064081443	0.19746546354144812	0.93603515625
37	0.2396104539369797	0.9187637433981272	0.19545290153473616	0.93798828125
38	0.23543637727368819	0.9192523823924965	0.19412671122699976	0.9375
39	0.23381566303795134	0.9209626190766652	0.19394041690975428	0.9384765625
40	0.22513884347093271	0.9224285365112131	0.19480090402066708	0.93505859375
41	0.22920307591684924	0.9208404594518548	0.19166026264429092	0.93896484375
42	0.22719808844287442	0.9208404594372922	0.1930879126302898	0.93798828125
43	0.2263667185106168	0.9229171753453941	0.1907057911157608	0.93994140625
44	0.22409528726154396	0.9227950159972726	0.192176409997046	0.9365234375
45	0.22423999537953881	0.9240166137161973	0.19106448721140623	0.93798828125
46	0.21802189635263514	0.9242609337230723	0.1886289780959487	0.9404296875
47	0.2167177692714659	0.9253603716424355	0.18938750308007002	0.93798828125
48	0.2146955741236736	0.9245052525503782	0.18873146129772067	0.93994140625
49	0.2139397026448095	0.9257268506916175	0.19235252914950252	0.93505859375
50	0.21582120746162972	0.9258490107824305	0.18941134959459305	0.93798828125
51	0.21031975393012192	0.927803566890971	0.1878072558902204	0.9384765625
52	0.21200736787742663	0.9264598092559845	0.1884347815066576	0.93798828125
53	0.20698211697241278	0.927925726530344	0.18784913746640086	0.93798828125
54	0.20446597684457837	0.9281700462605299	0.18573585245758295	0.94140625
55	0.20486484040571487	0.9280478869124086	0.18676512129604816	0.93701171875
56	0.20075217191554967	0.9293916442561435	0.18532206630334258	0.9423828125
57	0.20095245501915285	0.9282922063222178	0.18468663189560175	0.94287109375
58	0.19852691661268873	0.9301246032573878	0.19182060100138187	0.9345703125
59	0.1958453719463903	0.9290251651923987	0.1868846621364355	0.93798828125
60	0.1966829782676324	0.9308575619673805	0.18679745122790337	0.93798828125
61	0.19187999618481577	0.9308575616761289	0.18621465703472495	0.93798828125
62	0.1899635267998926	0.9320791592203024	0.18401721445843577	0.9423828125
63	0.18889572030316057	0.9308575615159405	0.1850195713341236	0.939453125
64	0.18570690445334354	0.9330564382429843	0.18579221703112125	0.93896484375
65	0.18459513416113785	0.9318348403929965	0.18373051332309842	0.93994140625
66	0.18456059508981315	0.9339115559952841	0.18353908974677324	0.93994140625
67	0.18153821122681282	0.9339115567379758	0.19187606452032924	0.93603515625
68	0.1784700063968998	0.9358661125698271	0.184600786305964	0.9384765625
69	0.17801468306594917	0.934644515011091	0.1862345840781927	0.9384765625
70	0.17471990249950903	0.9370877104198149	0.18758266884833574	0.93798828125
71	0.17214141777724995	0.9384314684916789	0.18302096240222454	0.9404296875
72	0.1759732294215161	0.935866112992142	0.18335696123540401	0.93994140625
73	0.17211122580751825	0.935866112715453	0.18320841249078512	0.94091796875
74	0.17025056311343253	0.9384314687829305	0.18234103405848145	0.9404296875
75	0.16733812328337924	0.9390422677079244	0.1824814542196691	0.94091796875
76	0.16542492654004365	0.9408746644829061	0.18588375439867377	0.93798828125
77	0.1636268681166896	0.9402638652666606	0.1841923277825117	0.93798828125
78	0.16151676144047702	0.9395309062654162	0.18507175892591476	0.9404296875
79	0.16406129420007495	0.9414854629710225	0.182411746121943	0.94091796875
80	0.16091471245694855	0.9427070605151961	0.18278477527201176	0.9404296875
81	0.15654003248983916	0.9416076230618355	0.18820001697167754	0.93798828125
82	0.15528856943805847	0.9424627417024528	0.18590114172548056	0.93798828125
83	0.15763312381606448	0.9420962617358281	0.18334181513637304	0.9404296875
84	0.1492982732435616	0.9464940141559725	0.1838790150359273	0.94091796875
85	0.15051456050610093	0.9439286586709982	0.18382311426103115	0.93994140625
86	0.15183315543522033	0.9439286586709982	0.18491570558398962	0.9384765625
87	0.1453849658053282	0.9472269728659651	0.1850185045041144	0.939453125
88	0.1464934425768455	0.9464940138501583	0.18576325802132487	0.939453125
89	0.1431459895875091	0.947349133102404	0.18687053071334958	0.93701171875
90	0.14188989995271806	0.9499144879903124	0.18546872772276402	0.94091796875
91	0.1408890448392326	0.9494258488503173	0.18492469936609268	0.9384765625
92	0.14169921979923397	0.9479599320128352	0.18483114195987582	0.94140625
93	0.13759786534973442	0.9495480086353161	0.18565475987270474	0.939453125
94	0.13744523322890972	0.9504031269846818	0.18668745877221227	0.939453125
95	0.13715380543081562	0.9506474467003051	0.18991683423519135	0.93994140625
96	0.13147344441496012	0.9518690446959187	0.1864760289900005	0.9384765625
97	0.13116161916982916	0.9543122405415201	0.18737427983433008	0.93798828125
98	0.13275384682148963	0.9501588081573759	0.18568520294502378	0.93798828125
99	0.1288918060437846	0.9556559977396293	0.18720399914309382	0.93896484375

The optimal condition:
	epoch: 57
	train_acc: 0.9282922063222178
	val_acc: 0.94287109375
	using time: 715.519445896
