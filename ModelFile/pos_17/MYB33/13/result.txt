The number of train datas: 13706
The number of test datas: 3428
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7074620789652164	0.5143732671996512	0.6912966491600179	0.5285880983640878
1	0.6904644219436629	0.5351670801152492	0.6862382647454252	0.5580513414730129
2	0.6821558618395933	0.5568364220223565	0.680956652520557	0.572345390689832
3	0.6749650091737374	0.5779950386778936	0.6750725578677557	0.5819719948457031
4	0.6662837647181018	0.593462717049525	0.6671366384176836	0.5936406060027408
5	0.6578971292352251	0.6156427841734124	0.6593377432300163	0.6044340719280888
6	0.6465430671448918	0.6254924850343493	0.6491803060891053	0.6225204207655151
7	0.6325687793559547	0.6457026120034445	0.6381210289730352	0.631271878229139
8	0.6193577483433381	0.6623376623289647	0.6261019642044254	0.6449824977783506
9	0.6052608977838553	0.6776594192411506	0.6078806798405241	0.6642357055336897
10	0.5882863465772133	0.6920326864060112	0.5865542826046047	0.686697782894277
11	0.565728753318095	0.708594776019204	0.5613190512256555	0.7100350062516078
12	0.5412038583990676	0.7347876842084913	0.5249939427353537	0.7459159868322705
13	0.5133485294216378	0.7552166934363358	0.4909096332734218	0.7718786467192749
14	0.4863143920046073	0.7731650372012834	0.45387267478705845	0.8042590434520637
15	0.45755084835489734	0.7984094557041289	0.4257638357762278	0.8135939328089061
16	0.434062521635625	0.8094994892834678	0.4044039345747392	0.8305134184162981
17	0.4154466079453143	0.8223405807762446	0.36974206149508543	0.8515169198343329
18	0.3908408142851336	0.8378812198949942	0.360574356490005	0.857934656471466
19	0.37104242985724845	0.8470013133021457	0.3336755722726379	0.8675612593754308
20	0.35956491833270315	0.8555377207149576	0.32994993665671823	0.8725204205568641
21	0.3442802368685675	0.8631985991536554	0.3151158320096994	0.8760210029441807
22	0.33276548466333833	0.869035458931797	0.29631828854910275	0.886522753653198
23	0.324710366257295	0.874872318701241	0.2873009953087102	0.8926487754217524
24	0.30901165452905244	0.8788121990456157	0.2788422923522068	0.8952742131337819
25	0.29538317150605536	0.8852327447659114	0.26470302819092884	0.9057759633559469
26	0.2865403275189392	0.8899751933285847	0.25878787614500787	0.9057759633559469
27	0.2796450521316943	0.8944257989027857	0.2495247850687946	0.9104434079300425
28	0.272525157786522	0.8961768568336189	0.24625689413750604	0.9130688440424142
29	0.2654091629749943	0.9028162848474544	0.2592921594338211	0.9002333728546579
30	0.2552495346127784	0.9056617539850583	0.23240131593571242	0.9133605608584027
31	0.24789511498597075	0.9095286735562222	0.22930240596328344	0.9226954491024396
32	0.2373250774592357	0.9114256529812915	0.2222763073555647	0.9247374561036065
33	0.23601600033304873	0.9128848679410477	0.21836770297209607	0.9256126019612494
34	0.2275274825691046	0.9157303370786517	0.21334425962444226	0.923570595864237
35	0.2242347476179019	0.9160951408055443	0.21912117363274305	0.921236872951236
36	0.21509754838872858	0.9222968043192762	0.2164377058609503	0.921236872951236
37	0.20963298961765903	0.9248504304510128	0.2022290890525631	0.9288214701059402
38	0.20590006947456513	0.9244126659856997	0.2102193544285161	0.9200700118772625
39	0.19991205926230576	0.9291551145309778	0.19625079623111627	0.9296966165895362
40	0.19442901044744793	0.927695899606012	0.19594075347328407	0.9276546092406176
41	0.193768268634016	0.9317817014533204	0.1920508318596988	0.9291131860177743
42	0.18681533210002366	0.93243834815129	0.19265390402238594	0.9288214695495374
43	0.1843399807819481	0.9312709762147965	0.19363603395786974	0.9279463245264986
44	0.17995976177111483	0.9360863855332854	0.1849217609770796	0.933197200020108
45	0.17813744426521613	0.9375456004495536	0.18622834580573347	0.9291131848354184
46	0.17255005295941922	0.9390048154093098	0.19512172912702816	0.9259043175948821
47	0.17276859059918975	0.9393696191275048	0.2103279523090693	0.9189031501773358
48	0.17294549354493802	0.9392236976332687	0.19305803412039055	0.9261960325330113
49	0.16654522405407576	0.942506931253581	0.18171010574145524	0.9296966165895362
50	0.1612443146754508	0.9425798920180942	0.21031194244584236	0.9203617266067406
51	0.15836447233155612	0.943601342477747	0.2501710370061278	0.9040256705974058
52	0.15704133171209295	0.9445498321989793	0.18000200289967735	0.9326137685441915
53	0.15251535239853548	0.9457172041267753	0.20403803611997962	0.9229871643883205
54	0.1564627324287911	0.9464468116153509	0.16967371083543906	0.9352392070212748
55	0.1508269603606751	0.9472493798162543	0.1905652939090929	0.9282380392559768
56	0.14985860972714854	0.9469575368451773	0.17590828603318304	0.930280046326694
57	0.14326741291009196	0.9504596527068437	0.1739866212618949	0.9349474905530379
58	0.14629960472929412	0.9485626732817745	0.18736079089178365	0.9267794628961222
59	0.143353014153737	0.9500218882241355	0.1757016241237469	0.9305717618907764
60	0.14040108238110816	0.9506055742010798	0.16535042695779367	0.9372812140224417
61	0.13670537401059762	0.9538888078213921	0.1655649537418381	0.9387397904518465
62	0.13459237512403835	0.9526484751290828	0.2177532379240528	0.9186114348914548
63	0.13409441608626285	0.953742886327156	0.16343612664638907	0.9393232210236085
64	0.13191638825121246	0.9546913760396907	0.16534811487832174	0.936406067608396
65	0.1300949328276631	0.9546913760396907	0.1656923717281226	0.9349474911789911
66	0.1326721960652332	0.9528673573617393	0.1629766202863206	0.9340723450431467
67	0.12730137916197834	0.9562965124588926	0.16088117413926986	0.9404900818889311
68	0.12708789187809785	0.9557857872464613	0.17800259095472104	0.9302800466048954
69	0.124916036925176	0.9565153947002467	0.17357395349402968	0.9308634768984559
70	0.12030275705503266	0.9565883554473648	0.17827080759625175	0.9288214698972891
71	0.12293726459605432	0.9591419816138917	0.1631654001415958	0.9396149360312881
72	0.12156308140275723	0.9578286881657668	0.15989337317306493	0.9396149360312881
73	0.11723819539748925	0.9592149423436146	0.16142562661176524	0.941073512460693
74	0.1164659010995205	0.9603093535503854	0.17423898169429605	0.935239205838919
75	0.11522198446376575	0.9592879030907326	0.19147786505024797	0.9279463248047
76	0.11376059290272257	0.959798628320559	0.17203872071855128	0.9317386227560989
77	0.11358466079926362	0.9603093535503854	0.17848428299644029	0.929988331040813
78	0.1140690967736867	0.9611119217860791	0.1603434208950056	0.9399066515953705
79	0.11051078472114141	0.9608200787976069	0.19554944945849226	0.9244457406090745
80	0.1098461610954225	0.9621333722457318	0.16260901787247653	0.9387397898954438
81	0.1121300444100419	0.9592879030907326	0.17381758356734223	0.9369894978324063
82	0.10691604742313647	0.9622792937399679	0.15889773103153135	0.9410735121824917
83	0.10623835720090331	0.9633737049467387	0.20052125947408664	0.9238623097591111
84	0.10585325893069573	0.9632277834525026	0.15696719466179365	0.9416569427542536
85	0.10429290148615619	0.9645410769006275	0.16364291218156157	0.9404900824453338
86	0.10112781474342594	0.9650518021304538	0.1603918586061048	0.9399066510389678
87	0.10116800975816086	0.9660002918429885	0.15797459689711188	0.9425320886118965
88	0.09575894984281987	0.9659273310958704	0.15984159421127903	0.9431155191836585
89	0.09918843170169425	0.9671676637968772	0.16026980526388873	0.941656943032455
90	0.09842491199478658	0.9676783890267037	0.18404705622510564	0.9352392063953218
91	0.0966056768581169	0.9678972712680578	0.15784789710506675	0.9439906653195028
92	0.09603805064407035	0.9677513497738217	0.17270644342954963	0.9349474909007897
93	0.09324875538915942	0.9686268787392383	0.15813901114561177	0.9434072344695396
94	0.09400665384086573	0.9681161534920167	0.16180803246856987	0.9416569427542536
95	0.09307726074048729	0.966729899314169	0.16172935845832423	0.942240373604217
96	0.09376651344813519	0.9678243105035446	0.1986873560914359	0.9270711783906542
97	0.0940102491466369	0.9673135852911133	0.17367547944344605	0.9337806300354672
98	0.08738997545515675	0.9702320151758353	0.16337326104679908	0.941073512460693
99	0.08714858223127622	0.9692835254633008	0.16341706644417664	0.941948658318336

The optimal condition:
	epoch: 91
	train_acc: 0.9678972712680578
	val_acc: 0.94399066532
	using time: 987.56588912
