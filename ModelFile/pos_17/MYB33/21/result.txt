The number of train datas: 13706
The number of test datas: 3428
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7070045982784169	0.5127681307369613	0.691704884293199	0.5256709443924724
1	0.6919672042283632	0.5224719101123596	0.6871955894811846	0.5513418901064014
2	0.6848022499328701	0.549175543557566	0.6825623097748016	0.568261376409297
3	0.6807212810716055	0.559317087406975	0.6777400578195044	0.5828471404946949
4	0.6728827958470206	0.5854370348839347	0.6711536974166906	0.6032672111323166
5	0.6637468189283755	0.6068145337982211	0.6648896389413742	0.605309219037638
6	0.6548837114907731	0.6145483729927345	0.657520186595071	0.61289381577504
7	0.6475774393140112	0.6211148401985687	0.6513080181012771	0.6213535591351388
8	0.6363455225355726	0.6378958120531154	0.6447061703669705	0.6251458568778867
9	0.6261585187550167	0.6459944550006143	0.6367707856199427	0.6371061838772083
10	0.6176262970094557	0.6576681745221071	0.6258133345195543	0.6449824979174512
11	0.6036416619481195	0.6702903837822275	0.6142728242462407	0.6665694280293887
12	0.5871264593854849	0.6913030789348308	0.5912398860084551	0.6849474906225883
13	0.5712284725477412	0.7064789143266876	0.5690754799470045	0.7068261376896149
14	0.544588818056782	0.7313585291113381	0.5331434348778519	0.747666278269355
15	0.518728319204899	0.7534656354707122	0.5119402213163387	0.7549591591644732
16	0.48681302170987967	0.7739676054369772	0.46620068520898716	0.7902567095211256
17	0.4606419361091679	0.7933022034232605	0.4273219171872356	0.8156359391145696
18	0.428944260103762	0.8136582518691966	0.39516903030552414	0.8386814469773684
19	0.4004898885471289	0.8298555377033111	0.37194152226804156	0.8494749116508101
20	0.38639044037582615	0.8395593170700117	0.35820744644802677	0.8506417732116361
21	0.36205316114804875	0.8518896833329623	0.3351273055045997	0.8658109691207022
22	0.3426215468175947	0.8627608346796446	0.3454250100056794	0.8503500579953055
23	0.3311782930256693	0.8687436159172319	0.31480886363788413	0.8725204197918103
24	0.31063973988022714	0.8772070626090186	0.31348686840041795	0.8640606764317115
25	0.29765660263022836	0.8833357653582373	0.2822164554787906	0.8917736287295053
26	0.28331995126923804	0.8904859185845038	0.2642498231963488	0.8996499417960435
27	0.27474742793400203	0.896030935356778	0.2525623471692396	0.9060676778072237
28	0.26608391337702264	0.8984386400116737	0.2518810772422871	0.9057759618953897
29	0.25669741900179766	0.9025244418328894	0.2612504120677049	0.901400233441779
30	0.24171395713998056	0.90923683056775	0.22847092353337844	0.9156942828672492
31	0.23588164867233938	0.914854808113235	0.23115526339693415	0.9148191363836531
32	0.2308666275293135	0.9153655333517591	0.23063033391463994	0.9113185533008331
33	0.22552043727048554	0.9178461987276799	0.22284453502196552	0.9189031510119399
34	0.21404593563481664	0.9202539033999708	0.2213247613666216	0.9168611437325717
35	0.21121684623933545	0.9225156865432352	0.22560969447171536	0.917152858670701
36	0.20461882583010932	0.9250693127097621	0.24206114100464027	0.9078179691747579
37	0.19931664785450956	0.9283525463126793	0.20807031386443864	0.9253208870231201
38	0.1945863999812321	0.9279877425944841	0.21684205096514947	0.91715285846205
39	0.19034243085759062	0.9300306434963944	0.21936637024061542	0.9215285879589157
40	0.186671365274794	0.9341894060995185	0.238917363914058	0.9054842474441128
41	0.1866577226420171	0.9330949949014453	0.2462285895035314	0.8990665113633822
42	0.17934852120203293	0.9344812490879907	0.1984537598375957	0.9296966163113348
43	0.17625383518861276	0.9352838173062892	0.21100754719423162	0.9232788796742015
44	0.17510407532494762	0.9355756603034591	0.24660705440311476	0.8990665113633822
45	0.17129763189796182	0.9395885013949518	0.21593227885150576	0.9194865809577488
46	0.16341428136498967	0.9412665985699693	0.19967275943124588	0.924445740330873
47	0.16523952576673312	0.9409017948343791	0.21631398690101564	0.9145274217932756
48	0.1632949976778093	0.9417773237910981	0.21173638178420318	0.9203617270935931
49	0.16086966082438506	0.9419232453027294	0.19791710871416324	0.9264877473320399
50	0.1572807745400022	0.9442579892018095	0.2810867505458856	0.8876896149358227
51	0.15276186149059098	0.9460090471152475	0.25741937711765356	0.8946907820751675
52	0.15107144005286785	0.945498321885421	0.21041646401551112	0.9194865816532523
53	0.14868128962905044	0.9473953013104904	0.34480781941875693	0.8593932324835689
54	0.1521233774336482	0.9461549686268788	0.19502595479979398	0.9259043170384793
55	0.1445906161261739	0.9485626732904721	0.2939797772340207	0.8847724617988114
56	0.1444965618395221	0.949365241500073	0.19256665129888295	0.9285297543332067
57	0.13910659519917737	0.951262220907747	0.2600861585056768	0.8987747964252529
58	0.1411250824032344	0.9511162994309061	0.2140297256366653	0.9174445746520854
59	0.14047648202571905	0.9514081424193783	0.20179586069030273	0.923570595655586
60	0.13422279525480268	0.955202101269517	0.19003088424545186	0.9326137697265474
61	0.1323683290532644	0.9543995330512185	0.1865501543604785	0.932613769448346
62	0.1297832621799913	0.954034729298233	0.24538318701131898	0.9008168033568695
63	0.1295381076492594	0.9549102582810448	0.19774924811571315	0.9250291723631923
64	0.12877910380415736	0.9557128264993433	0.18994069462826818	0.9305717624471791
65	0.1207426998342443	0.9585582956369473	0.1908992900314242	0.9317386230343003
66	0.12664520345447786	0.9546184152925726	0.18529527656116732	0.9346557761713115
67	0.12107674976030475	0.9576098059331103	0.21828070084717616	0.918903151220591
68	0.12114627283829182	0.9573179629359405	0.18836739341116562	0.9334889155841903
69	0.11620178244661175	0.9581205311368438	0.27006669266447164	0.893523921209845
70	0.1147559808357065	0.9597986283379542	0.20614475157881285	0.9212368736467395
71	0.11987651533281544	0.9589960601196557	0.1916068774607802	0.9323220544406664
72	0.11544976351103452	0.9604552750620167	0.18799574780978845	0.9311551930189411
73	0.10874385024559127	0.9627170582226762	0.19870779425983806	0.9291131853918211
74	0.11380507776019835	0.9611119217686839	0.19120003123058044	0.9294049013036552
75	0.10927030746169322	0.9622063329928499	0.2100849312968126	0.9232788796742015
76	0.10606089782409558	0.9641033124179191	0.20100242761914622	0.9241540256013948
77	0.106772080755279	0.9625711367110449	0.2378364344939259	0.9057759632168462
78	0.10445929108945606	0.9642492339121552	0.1987769917749051	0.9314469071224662
79	0.10667844405882936	0.9630818619582665	0.20369750693388275	0.9232788794655505
80	0.10464417097219478	0.9636655479352109	0.2622284587459637	0.9040256712233589
81	0.10359470557661174	0.9630089012111483	0.19786983008562753	0.9305717615430247
82	0.10018802485712101	0.965416605866044	0.19158302167541366	0.9302800471612982
83	0.09873573615762173	0.9668028600438918	0.3701279776772895	0.8693115519253208
84	0.1009469268253454	0.9657084488545162	0.19505714328661822	0.9329054850124283
85	0.09885600392211881	0.9649058806362177	0.19395637672172822	0.9288214704536919
86	0.09509207278611832	0.9664380563256968	0.1933184035183251	0.9305717621689777
87	0.0953906098847909	0.9673865460382314	0.19101655211999508	0.9326137697265474
88	0.09058114134920056	0.9692835254633008	0.21191813034313006	0.9197782957567774
89	0.09306932069327507	0.96818911425653	0.21083024624070043	0.9285297545418578
90	0.09132533987901706	0.9679702320151758	0.2083991456824673	0.9270711783906542
91	0.089488887162432	0.9700131329344812	0.1938031956014444	0.9320303376942282
92	0.09050881853616623	0.9692835254633008	0.26191929930358115	0.9008168033568695
93	0.08742921371744068	0.9701590544287173	0.22512929426677863	0.9168611440803234
94	0.0864451163079153	0.9703779366787691	0.46845912112329535	0.8436406067677946
95	0.08718055748259362	0.969575368451773	0.19555469434556216	0.931446908304822
96	0.08425724625970157	0.9711805048709748	0.19545441203453995	0.931446908304822
97	0.08461080941752276	0.97118050488837	0.2314212453207099	0.914235706785596
98	0.08237263806124581	0.9727126805778491	0.22104171184494725	0.9200700125032155
99	0.07994614747357927	0.9745366992558003	0.2063212993716693	0.9256126020307998

The optimal condition:
	epoch: 66
	train_acc: 0.9546184152925726
	val_acc: 0.934655776171
	using time: 1208.10934091
