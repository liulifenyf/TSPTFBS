The number of train datas: 2842
The number of test datas: 712
epoch	train_loss	train_acc	val_loss	val_acc
0	0.71933939539153	0.4996481352838977	0.6967293312040608	0.5000000013394302
1	0.7014067891951097	0.5144264601973225	0.6951962441540835	0.49859550461340485
2	0.6969125347603886	0.5207600282121091	0.6915598578667372	0.5308988784136397
3	0.698046942817586	0.5130190007666481	0.6893234674850207	0.5477528103281942
4	0.6918895097369463	0.5320197046432253	0.6875279023406211	0.5561797752808989
5	0.6900358063750163	0.5355383532723434	0.6858771162086659	0.5688202260585313
6	0.6901325073819359	0.5365939481756705	0.6843171186661452	0.561797754148419
7	0.6838536513346672	0.5408163264886667	0.6828769720002507	0.5814606754967336
8	0.6845898350974693	0.5559465167473774	0.6814078326975361	0.5856741579730859
9	0.6797818640098867	0.5622800844056266	0.6797514959667506	0.5969101130292657
10	0.6770262881788378	0.5738916258254914	0.6775267003627305	0.609550562467468
11	0.6789210494096476	0.5738916258254914	0.6748441310411089	0.6137640449438202
12	0.6705540878767702	0.592540464629429	0.6721569239423516	0.6264044950517376
13	0.669703286017942	0.5862068965517241	0.6696011959836724	0.6235955062876927
14	0.6651287247059129	0.5971147079102008	0.6663498737838831	0.6390449411413642
15	0.6635131788958469	0.5883180858550316	0.662768865569254	0.63623595639561
16	0.6585932512001451	0.6136523573688853	0.658645650643981	0.6404494395416774
17	0.6565116712276907	0.6249120339887567	0.6543781529651599	0.651685393258427
18	0.6538705909696789	0.6238564389595929	0.6500235266899794	0.6587078671776847
19	0.6393039854457058	0.647783251147636	0.6441837937644358	0.6685393271821268
20	0.6331854532672686	0.6537649544253473	0.6379767817057921	0.674157300691926
21	0.6372684248310844	0.6319493316664484	0.6323246741562747	0.6755617964133788
22	0.6264186101342322	0.6523574946381356	0.6262067770690061	0.6727528083190489
23	0.6256227472732807	0.6520056296703599	0.6206152633334814	0.6910112339459108
24	0.6137239673790338	0.6798029557908614	0.6153129540132672	0.6924157310067938
25	0.6062304002562515	0.6783954963392141	0.6088697823245873	0.6952247184314085
26	0.6017470955009783	0.682266010019999	0.6033869439296509	0.689606743582179
27	0.5958230581860741	0.6917663616332095	0.5980445983704556	0.698033710544029
28	0.5911540298039103	0.6977480646592475	0.5927535871441445	0.6966292161620065
29	0.5859078432287154	0.6924700917365432	0.5879936566513576	0.6994382002380457
30	0.583800971046625	0.6973962000270363	0.5842820660451825	0.6966292154922914
31	0.5780316874395367	0.6980999298367511	0.5797263450836867	0.7022471936900964
32	0.567183062528574	0.7111189302468619	0.5777419095628717	0.7134831487462762
33	0.565591867501932	0.7135819843501628	0.5732688234093484	0.7162921375103211
34	0.5576965266092825	0.7251935257700276	0.5717044278477015	0.7120786490065328
35	0.5493683260901556	0.7273047148216618	0.5643144678533747	0.7176966272043378
36	0.5489500053200732	0.7290640391991392	0.5610521690229352	0.7247191024630257
37	0.5488008209133887	0.72554539048613	0.5560315834002548	0.7303370799911156
38	0.5451343582391236	0.7227304716247811	0.5529960139413898	0.7176966265346227
39	0.5423638872660691	0.7350457425187962	0.5495894209722455	0.7373595525709431
40	0.5337455757984723	0.7361013371704499	0.5447777750786771	0.7247190997841653
41	0.5262343541867796	0.7420830401964879	0.5416541809446356	0.7387640456135354
42	0.5253344244473758	0.7427867700062026	0.539064487714446	0.7415730363867256
43	0.5197703898330543	0.7441942292900676	0.5345693692732393	0.7387640469529656
44	0.5176374245117786	0.7473610132030833	0.529202523526181	0.7331460674157303
45	0.5031832485531184	0.7646023925553738	0.5261524781752168	0.7317415703548474
46	0.5066675729813667	0.7607318787906977	0.5210754951734221	0.7387640442741051
47	0.4979081410995929	0.7751583390719113	0.5181834664237633	0.7471910139148155
48	0.4876192284670621	0.7702322310330917	0.5119001316220573	0.7485955042785473
49	0.4925379057235906	0.7691766360039278	0.5071563827857543	0.7528089874246148
50	0.482056169129022	0.7737508797461008	0.5027973996789268	0.7584269683012802
51	0.47551699048779866	0.7846586908529042	0.49749728869856075	0.7626404501079174
52	0.46468659394396433	0.785010555904571	0.4935890683967076	0.7710674177394824
53	0.4637499496938476	0.7913441236886569	0.5023194956645537	0.7570224705706822
54	0.4624909367844892	0.7871217450820418	0.4842243723655015	0.7766853925887118
55	0.4505032986549321	0.7997888811535604	0.47867911618747067	0.776685393258427
56	0.4447460925595849	0.799788880901887	0.47908338402094464	0.7780898863010193
57	0.4441882540104173	0.8029556651504672	0.4675178216414505	0.7921348341395346
58	0.4284384181011235	0.8145672062767131	0.4623081898421384	0.7893258400177687
59	0.42218375765966915	0.8124560169734055	0.4574467978450689	0.7907303350695064
60	0.4223393740618757	0.8110485574798127	0.4522447331567829	0.8005617950739485
61	0.4195648089921617	0.8216045039963504	0.4467121145028747	0.8005617957436637
62	0.42015416224937385	0.8201970441671931	0.44150145167715094	0.8132022451818659
63	0.4073737708721926	0.8258268823932376	0.43696434444256044	0.8103932590966814
64	0.4003398487007509	0.8367346937097687	0.4311401870813263	0.8160112339459108
65	0.388444294252503	0.8409570726100027	0.4296020547325691	0.8202247191011236
66	0.3832401710023014	0.8430682615777458	0.4258362295922269	0.8230337078651685
67	0.3756121671971597	0.8391977481905798	0.41582960894938265	0.8300561784358507
68	0.3834777734885326	0.8395496130744644	0.4113493745916345	0.8426966292134831
69	0.36436713815658217	0.8525686137781942	0.41402367326650724	0.8272471930203813
70	0.3546289941695775	0.8557353974395365	0.4017276442452763	0.8426966298831983
71	0.3564646008105281	0.8515130190845949	0.39898129661431475	0.8441011235955056
72	0.3524254397721797	0.8550316679653863	0.3943510443976756	0.8455056173078129
73	0.346929080841996	0.859605911162267	0.3888470928990439	0.8441011235955056
74	0.345335728827704	0.8659394792819174	0.3855746311418126	0.8497191024630257
75	0.34190445205093184	0.8617171006753024	0.38835715125785786	0.8469101143686959
76	0.3373355753903319	0.8666432090916322	0.38454869406276876	0.8497191031327408
77	0.3298519450455464	0.865939479030244	0.37646354785126246	0.8525280918967858
78	0.3254504487767847	0.8715693174240708	0.3713272672690702	0.8567415750428532
79	0.3183431897383186	0.8740323715693173	0.36889507362012114	0.8609550581889206
80	0.31576425501949595	0.8768472907242852	0.36701110306750523	0.8567415750428532
81	0.30504843198355447	0.8849401830116852	0.36781931459234	0.8567415750428532
82	0.3038177507641784	0.8888106967763613	0.36688826693577714	0.851123595505618
83	0.2958358692334287	0.8807178041533967	0.3591451407148597	0.8595505638068981
84	0.297173762011075	0.8793103448695317	0.35860223766793026	0.8637640476226807
85	0.28823708288271943	0.8895144262505115	0.3708368047569575	0.8483146047324277
86	0.28602070872587354	0.8835327234761469	0.3549427550830198	0.8637640469529656
87	0.27918460890703184	0.8923293453215881	0.35295904184995075	0.8567415743731381
88	0.284552413527182	0.8863476422955502	0.34882834185375255	0.8665730357170105
89	0.27746984949840114	0.8976073186218025	0.35395678961544896	0.8651685420047032
90	0.2629054367835886	0.8930330753410307	0.34747164972712485	0.865168541334988
91	0.27239865024772686	0.8926812101635272	0.34963741680879273	0.8679775307687481
92	0.25705546308453026	0.9000703727670492	0.34594417388519544	0.8707865188630779
93	0.26080830130964666	0.8954961295282229	0.3433770343159022	0.8693820251507706
94	0.25707076184771416	0.8976073188315303	0.3438949116160361	0.8609550581889206
95	0.26055254689158897	0.9035890218575684	0.3416876406147239	0.8693820251507706
96	0.2560507729177656	0.9025334269542412	0.3389049507258983	0.867977530099033
97	0.252071140067918	0.9032371566800649	0.3388750536388226	0.8665730363867256
98	0.2493250179173324	0.9102744543997021	0.34843947277979903	0.8637640456135354
99	0.23996426375880364	0.9095707249255519	0.33688981630159226	0.8651685420047032

The optimal condition:
	epoch: 92
	train_acc: 0.9000703727670492
	val_acc: 0.870786518863
	using time: 255.881208897
