The number of train datas: 3936
The number of test datas: 986
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7014897320328689	0.5073678861788617	0.6930627399719269	0.5162271808296381
1	0.6930566590006758	0.524390243902439	0.6875203881737668	0.5517241383541912
2	0.6878377048949885	0.5464939019544338	0.6814428434894244	0.5882352946012547
3	0.6821294683751052	0.5574186991869918	0.6738896770119426	0.6318458413013822
4	0.6742377765779572	0.5797764232488183	0.6642842605921608	0.6754563911449595
5	0.6650279920275618	0.6021341458568729	0.650196085716116	0.7363083149791972
6	0.6528031976242376	0.6290650411349971	0.6326024774121948	0.7586206884461533
7	0.6331600750364909	0.657520325203252	0.6100226730168712	0.7910750491382142
8	0.6154435087994832	0.6869918704032898	0.5850605889701457	0.8194726176000754
9	0.597538076765169	0.6943597556129704	0.5570703054538363	0.8265720063000616
10	0.5742517685502525	0.71875	0.5266183179483936	0.8275862081055709
11	0.5446339191460028	0.7530487809723955	0.49296479667659704	0.8397565935011084
12	0.5147590848003946	0.7690548780487805	0.4546468559554334	0.8509127770911366
13	0.48371100231883973	0.7942073170731707	0.4247067583985551	0.8600405661377897
14	0.4617853530538761	0.8013211386959728	0.39781213302399515	0.8681541564014814
15	0.438608769721132	0.8099593495934959	0.37752403442806454	0.8732251503162887
16	0.4122063299504722	0.827489837398374	0.35763619794806895	0.8742393490992502
17	0.39087922010964493	0.8348577230926452	0.34333732742325046	0.8701825563854426
18	0.3851777528359638	0.8381605695902816	0.32627723291969685	0.8884381318189067
19	0.3683153788248698	0.8475609760943467	0.3184968313508295	0.8843813393469031
20	0.34984125330196164	0.858993902923615	0.3002303159865598	0.8945233245166755
21	0.34218772736991326	0.8620426829268293	0.2887539832756437	0.8995943184314829
22	0.32193668525878005	0.8732215447154471	0.27868554116988037	0.9056795137890937
23	0.3129040574639793	0.8810975614602004	0.2661634644315886	0.9107505050440589
24	0.2989740950789878	0.888973577720363	0.2622444670775841	0.908722107357234
25	0.28760612156332993	0.8879573170731707	0.26047509379730266	0.8975659234045001
26	0.2732664211009576	0.8976117881332956	0.2514870145318474	0.9046653148852304
27	0.2694874093299959	0.9006605686211004	0.23767015111252937	0.9198782966296523
28	0.25959787354236696	0.904979674796748	0.23087513483078437	0.9198782967505542
29	0.25204070748352425	0.9110772352877671	0.22779330517529958	0.9188640978466909
30	0.24445300785506643	0.9179369913853281	0.22373192187617807	0.9198782938489082
31	0.2404619897526454	0.915650406504065	0.22077385579475767	0.9198782938489082
32	0.23609698933314502	0.9159044715447154	0.2181509071262081	0.9229208901977926
33	0.23178341015567624	0.921239837398374	0.2120916442624454	0.9249492877637155
34	0.22227481516396128	0.920223577720363	0.22880873331917226	0.916835697379122
35	0.2188853810473186	0.9237804873202874	0.20687201561719845	0.9269776853296384
36	0.21413213063061723	0.9242886174015883	0.20386346545954506	0.9300202816785228
37	0.2122305400245558	0.9247967479674797	0.2097306342806826	0.9249492876428136
38	0.2056949657153308	0.9275914638992248	0.2077098539586483	0.9259634864257751
39	0.19980757435162863	0.9334349598341841	0.19932664556024524	0.9290060828955613
40	0.19474435082780636	0.9339430889463037	0.19975317388954317	0.927991883991698
41	0.1935546561712172	0.9308943084584989	0.2038943208376244	0.927991883991698
42	0.1875542770556318	0.9408028460130459	0.19423376389497676	0.9320486791235438
43	0.18790817272856952	0.936483740321989	0.19934935713636465	0.9330628779065053
44	0.1847184702632873	0.9367378043934582	0.19241093594815137	0.9310344803405823
45	0.18243122464273034	0.9382621956065418	0.18745628150433122	0.9300202816785228
46	0.17749157620639336	0.9402947149625639	0.19363065402478766	0.9320486791235438
47	0.17508774014507852	0.9397865848812631	0.18495433392195865	0.9310344831213264
48	0.1738021613015392	0.9428353658536586	0.1840735261628884	0.9320486819042879
49	0.1674271546970538	0.9446138206536208	0.18310817181459546	0.9320486819042879
50	0.1745390065801822	0.942835365369068	0.18902849900190535	0.9340770766894667
51	0.16791022914211925	0.9420731702471167	0.1873002633543092	0.9371196730383511
52	0.16805053266083322	0.9446138211382114	0.181663590167889	0.9340770766894667
53	0.1558573862643746	0.946646340978824	0.18659275026640593	0.9361054769152318
54	0.1598008460387951	0.9471544710601248	0.17627628561691144	0.9350912782531723
55	0.15146464363830844	0.9486788622732085	0.1746884968894974	0.9350912782531723
56	0.14835793930825178	0.9494410564259785	0.17823307427745805	0.9361054742553897
57	0.15049290838764934	0.9486788622732085	0.18102955263538728	0.9371196756981933
58	0.14748164551044868	0.9517276417918321	0.17228219641512355	0.9361054770361338
59	0.14516545347566526	0.9514735772357723	0.17376843158299252	0.9340770794702108
60	0.14232202849494732	0.953760162601626	0.17212206206868194	0.9350912782531723
61	0.14250154096663484	0.9532520330049158	0.1739561970347565	0.9330628806872494
62	0.13907494856332375	0.9527439024390244	0.17643192330371535	0.9350912754724282
63	0.1377722116989818	0.9540142276422764	0.17306326124174842	0.9350912754724282
64	0.13874388988909683	0.9529979674796748	0.17068514490828796	0.9340770794702108
65	0.133688099016019	0.9575711377267915	0.1677636568855804	0.9350912782531723
66	0.13186136366632895	0.9557926834114199	0.17506931855156263	0.934077079349309
67	0.13354903822991906	0.9560467479674797	0.16671553613810702	0.9350912754724282
68	0.12928133524530303	0.9565548780487805	0.17085037572388717	0.9350912781322703
69	0.1329884094193699	0.958333333817924	0.16390669397239027	0.9350912754724282
70	0.1259337529176619	0.9580792687772736	0.16635418285825432	0.9340770766894667
71	0.12379016278962779	0.9590955284552846	0.17966875143757213	0.9350912753515263
72	0.11299841796479575	0.9629065040650406	0.17296705910327712	0.934077079349309
73	0.11952305470055681	0.9588414629300436	0.17532217221497037	0.9350912781322703
74	0.11604346577229539	0.9631605686211004	0.17536393746461637	0.9350912781322703
75	0.11792934013576042	0.9596036580519948	0.16335470596626855	0.9340770766894667
76	0.11350167058105391	0.9646849598341841	0.16812721440383435	0.9371196756981933
77	0.12055434765127616	0.9598577235772358	0.16035251322430966	0.9361054742553897
78	0.11009429649608891	0.9654471549561353	0.16219837770138018	0.9350912754724282
79	0.11427191063398268	0.96290650358045	0.1684135445535304	0.9361054741344877
80	0.10855090527272807	0.9659552840682549	0.1624087883541115	0.9340770766894667
81	0.10829200226116956	0.9626524390243902	0.1604732054060903	0.9350912754724282
82	0.10702692559821819	0.9649390239056533	0.16328162633441767	0.9361054742553897
83	0.10625215686433684	0.9626524385397996	0.1579067900202579	0.9381338718213126
84	0.10288360575592614	0.9654471549561353	0.17172628854218167	0.9371196729174492
85	0.09811973995794125	0.9662093491089053	0.16800174692883696	0.9371196729174492
86	0.10116331364081158	0.9684959349593496	0.16199121986937087	0.9381338744811547
87	0.09576119567320598	0.967733740321989	0.15552856708153268	0.9361054770361338
88	0.09599089898108466	0.968495934474759	0.16236261152955145	0.9391480704833721
89	0.09269763850341968	0.9712906504065041	0.16349939628679902	0.9391480704833721
90	0.09899862601262767	0.9667174801593874	0.15500850241034317	0.9391480706042741
91	0.09404273809698539	0.9705284547999622	0.17269299401472837	0.9361054741344877
92	0.09880739462569477	0.9682418704032898	0.15598086922091353	0.9391480732641162
93	0.09484955535186984	0.96875	0.15584215059362608	0.9401622720470777
94	0.09618801129906158	0.9664634141495557	0.16663256766648613	0.9381338717004106
95	0.08893648177627625	0.9717987809723955	0.15843622508868727	0.9381338744811547
96	0.08668540902738649	0.9735772362569484	0.15784213534777353	0.9391480732641162
97	0.08647126328896701	0.9738313008130082	0.15286975890458476	0.9381338718213126
98	0.0862649189747446	0.9728150406504065	0.16843028958985096	0.9401622692663336
99	0.08609678529626955	0.9707825198406126	0.1585010786901623	0.9381338717004106

The optimal condition:
	epoch: 93
	train_acc: 0.96875
	val_acc: 0.940162272047
	using time: 280.636935949
