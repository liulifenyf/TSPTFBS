The number of train datas: 3792
The number of test datas: 948
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7137455912581979	0.5218881855282602	0.684084045987592	0.5411392403805809
1	0.6883531124782964	0.545094936205868	0.6756213870732594	0.6002109705898833
2	0.6806726415449054	0.5524789032050829	0.6683673295290661	0.6339662462347168
3	0.6719899622699882	0.5799050635426356	0.6594242901238712	0.6824894527342752
4	0.6601776611452868	0.6086497885265431	0.6487658685269738	0.6845991573756254
5	0.6571636257795342	0.6078586492860367	0.637526598157762	0.7056962025316456
6	0.6432448947479956	0.6395042199122755	0.625183412545844	0.7046413497079776
7	0.6364475543991925	0.6547995778075754	0.6108974711301458	0.7267932496996369
8	0.6192199527462826	0.6843354425349819	0.5955890811948333	0.7341772159443626
9	0.6000903605911803	0.6930379741805516	0.5781606028351602	0.7373417711459131
10	0.5879203483525208	0.6988396619442646	0.561497337455991	0.745780589711314
11	0.5706144219209374	0.7130801690278677	0.5468704199992152	0.7521097053958394
12	0.5584527887875521	0.7273206748539889	0.53023395055457	0.7637130816777548
13	0.5448535353825565	0.7281118148489844	0.5148991942405701	0.7710970454075166
14	0.5289983691545478	0.7452531643054656	0.5017825870574275	0.7710970461620057
15	0.5110454297769925	0.7581751049822393	0.486541440969781	0.7763713077653812
16	0.4993155845106906	0.7637130806717691	0.47273134405602885	0.7827004216894319
17	0.47992999531045744	0.7766350213485428	0.45864006612874286	0.7943037964623688
18	0.47383173231334125	0.7816455693687567	0.44714745828874003	0.8027426157822589
19	0.4543864899295292	0.790611814597488	0.43258465178908173	0.8122362866683348
20	0.44140192979498755	0.8016877632100874	0.41899956655904713	0.8164556959510353
21	0.41923116329853044	0.8198839667477186	0.4052476200121867	0.8227848113840642
22	0.41275084534274875	0.8204113919020705	0.39523419272547533	0.828059071226965
23	0.3861719473001826	0.8396624470058875	0.37618689333336264	0.8459915606784418
24	0.3701504350714543	0.8486286924861152	0.36242349100012317	0.8470464129991169
25	0.349349918747753	0.8539029538379943	0.3492780171869173	0.8533755276776567
26	0.34023183081220476	0.861814346494554	0.3393661609933346	0.8597046398412326
27	0.331067781533873	0.8631329111409086	0.32482911929299557	0.8702531655629476
28	0.3085748207468524	0.8773734179730154	0.3122951946052318	0.8744725723306841
29	0.29824680555218885	0.8818565398328918	0.301571161938116	0.8818565385754098
30	0.2763690148099062	0.8924050632911392	0.28522039233129237	0.8892405048201356
31	0.27782730852501303	0.8900316455696202	0.2796425634547125	0.8913502094614858
32	0.2541043560967667	0.8963607589906781	0.26904703921909573	0.8945147664235111
33	0.24745509833223206	0.9026898739207143	0.26058115115397085	0.893459914102836
34	0.23270685712999434	0.9119198317266215	0.24959713119997756	0.9050632921452261
35	0.2199264864126841	0.9187763718110097	0.24345800368594722	0.9050632921452261
36	0.21604619687619592	0.9195675100455304	0.23643618092758242	0.9082278491072514
37	0.2064203539478125	0.9264240511359042	0.23756416456357335	0.9061181444659012
38	0.20221052780936036	0.9256329108894122	0.2287003021954484	0.9124472583899518
39	0.19731067297076374	0.9293248940117752	0.21961420214880367	0.9113924060692767
40	0.18685701740944938	0.9314345986531254	0.22178849294970307	0.9135021107106269
41	0.18457117349789615	0.9316983127392797	0.21440143524845945	0.9145569630313021
42	0.17948704989399086	0.9322257378936317	0.20936163071590133	0.9166666676726523
43	0.17053789466242247	0.9385548528236679	0.2055962672967951	0.9219409292760278
44	0.16731232681354893	0.9419831218598764	0.20695399785343604	0.9219409292760278
45	0.16628547421487574	0.9406645569620253	0.20317556705907427	0.9229957815967028
46	0.16086297856353005	0.9443565403358846	0.19920933938227625	0.9251054862380531
47	0.15449359151632977	0.9451476795763909	0.1942556397321355	0.9314346001621037
48	0.15840910940985137	0.9446202534160534	0.19617515708072275	0.924050633917378
49	0.14878732399849953	0.9475210967949171	0.1872619918001352	0.9345991563696399
50	0.14810972758234806	0.9498945145164361	0.18535221584990055	0.9335443040489647
51	0.1399778248388556	0.950685653505446	0.18798319080585166	0.9314346001621037
52	0.1375278457056118	0.9501582283510941	0.18072505861143523	0.9345991563696399
53	0.13961616435131444	0.9504219411797664	0.18121809691567964	0.9324894524827788
54	0.1347240343501296	0.9522679329924443	0.17837647936515164	0.935654008690315
55	0.13545655248537344	0.9517405058261211	0.17918580996839306	0.933544304803454
56	0.1254250409105156	0.9585970459105093	0.17621495678455015	0.9356540094448041
57	0.12331529106268903	0.9570147674294966	0.1855310074010479	0.9367088617654792
58	0.12534770737343195	0.957805906670003	0.17397909771792497	0.93670886101099
59	0.11862874565496727	0.9580696197501718	0.1745274770486204	0.9398734187275045
60	0.11682999479871259	0.9591244723223433	0.1766507094293707	0.9377637140861543
61	0.11329777805991313	0.9599156123173388	0.17121236365807208	0.935654008690315
62	0.1088822609607429	0.9649261608405455	0.17091393420464882	0.9377637133316652
63	0.11477500319732392	0.9617616036270238	0.16817333231746898	0.9377637133316652
64	0.11393773090487291	0.9614978907983515	0.18011155510753518	0.9377637140861543
65	0.10926806676802756	0.9622890295358649	0.16894696982978266	0.9388185664068295
66	0.10400704813154438	0.9651898729147287	0.1671974766480772	0.9377637133316652
67	0.10609802075579197	0.9636075949367089	0.16752263573528844	0.9388185664068295
68	0.10468662171801434	0.9641350205940536	0.1644034894961345	0.9377637133316652
69	0.10480969605126461	0.9667721521502306	0.1733726296683907	0.9419831233688548
70	0.10222940521023947	0.9672995785620645	0.16772011758657449	0.9430379756895299
71	0.10018545808860019	0.9636075949367089	0.16746323225618917	0.9419831233688548
72	0.09763590771437697	0.9683544303797469	0.1650266067639685	0.9388185656523402
73	0.09784737109886443	0.9686181439629084	0.1724467149892437	0.944092828010205
74	0.09161007438908146	0.9712552747645962	0.16644899965212817	0.9409282702936905
75	0.09434405685980109	0.966772152401727	0.16772643008312596	0.944092828010205
76	0.09126970825819024	0.9699367091122559	0.16466892969633457	0.9409282702936905
77	0.08787344921113066	0.97336497915445	0.16714542230221793	0.944092828010205
78	0.08542326407090521	0.9704641345181043	0.16597371620719442	0.9430379749350407
79	0.08639425495128591	0.9720464135021097	0.1603737281407485	0.9440928272557157
80	0.0843707037940307	0.9704641355240898	0.1658040521202711	0.9419831226143656
81	0.08332604572239807	0.9704641345181043	0.16295937043202074	0.9440928272557157
82	0.08229918916265673	0.9760021099561378	0.15934863296742177	0.9440928272557157
83	0.07650255223241033	0.9738924053147875	0.15993501909297228	0.9451476795763909
84	0.07783994267258464	0.9754746840472965	0.16496595906934658	0.94514768033088
85	0.07885167515101815	0.9738924050632911	0.15886839268579764	0.9451476795763909
86	0.08122704174951159	0.971518987844765	0.16579440814533314	0.944092828010205
87	0.0721921778680906	0.9770569620253164	0.1581043123821669	0.946202531897066
88	0.07390804425322053	0.9765295361164753	0.1804091497815611	0.9419831223628692
89	0.07656736412568937	0.9767932489451476	0.17442779194264976	0.9451476793248945
90	0.0783842465671306	0.97257384016544	0.16853138169407342	0.9430379756895299
91	0.07170764831551017	0.974947257886959	0.16157532756841636	0.94514768033088
92	0.06950660255827984	0.9767932494481405	0.1639953209126549	0.94514768033088
93	0.07133105796474948	0.9770569625283092	0.1606442987415861	0.9472573849722303
94	0.07329293450474236	0.9767932491966441	0.16087435839799888	0.944092828010205
95	0.0723802294534973	0.9741561186464527	0.15756609564340568	0.946202531897066
96	0.07266167780769525	0.9744198317266215	0.15793410386843018	0.9483122372929054
97	0.06280732871610907	0.9783755269231675	0.1597260094644651	0.94514768033088
98	0.06245613946944852	0.9791666671696595	0.15902697782224745	0.946202531897066
99	0.06803467588397018	0.9778481017688155	0.15910781432681947	0.9472573849722303

The optimal condition:
	epoch: 96
	train_acc: 0.9744198317266215
	val_acc: 0.948312237293
	using time: 315.632688046
