The number of train datas: 3792
The number of test datas: 948
epoch	train_loss	train_acc	val_loss	val_acc
0	0.71275036018106	0.5192510551038171	0.683104636799937	0.5337552745759738
1	0.6886160426501986	0.5453586502920224	0.6719654894076319	0.6149789021990973
2	0.6787004777650792	0.562763712577176	0.6646060309832609	0.6487341784726718
3	0.6703692081105357	0.5880801687763713	0.6558720072110494	0.6708860746918851
4	0.6569599531873872	0.6168248940117752	0.645797062272261	0.6814345986531254
5	0.6549138260793083	0.6131329118953979	0.6350652894893276	0.7025316455696202
6	0.6436689035801948	0.6455696207561573	0.6242889880128047	0.7035864966328134
7	0.6327920689361508	0.6492616036270238	0.6109267918369438	0.7299578043981947
8	0.6161662239565628	0.6832805904658031	0.5970011273013891	0.7246835453097831
9	0.5967522937537245	0.70042194092827	0.5794400680920243	0.7436708875849277
10	0.5831391303348139	0.7130801685248749	0.5612046077281614	0.7521097053958394
11	0.5639209691985247	0.7246835445552938	0.5448368083575607	0.7594936716405651
12	0.5460007567948932	0.7394514772962417	0.5266476331380853	0.7732067525638306
13	0.5393049224016535	0.7394514770447453	0.511530009503103	0.7742616023695419
14	0.5197539321983917	0.7544831226143656	0.4973495748475634	0.7816455686142676
15	0.5007548552273698	0.7742616038785202	0.48101753310815193	0.7921940918210186
16	0.48082708130405927	0.7816455693687567	0.46557354210298274	0.795358648783044
17	0.4601620409307601	0.792721518484349	0.44948420884237006	0.8132911382345208
18	0.4585492271411268	0.7943037977198508	0.4373589220932264	0.8101265827814738
19	0.43720970060754927	0.8090717299578059	0.42327172670686297	0.8238396614412719
20	0.41750421403329585	0.8167194092827004	0.4069334023360965	0.8291139255596113
21	0.3968311085479672	0.8367616036270238	0.39299909902524344	0.8386075961941908
22	0.3897098224877305	0.8320147684354823	0.38005734307353506	0.8459915624389166
23	0.3593650972038382	0.8562763713080169	0.3612873780576489	0.8523206740994996
24	0.34282574837217855	0.8562763718110097	0.34685146594852334	0.8628691970547543
25	0.32075041482217204	0.8707805907172996	0.3349709646611274	0.8702531640539692
26	0.3151748752543695	0.8755274259088411	0.3302981986149454	0.874472574845648
27	0.30250285106872205	0.8831751052337357	0.3084229118964843	0.8786919833738592
28	0.28208438517675116	0.8929324899544696	0.2973358462631451	0.885021098052399
29	0.2716588540167748	0.8989978900438622	0.2893019066455495	0.8871308026937493
30	0.25318239648130875	0.9053270039679129	0.2751999482952593	0.8976793251460111
31	0.2552648946202757	0.9045358654818957	0.266319819895024	0.8987341767121971
32	0.23506294813337206	0.9164029535864979	0.2578733608692507	0.9008438821080365
33	0.22355523051591866	0.9119198317266215	0.2500719360787154	0.9040084390700618
34	0.21623482382247217	0.9195675105485233	0.24183749310074978	0.9092826999189482
35	0.20138458065091305	0.9282700416911001	0.23547666592185507	0.9145569615223237
36	0.19945362813865083	0.926951476793249	0.22883181864953744	0.9156118138429987
37	0.19586781157722957	0.9322257388996172	0.22700891527445508	0.9145569622768128
38	0.19010620523354171	0.9301160337552743	0.2222799350063509	0.916666666918163
39	0.17999825573168726	0.941455696454028	0.21494212859793554	0.9187763708050241
40	0.17577744121289957	0.93829113898901	0.21426122173478332	0.9208860762008635
41	0.17135009955504776	0.9419831226143656	0.20740900254702266	0.9251054847290747
42	0.16422366596098187	0.9427742621063683	0.20520670674269711	0.9272151901249142
43	0.1637921607444055	0.9406645572135217	0.20340191362276358	0.9251054854835639
44	0.16168616995026794	0.9438291134210578	0.20042207598183226	0.926160337804239
45	0.15982373159394486	0.9462025311425768	0.19557660151634537	0.9303797463324502
46	0.15083739790232373	0.948575949618585	0.1935377787437117	0.9314345986531254
47	0.14832264958303185	0.9488396624472574	0.19427292224978596	0.9272151901249142
48	0.151377927527649	0.95121307991728	0.1912356304468485	0.9282700416911001
49	0.14298235062305434	0.9501582278481012	0.18775097114124378	0.9324894509738004
50	0.1399959244682819	0.9575421943443234	0.18662216530067507	0.9356540079358258
51	0.13487523228307313	0.9546413497079776	0.1858964608314168	0.9282700416911001
52	0.12910465701219906	0.954377636627809	0.18379729778706272	0.9324894509738004
53	0.13280658713121454	0.9567510548523207	0.1821275110108943	0.9324894509738004
54	0.128512091337377	0.9572784812641546	0.18203727001882303	0.9388185648978511
55	0.12833305080480215	0.9599156113113532	0.1821346611790516	0.9324894524827788
56	0.12373312697883397	0.9585970464135021	0.17954458748992486	0.9409282695392013
57	0.11964580052009614	0.9612341777181826	0.18535121866670842	0.9282700432000784
58	0.11819095340584904	0.9609704646380138	0.17692652910570555	0.937763712577176
59	0.11432705300895474	0.9604430384776763	0.17675350160035402	0.935654008690315
60	0.11185738963039615	0.9636075954397016	0.17555045943219955	0.9356540079358258
61	0.11170764081966023	0.9638713085198705	0.17532410632960405	0.93670886101099
62	0.10790105066596205	0.9651898736692179	0.17388334090699625	0.93670886101099
63	0.11163529939163586	0.9659810129097243	0.17308291170416	0.937763712577176
64	0.11054531786637971	0.9662447262413895	0.17883690776704234	0.9314345994076145
65	0.10866989097891981	0.9672995780590717	0.1719027001269256	0.9398734179730154
66	0.10067848201039471	0.9696729955290944	0.17237757353843014	0.93670886101099
67	0.10437343065245745	0.968354429876754	0.171935616917751	0.93670886101099
68	0.10020194941432164	0.9672995783105681	0.17399486402670541	0.9430379741805516
69	0.10416477216006834	0.9657172998295555	0.17202410422548464	0.9377637133316652
70	0.09702323729227363	0.9670358644759102	0.16968492000414853	0.9409282702936905
71	0.10158468598995028	0.9646624472573839	0.17089479809571922	0.93670886101099
72	0.10028006293602633	0.9678270037164165	0.16986366905240569	0.9377637133316652
73	0.092867695643932	0.9694092832034147	0.1722109408946983	0.9377637133316652
74	0.090422320906623	0.9704641355240898	0.1687169636477901	0.9419831226143656
75	0.09104485419983602	0.9696729955290944	0.16893349550192868	0.9388185656523402
76	0.08630401087838387	0.9720464140051025	0.1691514019724689	0.9419831226143656
77	0.08488305746125772	0.9717827009249337	0.17163085497381314	0.9377637133316652
78	0.08627768304151824	0.9717827009249337	0.1712032247821993	0.9388185656523402
79	0.08658841071563934	0.9707278483527623	0.1690690163444366	0.9419831226143656
80	0.08468818054672032	0.971518987844765	0.16969675259499611	0.9398734179730154
81	0.08410106624480541	0.9720464140051025	0.16848469446983017	0.9430379749350407
82	0.0823311454573261	0.970200422443921	0.17021118821222572	0.9440928265012266
83	0.07735063644904125	0.9752109709671278	0.16857814310975217	0.9419831226143656
84	0.08151756701715888	0.9744198317266215	0.16914241198245986	0.9409282702936905
85	0.07535928670112593	0.9754746835443038	0.16968298574540183	0.9451476795763909
86	0.07934610998328728	0.9767932486936513	0.17148806745744455	0.9398734179730154
87	0.0719140860554664	0.9767932489451476	0.16883615489247478	0.9430379749350407
88	0.07577809103556322	0.9760021092016485	0.1723736269941813	0.9409282702936905
89	0.07535098920643078	0.9754746835443038	0.1694279324404801	0.9377637133316652
90	0.07803433416764947	0.9720464140051025	0.17071434629114368	0.9388185656523402
91	0.07088428254746183	0.9760021094531449	0.16874738245070736	0.9398734179730154
92	0.06564293377384355	0.9799578054041802	0.1707093935098326	0.9388185656523402
93	0.07282907251693026	0.9746835448067902	0.16921232942538925	0.9440928272557157
94	0.0702489132163771	0.9794303799983318	0.16976537036744854	0.9377637133316652
95	0.07157377930130134	0.9752109707156315	0.16813674185597946	0.9419831226143656
96	0.07207536370442387	0.979694093329997	0.1686382618131517	0.9440928272557157
97	0.06501224907390175	0.9786392400033364	0.16964463273432687	0.946202531897066
98	0.0614205711375812	0.9820675108000196	0.17127145757655052	0.9451476795763909
99	0.06645649350896667	0.9752109699611422	0.16964360417695992	0.946202531897066

The optimal condition:
	epoch: 99
	train_acc: 0.9752109699611422
	val_acc: 0.946202531897
	using time: 336.707860947
