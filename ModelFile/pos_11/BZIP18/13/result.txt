The number of train datas: 3792
The number of test datas: 948
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7106812835242677	0.5139767929974488	0.6836275591628964	0.5443037974683544
1	0.6921604778696213	0.5345464129991169	0.6772647155488091	0.5896624473831321
2	0.6855298577481684	0.5435126584793445	0.6719574958463258	0.6191983127392797
3	0.6771898214324115	0.5727848096235895	0.6663087689423863	0.6487341774666863
4	0.6670097298762969	0.5949367088607594	0.6594027469429788	0.6540084400760473
5	0.6684589411135967	0.5814873417721519	0.6509908613776356	0.6856540069298402
6	0.6598897827828484	0.6120780585687372	0.6421032605794915	0.6972573842177411
7	0.6540934508862878	0.616297468102934	0.6315000434465046	0.7194092819459328
8	0.6383631161496609	0.6521624475088803	0.6190099011996627	0.7331223621147092
9	0.6254682611312544	0.6621835440523011	0.6023009323872595	0.75
10	0.6117490773965538	0.676951476793249	0.5848474537772972	0.7573839677537041
11	0.5942570831202254	0.6948839667477186	0.5690481094368399	0.7658227848101266
12	0.5792488151461767	0.7114978897923658	0.5507512588038224	0.7700421956018053
13	0.5647435444819776	0.7220464137536061	0.5331588186292205	0.7763713070108921
14	0.5458626060546199	0.7360232064995584	0.5168136658799296	0.7753164561991953
15	0.5291189853149124	0.7418248950177607	0.49696532734335724	0.7890295356134825
16	0.511684981579519	0.7629219414312628	0.4794871349374956	0.7911392410093219
17	0.4878483361835721	0.7758438818565401	0.46092387115905054	0.8090717289518203
18	0.4826713735041236	0.7790084393215582	0.4445230311985257	0.8069620250649593
19	0.458399578614577	0.7890295361164753	0.4282990831111554	0.8217299567999216
20	0.44171343247095746	0.8132911397434991	0.4100069564606067	0.8312236284404867
21	0.41654810648930224	0.8212025313940732	0.3928078029477647	0.8364978907983515
22	0.4069609542687734	0.8241033755274262	0.37685368647052264	0.8449367093637523
23	0.3753994585089543	0.8467827004219409	0.358484308930892	0.8533755286836423
24	0.3634993799879581	0.84757384016544	0.3425180305911519	0.8618143472490432
25	0.3385678435428233	0.8665611811831028	0.32663686164823763	0.8681434586581298
26	0.3277893397124005	0.8689345994076145	0.31491549193607604	0.8755274264118339
27	0.30929662670767255	0.8755274264118339	0.3018255949271882	0.8797468356945344
28	0.29264982704874837	0.8821202529130606	0.28937088871052496	0.8902953596557746
29	0.2803086503900053	0.892141349959474	0.27790251499992885	0.8997890305418506
30	0.25728265293539826	0.90242615983456	0.26763008440597147	0.9050632921452261
31	0.2595450304731538	0.903744725989893	0.25981100878132046	0.9082278465922875
32	0.24048946923595943	0.9058544308827396	0.25151876445058025	0.9113924035543128
33	0.23025127817809835	0.9132383961214798	0.24435955128840756	0.9103375537486016
34	0.21623243108580384	0.9219409277670494	0.2356529758323597	0.9145569630313021
35	0.2090628153412654	0.9200949372118535	0.2291791425852836	0.9198312246346776
36	0.19831069562002576	0.9272151898734177	0.2243485684007532	0.9187763723140024
37	0.19635029093122683	0.9306434604186046	0.22374399103821582	0.9156118128370132
38	0.19045692575380269	0.928797468102934	0.2182937344921289	0.9229957790817389
39	0.1858976475171399	0.9340717294548131	0.2123349380644062	0.9272151908794033
40	0.1831858495116737	0.9345991561181435	0.21586653791399446	0.9219409267610639
41	0.1800022234645071	0.935126582278481	0.20648380089158247	0.9282700406851144
42	0.17331099280702414	0.9361814340961634	0.20333641827232224	0.9293248930057896
43	0.16209834009283203	0.9419831226143656	0.20035546939458526	0.9314345976471398
44	0.16150855521361032	0.944883965741733	0.20081806644985947	0.9293248930057896
45	0.1559148449057768	0.9485759491155922	0.1958305995738456	0.9303797453264647
46	0.15281158937180594	0.9483122362869199	0.19358059414957143	0.9335443022884901
47	0.1483202845738407	0.9472573842177411	0.19282700240863526	0.9324894499678149
48	0.15129658190006948	0.9472573837147483	0.19254394787273327	0.9324894499678149
49	0.14481588952903507	0.9493670886075949	0.18914201711049058	0.9335443022884901
50	0.14253581463033138	0.9535864981417917	0.18659039982889272	0.9345991546091651
51	0.13726008579700807	0.954641349959474	0.18570930293843715	0.9335443022884901
52	0.13928804857821403	0.9501582283510941	0.18365409017740925	0.9345991546091651
53	0.13794276464086042	0.9509493665856148	0.1828073622179434	0.9377637115711904
54	0.13109157577094147	0.9538502109704642	0.18183402390168185	0.9377637115711904
55	0.13230538814631193	0.9546413502109705	0.18004013296169571	0.9377637115711904
56	0.12244521949110151	0.9607067505518595	0.17912910447970723	0.9377637115711904
57	0.12207483119853942	0.9580696207561573	0.1801698910158898	0.9377637123256796
58	0.121956582625204	0.958333333081837	0.17722014391221075	0.9367088592505153
59	0.11795520622141753	0.9588607597451673	0.17783346127734406	0.9388185646463547
60	0.11168791589480412	0.9636075944337161	0.17620492352463524	0.9398734169670299
61	0.11083944512821954	0.9622890300388578	0.17463032700089964	0.9388185638918656
62	0.10920339168878547	0.9651898734177216	0.17407394782148836	0.9398734169670299
63	0.1137349421339196	0.9580696207561573	0.1742916323464631	0.9377637115711904
64	0.10990724454826444	0.9665084390700618	0.17464179319294193	0.9451476793248945
65	0.10947563378179627	0.9649261605890491	0.1718833074916767	0.9388185646463547
66	0.10718712418139735	0.9622890290328722	0.17226020061265568	0.9430379739290551
67	0.10767246927390119	0.9638713085198705	0.1706236865890177	0.9409282692877049
68	0.10109199853889046	0.9667721518987342	0.1720518076218633	0.9388185638918656
69	0.10448749093063774	0.964398734680208	0.17165771863945928	0.9451476793248945
70	0.10229623094515458	0.9680907175510745	0.16941942809000296	0.9409282692877049
71	0.0988510309518138	0.9662447257383966	0.16922757362766105	0.9430379739290551
72	0.09858849078794069	0.9665084390700618	0.16840090715809714	0.94198312160838
73	0.09558701376874738	0.9686181434599156	0.16869651873592084	0.9430379739290551
74	0.09361183171785331	0.9715189875932685	0.16786167387092163	0.9462025308910804
75	0.09594069443297286	0.9686181432084192	0.1669951667891273	0.9462025308910804
76	0.09096713907985245	0.9704641355240898	0.16668706434436992	0.9462025308910804
77	0.09046961760093392	0.9725738399139436	0.16712774098988323	0.9451476785704054
78	0.09175336901648638	0.9675632911392406	0.16738559091895944	0.9462025316455697
79	0.0860452922493345	0.9707278481012658	0.1669021784190387	0.94198312160838
80	0.09138835017188189	0.9686181429569228	0.16589188170206698	0.9451476785704054
81	0.08709567112510215	0.971255274010107	0.1652753528852	0.9440928262497302
82	0.08625875831530568	0.9699367083577667	0.16838715244320374	0.94198312160838
83	0.08244187645771332	0.9712552747645962	0.1662096656261617	0.9409282692877049
84	0.08110546657053228	0.9738924053147875	0.16653505840067623	0.9483122362869199
85	0.079734181144318	0.9728375529941125	0.16974333051262022	0.94198312160838
86	0.0817467437011783	0.9712552745130998	0.16688389939409268	0.9493670886075949
87	0.07880788918914675	0.971518987844765	0.1670939738740398	0.9430379739290551
88	0.07990910606419487	0.9746835438008047	0.16855181621599802	0.9472573839662447
89	0.07799748546652151	0.9757383966244726	0.16614247064738838	0.9472573839662447
90	0.07469016335558791	0.9760021099561378	0.16486900721043976	0.9483122362869199
91	0.07467258004825326	0.9754746840472965	0.16598298732301353	0.9493670886075949
92	0.0716798417584554	0.9778481012658228	0.16546196481095085	0.9472573839662447
93	0.07416625056840197	0.975474683041311	0.16581706792304787	0.9472573839662447
94	0.07580105334771836	0.9738924053147875	0.1656435481763842	0.9462025316455697
95	0.07302343933391169	0.9738924053147875	0.16546612990556386	0.94198312160838
96	0.07016740472130635	0.9762658222818174	0.16451743320573733	0.9430379739290551
97	0.06817691035977395	0.9781118148489844	0.16547499663090404	0.9430379739290551
98	0.06599715198016871	0.9775843886886468	0.1670652571986999	0.9430379739290551
99	0.07131369298771967	0.9770569625283092	0.16872719200603067	0.9430379739290551

The optimal condition:
	epoch: 91
	train_acc: 0.9754746840472965
	val_acc: 0.949367088608
	using time: 288.751611948
