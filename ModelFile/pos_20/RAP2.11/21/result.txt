The number of train datas: 2400
The number of test datas: 602
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6943849317232768	0.553333334128062	0.6544187322407465	0.664451830014834
1	0.6743634883562724	0.5791666674613952	0.6290779991007327	0.7242524895161093
2	0.6430223441123962	0.6420833325386047	0.59438613482884	0.813953485797806
3	0.5979513049125671	0.7141666674613952	0.542668823981998	0.8737541538140307
4	0.539294480085373	0.7912499992052714	0.46827712348133227	0.9202657815229853
5	0.45811681230862933	0.8491666674613952	0.3767887797466544	0.9352159428834123
6	0.369785730044047	0.8941666674613953	0.2872871877347116	0.9451827202920502
7	0.2882151790459951	0.9166666666666666	0.22467239884245038	0.9451827200940282
8	0.23846625407536826	0.9283333325386047	0.1866537228078145	0.9451827244505138
9	0.20732194900512696	0.9362500007947286	0.16216247610475534	0.9518272427229391
10	0.17053705434004465	0.9508333333333333	0.15339642300261216	0.9501661131548327
11	0.16124627967675528	0.946666665871938	0.14504224079292874	0.950166108600325
12	0.15025281180938085	0.9500000007947286	0.14548153479728984	0.9534883677365376
13	0.13778586119413375	0.956666665871938	0.13375480418585464	0.9568106268727502
14	0.1348484565814336	0.9583333341280619	0.13654976929739068	0.9534883677365376
15	0.13352660755316417	0.95625	0.13267148961854536	0.9601328860089628
16	0.13002171834309895	0.957916665871938	0.13206451217894538	0.9601328860089628
17	0.1269730071226756	0.9604166658719381	0.1275342761158349	0.9601328860089628
18	0.11785205036401748	0.959583334128062	0.132383196852928	0.9568106268727502
19	0.11322740286588669	0.9616666666666667	0.13330762719494163	0.9551494973046439
20	0.11231756846110026	0.9620833333333333	0.13202225082736474	0.9568106268727502
21	0.10280256470044453	0.9687500007947286	0.1377313126905812	0.9518272381684313
22	0.10877323110898336	0.9583333325386048	0.12556625905128016	0.9601328860089628
23	0.09869981626669566	0.967916665871938	0.11914434473330396	0.9601328860089628
24	0.10457063982884089	0.9641666674613952	0.1279713030892155	0.9584717564408566
25	0.10006793916225433	0.967916665871938	0.1265887272763886	0.9584717564408566
26	0.0945033253232638	0.9708333341280619	0.1250319764191328	0.9584717564408566
27	0.09858600536982219	0.96875	0.12472242858273247	0.9601328860089628
28	0.09692752649386724	0.9662499992052714	0.12465724940612863	0.9601328860089628
29	0.09218814452489217	0.9695833325386047	0.12195989621982622	0.9601328860089628
30	0.09105112100640933	0.9683333325386048	0.12512135286614348	0.9601328860089628
31	0.0933195647597313	0.9674999992052714	0.12196601422324133	0.9601328860089628
32	0.09605269978443781	0.9687499992052714	0.12243708808507238	0.9601328860089628
33	0.08438338612516721	0.9725	0.117713134909092	0.9601328860089628
34	0.08503447482983272	0.9695833333333334	0.11804260110538267	0.9601328860089628
35	0.08596802100539208	0.97375	0.11468795710475342	0.9634551451451755
36	0.08335825577378272	0.9741666658719381	0.11991508834781837	0.9601328860089628
37	0.08889105012019476	0.9725	0.11643160081335477	0.9617940155770691
38	0.08289398193359375	0.9720833333333333	0.11413988619547746	0.9634551451451755
39	0.0786245905359586	0.972916665871938	0.1134533236341619	0.9651162747132818
40	0.08451724668343862	0.9733333325386048	0.11434558405234568	0.9634551451451755
41	0.08231279755632083	0.9733333325386048	0.11665968626638584	0.9617940155770691
42	0.07601807713508606	0.9766666666666667	0.1166910687678082	0.9617940155770691
43	0.07479836786786716	0.9766666674613953	0.12001107417764854	0.9617940155770691
44	0.07645010620355606	0.9758333333333333	0.11807783555697365	0.9617940155770691
45	0.07543258190155029	0.9754166666666667	0.11498547260002837	0.9634551451451755
46	0.07626581435402234	0.9750000007947286	0.11122986445345752	0.9634551451451755
47	0.07460625231266022	0.9724999992052714	0.11316490464184767	0.9634551451451755
48	0.07233848641316096	0.9770833341280619	0.10738697794089681	0.9684385338494944
49	0.07482194935282072	0.9733333325386048	0.11632308329260627	0.9634551451451755
50	0.06532516876856485	0.9779166674613953	0.10686693716781875	0.9684385338494944
51	0.07294501915574074	0.975833334128062	0.10795250621645949	0.9684385338494944
52	0.06816928346951802	0.9758333333333333	0.10386662701287143	0.9684385338494944
53	0.07761449277400971	0.9741666666666666	0.11272159125965299	0.9634551451451755
54	0.06943144649267197	0.9745833333333334	0.10446093068071378	0.9684385338494944
55	0.07153615474700928	0.9783333325386048	0.1068320485865357	0.9684385338494944
56	0.068549811343352	0.9754166674613952	0.10389901882043709	0.9684385338494944
57	0.06731353839238485	0.9800000007947286	0.10548640501707099	0.9684385338494944
58	0.07067249377568563	0.9783333325386048	0.10620440842206295	0.9667774042813881
59	0.07233394712209701	0.9758333333333333	0.10069604472959556	0.9684385338494944
60	0.06549347261587779	0.980833334128062	0.10837617203395232	0.9651162747132818
61	0.06456594206392766	0.9783333333333334	0.10343895955289717	0.9684385338494944
62	0.05777716154853503	0.9820833325386047	0.101913699119095	0.9684385338494944
63	0.06461824297904968	0.9804166666666667	0.1050296155890555	0.9667774042813881
64	0.0625082378089428	0.9783333325386048	0.10149468788474897	0.9684385338494944
65	0.06490462119380633	0.9808333333333333	0.10658575719426637	0.9667774042813881
66	0.059740423386295635	0.9783333333333334	0.10072568230999268	0.9684385338494944
67	0.06279443884889285	0.97875	0.10719485156411349	0.9667774042813881
68	0.05370768795410792	0.9837499992052714	0.10462416194849632	0.9667774042813881
69	0.05841646502415339	0.9820833333333333	0.10317514653617757	0.9667774042813881
70	0.06214412907759349	0.9795833333333334	0.10282858912879446	0.9667774042813881
71	0.05673291211326917	0.9808333325386047	0.10316485428928933	0.9667774042813881
72	0.06213793081541856	0.9775	0.10432739397418063	0.9667774042813881
73	0.05447856013973554	0.9833333325386048	0.10012293682492453	0.9684385338494944
74	0.05291015615065892	0.9833333325386048	0.10255842733868333	0.9667774042813881
75	0.05291941108802954	0.9820833333333333	0.10108578014512394	0.9684385338494944
76	0.05147610187530518	0.9866666674613953	0.10131297076114784	0.9684385338494944
77	0.05779013713200887	0.9816666658719381	0.09948161985737541	0.9684385338494944
78	0.05696289007862409	0.9812500007947286	0.0970886492872753	0.9684385338494944
79	0.04885921329259872	0.9820833341280619	0.09736206391176512	0.9684385338494944
80	0.052558136234680815	0.9841666674613953	0.10167756640782388	0.9667774042813881
81	0.049055569370587665	0.9845833333333334	0.10402205718860674	0.9684385338494944
82	0.04980489671230316	0.9833333333333333	0.09988648133767007	0.9684385338494944
83	0.04715587948759397	0.9829166666666667	0.09610078275896781	0.9684385338494944
84	0.04824177116155624	0.9854166658719381	0.09693813347489731	0.9684385338494944
85	0.05009406571586927	0.9833333325386048	0.10255618441689054	0.9684385338494944
86	0.055472111999988555	0.9787499992052714	0.09653163732236802	0.9684385338494944
87	0.04684881180524826	0.982916665871938	0.09600070819407207	0.9684385338494944
88	0.04922267317771912	0.984583334128062	0.09697772282797633	0.9684385338494944
89	0.04898561718563239	0.985	0.09709162732889486	0.9684385338494944
90	0.05194837977488836	0.984583334128062	0.09594019800672103	0.9684385338494944
91	0.049226884146531424	0.9816666674613953	0.09753566653625513	0.9684385338494944
92	0.045011081447203956	0.9841666674613953	0.09669494172217838	0.9684385338494944
93	0.04330652333796024	0.9866666666666667	0.09635770422378648	0.9684385338494944
94	0.04794996604323387	0.9854166674613952	0.09582213323526208	0.9684385338494944
95	0.04261663094162941	0.9833333333333333	0.09645054374273829	0.9684385338494944
96	0.0422660165031751	0.9866666658719381	0.09903355314090007	0.9700996634176007
97	0.03999321843187014	0.9870833325386047	0.09566474416327239	0.9684385338494944
98	0.04222638875246048	0.9845833325386047	0.09639673276597083	0.9684385338494944
99	0.04003223034242789	0.9904166666666666	0.09505272162861603	0.9684385338494944

The optimal condition:
	epoch: 96
	train_acc: 0.9866666658719381
	val_acc: 0.970099663418
	using time: 228.793212891
