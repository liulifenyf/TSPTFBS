The number of train datas: 5886
The number of test datas: 1472
epoch	train_loss	train_acc	val_loss	val_acc
0	0.700542325010277	0.5033978932858971	0.6809891928797183	0.5842391304347826
1	0.6728086774947892	0.5844376483742898	0.6502540733503259	0.7262228260869565
2	0.6279513666996775	0.674651716280421	0.5784291158551755	0.8165760869565217
3	0.5344196609137538	0.7750594633556409	0.46160701305969903	0.8525815217391305
4	0.4131947391765522	0.8494733266995709	0.3491396191327468	0.876358695652174
5	0.3300825656979334	0.8766564724399166	0.29771427874979767	0.8838315217391305
6	0.2805621108756031	0.8999320422959012	0.27434813457986584	0.8879076086956522
7	0.2580893624154962	0.9074074068605757	0.2660414579769839	0.8885869565217391
8	0.2408709637858695	0.9111450894770879	0.2503105343683906	0.8967391304347826
9	0.22621682120694053	0.9186204547911244	0.24104881804922354	0.9008152173913043
10	0.21819961188481934	0.921168874730231	0.23995099054730457	0.9028532608695652
11	0.20542555355292536	0.9252463467583704	0.23245849460363388	0.9096467391304348
12	0.1971187720767017	0.9298335027014201	0.2251280215771302	0.9103260869565217
13	0.1879218418582783	0.9323819226607797	0.21420481444700903	0.9157608695652174
14	0.18240231813276214	0.935270132558345	0.2057212114981983	0.9177989130434783
15	0.1710362670486815	0.9379884466159275	0.2030522632210151	0.9211956521739131
16	0.16761100247142835	0.9407067612405946	0.1980386654967847	0.923233695652174
17	0.1665315691646248	0.9452939178317411	0.18989350970672525	0.9273097826086957
18	0.15975310113451896	0.9493713891510246	0.18637985055861267	0.9293478260869565
19	0.15562297607861608	0.9485219159054991	0.18042266822379568	0.936141304347826
20	0.14774766531964365	0.9500509678122546	0.17819886298283286	0.9368206521739131
21	0.1482086811686834	0.9519198097787339	0.1776236869070841	0.9375
22	0.14307408987706186	0.955317703064631	0.17046262259068695	0.938858695652174
23	0.13554947249366037	0.9551478077512269	0.16876921705577685	0.9408967391304348
24	0.13648567412768825	0.9570166496974531	0.16374076319777447	0.9456521739130435
25	0.13197193939062837	0.9592252803869569	0.16215990046444145	0.9449728260869565
26	0.12690487007300058	0.9602446483990549	0.16308825770797936	0.9429347826086957
27	0.1287655084211325	0.9576962277308395	0.15929766582406085	0.9470108695652174
28	0.12421987999409104	0.9612640157022972	0.15553233966879224	0.9497282608695652
29	0.12008118190724469	0.9634726463715478	0.15968481386485306	0.9483695652173914
30	0.11364332475894737	0.961264016370647	0.15455249065290327	0.9504076086956522
31	0.11922835895359374	0.963982330975061	0.15296302087928937	0.9510869565217391
32	0.11568888629977492	0.9631328570206799	0.1531732629822648	0.9510869565217391
33	0.11272443056288844	0.9668705403055418	0.1484230100784613	0.951766304347826
34	0.10978534689342088	0.9667006456199811	0.14999147488371187	0.9524456521739131
35	0.10572882524982342	0.9687393816036713	0.14912989071529845	0.9524456521739131
36	0.10668246539431772	0.96653075032683	0.1477827345547469	0.953125
37	0.1007587855015326	0.9690791703266957	0.14544490255091502	0.951766304347826
38	0.10095637796476428	0.9695888543023652	0.14534160608182783	0.954483695652174
39	0.1050911731119266	0.9692490656400998	0.14356726375610931	0.953125
40	0.0985430590213459	0.9714576962688445	0.14418144345931386	0.9558423913043478
41	0.09930535178787239	0.9723071689675383	0.1421730665732985	0.954483695652174
42	0.0959916804523805	0.9741760109340176	0.142782728633155	0.954483695652174
43	0.09844724211058282	0.9706082222739572	0.14585843714682953	0.954483695652174
44	0.09791978500021424	0.9728168535710515	0.13994167907082516	0.954483695652174
45	0.09403856801938087	0.9728168535913045	0.14014184879867927	0.954483695652174
46	0.0961826018915669	0.9717974849513628	0.13913871396494948	0.954483695652174
47	0.0910587932761332	0.9753652735911702	0.1433067682158688	0.9558423913043478
48	0.08869793995166773	0.9762147468772017	0.14085915652306183	0.9572010869565217
49	0.08719782405439543	0.9774040089065106	0.13865711928709692	0.954483695652174
50	0.08602038288132657	0.9765545356002261	0.13864510619769926	0.954483695652174
51	0.08877884416081165	0.974855588947151	0.1376779304574365	0.9565217391304348
52	0.086630059823247	0.9745158002038736	0.13743419694187847	0.9565217391304348
53	0.08318833174577	0.9765545361875637	0.13915544829290846	0.9585597826086957
54	0.08210895667210186	0.9765545362078167	0.13735488462059395	0.9565217391304348
55	0.08314589482412182	0.9762147468974547	0.1378425246347552	0.9572010869565217
56	0.08368979504561691	0.9768943255384318	0.1364719454684983	0.9578804347826086
57	0.0845865466199357	0.9763846415627623	0.13802457374075186	0.9578804347826086
58	0.0834022535190285	0.9782534828406388	0.13781342744503333	0.9578804347826086
59	0.0867625215741756	0.9760448516043035	0.13456783840513747	0.9585597826086957
60	0.08231622436233536	0.9777437982168726	0.13345550518968832	0.9572010869565217
61	0.08018599534131944	0.9791029562076824	0.1350267271956672	0.9578804347826086
62	0.0832688707505162	0.9767244302250275	0.13315926832349403	0.9578804347826086
63	0.07947967153623564	0.9780835875879936	0.13381603732705116	0.9585597826086957
64	0.07906938403986605	0.9780835875474876	0.1329474983655888	0.9585597826086957
65	0.0756022116404142	0.9784233775464524	0.13338378096080344	0.9592391304347826
66	0.07857565650911992	0.9789330608942781	0.13206266125907068	0.9585597826086957
67	0.0767994737932968	0.9799524295342199	0.13178456590875334	0.9578804347826086
68	0.0731826960835435	0.9814814815017345	0.13135248220161252	0.9592391304347826
69	0.07165195981013382	0.9809717968982213	0.13379834738114607	0.9592391304347826
70	0.07570148751296601	0.980292218844582	0.13094305052705432	0.9592391304347826
71	0.07276295308014831	0.9811416921711195	0.13210748751526294	0.9592391304347826
72	0.07383767557699097	0.98131158685668	0.13116352252014304	0.9592391304347826
73	0.07210917759723418	0.9808019028607575	0.12954663015578105	0.9599184782608695
74	0.07239627811046348	0.9818212701842528	0.13011616436035736	0.9585597826086957
75	0.06965418805653369	0.9813115861883303	0.12990562990307808	0.9599184782608695
76	0.06827056945519629	0.9825008488454828	0.13121561527900075	0.9585597826086957
77	0.06920926165528092	0.9823309542004284	0.13030785484158475	0.9599184782608695
78	0.0724615004702243	0.9792728508527369	0.12811829651827397	0.9599184782608695
79	0.06922900049389928	0.9821610601629646	0.12947442803693854	0.9599184782608695
80	0.07053737356787913	0.9811416915230228	0.12896354804220406	0.9605978260869565
81	0.0654733392150172	0.9828406388241946	0.1292894863240097	0.9599184782608695
82	0.06990594045213806	0.9825008488454828	0.12860281919331654	0.9605978260869565
83	0.06814022605015313	0.9816513755391983	0.12811736641046795	0.9605978260869565
84	0.06561201635648149	0.983520216857581	0.12757104181725046	0.9605978260869565
85	0.06431438179697425	0.9828406388241946	0.12723474220737166	0.9599184782608695
86	0.06540086399099271	0.9831804275269659	0.12786650762933752	0.9612771739130435
87	0.0623503013308604	0.9838600061881959	0.1274831188113793	0.9599184782608695
88	0.06325281805583825	0.9835202174854246	0.12690839025637377	0.9599184782608695
89	0.06266314332283884	0.9831804275269659	0.12661007726969925	0.9599184782608695
90	0.06415517471105397	0.9833503227998641	0.12598593597826752	0.9605978260869565
91	0.06137865184826224	0.9830105328616584	0.1270388445776442	0.9599184782608695
92	0.06219425503287314	0.9831804275269659	0.12866148360721444	0.9599184782608695
93	0.0644174969058599	0.9826707435715494	0.12635244445308394	0.9626358695652174
94	0.05860800018348623	0.9836901115228884	0.1258933909399354	0.9626358695652174
95	0.0618182941942121	0.9841997961466546	0.1255298469863508	0.9619565217391305
96	0.06161942689689373	0.9826707435310433	0.12506274895175643	0.9633152173913043
97	0.05979411456274451	0.9847094801425772	0.1258586045840512	0.9605978260869565
98	0.054811389445296524	0.9858987427794768	0.1263800209145183	0.9619565217391305
99	0.05977898155507732	0.984199795498558	0.12496227187954861	0.9619565217391305

The optimal condition:
	epoch: 96
	train_acc: 0.9826707435310433
	val_acc: 0.963315217391
	using time: 446.184653997
