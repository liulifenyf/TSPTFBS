The number of train datas: 5886
The number of test datas: 1472
epoch	train_loss	train_acc	val_loss	val_acc
0	0.6983463990214404	0.5139313624539507	0.6822700552318407	0.5570652173913043
1	0.672079973568367	0.5857968057575089	0.6490898261899534	0.7058423913043478
2	0.6218541051674732	0.6816173968896792	0.5757170267727064	0.8023097826086957
3	0.5253156629136903	0.781005776033813	0.45772266387939453	0.8457880434782609
4	0.4047253371054649	0.8518518520746351	0.34826277779496234	0.8709239130434783
5	0.3248131678515942	0.8809038397207011	0.3000038512375044	0.8797554347826086
6	0.28036265462545806	0.8941556236754459	0.28028926253318787	0.8865489130434783
7	0.2595649516951094	0.9063880394965744	0.27321520091398904	0.8885869565217391
8	0.24611769893057606	0.9106354055014185	0.2593374368937119	0.8940217391304348
9	0.2329949080701025	0.9143730881786898	0.25006731826326123	0.8987771739130435
10	0.22753489133435126	0.9159021401462043	0.25294802532247873	0.9001358695652174
11	0.2115421752175465	0.9203194014239465	0.2431195621257243	0.9028532608695652
12	0.20478478514577028	0.9262657147097093	0.2360770718558975	0.90625
13	0.19851810913729173	0.9252463467381173	0.22511530764724896	0.907608695652174
14	0.19169440790074155	0.9294937139378897	0.21599714587564053	0.9184782608695652
15	0.1825149077472742	0.9361196052975449	0.21291116009587827	0.9157608695652174
16	0.17715766906454739	0.9420659185833077	0.2070221816715987	0.9191576086956522
17	0.17406803070790014	0.9388379205703087	0.19908300009758575	0.9245923913043478
18	0.16581548361036189	0.9429153918895923	0.19705425267634186	0.9239130434782609
19	0.16026956458157354	0.9444444439178659	0.18879259215748828	0.9300271739130435
20	0.15518548739096197	0.9459734964727181	0.18589341575684754	0.9300271739130435
21	0.15446215111798994	0.9486918104897946	0.18419413981230362	0.9320652173913043
22	0.148146474425723	0.9512402304694072	0.1765997157148693	0.9368206521739131
23	0.14428293114864132	0.9515800204278659	0.1751630247935005	0.9368206521739131
24	0.14242360574572094	0.9525993884197109	0.16991445422172546	0.9408967391304348
25	0.1365907454051171	0.9541284404277316	0.16768970988366916	0.9436141304347826
26	0.12993881073465485	0.9565069657825427	0.17205083953297656	0.9395380434782609
27	0.13162204201706323	0.9570166490493565	0.16527907841879388	0.9442934782608695
28	0.12717150142615724	0.9565069650736869	0.16190536384997162	0.9456521739130435
29	0.1208578264261645	0.9619435943837803	0.16286668667326804	0.9476902173913043
30	0.11970724461133732	0.9599048584000901	0.159792917902055	0.9483695652173914
31	0.12312724953438205	0.9605844376689109	0.159345388898383	0.9490489130434783
32	0.12062952894055434	0.9624532789872935	0.15707538357895354	0.9510869565217391
33	0.11715954944182527	0.9624532790075465	0.15429183128087418	0.9510869565217391
34	0.11378915096666997	0.9653414882975211	0.15780511919571005	0.9483695652173914
35	0.11093299312126544	0.9656812776281362	0.15571460241208906	0.951766304347826
36	0.11264646465210051	0.962623173672854	0.15516196013144826	0.9510869565217391
37	0.10750063833556854	0.9660210663714135	0.1520994802855927	0.9524456521739131
38	0.10709094485654704	0.96721032898806	0.15135115595615428	0.953125
39	0.1084184414405544	0.9673802243217172	0.15001688492686852	0.9524456521739131
40	0.10501117124834557	0.9650016983390624	0.1510760978512142	0.9497282608695652
41	0.1029085421512575	0.9677200130042356	0.14845313018430834	0.9524456521739131
42	0.10223856218971851	0.9692490650122562	0.14800942203272943	0.953125
43	0.102794865325392	0.9687393816036713	0.15336176825930242	0.953125
44	0.10509086621028406	0.9697587489676727	0.14721888838254887	0.9524456521739131
45	0.10173227462058079	0.9692490649717501	0.14715755795655044	0.9551630434782609
46	0.10017012693608168	0.9709480116450783	0.14704733568689096	0.9572010869565217
47	0.09695287722229674	0.9695888549707149	0.1521537849760574	0.953125
48	0.09345812077348913	0.9717974849513628	0.1485624883485877	0.9558423913043478
49	0.0933807981619817	0.9709480122526689	0.14605925475125728	0.9551630434782609
50	0.09239895093199998	0.972986748256612	0.14612307723449625	0.9565217391304348
51	0.09473494109939727	0.9726469589462501	0.1462494973903117	0.954483695652174
52	0.0925238311222387	0.9724770642201835	0.1456996202468872	0.954483695652174
53	0.08778019737347206	0.9765545361875637	0.1481555397419826	0.9558423913043478
54	0.08789032952106206	0.9751953789056097	0.14556173299965652	0.9565217391304348
55	0.08822823328010654	0.9741760102454149	0.14686034927549568	0.954483695652174
56	0.08776710318629935	0.9741760108935116	0.14419793078432913	0.9565217391304348
57	0.0869622152998684	0.975195378257513	0.14804684289771577	0.9558423913043478
58	0.08870762884059893	0.9762147468569486	0.14536523802772813	0.9551630434782609
59	0.09110471349294356	0.9750254835922054	0.1449727485685245	0.9551630434782609
60	0.08634545545514914	0.9755351681957186	0.14200543936180032	0.9578804347826086
61	0.08706181821695931	0.974855588947151	0.14362405985593796	0.9565217391304348
62	0.08759095472059929	0.9767244302250275	0.14183862896069235	0.9572010869565217
63	0.08281096873277716	0.9774040089065106	0.1427356616958328	0.9558423913043478
64	0.08165314460424514	0.9782534822127951	0.1438861805135789	0.9551630434782609
65	0.07979816414043688	0.9765545362280698	0.141993409184658	0.9572010869565217
66	0.08242084681633334	0.9784233768983557	0.14317720990789973	0.9565217391304348
67	0.08090447879773276	0.976894324910588	0.1411733358450558	0.9578804347826086
68	0.0787710571535643	0.9787631662087176	0.14094996322756229	0.9565217391304348
69	0.07665146432368884	0.9774040095546073	0.14282644718237544	0.9565217391304348
70	0.07881155404516357	0.9772341142412031	0.14163451002019903	0.9572010869565217
71	0.07772908456474188	0.9780835875677406	0.1431178194673165	0.9565217391304348
72	0.07969612686702114	0.9774040095748603	0.14476977653153564	0.9565217391304348
73	0.07572237280429402	0.9791029555798387	0.14059398679629617	0.9585597826086957
74	0.07836545420404886	0.9794427448699476	0.14079184360478236	0.9585597826086957
75	0.07500795792943962	0.9801223241792745	0.14050957414767015	0.9578804347826086
76	0.07116279336634923	0.9809717968577153	0.14325344060426173	0.9558423913043478
77	0.07367794993395227	0.9804621128820458	0.13990187482989352	0.9585597826086957
78	0.07397818173978996	0.979612640203605	0.13998844377372577	0.9585597826086957
79	0.07392266484352751	0.9801223235514307	0.1431892336062763	0.9558423913043478
80	0.0732179833421021	0.9802922181964853	0.13945411647791447	0.9585597826086957
81	0.06927615700456062	0.9816513755189453	0.14035687012516934	0.9578804347826086
82	0.07254694408610225	0.9794427454977914	0.1409148445109958	0.9592391304347826
83	0.07260818497951525	0.9804621128820458	0.14078457183811977	0.9599184782608695
84	0.07145024615305441	0.9804621128820458	0.1385473291511121	0.9585597826086957
85	0.06986931711435318	0.9818212702045058	0.13888291301934616	0.9558423913043478
86	0.06808276610424273	0.9814814808738909	0.14015822412203188	0.9572010869565217
87	0.06615945933411367	0.9811416915230228	0.14032940080632333	0.9592391304347826
88	0.0681012491542103	0.9814814808738909	0.13897182630456012	0.9578804347826086
89	0.06516324151769366	0.981651376207548	0.14258850041938864	0.9578804347826086
90	0.06444125757763125	0.9831804281345565	0.13820972455584485	0.9572010869565217
91	0.06520726185670483	0.9813115862085833	0.13912518614012262	0.9578804347826086
92	0.06535226578539098	0.980292218844582	0.14457079541424048	0.9558423913043478
93	0.06657408217346024	0.9825008495340856	0.1384071461532427	0.9578804347826086
94	0.06115522339681845	0.9840299014813472	0.13830163135476733	0.9578804347826086
95	0.06539015798515257	0.9828406381963509	0.137708503914916	0.9578804347826086
96	0.06561099820160518	0.9816513755391983	0.1397438493111859	0.9578804347826086
97	0.05969800136545423	0.9840299014813472	0.1390579958324847	0.9585597826086957
98	0.058658353603345946	0.9850492694529391	0.13976919197517892	0.9585597826086957
99	0.061620370709254066	0.9836901115026354	0.13872926698430724	0.9578804347826086

The optimal condition:
	epoch: 83
	train_acc: 0.9804621128820458
	val_acc: 0.959918478261
	using time: 482.261525154
