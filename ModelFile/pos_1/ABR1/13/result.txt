The number of train datas: 2376
The number of test datas: 596
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7258712089422977	0.5058922557919113	0.6885194618429914	0.5369127552781329
1	0.6884813854590008	0.5551346797333021	0.6713352359381298	0.6040268450375371
2	0.6686615861626185	0.5900673394652729	0.653791467615422	0.6661073827503512
3	0.6512181114668798	0.6435185177157624	0.6324769526520031	0.7516778531490557
4	0.6289971346405621	0.6792929284901731	0.6054618362612372	0.8355704693986266
5	0.6051682093328097	0.7188552186545298	0.5683199183252834	0.8842281911197125
6	0.5560211709854177	0.7954545462573016	0.5178038477897644	0.9211409379971908
7	0.5111305601267703	0.8303872059892725	0.45311977579289636	0.9395973138361169
8	0.44720499001769504	0.8619528627556181	0.38159060678226037	0.946308725232246
9	0.3904892695873273	0.8884680128659463	0.3121382244081305	0.9479865731808963
10	0.3314876771133757	0.9099326607354161	0.2531891513190814	0.9580536872748561
11	0.27773660877939027	0.927188551586485	0.20812224331718163	0.9530201302278762
12	0.2363250529525256	0.9343434347448124	0.175662369736089	0.9546979825768694
13	0.20954165544975487	0.9372895620888733	0.1538823834001618	0.9563758349258628
14	0.18942952331669805	0.9427609429616318	0.13947554727728734	0.9513422778788829
15	0.17963079807132182	0.9427609419581866	0.13059872218826474	0.9546979845770254
16	0.17379326661829195	0.9385521893549447	0.12194548782286228	0.9580536892750119
17	0.14597739976664584	0.9545454551475216	0.11588419578819467	0.9580536892750119
18	0.14186484888446854	0.9583333329319552	0.11238102914902988	0.9563758369260187
19	0.13449315849679086	0.952020201819513	0.10729738474892289	0.9580536892750119
20	0.12797982983215891	0.9549663293642628	0.10035089003359711	0.9614093939729985
21	0.14620333449657918	0.9482323232323232	0.10369657107547625	0.9580536892750119
22	0.12829785904398672	0.9579124575110798	0.09843763866580572	0.9580536892750119
23	0.11618044949842221	0.9617003362989586	0.09496521784755207	0.9597315416240052
24	0.1208269006074077	0.9608585852565188	0.09240479359790783	0.9597315416240052
25	0.12060416745718079	0.9604377100363324	0.09197497537872135	0.9580536892750119
26	0.11206473038854824	0.9595959591945815	0.09027164899462821	0.9580536892750119
27	0.11442231617692343	0.9591750837737061	0.0867463343795514	0.9597315416240052
28	0.1165903422868613	0.9583333341360895	0.08896767548066657	0.9597315416240052
29	0.10972620479085228	0.9629629621602068	0.08393702741037279	0.9614093939729985
30	0.11209198832511902	0.9612794610787723	0.08167156264585937	0.9630872463219918
31	0.10180678554757276	0.9663299663299664	0.08305120248122504	0.9630872463219918
32	0.10605718599325077	0.9646464640443976	0.08209076096247507	0.964765098670985
33	0.09734085776689479	0.9718013463999687	0.07845709067863106	0.964765098670985
34	0.09856775663918518	0.9675925917898365	0.07518079621879846	0.969798655717965
35	0.09924668398519558	0.9654882152875265	0.07994890378025554	0.9630872463219918
36	0.09753791584009273	0.9688552188552189	0.07338365994943868	0.9681208033689717
37	0.0959160001289965	0.9696969692955916	0.07110233597407405	0.969798655717965
38	0.09232272363270974	0.9667508425535979	0.07115630902999999	0.9731543604159515
39	0.09197513593567742	0.9692760938747162	0.06893707856835934	0.969798655717965
40	0.0946266577902065	0.9696969692955916	0.06799502440746999	0.9748322127649448
41	0.08769492930434769	0.9709595955582179	0.06803659762212094	0.9748322127649448
42	0.08770887445821506	0.971801347604103	0.06580895525497078	0.9765100651139381
43	0.079379083808223	0.973063972662595	0.06529967164333235	0.9765100651139381
44	0.08352653391232795	0.9730639724619059	0.06601154669219216	0.9731543604159515
45	0.07809603357254857	0.9726430972417196	0.06269520568667643	0.9781879174629314
46	0.08441713492476981	0.972222221419466	0.06357068673476277	0.9731543604159515
47	0.08608404271028659	0.9722222220215332	0.06117165868714352	0.9798657698119246
48	0.0822117047428282	0.9722222220215332	0.06181376742436582	0.9748322127649448
49	0.07874706161744667	0.9772727272727273	0.061432791086251305	0.9748322127649448
50	0.08228561864156113	0.9739057233036568	0.058937995375802854	0.9798657698119246
51	0.07265369072305634	0.9793771041764153	0.05870395348776107	0.981543622160918
52	0.07361855581151917	0.9776936022922246	0.056585004615703684	0.9798657698119246
53	0.07233770145260124	0.9768518516511628	0.056234849529378364	0.981543622160918
54	0.07361553205484493	0.9772727268713491	0.05549323171277174	0.981543622160918
55	0.07294908693994737	0.978114477913789	0.05548242739583022	0.981543622160918
56	0.069945725979227	0.9768518516511628	0.05380732338600511	0.981543622160918
57	0.06746118527018663	0.9789562289562289	0.05504564435890057	0.981543622160918
58	0.07096172884257153	0.9768518510490957	0.05356723592685373	0.981543622160918
59	0.0688480219556025	0.9776936022922246	0.051361300001208414	0.981543622160918
60	0.06481118567338094	0.9776936024929137	0.05246968752385786	0.981543622160918
61	0.06336747754603524	0.9802188550181662	0.05118297873027373	0.981543622160918
62	0.06322524236258031	0.9793771041764153	0.04963303369863721	0.9832214745099113
63	0.058103209743997464	0.9819023565009788	0.049199257371009594	0.9832214745099113
64	0.06294447956261812	0.980218854416099	0.04934923060788404	0.981543622160918
65	0.06338772448626431	0.9823232329252994	0.049948245549461985	0.981543622160918
66	0.06239937637189422	0.9806397300376635	0.04895317513220662	0.9832214745099113
67	0.061510380871769556	0.9819023565009788	0.048120445853111725	0.9832214745099113
68	0.06428515692852964	0.9764309758289094	0.04733844761480421	0.9832214745099113
69	0.06241368182530307	0.976010100809412	0.049198269781550306	0.9832214745099113
70	0.059251696962599805	0.9814814812807925	0.045080970772760826	0.9848993268589046
71	0.0592717293286163	0.9814814810801034	0.04555522022931368	0.9848993268589046
72	0.056952254740076036	0.9831649825629161	0.04432748938166855	0.9848993268589046
73	0.0609821621265877	0.981060605659228	0.04346924880206985	0.9848993268589046
74	0.060071269420260934	0.9827441075434187	0.042587297274762355	0.9865771792078978
75	0.05789122522278667	0.9844276090262314	0.042484006300668585	0.9865771792078978
76	0.05794162259308577	0.9831649831649831	0.04272374025727278	0.9848993268589046
77	0.05606681522395876	0.984006733605356	0.04219048542764363	0.9848993268589046
78	0.053960926479562764	0.9827441077441077	0.041313748181666304	0.9865771792078978
79	0.05197806811267479	0.9852693602693603	0.04220690154439251	0.9848993268589046
80	0.05742748722634733	0.9831649829642941	0.04095684881978387	0.9865771792078978
81	0.05380546517344035	0.9844276094276094	0.0411639398701439	0.9865771792078978
82	0.05596253333569376	0.9844276094276094	0.039977201291878754	0.9865771792078978
83	0.05342252167437213	0.9848484846477958	0.040240702625589084	0.9882550315568911
84	0.049110259371574476	0.9882154880147992	0.04010929848573752	0.9865771792078978
85	0.05374802684141731	0.9835858579837915	0.03945351642050199	0.9882550315568911
86	0.047706119703624386	0.9848484846477958	0.038182865428244506	0.9865771792078978
87	0.053106630264909985	0.9827441073427297	0.03898660209804973	0.9882550315568911
88	0.04892625483474145	0.9844276094276094	0.03786647131028992	0.9882550315568911
89	0.05312241466483885	0.9856902356902357	0.03970253186287896	0.988255033557047
90	0.04770692584641052	0.9865319865319865	0.03833601446259742	0.9882550315568911
91	0.045784603415514886	0.9856902352888576	0.03639549717007067	0.9882550315568911
92	0.04118250290352086	0.9877946125939238	0.03720939480668346	0.9882550315568911
93	0.051403660690945006	0.9835858585858586	0.035827189108869374	0.9882550315568911
94	0.04623169760511379	0.9873737367716703	0.03898098612291701	0.988255033557047
95	0.04313745457515973	0.9869528617521729	0.03593522359010757	0.9899328839058844
96	0.04431052315315413	0.9873737369723593	0.03651631249727419	0.9882550315568911
97	0.04429605083935188	0.9865319865319865	0.03583644428009155	0.9899328839058844
98	0.043615188587594916	0.9882154882154882	0.0352736455232105	0.9899328839058844
99	0.04378517360899986	0.9856902352888576	0.034755880463143325	0.9899328839058844

The optimal condition:
	epoch: 99
	train_acc: 0.9856902352888576
	val_acc: 0.989932883906
	using time: 184.480223894
