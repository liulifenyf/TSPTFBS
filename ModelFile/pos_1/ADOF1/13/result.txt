The number of train datas: 7432
The number of test datas: 1858
epoch	train_loss	train_acc	val_loss	val_acc
0	0.70784717329865	0.5145317545748116	0.682486542844413	0.5764262638384611
1	0.6941592626602452	0.5282561894510226	0.6759755570998874	0.5990312166824793
2	0.6863339671021	0.5501883745963402	0.6705120478559233	0.6297093638819437
3	0.6798156816813097	0.5702368137782562	0.6641115388392889	0.6447793326157158
4	0.6702351235214168	0.5916307857911733	0.6546490665914168	0.6679224971164544
5	0.6641626619805048	0.5941872981700753	0.6431781241531905	0.686221744644629
6	0.6558962934625419	0.61248654467169	0.6296084968471425	0.7093649083112875
7	0.6410865886347414	0.6454520990312164	0.6138815772674568	0.7395048436615516
8	0.6295457079413119	0.660118406889128	0.5976091928707898	0.7459634013786768
9	0.6093516329261279	0.6828579117330463	0.572457018209094	0.7771797635070218
10	0.5974918558343492	0.6942949407965554	0.5515271196837574	0.791173304371993
11	0.5710477250256246	0.714881593110872	0.5237793181376257	0.8013993544650412
12	0.5527774770498532	0.7319698600645855	0.499679521608404	0.8186221746376949
13	0.5255102204044617	0.751210979547901	0.47624057820076837	0.817545747282174
14	0.5121458795150207	0.7645317545748116	0.456647240499634	0.8277717984017823
15	0.4836325128637936	0.78740581270183	0.4380426395311551	0.8283100099301826
16	0.4649268188568953	0.7906350914962325	0.4085137352620054	0.8433799793055548
17	0.4407986139455576	0.8114908503767492	0.3890734945611369	0.8493003222221194
18	0.42584272285580504	0.8168729817007535	0.3807268161627397	0.8509149625817207
19	0.40885003227078875	0.8295209903121636	0.3562103761730974	0.8611410111349288
20	0.3925505272474689	0.8396124865446717	0.3521337976240111	0.8632938641136506
21	0.37579959614926184	0.8497039827771797	0.33141448840386645	0.8719052753869376
22	0.36366461867023464	0.8553552206673842	0.3367235129308136	0.8670613565537336
23	0.35083224275525343	0.864908503767492	0.3069914520685075	0.8842841758923073
24	0.3290477901600919	0.8768837459634015	0.2947291289451176	0.8918191607724735
25	0.3184166390877879	0.885091496232508	0.2821600938253947	0.8934337991431147
26	0.30371116972713863	0.8880516684607105	0.2741386707876162	0.898815930980399
27	0.30350437991329104	0.8895317545748116	0.2628467161092101	0.9031216366170425
28	0.28945156545313105	0.8939720129171151	0.2653122449011028	0.9004305708908804
29	0.274338836064893	0.903659849300323	0.24509774684200245	0.9133476861326507
30	0.2700898934745173	0.908772874058127	0.2402655030926539	0.9165769639004933
31	0.2597745878960781	0.9115984930032293	0.2409961874826347	0.9106566193799285
32	0.25096731794149935	0.9148277717976319	0.23374310803105422	0.9138858997783312
33	0.24784814314144804	0.9185952637244349	0.22015487162879516	0.9251883750454601
34	0.23713394566424054	0.9198062432723358	0.22591463908697484	0.9155005391755324
35	0.23222675074224708	0.9259956942949408	0.21461702219187506	0.9208826704995368
36	0.23355771965308134	0.9241119483315393	0.20523399979164833	0.9327233583857861
37	0.21942642857235395	0.9305705059203444	0.21451803772390465	0.9214208836319372
38	0.2147783649798615	0.9339343379978472	0.19630158674152343	0.9343379977829874
39	0.20903026198705638	0.9335306781485468	0.19169081372195862	0.9354144251385084
40	0.2067935299308744	0.9370290635091496	0.19114407771883535	0.9348762120061079
41	0.2020444866947517	0.9398546824542519	0.2065273553806691	0.9289558674855433
42	0.20650876339111954	0.935010764262648	0.1869401216218238	0.9391819159745913
43	0.19216745145482575	0.9405274488697524	0.17991373127384513	0.9397201285937117
44	0.1914169891658204	0.9403928955866523	0.18843003300663216	0.9375672770906701
45	0.1897603138816113	0.9426803013993541	0.18061662653803953	0.9413347685041931
46	0.18732847432145774	0.9453713670613563	0.17482393449102201	0.9407965564625127
47	0.18189349364733928	0.9468514531754575	0.1692987972042404	0.9445640483893157
48	0.18064414793214448	0.9465823466092572	0.17617463674175726	0.9467168993149173
49	0.1724918719192624	0.946178686759957	0.16941074905084974	0.9461786861825169
50	0.1724625962221969	0.94994617868676	0.17024220190982386	0.9472551124473177
51	0.16641380847206158	0.9503498385360603	0.16731479683784672	0.948869751844519
52	0.1647313877988298	0.9537136706135629	0.16123017702408063	0.9494079649769195
53	0.16111136109952137	0.9537136706135629	0.16352268426295116	0.9488697523577991
54	0.15834712077521662	0.9541173304628633	0.16136845880547945	0.9499461781093199
55	0.1619944728457793	0.9535791173304629	0.16703913518828134	0.9483315392253987
56	0.15568991159204199	0.9572120559741658	0.15951177957432647	0.9515608175065212
57	0.1536054640719657	0.9578848223896663	0.15640946946821635	0.9472551140513179
58	0.15185533189670902	0.9558665231431647	0.15521929611174232	0.9499461781093199
59	0.147225702551381	0.957481162540366	0.17033018219907267	0.9477933260929983
60	0.1446963656769887	0.9607104413347686	0.15661711678053258	0.9526372442846021
61	0.14611356739913173	0.9581539289558665	0.1551113485231338	0.9515608180198012
62	0.14714489984691978	0.9601722282023681	0.1532594057760403	0.9520990306389217
63	0.1444364234051227	0.9586921420882669	0.15225273062774775	0.9510226043741208
64	0.13500873409251735	0.9621905274488698	0.14946937018883114	0.9510226059781209
65	0.1405424702475479	0.9619214208826695	0.15276207939287562	0.9520990311522016
66	0.13720192058479055	0.9629978471474704	0.19400297931372412	0.9332615714540266
67	0.14397053643499688	0.9604413347685683	0.14691078545780306	0.9504843928457205
68	0.13202555801627197	0.9627287405812702	0.16181576848671692	0.9477933266062782
69	0.13232946202191007	0.964881593110872	0.1463554472902106	0.9520990322429218
70	0.13296839655793008	0.9646124865446717	0.16612519078413818	0.9467169003414774
71	0.1345492959808482	0.964881593110872	0.145840847325402	0.9542518847725234
72	0.13075060562598564	0.9644779332615716	0.1454811240070218	0.9531754569037225
73	0.12887889484747586	0.9634015069967707	0.1446646399338869	0.9531754585077227
74	0.12377440574928814	0.9651506996770721	0.14706236590802735	0.9537136705494029
75	0.12397193851047651	0.9663616792249731	0.14721489424212755	0.953713670036123
76	0.12460493112726796	0.9663616792249731	0.14807347116031483	0.9510226048874008
77	0.12020908384328254	0.9670344456404736	0.14213673042211644	0.9537136716401231
78	0.1227812808091212	0.9678417653390743	0.16267728585793975	0.9445640483251557
79	0.12118967222320508	0.9671689989235738	0.1464033254188665	0.9531754574170025
80	0.11595507965406124	0.9668998923573735	0.14022446628279014	0.9537136716401231
81	0.11366868422409786	0.9691872981700753	0.1438737666260439	0.953713670036123
82	0.11595336897088168	0.9686490850376749	0.1469085867906669	0.9542518836818034
83	0.11064037518571777	0.9697255113024758	0.1443465243467602	0.9547900963009238
84	0.11302521581028711	0.9703982777179763	0.1426431643500908	0.9531754574170025
85	0.11294261572242938	0.971340150699677	0.14379249527585264	0.9520990306389217
86	0.11340767854124917	0.9693218514531755	0.15739339222756601	0.9461786861183569
87	0.1110074432853477	0.9679763186221744	0.1564689950678654	0.9488697533843592
88	0.1071084400937683	0.9702637244348762	0.13965635187723408	0.9537136716401231
89	0.10334006311177438	0.9729547900968784	0.16152508181506775	0.9445640467211556
90	0.10828447123774927	0.9708019375672766	0.13758295812153842	0.9542518847725234
91	0.10148492609466495	0.9730893433799784	0.13747683964645643	0.9553283110373243
92	0.09955555363382795	0.9734930032292788	0.15457911993125284	0.9499461780451599
93	0.10184816927904718	0.9718783638320775	0.14068194136296203	0.9537136716401231
94	0.10216337645705087	0.9722820236813778	0.14541654668916798	0.9515608190463614
95	0.09925010949533646	0.9733584499461787	0.13936484443871916	0.9547900979049239
96	0.09807856448307489	0.972551130247578	0.138268693800378	0.9531754585077227
97	0.09915430443932827	0.9737621097954791	0.137725792704922	0.9547900979049239
98	0.09764633545064567	0.9730893433799784	0.1637713147890709	0.9461786861183569
99	0.10139691922713404	0.9722820236813778	0.14180974136191882	0.9526372447978821

The optimal condition:
	epoch: 91
	train_acc: 0.9730893433799784
	val_acc: 0.955328311037
	using time: 498.033931971
