The number of train datas: 8052
The number of test datas: 2014
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7065103995344026	0.5106805762247368	0.6887600479320121	0.5357497526848801
1	0.6963996377029172	0.5182563342446423	0.6846373346379876	0.5516385309390776
2	0.6883811755554627	0.5388723297226921	0.6796480213045009	0.588381331513868
3	0.6845071824166648	0.5567560858295382	0.6744501956524892	0.619165840428304
4	0.6765333860298324	0.5715350227692325	0.6671344404660957	0.6325719968564697
5	0.6736680759876685	0.5851962247773657	0.6587780737119256	0.6678252245605643
6	0.6657858232449846	0.5920268258998718	0.64801919910143	0.6936444897045564
7	0.6500861770290672	0.6302781913390636	0.6325685645286234	0.6956305865498025
8	0.6336399459803336	0.6525086934034705	0.6086669988641673	0.7552135067047642
9	0.6122446839216036	0.6774714356977668	0.5795825109581251	0.7864945393569893
10	0.5815352631396935	0.7101341279004263	0.5371497202416754	0.8118172803488601
11	0.5488698043399229	0.7362146050374542	0.4896299954144933	0.8515392260139488
12	0.49768879765369856	0.7812965721025197	0.4300309536828777	0.8773584910987505
13	0.445445986171297	0.8214108296963805	0.3670067561655319	0.903177756124362
14	0.39828947852691843	0.8466219572184752	0.3117174863105024	0.9245283020643634
15	0.33977382851073357	0.8811475411612657	0.24920357334637477	0.94687189684132
16	0.295338141676862	0.8987829108411142	0.2108256111167512	0.9558093347165886
17	0.2590124411513067	0.913437655448203	0.16978526532709184	0.9622641510025866
18	0.2256738740564044	0.9284649774084266	0.1449949498387292	0.9657398213104317
19	0.2082847747498345	0.9323149524218279	0.1257757410377471	0.9697120158887785
20	0.18552574372475147	0.9439890706533232	0.11365988768467009	0.9716981132075472
21	0.16982878685382488	0.9493293594911332	0.10281907376401356	0.9751737835153923
22	0.15817557269373286	0.9564083460487066	0.09370427713715568	0.9751737835153923
23	0.14827657142682746	0.9567809243197472	0.08880597041862487	0.9801390268123138
24	0.13885466751475506	0.9621212120027727	0.082411122838518	0.9791459781529295
25	0.13193274250506645	0.9641082956609712	0.0794474615862495	0.9831181727904668
26	0.12555978821763575	0.965971187016174	0.07374957267124697	0.980635551142006
27	0.12048991503433629	0.9703179337583959	0.07028814738888253	0.9831181727904668
28	0.11886272227629405	0.9698211625921626	0.06942175880126293	0.9831181727904668
29	0.11615954927630052	0.970566319075024	0.06814787102180654	0.9821251241310824
30	0.10999457517400998	0.9715598604895852	0.06647859354130739	0.9846077457795432
31	0.10677717494886134	0.973919523099851	0.06440833536861788	0.9826216484607746
32	0.10654930594958775	0.9715598606376344	0.062186984622771474	0.9846077457795432
33	0.10609017932483111	0.974292101489331	0.06328232814636463	0.9836146971201589
34	0.1003269855427138	0.9745404865690801	0.05919729581781568	0.9856007944389275
35	0.10069705535168678	0.9749130646624615	0.05910993419040102	0.9846077457795432
36	0.10031033939854517	0.9760307993867536	0.05973424806140267	0.9841112214498511
37	0.0988901444408678	0.9751614507193359	0.05777430878961394	0.9856007944389275
38	0.09202619341849333	0.9785146550402615	0.05780787620963501	0.9846077457795432
39	0.08783558478890754	0.9787630403864994	0.0564263558298231	0.9846077457795432
40	0.09211464709626817	0.9780178833410507	0.0555484235590063	0.9860973187686196
41	0.09324732770004263	0.97739692019753	0.055994685539511486	0.9851042701092354
42	0.09001225512891164	0.9778936910084451	0.0549210745271558	0.9856007944389275
43	0.08588794492632965	0.9786388477874051	0.054261134741337674	0.9846077457795432
44	0.08316187125293402	0.9793840042702665	0.05340109417786546	0.9851042701092354
45	0.07742695938249873	0.9800049672953477	0.052478342541782956	0.9860973187686196
46	0.08150924767575274	0.9793840042702665	0.052599061480256275	0.9856007944389275
47	0.08140565548415984	0.9793840039741679	0.05231027473818581	0.9865938430983118
48	0.07802208845762251	0.9819920513976941	0.053322069124941085	0.9851042701092354
49	0.07676977021328206	0.9812468952109312	0.05182528056670443	0.9856007944389275
50	0.07635074242083398	0.9814952802610706	0.05239751318131149	0.9856007944389275
51	0.07346732056317078	0.9831097863884749	0.05232393645238438	0.9856007944389275
52	0.0746792058779183	0.9816194730082141	0.05255393165255256	0.9851042701092354
53	0.07290218085405901	0.9822404373065192	0.050022560751663066	0.9860973187686196
54	0.07196874584182837	0.9814952805571691	0.051005819917849776	0.9856007944389275
55	0.07226870402182979	0.981246895062882	0.050926433787371335	0.9851042701092354
56	0.06896228624542021	0.9829855939374299	0.04976786321811489	0.9856007944389275
57	0.06889527718551823	0.9836065576731478	0.05048236879219543	0.9860973187686196
58	0.06503842335788397	0.9846000989396597	0.05107608769188867	0.9865938430983118
59	0.06975551658914685	0.9827372081470442	0.05147545394980623	0.9860973187686196
60	0.06796182925043506	0.9843517138599106	0.05066602582032418	0.9851042701092354
61	0.06469234661141321	0.984600099502247	0.049935563823509714	0.9841112214498511
62	0.06399060478198013	0.984600099087709	0.05002120102995261	0.9846077457795432
63	0.06419815671603832	0.984475906636664	0.0515167860271707	0.9860973187686196
64	0.062306569988195774	0.9844759061925161	0.05101121722534669	0.9846077457795432
65	0.06345486465676826	0.9849726777436777	0.050188275268662055	0.9851042701092354
66	0.06099603889381418	0.9841033283656234	0.050373097197286776	0.9851042701092354
67	0.0620191427335417	0.9847242923974399	0.05077976726694726	0.9841112214498511
68	0.06313659456524752	0.9853452557186196	0.05221707449880056	0.9856007944389275
69	0.05941617653195798	0.9843517135934219	0.050203851514792786	0.9856007944389275
70	0.05854113241384649	0.9844759067551034	0.050788732003254115	0.9841112214498511
71	0.0598955738880536	0.9848484845819961	0.05242436620024844	0.9856007944389275
72	0.05807610816968595	0.9860904124679698	0.05373806372292288	0.9851042701092354
73	0.05752768155078182	0.9844759063405655	0.05124783805407798	0.9836146971201589
74	0.056366641311297885	0.9855936414793955	0.051624358512365	0.9836146971201589
75	0.05345265276293315	0.9863387978142076	0.051245959442341935	0.9836146971201589
76	0.05396037646307912	0.9855936413313463	0.05194170983339907	0.9841112214498511
77	0.05527190804126188	0.9873323400874547	0.05143403107357741	0.9846077457795432
78	0.05358550845799432	0.9857178343745884	0.05207135380535223	0.9841112214498511
79	0.04805133062781709	0.9875807248711053	0.05234145602653434	0.9826216484607746
80	0.05451044087912156	0.9872081466296746	0.054867495672616375	0.9826216485199649
81	0.05412207341762662	0.9863387973996697	0.0526869695119434	0.9821251241310824
82	0.05147567592187421	0.9869597618460241	0.055955271871969504	0.9826216485199649
83	0.047814536676869364	0.9865871828939567	0.05341988582582081	0.9826216484607746
84	0.04935121522930447	0.9874565328345983	0.05390257571103438	0.9831181727904668
85	0.04784271290171401	0.9889468455042225	0.054390204300902335	0.9821251241902728
86	0.049251638708189244	0.987953303112536	0.053107150951483634	0.9831181727904668
87	0.04784865522275087	0.9882016891694104	0.053461909350544186	0.9841112214498511
88	0.048052128528370174	0.9874565321239618	0.053721980522863026	0.9841112214498511
89	0.046642079399745975	0.9874565328345983	0.05405181902900057	0.9826216484607746
90	0.04864887187189862	0.9867113763517369	0.054338893060532675	0.9831181727904668
91	0.045629222665890735	0.9889468450896846	0.05416956740175304	0.9826216484607746
92	0.04433740938606987	0.9877049183288855	0.05466003210284741	0.9821251241310824
93	0.04670806296106837	0.9873323400874547	0.057375006414690934	0.9801390268715041
94	0.04628728704838849	0.9885742672627919	0.06567679545745002	0.9781529296119258
95	0.042774328330908315	0.9883258817685047	0.055983569165978436	0.9816285998605806
96	0.04336909872608817	0.9873323400874547	0.055672148373921315	0.9831181727904668
97	0.042633007797313105	0.9880774964222668	0.05620870106070198	0.9811320755308884
98	0.041998325923427206	0.988325881916554	0.05701284358775485	0.9806355512011963
99	0.04134166759975029	0.9893194237456533	0.05637740668985908	0.9811320755308884

The optimal condition:
	epoch: 58
	train_acc: 0.9846000989396597
	val_acc: 0.986593843098
	using time: 694.981462955
