The number of train datas: 4858
The number of test datas: 1216
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7131468343263597	0.5078221490325237	0.6896222704335263	0.537828947368421
1	0.6926543262084358	0.5374639762090822	0.6813221228750128	0.5699013157894737
2	0.6848931182014839	0.5436393575150077	0.6746494079891004	0.609375
3	0.6771313403309398	0.5697818035302019	0.6682687809592799	0.6266447368421053
4	0.6714711515390122	0.5837793323717867	0.6609302884653995	0.6398026315789473
5	0.6710613518646589	0.5881020989178531	0.6534360647201538	0.6595394736842105
6	0.65727913205444	0.6121860846122531	0.6440884063118383	0.6702302631578947
7	0.6485573466838068	0.632770688114661	0.634329827208268	0.6957236842105263
8	0.6347074194080107	0.6552079043156721	0.6224395726856432	0.7113486842105263
9	0.6233995531065664	0.6687937418636151	0.6077820815538105	0.7327302631578947
10	0.6077165129058103	0.6815561955727977	0.5929710582682961	0.7442434210526315
11	0.5927305964345841	0.6978180319647477	0.575937220924779	0.7631578947368421
12	0.5789273287985932	0.7109921784644364	0.5553346182170668	0.7828947368421053
13	0.5552983437118436	0.7385755461299798	0.5339862861131367	0.7837171052631579
14	0.5423975462970443	0.7396047755296753	0.5094730540325767	0.8199013157894737
15	0.5115996619564558	0.7706875261233735	0.4849324069525066	0.8297697368421053
16	0.49154197789357496	0.7885961297511466	0.45421419959319265	0.8495065789473685
17	0.4659701559022406	0.8007410463358258	0.4235568328907615	0.8618421052631579
18	0.4387555490456868	0.8225607247252482	0.3931955067734969	0.875
19	0.40963793754234096	0.8373816392214616	0.3619875154997173	0.8930921052631579
20	0.3903440317287029	0.8462330181199172	0.3323481882873334	0.9046052631578947
21	0.36870176447865993	0.8589954718290999	0.3046692060796838	0.915296052631579
22	0.34095481343601114	0.8740222308310819	0.27753133522836787	0.9226973684210527
23	0.32029674036260397	0.8791683824919241	0.2593927242253956	0.9251644736842105
24	0.29286022172046816	0.9024289835623234	0.23308826590839185	0.9391447368421053
25	0.2824679742187274	0.9073692872328933	0.21580524036758825	0.946546052631579
26	0.2625174993298681	0.912721284430132	0.2010021923403991	0.9498355263157895
27	0.2493664610160138	0.9178674353548115	0.18898947615372508	0.9514802631578947
28	0.24033547488197274	0.9242486619517458	0.18184008645383934	0.9514802631578947
29	0.22389092423043264	0.9308357350911658	0.1716380464403253	0.9555921052631579
30	0.22466351301054643	0.9277480439228892	0.1620423425185053	0.9588815789473685
31	0.21625156606136894	0.9324825037993144	0.1616242041713313	0.9555921052631579
32	0.20693015767596493	0.9359818850097562	0.1494236470837342	0.9605263157894737
33	0.2030728479786732	0.9376286542332187	0.14838803245833046	0.9588815789473685
34	0.20169660782755133	0.9403046520711366	0.14047748556262568	0.9629934210526315
35	0.19101813768054685	0.9425689581491762	0.14485364015165128	0.9588815789473685
36	0.18507118141543183	0.9452449567477955	0.13842615877327166	0.9605263157894737
37	0.18330396692808787	0.9473034172648999	0.1349726389897497	0.9613486842105263
38	0.18537229628978122	0.945039111211399	0.13647550383680745	0.9605263157894737
39	0.1745399959222826	0.9487443394551016	0.13287979952598872	0.9605263157894737
40	0.17586566815777735	0.9477151098100184	0.12826666549632423	0.9646381578947368
41	0.17037296881642347	0.9508027992360432	0.1318463647836133	0.959703947368421
42	0.16701421075983272	0.9489501852368857	0.12540095809258914	0.9654605263157895
43	0.16428969742806177	0.9518320293719016	0.12905326250352359	0.9613486842105263
44	0.1682915241814484	0.950185261890691	0.12377980704370298	0.9654605263157895
45	0.1594002204803392	0.9524495682141181	0.12227280986936469	0.9654605263157895
46	0.15877110246352671	0.9520378751536857	0.11812773739036761	0.9662828947368421
47	0.1582294660169875	0.953478797589275	0.1295253412896081	0.9605263157894737
48	0.15483929808245808	0.9543021827040508	0.12419091321920094	0.9654605263157895
49	0.15551626971225377	0.9538904893982307	0.12013721348423707	0.9662828947368421
50	0.15693086306589432	0.9545080274797457	0.11945331410357826	0.9662828947368421
51	0.15117040705342213	0.9553314123245952	0.1142595731898358	0.9671052631578947
52	0.15070459911635797	0.9549197207855658	0.12062459027296618	0.9662828947368421
53	0.1437936552381162	0.9586249490292684	0.12142437676850118	0.9646381578947368
54	0.14404236966074618	0.9567723345147969	0.11917678011875403	0.9638157894736842
55	0.14305086962084262	0.9547138744884678	0.12108907103538513	0.9646381578947368
56	0.1437508850958476	0.9586249480231793	0.11597150917115964	0.9654605263157895
57	0.14424618357810134	0.9563606429757675	0.11305783414526989	0.9679276315789473
58	0.1363396984760827	0.9602717164859402	0.11613129549904873	0.9654605263157895
59	0.1385086135468693	0.9602717174920293	0.12113488896896965	0.9629934210526315
60	0.13608284756547387	0.9578015639144926	0.11868505807299363	0.9638157894736842
61	0.13451703812370286	0.9590366413289994	0.11396399905022822	0.9671052631578947
62	0.131609374714786	0.9598600241862093	0.1158703938126564	0.9654605263157895
63	0.12937933373421787	0.9598600249223721	0.11410562027441828	0.9671052631578947
64	0.12905656781926378	0.9648003295990311	0.10759837376443963	0.9712171052631579
65	0.12731477748886358	0.959654179140588	0.10882246611933959	0.96875
66	0.12582494104231223	0.962330177272971	0.11153324203271615	0.9679276315789473
67	0.11785568682781312	0.9658295592195755	0.1101368618638892	0.9679276315789473
68	0.11933398578958582	0.9608892545674553	0.10958817718844664	0.9679276315789473
69	0.12028875320646781	0.9633594068935154	0.10974221049170745	0.9679276315789473
70	0.11109705409207625	0.964594483817247	0.1177637486865646	0.9629934210526315
71	0.12053907176149191	0.9633594066481278	0.11249322365773351	0.9679276315789473
72	0.11414747199633328	0.9660354057620612	0.10872666263266613	0.96875
73	0.11371141536251024	0.9648003298444187	0.1127739762397189	0.9671052631578947
74	0.11222640898871589	0.9656237141984929	0.12422491512016247	0.9613486842105263
75	0.11559143131188573	0.9633594068935154	0.11837614857052502	0.9629934210526315
76	0.11025984128250807	0.9674763271915613	0.10671560740784596	0.9712171052631579
77	0.10989485041822314	0.9674763281731117	0.11256247405943118	0.9654605263157895
78	0.10825222554571003	0.9664470978164045	0.10968137728540521	0.96875
79	0.11198266172921918	0.9664470983071797	0.11328902134769842	0.9671052631578947
80	0.11064610426908857	0.9674763271915613	0.12160277837201168	0.9613486842105263
81	0.1005075282339404	0.9670646353826056	0.10546363811743886	0.9720394736842105
82	0.10438528445006005	0.9658295589741879	0.11494875385573036	0.9662828947368421
83	0.10085956242814285	0.9697406347419264	0.11565501262482844	0.9646381578947368
84	0.09741117339006124	0.9678880204973813	0.11291752147831415	0.9662828947368421
85	0.1008054519470163	0.9705640186052256	0.10793366087110419	0.9712171052631579
86	0.09784527896558762	0.9705640175991365	0.12121165034018065	0.962171052631579
87	0.0986590730359938	0.9689172496271506	0.11308044763772111	0.9671052631578947
88	0.0981913235524693	0.9689172496271506	0.1094422199224171	0.9679276315789473
89	0.09578820431168651	0.9707698641170833	0.10808358027746803	0.9695723684210527
90	0.09265736539258836	0.9709757109049565	0.10972812536515687	0.9679276315789473
91	0.09574698226448929	0.9682997125517248	0.10738166304011094	0.9712171052631579
92	0.09025516384923443	0.9715932489864715	0.11091875382944157	0.9679276315789473
93	0.09399253011559595	0.9691230961696362	0.13089452958420703	0.9605263157894737
94	0.08905022924466112	0.9709757106595689	0.11726181052233044	0.9638157894736842
95	0.08744496296663351	0.9734458629610903	0.11190644122268024	0.9671052631578947
96	0.08767417892230887	0.9711815556806515	0.1081270583366093	0.9712171052631579
97	0.0863381306122806	0.9715932484956964	0.1148477659413689	0.9638157894736842
98	0.08587404936490702	0.9734458627157027	0.12067393331151259	0.9638157894736842
99	0.08564177341222419	0.9738575550399724	0.12074306136683415	0.962171052631579

The optimal condition:
	epoch: 81
	train_acc: 0.9670646353826056
	val_acc: 0.972039473684
	using time: 322.172307014
