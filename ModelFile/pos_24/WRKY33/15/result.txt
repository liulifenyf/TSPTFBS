The number of train datas: 4858
The number of test datas: 1216
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7184952166699833	0.499794153702902	0.6914332540411698	0.5345394736842105
1	0.7013371114428517	0.5170852202429796	0.6855094558314273	0.5476973684210527
2	0.6936008100060094	0.5212021408232214	0.6799247641312448	0.5797697368421053
3	0.6852933177735984	0.5494030470365161	0.676142228277106	0.6019736842105263
4	0.6824913173607221	0.5549608893039149	0.6715961443750482	0.6217105263157895
5	0.6805908004410133	0.5549608890339885	0.6674412018374393	0.6307565789473685
6	0.6723241318935914	0.5856319478678085	0.6616253068572596	0.6488486842105263
7	0.6657794140503209	0.59613009454194	0.6555546584882235	0.6595394736842105
8	0.6544706888432461	0.6204199251838062	0.6480260365887692	0.6759868421052632
9	0.648764520552287	0.6268011522960545	0.6392441768395273	0.6842105263157895
10	0.6397088422800788	0.634623302359206	0.6304262123609844	0.6875
11	0.6282078192871066	0.6547962117950923	0.621398787749441	0.6957236842105263
12	0.6223129398197537	0.6663235892921674	0.6117829209879825	0.7006578947368421
13	0.6095363908758278	0.6786743521984834	0.6014875550019113	0.712171052631579
14	0.5978688111320941	0.680732811464111	0.587968951777408	0.7261513157894737
15	0.5823516791717855	0.7009057226177104	0.5737370064384059	0.7351973684210527
16	0.5691303869930988	0.7169617132524151	0.5581017858103702	0.75
17	0.5523898677847522	0.733429395426149	0.5408929555039657	0.7689144736842105
18	0.5312013729161419	0.7457801570319108	0.5199802706116124	0.7796052631578947
19	0.5187828243883023	0.7498970771091079	0.49757942086771917	0.7952302631578947
20	0.4924576580401751	0.77809798258624	0.4702150445235403	0.8248355263157895
21	0.47343047539262234	0.784685055504811	0.4412957273031536	0.8412828947368421
22	0.4464805449488331	0.8102099631194865	0.40783149317691203	0.8651315789473685
23	0.41819100927894326	0.8202964189416737	0.3765502603430497	0.8807565789473685
24	0.39151781477178255	0.8404693290646452	0.3426631265564969	0.8947368421052632
25	0.36688612745641536	0.8608480860736449	0.31161278956814814	0.9078947368421053
26	0.3389669189167494	0.8680526962639521	0.2827836918203454	0.921875
27	0.3127011829759418	0.8824619189266709	0.2541948870608681	0.930921052631579
28	0.2925093630769705	0.8950185265841432	0.2345291140832399	0.9317434210526315
29	0.2680770695307658	0.907780980268787	0.2103757607309442	0.9481907894736842
30	0.2665048926921478	0.9059283650426916	0.19432590196007177	0.9555921052631579
31	0.253301126432301	0.9172498965371337	0.18594125305351458	0.9514802631578947
32	0.2370227699345549	0.9205434337080433	0.17074902669379585	0.9539473684210527
33	0.2267269827655531	0.9254837388754774	0.16483011057502345	0.953125
34	0.22588311971927091	0.9254837376240007	0.1548714214249661	0.9605263157894737
35	0.20761403003412296	0.9337175799623445	0.1516545516879935	0.9564144736842105
36	0.20822112547512062	0.9343351180438595	0.1429668610033236	0.9613486842105263
37	0.19658310667214055	0.9382461913086446	0.13915360366043292	0.9613486842105263
38	0.2024349525797853	0.9343351170377704	0.1408029939783247	0.9605263157894737
39	0.18131714407776353	0.9417455747766522	0.13062970967669235	0.9638157894736842
40	0.18818280238239496	0.941128036204362	0.12896391670954854	0.9629934210526315
41	0.18101445093793897	0.9464800336715271	0.1306042404551255	0.9613486842105263
42	0.1729586332079411	0.9438040348029814	0.12474296320425837	0.9646381578947368
43	0.16701463855014706	0.9481268018889005	0.1210994242053283	0.9654605263157895
44	0.17621246008482327	0.9458624953200857	0.11853602058009098	0.9654605263157895
45	0.1660942887820644	0.9495677240791023	0.12134169434246264	0.9638157894736842
46	0.16404200870713956	0.9485384929371548	0.11441873406109057	0.9695723684210527
47	0.16036283908225518	0.9489501859975872	0.1254350003835402	0.9629934210526315
48	0.15994624148466893	0.9479209546102522	0.11694062501192093	0.9646381578947368
49	0.1600357614252095	0.951420338053721	0.11449552680316724	0.9654605263157895
50	0.15576009027208992	0.9516261830993423	0.120199949921746	0.962171052631579
51	0.15271851598308528	0.9512144917811617	0.11341371112748196	0.9654605263157895
52	0.15032261724136356	0.9547138747583941	0.1127790518497166	0.9654605263157895
53	0.1470894127863334	0.9557431036427758	0.11480911723092983	0.9638157894736842
54	0.1440492998969658	0.9530671060257068	0.11285191813581869	0.9654605263157895
55	0.14469695588157422	0.9557431046243262	0.11208073128210871	0.9662828947368421
56	0.14493955474250256	0.9530671052895441	0.10945019518074237	0.9671052631578947
57	0.14352391960813263	0.9530671057803192	0.10863918771869258	0.9679276315789473
58	0.13478295278676797	0.9582132559688359	0.10820415302326805	0.9671052631578947
59	0.1350442919130186	0.9580074101870518	0.11135653327954442	0.9654605263157895
60	0.1309624872994354	0.9584191030020967	0.1074968303896879	0.9646381578947368
61	0.13151065956459168	0.9559489499153351	0.10362343529337331	0.9720394736842105
62	0.1310862437191202	0.9590366410836118	0.10861626228219584	0.9662828947368421
63	0.12813583856848051	0.9590366405682978	0.10273259760517824	0.9712171052631579
64	0.12537461905726782	0.9621243312457993	0.10187750074424241	0.9703947368421053
65	0.12437729947897769	0.9596541793859756	0.10605190361016675	0.9662828947368421
66	0.12134998052171249	0.9606834095463728	0.10305820758405485	0.9695723684210527
67	0.11701986039982945	0.9608892545674553	0.10381968554697539	0.9671052631578947
68	0.11600454810802806	0.9617126384307544	0.10441799853977404	0.9671052631578947
69	0.11816100332657463	0.9621243312212605	0.10212948310532068	0.96875
70	0.1078196995484824	0.9666529440889637	0.10753379056328222	0.9662828947368421
71	0.11782203608577071	0.9650061753562764	0.11012703062672365	0.9662828947368421
72	0.10879395633150687	0.9633594076542169	0.1010727621614933	0.9695723684210527
73	0.10995955377841693	0.9641827920082912	0.10260982870271332	0.9695723684210527
74	0.10918215337715899	0.9645944830565455	0.11584171133213922	0.9638157894736842
75	0.10971660501932892	0.9645944835473206	0.11084078683664925	0.9662828947368421
76	0.10708081427794418	0.9652120211380605	0.1041048482844704	0.96875
77	0.10322280680878067	0.9672704819005524	0.10181566288596705	0.9703947368421053
78	0.10410406933418759	0.967682173218733	0.10569609348711215	0.9654605263157895
79	0.10381224775704498	0.9676821742248221	0.10244739585016903	0.96875
80	0.10199520751962744	0.9670646358733808	0.10700354921190362	0.9654605263157895
81	0.0968340919949283	0.9691230956543223	0.10004199119774919	0.96875
82	0.1017781774133456	0.9678880194912922	0.10931741171761562	0.9654605263157895
83	0.09563146944139758	0.9672704821704787	0.11064007446954124	0.9646381578947368
84	0.09426810832892783	0.9682997117910233	0.1016971786555491	0.9703947368421053
85	0.09690631303695456	0.9693289424421955	0.09977122219769578	0.9695723684210527
86	0.09448960424083012	0.9695347887147547	0.10320412602863814	0.9671052631578947
87	0.0954265120761686	0.9695347879540532	0.10232974824152495	0.96875
88	0.09057584739592695	0.9720049407954273	0.10651317748584245	0.9662828947368421
89	0.08937637055788869	0.9720049402801134	0.10342815792874287	0.9662828947368421
90	0.08401895720264754	0.972828324904114	0.10103234531063783	0.9695723684210527
91	0.08698422053944628	0.9703581725780539	0.09879211316767492	0.9695723684210527
92	0.08523841258238107	0.9763277076114201	0.10891480763491831	0.9646381578947368
93	0.08474659623126524	0.9695347882239796	0.11027079801026143	0.9646381578947368
94	0.08091726029861508	0.9732400172038449	0.10261363202804014	0.9695723684210527
95	0.07840139705943884	0.97385755528536	0.10567373860823481	0.9679276315789473
96	0.0806767239418232	0.9736517082520992	0.10027768835425377	0.9703947368421053
97	0.08059852904789287	0.9736517090128007	0.106110251851772	0.9671052631578947
98	0.07445268362404732	0.9757101687692035	0.11933916620910168	0.962171052631579
99	0.07972501224146894	0.9732400167130698	0.10693242636166121	0.9662828947368421

The optimal condition:
	epoch: 61
	train_acc: 0.9559489499153351
	val_acc: 0.972039473684
	using time: 393.152312994
