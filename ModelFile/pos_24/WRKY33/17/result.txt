The number of train datas: 4858
The number of test datas: 1216
epoch	train_loss	train_acc	val_loss	val_acc
0	0.716233933472545	0.5041169200526583	0.6894437733449434	0.5370065789473685
1	0.7017948297671007	0.5135858375356737	0.6845870206230565	0.5649671052631579
2	0.694557679636874	0.52490736855161	0.6799240990688926	0.5855263157894737
3	0.6858733217624933	0.5481679703827108	0.675592955790068	0.6077302631578947
4	0.681908882537856	0.5570193500664068	0.6713590151385257	0.6217105263157895
5	0.6790361032411364	0.5716344167195804	0.6667226490221525	0.6225328947368421
6	0.6718648777375157	0.5736928769912971	0.6602883307557357	0.6348684210526315
7	0.6657856510666085	0.5959242479749156	0.653519796697717	0.6521381578947368
8	0.6541343843460868	0.6230959245676658	0.645003993260233	0.678453947368421
9	0.6451725470229597	0.6274186913836587	0.63511082686876	0.680921052631579
10	0.6341256520148412	0.6459448328720978	0.6244920335317913	0.6916118421052632
11	0.6244534899198062	0.6607657473437725	0.6135652661323547	0.7014802631578947
12	0.6167760779701569	0.6790860432712764	0.6013360243094595	0.7154605263157895
13	0.6071503177598063	0.6832029637901711	0.5913506746292114	0.7146381578947368
14	0.5891077747900528	0.6988472621006061	0.5737577300322684	0.7524671052631579
15	0.5700563589895444	0.7161383283830268	0.5578123205586484	0.7549342105263158
16	0.5552726036582576	0.729312474122014	0.5388877078106529	0.7680921052631579
17	0.5377492033782542	0.7486620001853764	0.5196482570547807	0.7763157894736842
18	0.5228509877924568	0.7550432282546362	0.49869366696006373	0.7853618421052632
19	0.502940235963914	0.764717991335395	0.4763687817673934	0.8050986842105263
20	0.48074286709895786	0.7844792096984882	0.4491595751360843	0.8264802631578947
21	0.4593149920999881	0.7990942778730648	0.42401767404455887	0.8404605263157895
22	0.44106944658079966	0.8163853431739352	0.39752878013410065	0.8560855263157895
23	0.4233014377462074	0.8221490326709049	0.3731894806811684	0.8700657894736842
24	0.3963086187913124	0.8425277896308271	0.34590429067611694	0.8865131578947368
25	0.37741076624800807	0.852202552687047	0.3249773006690176	0.8939144736842105
26	0.35146591666059857	0.8662000817494807	0.30131546290297256	0.8980263157894737
27	0.33848919529588983	0.8672293128914281	0.2842450769324052	0.9136513157894737
28	0.3188775718187589	0.8853437625709116	0.2686357372685483	0.9136513157894737
29	0.3020233461742982	0.8915191431406743	0.2536323415605645	0.9202302631578947
30	0.296928418902224	0.8935776041485538	0.24113747006968447	0.9276315789473685
31	0.2871377368236383	0.8981062172371058	0.23151234733430961	0.9325657894736842
32	0.27448577954966424	0.9042815973160934	0.22137209302500674	0.9358552631578947
33	0.2688506661176976	0.9116920538034985	0.21521881458006406	0.9342105263157895
34	0.26390148302369176	0.912721284430132	0.20726940427955828	0.9391447368421053
35	0.24666870202287916	0.9129271312180053	0.20007921833741038	0.9399671052631579
36	0.2393311522241579	0.9197200495993566	0.19198103327500193	0.9523026315789473
37	0.236926997049005	0.9186908189727231	0.18858819572549118	0.9481907894736842
38	0.23815447463818468	0.9221902024407306	0.18629557913855502	0.9457236842105263
39	0.2202131526123697	0.9304240423006597	0.17942589364553752	0.9481907894736842
40	0.22888531294463837	0.9238369698974025	0.17580171713703557	0.9555921052631579
41	0.21710891578731442	0.9326883493357109	0.17838149792269656	0.9449013157894737
42	0.21197595991142104	0.9363935770640995	0.16967931076099999	0.9555921052631579
43	0.20248119831821368	0.9384520378511303	0.1641934733641775	0.9564144736842105
44	0.21214179884827936	0.936393577824801	0.162645833272683	0.9547697368421053
45	0.2013278895626347	0.9421572665856079	0.16104526582517123	0.9572368421052632
46	0.19565238630933593	0.9398929597959443	0.15766477898547523	0.9588815789473685
47	0.19078349695989946	0.9396871135233851	0.1585923488202848	0.9572368421052632
48	0.190164431224099	0.9421572665856079	0.15463430865814812	0.9580592105263158
49	0.18676353717424488	0.9421572665856079	0.15138694879255796	0.959703947368421
50	0.18704929224573177	0.9419514208038239	0.15232746381508677	0.9605263157894737
51	0.17892884377492901	0.9435981890211973	0.14725686217609205	0.9613486842105263
52	0.17954058820031316	0.9438040340668187	0.14836800137632772	0.9605263157894737
53	0.1733037340832424	0.949361877806543	0.14797815092300115	0.959703947368421
54	0.1649337661283504	0.9475092627767576	0.14098381133455978	0.9638157894736842
55	0.17094759756569608	0.9485384939187052	0.14444648945017866	0.959703947368421
56	0.17313934177982312	0.9475092625559088	0.14013338990901647	0.9629934210526315
57	0.16912784197046807	0.9483326478915334	0.14487932308724052	0.9572368421052632
58	0.16207961030779872	0.9540963354254024	0.14070612505862587	0.9613486842105263
59	0.161549371258866	0.950802799972206	0.14067892573381724	0.9613486842105263
60	0.15708545562586895	0.9538904893982307	0.14144625161823474	0.9605263157894737
61	0.16177174068002753	0.951626183835505	0.13327066090546155	0.9671052631578947
62	0.15420023602509803	0.9505969542149606	0.14029652468468012	0.959703947368421
63	0.1488025571312027	0.9540963354008637	0.13596645703441218	0.9613486842105263
64	0.1490591736721276	0.9540963364314915	0.1296156495809555	0.9679276315789473
65	0.14501845642783212	0.9530671062710944	0.13410958824189087	0.9605263157894737
66	0.14506278238874643	0.9534787985953641	0.13315602548812566	0.9613486842105263
67	0.1367343626164909	0.9584191030020967	0.13245983853151924	0.9613486842105263
68	0.13968990773833695	0.9561547959425067	0.12939506847607463	0.9654605263157895
69	0.14087460021660522	0.9573898718601492	0.13511082275133385	0.959703947368421
70	0.1348663297343421	0.9602717164859402	0.13736290308205704	0.959703947368421
71	0.14006554138125485	0.9573898723509244	0.12877522369748667	0.9646381578947368
72	0.1329804915626533	0.9582132564596111	0.12964636675621333	0.9638157894736842
73	0.12998567616659804	0.9602717174920293	0.12778014160300555	0.9638157894736842
74	0.1282506646774786	0.960065870213381	0.13882834170209735	0.9572368421052632
75	0.1310683562032673	0.9602717162405526	0.1370822052030187	0.9588815789473685
76	0.12513328619384137	0.9613009466217987	0.1318563638549102	0.9605263157894737
77	0.12451188348482155	0.9594483328680288	0.12583071052243835	0.9654605263157895
78	0.12637581152955707	0.9602717172466417	0.13000551630791865	0.9629934210526315
79	0.12146841798141789	0.9625360230302162	0.1312367921989215	0.962171052631579
80	0.12147177648475603	0.964182791002202	0.14125188067555428	0.9564144736842105
81	0.12137439247019843	0.9637710991932463	0.13380166574528343	0.959703947368421
82	0.11842390964825293	0.9637710989478587	0.13482275683628886	0.959703947368421
83	0.11665595502900508	0.964594483817247	0.13467365973874143	0.959703947368421
84	0.11277766504887447	0.9672704814097772	0.1308959814670839	0.9629934210526315
85	0.11441171432152458	0.9658295602256646	0.12569841762122355	0.9671052631578947
86	0.11419540979259542	0.9648003290837172	0.13599411221711258	0.9572368421052632
87	0.11327184150865806	0.9670646353826056	0.13283462626369377	0.9605263157894737
88	0.1121298608317597	0.9662412515193064	0.1312328726053238	0.9629934210526315
89	0.10620234674782163	0.9697406339812249	0.13186793343016975	0.9613486842105263
90	0.10036820891635709	0.9691230954089347	0.13186958079275332	0.9605263157894737
91	0.10594267908218419	0.9664470978164045	0.12800739568315053	0.9662828947368421
92	0.102726240095998	0.9670646356279932	0.13484081322033153	0.9613486842105263
93	0.10574977776245013	0.9654178679259336	0.14486801771349028	0.9539473684210527
94	0.09675458427894355	0.972210786822599	0.13779795179633716	0.9564144736842105
95	0.09997467934079207	0.9682997122817983	0.13107269335734217	0.9638157894736842
96	0.10076777020161806	0.9687114033545914	0.1246145940140674	0.9662828947368421
97	0.09625125649860976	0.9715932484956964	0.13786126643811403	0.959703947368421
98	0.09816406551286878	0.9689172498725382	0.1369402492909055	0.959703947368421
99	0.0977627535819541	0.9736517090128007	0.13642352564554466	0.9605263157894737

The optimal condition:
	epoch: 64
	train_acc: 0.9540963364314915
	val_acc: 0.967927631579
	using time: 387.959666014
