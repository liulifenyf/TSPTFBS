The number of train datas: 4858
The number of test datas: 1216
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7110659313476738	0.5150267597258753	0.6919022077008298	0.5082236842105263
1	0.6996902901726821	0.5197612178723181	0.6869811698010093	0.537828947368421
2	0.6914918607230439	0.5349938238830221	0.6831494161957189	0.5748355263157895
3	0.6863509409218572	0.5454919712687776	0.679481631831119	0.5929276315789473
4	0.6827700626413338	0.5574310410901223	0.6754164946706671	0.6126644736842105
5	0.68055498305541	0.5599011934407212	0.6707460096007899	0.6348684210526315
6	0.6725140970496299	0.5808974882122321	0.6651398570914018	0.6447368421052632
7	0.6687678818645768	0.5897488676505405	0.6591809956650985	0.6554276315789473
8	0.6561012346835822	0.6173322350461574	0.6516419272673758	0.662828947368421
9	0.6493448665133226	0.6270069983232262	0.6430307313015586	0.6677631578947368
10	0.6382951988217859	0.6403869903838502	0.6332429521962216	0.6735197368421053
11	0.6287182678946648	0.663030053127347	0.6234485350157085	0.680921052631579
12	0.6202052348972398	0.6661177432895344	0.612212714396025	0.6899671052631579
13	0.6109846480936119	0.6776451210565358	0.60112852799265	0.6973684210526315
14	0.5996498040772112	0.6856731160916925	0.5869360597510087	0.7088815789473685
15	0.5837354444829266	0.6951420338569035	0.5750092958149157	0.7228618421052632
16	0.5706663205330144	0.7177850968457878	0.5581585419805426	0.7401315789473685
17	0.5535706509381667	0.7237546313883788	0.539562746098167	0.7557565789473685
18	0.5378382615024242	0.7396047762167606	0.5218081505675065	0.7648026315789473
19	0.5184980076544076	0.7564841500031403	0.5010378548973485	0.7828947368421053
20	0.5020178075237204	0.764717991335395	0.47883539764504685	0.8092105263157895
21	0.4793798643137114	0.7822149036449874	0.45379248732014704	0.8166118421052632
22	0.4646639096830155	0.7960065872201021	0.42879221627586767	0.8379934210526315
23	0.4454777044688492	0.8077398102781124	0.40492725999731766	0.8585526315789473
24	0.4198214829139819	0.8188554967269333	0.3778034385881926	0.8717105263157895
25	0.4019482693784077	0.8429394817097092	0.35352950660805954	0.8848684210526315
26	0.3778360044701004	0.8489090154670599	0.32945173665096883	0.8980263157894737
27	0.3586401309482155	0.854261012934225	0.30572334559340225	0.90625
28	0.3390518162858098	0.8756690000300056	0.29063879188738373	0.9078947368421053
29	0.31836382049059564	0.882667764708455	0.26954111143162374	0.9185855263157895
30	0.3109391840115748	0.8867846852518885	0.25366389908288656	0.9235197368421053
31	0.2984015193678509	0.8944009880118529	0.24124545643204137	0.9268092105263158
32	0.2858101152352906	0.8929600653063372	0.22907656901761106	0.9350328947368421
33	0.27619610571625697	0.901193906417743	0.2205156181987963	0.9325657894736842
34	0.26887146739029205	0.9075751342416153	0.2099820061733848	0.9432565789473685
35	0.2576354439978052	0.9121037466185433	0.20256744403588145	0.9416118421052632
36	0.24654363270599	0.9193083577904009	0.1961594969034195	0.9416118421052632
37	0.24133562272396927	0.9197200491085814	0.18714461122688494	0.946546052631579
38	0.23606640007231844	0.9277480449289783	0.18696003838589317	0.9407894736842105
39	0.2233727094738412	0.9252778923575306	0.17494390983330577	0.9490131578947368
40	0.2250984110438122	0.9300123504671652	0.1722883519373442	0.9481907894736842
41	0.21455615912876586	0.9355701934707268	0.1709702767823872	0.9473684210526315
42	0.20747254807893117	0.9345409628195545	0.16313806176185608	0.9547697368421053
43	0.20034111479811828	0.9403046520956754	0.1587467295558829	0.953125
44	0.20788555299367076	0.9374228082060471	0.15770714141820608	0.9539473684210527
45	0.19803497621604768	0.9368052698791445	0.1543802697407572	0.9539473684210527
46	0.19317455973189374	0.9374228079606595	0.150075354074177	0.959703947368421
47	0.18598581389200056	0.9429806502035195	0.15565374650453268	0.9506578947368421
48	0.18454558338805843	0.9464800329108256	0.1476582994586543	0.9564144736842105
49	0.18299774056896354	0.9427748049125106	0.14529377692624143	0.9588815789473685
50	0.1811353415925594	0.9460683406110947	0.15065032714291623	0.9523026315789473
51	0.17259149526362066	0.9460683408564823	0.1436061608163934	0.9580592105263158
52	0.17623813787130918	0.9470975717530421	0.14391172755705683	0.959703947368421
53	0.16962248907444064	0.9489501849914981	0.14312694104094253	0.9564144736842105
54	0.16364326638147733	0.9479209545857133	0.1378759949615127	0.959703947368421
55	0.16286476268695677	0.9512144912658478	0.13778963488967796	0.959703947368421
56	0.16901397319512879	0.9505969542149606	0.1359389977235543	0.959703947368421
57	0.16066011105510325	0.9501852616453034	0.13963982227601504	0.9580592105263158
58	0.1582558835182184	0.9526554144866773	0.13793408713842692	0.9580592105263158
59	0.1559315802764873	0.9549197195340892	0.13219282344767921	0.9605263157894737
60	0.14873733545414652	0.9559489501607227	0.13223438043343394	0.962171052631579
61	0.15220661081616013	0.9538904896436183	0.12902095404110456	0.9638157894736842
62	0.14502848654114303	0.9557431036427758	0.1317427181883862	0.9605263157894737
63	0.1431236033726249	0.9573898723509244	0.1315467208623886	0.959703947368421
64	0.14192962435757786	0.9547138735069174	0.12656938872839274	0.9646381578947368
65	0.13907879510623725	0.9582132571957739	0.1272131961427237	0.9638157894736842
66	0.13843445984448066	0.958830794050351	0.1284283321154745	0.962171052631579
67	0.1317861333409667	0.958830794050351	0.1283770599647572	0.9613486842105263
68	0.13208203021392453	0.9573898731116259	0.1271066230378653	0.9638157894736842
69	0.13135656373964116	0.9602717174674906	0.12542763940597834	0.9662828947368421
70	0.12747724354573856	0.9606834082948961	0.12912994623184204	0.9605263157894737
71	0.1336312728771804	0.9586249482685668	0.12490775789085187	0.9662828947368421
72	0.12288243353931243	0.9625360225394411	0.12371306121349335	0.9679276315789473
73	0.12206610931430936	0.9617126384307544	0.12355674724829824	0.9654605263157895
74	0.11760181657580399	0.9635652526752995	0.13510097249558098	0.959703947368421
75	0.12430003975560608	0.9619184854640151	0.1329365055027761	0.959703947368421
76	0.11802059043921184	0.9635652529206871	0.12585867392389397	0.9646381578947368
77	0.1177802081704876	0.9645944835473206	0.12492882440748967	0.962171052631579
78	0.11862735212548567	0.9641827915175161	0.1284978123087632	0.9613486842105263
79	0.11485548621713011	0.9660354060074487	0.1226939668780879	0.9638157894736842
80	0.1127338814865468	0.9641827919837525	0.1356134197037471	0.9588815789473685
81	0.10548432734509268	0.968711403599979	0.12540063183558614	0.9629934210526315
82	0.11107925656598602	0.9662412512739189	0.1333978693736227	0.9613486842105263
83	0.10890569013668805	0.9668587901161354	0.13694836826700912	0.9572368421052632
84	0.10801341520225918	0.9676821734641206	0.12533281351390638	0.9638157894736842
85	0.1049233901894549	0.9676821742248221	0.12203926789133172	0.9654605263157895
86	0.10494306438152758	0.9685055573274197	0.12791629135608673	0.962171052631579
87	0.10340231906710068	0.9650061761169779	0.12212320338738591	0.9662828947368421
88	0.1039133855698039	0.9676821734641206	0.12035757813014482	0.9671052631578947
89	0.09850935623227643	0.9728283241434125	0.12783225547326238	0.9629934210526315
90	0.09782657690404521	0.9697406334904498	0.12144078490765471	0.9662828947368421
91	0.09690763741369697	0.9703581723326663	0.12387848057244953	0.9662828947368421
92	0.09374203000443126	0.9701523263054946	0.12636740780190417	0.9638157894736842
93	0.09621092340015197	0.9687114033545914	0.13480302387554394	0.9605263157894737
94	0.08801278741873061	0.974475093366875	0.12931930587479942	0.9613486842105263
95	0.09253255784904187	0.97159324822577	0.12754236200922414	0.962171052631579
96	0.09215436313575852	0.9730341711766732	0.12023295383704335	0.9671052631578947
97	0.08987650739012946	0.9722107870679866	0.12712980042162694	0.962171052631579
98	0.08857254405456494	0.9728283246341877	0.1394093068022477	0.959703947368421
99	0.0876294912416879	0.9720049407954273	0.13474786056107596	0.9588815789473685

The optimal condition:
	epoch: 72
	train_acc: 0.9625360225394411
	val_acc: 0.967927631579
	using time: 425.311231852
