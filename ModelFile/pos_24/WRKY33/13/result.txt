The number of train datas: 4858
The number of test datas: 1216
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7120183482735478	0.5117332235365162	0.6911459502420927	0.5337171052631579
1	0.6967777226284336	0.5345821328347679	0.6853656078639784	0.5625
2	0.6913417135555099	0.5310827496121479	0.6814515276959068	0.5805921052631579
3	0.6838676019576706	0.5516673521084666	0.6776695408319172	0.5921052631578947
4	0.679116638465495	0.5687525728790296	0.6729904381852401	0.6019736842105263
5	0.6755902585103807	0.5722519558317233	0.668700679352409	0.6151315789473685
6	0.6686069462317996	0.5878962536268443	0.6631091895856356	0.6324013157894737
7	0.6650125943323671	0.597982709498109	0.6571216018576371	0.647203947368421
8	0.6522329504620444	0.6259777679174414	0.6501762365040026	0.6587171052631579
9	0.6463035297226936	0.6315356109455418	0.6408586188366538	0.6726973684210527
10	0.633151714376777	0.6490325237459094	0.6320279209237349	0.6833881578947368
11	0.6246827261935737	0.6650885141597652	0.6226453843869661	0.6875
12	0.6191408385117391	0.6599423627197718	0.6119840741157532	0.6842105263157895
13	0.6025345589752401	0.6821737338997004	0.6016044993149606	0.6850328947368421
14	0.595828042937287	0.6832029640355587	0.5878287114595112	0.7179276315789473
15	0.578281731161869	0.7009057226177104	0.5757866846887689	0.7360197368421053
16	0.5676602777408052	0.7204610947082444	0.5575519988411352	0.75
17	0.5507913416135748	0.7354878556733271	0.5398139608533759	0.7615131578947368
18	0.5317929927926831	0.7470152329495533	0.5202478044911435	0.7804276315789473
19	0.5146933951315049	0.7525730757077274	0.4989432723898637	0.7894736842105263
20	0.49469754010279415	0.7706875263442223	0.4762702427412334	0.8116776315789473
21	0.475335345365423	0.787772746133235	0.44785332366039876	0.8322368421052632
22	0.4500538307901958	0.8095924245226575	0.41925829021554245	0.8495065789473685
23	0.42870481477298084	0.8221490332107575	0.3927621810059798	0.8692434210526315
24	0.4015298778380617	0.8342939475378709	0.3608090861847526	0.8832236842105263
25	0.3823413231727173	0.8503499379517268	0.3333966590856251	0.9004934210526315
26	0.3512618715697328	0.8651708523743238	0.3055980550615411	0.9136513157894737
27	0.33166818396207876	0.8758748452964757	0.2808823569824821	0.9177631578947368
28	0.3129813576269758	0.8867846852518885	0.26395229132551895	0.9202302631578947
29	0.29132330163656905	0.8974886786648156	0.24207353905627602	0.9268092105263158
30	0.285222266487449	0.9048991351522208	0.22533981423628957	0.9383223684210527
31	0.27134542632809683	0.9065459033695942	0.21789978444576263	0.9342105263157895
32	0.25558491643194603	0.9168382049735655	0.2027591796297776	0.9449013157894737
33	0.24812478201288213	0.9178674358701254	0.19413983272878746	0.9457236842105263
34	0.24081531030840225	0.9217785093802981	0.18368466590580187	0.9490131578947368
35	0.22443323899267534	0.9291889661130909	0.18038974074940933	0.9481907894736842
36	0.22441764446431692	0.9300123514732543	0.17392758476106743	0.9498355263157895
37	0.2190862380952784	0.9318649654724118	0.17195317776579605	0.9498355263157895
38	0.21871486980392885	0.931041580357636	0.16809625531497754	0.9506578947368421
39	0.2020535292560154	0.9365994233611976	0.15940682433153452	0.9539473684210527
40	0.20337772927028056	0.938657884369077	0.15695249014779142	0.9547697368421053
41	0.20277456231890711	0.9403046520956754	0.15867880300471657	0.953125
42	0.19063654994709398	0.9423631126127797	0.14970194038591886	0.9605263157894737
43	0.18546866922773123	0.9429806502035195	0.1483845491158335	0.9588815789473685
44	0.19048353227851517	0.9390695764234205	0.14613750263264305	0.9580592105263158
45	0.1827288032706847	0.9427748041763478	0.14838387228940664	0.9572368421052632
46	0.18056298968427806	0.946274186883654	0.1413992674727189	0.9613486842105263
47	0.1746999310607918	0.9458624943385354	0.14591295938742788	0.9572368421052632
48	0.1757255846603067	0.9454508030203548	0.14500487987932406	0.9572368421052632
49	0.17260260389218265	0.9491560307732821	0.14089058300382212	0.959703947368421
50	0.17076291820550465	0.9473034165287371	0.1383252551681117	0.9605263157894737
51	0.17105535710113143	0.9491560320002201	0.13646791130304337	0.9613486842105263
52	0.16595338419932504	0.9495677240791023	0.13611633212942825	0.9613486842105263
53	0.16026713832838638	0.950596953969573	0.13933825728140378	0.9588815789473685
54	0.15784849943006515	0.9532729525436536	0.13645177256119878	0.9588815789473685
55	0.15690561589168	0.9536846433465203	0.13389977263776878	0.9613486842105263
56	0.16044401106899683	0.9520378764051624	0.13025339575190292	0.9638157894736842
57	0.15481181897318083	0.9543021814525741	0.13091315211434112	0.9613486842105263
58	0.15065245111938758	0.9547138745130066	0.1299427794782739	0.962171052631579
59	0.15410142906313817	0.9547138742430802	0.1307102692754645	0.9605263157894737
60	0.14776561829154508	0.9536846436164467	0.13205437911184212	0.959703947368421
61	0.147179593310257	0.9559489496699475	0.1288902387022972	0.962171052631579
62	0.14270253928540028	0.9586249482685668	0.13032132191093346	0.959703947368421
63	0.14336713183534738	0.9563606424604536	0.1254422986193707	0.9638157894736842
64	0.1365642387860103	0.9580074099416642	0.12152086747320075	0.9671052631578947
65	0.13482055700502557	0.9575957186234837	0.12722045340036092	0.9605263157894737
66	0.13658409351279777	0.9582132567295374	0.12467846666511737	0.962171052631579
67	0.1267915663649487	0.9608892553281568	0.12440425863391474	0.962171052631579
68	0.12764810382730923	0.9584191019960075	0.12308016693905781	0.9638157894736842
69	0.1278855546591163	0.9606834092764464	0.11980109426536058	0.9662828947368421
70	0.12082213778685227	0.9600658704587686	0.12545242474267357	0.9588815789473685
71	0.13266362413033972	0.960065870213381	0.12223577813098305	0.962171052631579
72	0.11916584453130269	0.9625360225394411	0.1195867038086841	0.9662828947368421
73	0.11885382720917623	0.9635652526752995	0.12026984166157872	0.9646381578947368
74	0.11813213985709312	0.9602717164859402	0.13283489428852735	0.9555921052631579
75	0.12043050756641945	0.9631535608663437	0.12577073726999133	0.9580592105263158
76	0.11791042250436537	0.9606834087856712	0.11992254225831282	0.9629934210526315
77	0.11409418507582271	0.9627418693027755	0.12105512579804972	0.9613486842105263
78	0.11371624246761111	0.9629477155998736	0.12254235579779274	0.9605263157894737
79	0.1138038727673006	0.9627418693273143	0.1187903861466207	0.9638157894736842
80	0.11023996917001011	0.9666529433282622	0.13002391002680125	0.9547697368421053
81	0.10602564287681351	0.9660354054921347	0.11795287814579512	0.9654605263157895
82	0.10881636414129384	0.9645944830565455	0.13076439970418027	0.9555921052631579
83	0.10670533694691892	0.9668587901161354	0.12581982542025416	0.9572368421052632
84	0.10362365797695774	0.9654178671652321	0.12405445152207424	0.959703947368421
85	0.1036990533221303	0.9650061758715903	0.12074915868671317	0.9613486842105263
86	0.09954517784372383	0.9707698646323972	0.1288199983537197	0.9580592105263158
87	0.10426989096815373	0.9660354050013596	0.12022772941150163	0.9613486842105263
88	0.10177062659498692	0.9668587901161354	0.12444803550055153	0.9588815789473685
89	0.09662609388794904	0.9701523262809558	0.11931067234591435	0.9605263157894737
90	0.09460662015184251	0.971593248741084	0.12056178325100948	0.9605263157894737
91	0.09487358244659724	0.9691230961696362	0.11462742129438802	0.96875
92	0.09150288042989274	0.9709757109049565	0.13016529596949877	0.9580592105263158
93	0.09386072380521161	0.969946480278323	0.1295270772748872	0.9572368421052632
94	0.08704334553277458	0.9715932477349949	0.12328481105597396	0.959703947368421
95	0.08702666296812672	0.9695347884448284	0.1189203587801833	0.962171052631579
96	0.08796041874777098	0.9703581715719648	0.11612136524758841	0.9654605263157895
97	0.08977196875234207	0.9717990942774805	0.11847752450328124	0.962171052631579
98	0.0867875491078374	0.9715932479803824	0.12221070457445948	0.9605263157894737
99	0.08750886578663429	0.9734458627402415	0.12321178615093231	0.9613486842105263

The optimal condition:
	epoch: 91
	train_acc: 0.9691230961696362
	val_acc: 0.96875
	using time: 355.845501184
