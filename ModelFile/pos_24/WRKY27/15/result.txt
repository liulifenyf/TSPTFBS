The number of train datas: 2292
The number of test datas: 574
epoch	train_loss	train_acc	val_loss	val_acc
0	0.7105770030986992	0.4952006975601689	0.6903168511307614	0.5418118481436673
1	0.7110353799806631	0.491710295643898	0.6869714814611428	0.5592334525925773
2	0.6994592425710868	0.5161431062491985	0.6843772273030431	0.5749128951012881
3	0.6943369566041969	0.5383944153577661	0.6818594031217622	0.5940766581674901
4	0.6921210162094542	0.5327225139211818	0.6797623565803421	0.5958188136695569
5	0.6877083838714146	0.5366492146596858	0.6773263567000731	0.61672474012973
6	0.6820593055006097	0.5610820251609643	0.674858070416733	0.6358885031959322
7	0.6729518777412894	0.5916230359210601	0.6726464390339336	0.6445993012667534
8	0.6777668027353536	0.5732984285912173	0.6696295526384892	0.6585365834967185
9	0.6726412161482567	0.5863874353871503	0.6662376763928642	0.6445993062511138
10	0.6655024170459461	0.5955497395721822	0.6623103967527064	0.6620209069617534
11	0.6609519343517629	0.6134380441269534	0.6583769232138524	0.6724738705033625
12	0.6586874044170347	0.6230366487985715	0.6533544196484397	0.6846689922469003
13	0.6566301297142868	0.6116928449892041	0.6479294754902245	0.6951219537116925
14	0.6518213196574706	0.6217277474428347	0.6425751285685894	0.7038327505364236
15	0.6403562124903082	0.6579406638003977	0.6363427373175007	0.7229965136026256
16	0.6305195504042075	0.6644851648578677	0.6284862451437043	0.7351916353461634
17	0.6274501831119598	0.6697207665360203	0.6203409713735148	0.7386759573574265
18	0.6229684011682374	0.6640488658275904	0.6118455124233658	0.7648083648615183
19	0.6110339624511426	0.6867364757348106	0.6023378029517595	0.7717770043150474
20	0.5980887681401837	0.7033158798700436	0.592450848855208	0.7770034836975124
21	0.5924139500288439	0.7024432810813345	0.5815738834155146	0.7857142834297871
22	0.583609740251438	0.7098603838401315	0.570078632972797	0.7891986039872784
23	0.5756397907854582	0.7194589884077275	0.5577944645898267	0.8013937271845881
24	0.5558480370731254	0.7399650974423474	0.5432561679584224	0.8083623668457989
25	0.5404352982630904	0.7530541021578391	0.5285329704500656	0.8066202098899602
26	0.5248954980577266	0.7652705050679818	0.5124137908324132	0.8240418108082814
27	0.51865135135867	0.765706807114899	0.4965086166036254	0.8344947710269834
28	0.49598444215498255	0.7835951123978246	0.47838162638584497	0.8414634121419661
29	0.4763193715617295	0.8115183245033077	0.4595515860913107	0.850174216443238
30	0.4661136747550798	0.8119546251979382	0.44279293004644044	0.8536585372084109
31	0.4408158582958667	0.8224258277220667	0.4220050377089803	0.8675958159077873
32	0.4248264504768878	0.8328970339909898	0.40162501310222243	0.869337976186533
33	0.4155267308519773	0.8359511356287186	0.3833219217921799	0.8815330981377525
34	0.3844254583276379	0.8603839438415115	0.36334048881348	0.9024390262593791
35	0.3731760189691347	0.8520942396934535	0.34473442699020335	0.8954703836906247
36	0.36310589162675083	0.8743455504663744	0.325815997161101	0.912891987931853
37	0.33696887177946677	0.8721640501138843	0.3090145705261297	0.925087108221619
38	0.3193322437803991	0.876527050298754	0.2889248322734434	0.9303135907193094
39	0.30313399959401105	0.8965968584306994	0.27214194797888036	0.9355400715555463
40	0.281059957299557	0.9088132646695481	0.25566856557899237	0.9425087126705289
41	0.2787129868595596	0.9035776611189984	0.24134643843157366	0.9529616710200958
42	0.2682005691798778	0.9066317619245506	0.22828051764582924	0.9529616726815493
43	0.2485731994086327	0.9179755662540283	0.21691434069792984	0.9547038296373879
44	0.23594235050220555	0.9249563691503715	0.20459927763880753	0.9529616743430028
45	0.2182353164669107	0.9336823725367508	0.19315890038470357	0.9581881518563327
46	0.2218928170921915	0.9275741711336905	0.1833369342499909	0.9581881518563327
47	0.20591971808703158	0.9319371728788912	0.17434843865836538	0.9599303121350784
48	0.20506637456321383	0.9397905750840538	0.16763857972746526	0.961672472413824
49	0.19503803663020775	0.9380453753221721	0.16569231720543903	0.9668989515886074
50	0.18176840521382204	0.9485165800307642	0.15467081668069554	0.9634146326925697
51	0.17788696016004574	0.9441535782855635	0.1476065013362971	0.9651567913098618
52	0.1696354270917583	0.9506980798631438	0.14154734272990077	0.9668989515886074
53	0.16171624726025846	0.9511343805577742	0.13562705411935932	0.9668989515886074
54	0.16758781203424744	0.9502617807288445	0.13361119388080225	0.968641111867353
55	0.15252779265556868	0.9541884802190838	0.1282511267564438	0.9668989515886074
56	0.14579395497344552	0.9576788836956857	0.12310906857875166	0.968641111867353
57	0.1474856720232839	0.9576788831755753	0.12078505879079839	0.9721254324248444
58	0.14986313114927702	0.9642233847531557	0.11701701096022171	0.9721254324248444
59	0.1433436468139577	0.9589877831790252	0.11626141718248041	0.9721254324248444
60	0.134303736307026	0.9624781845751857	0.11191473963576327	0.97386759270359
61	0.13403782797213415	0.9616055852663663	0.10872582190439677	0.97386759270359
62	0.1284980230930588	0.9655322852767159	0.10651709326260597	0.9756097529823357
63	0.12853751925793827	0.9629144837094851	0.10604068037213349	0.97386759270359
64	0.1299688979645258	0.9624781840550753	0.10314927987416862	0.9773519132610813
65	0.11940417033059435	0.9637870850987459	0.10208153127585554	0.97386759270359
66	0.12033662999643706	0.9664048851056457	0.100957341362375	0.9773519132610813
67	0.1188514126858058	0.970767889347376	0.09839039791751822	0.9756097529823357
68	0.11975664061609571	0.9703315877165469	0.09722198099417138	0.9773519132610813
69	0.11069420520963885	0.9725130875489266	0.09561500742460377	0.9756097529823357
70	0.11429129468104811	0.9677137881257355	0.09481225720889061	0.9756097529823357
71	0.10304959332911756	0.9703315877165469	0.0930893395991691	0.9756097529823357
72	0.10393097241901603	0.9742582897033158	0.09202689620364418	0.9756097529823357
73	0.10465139595313847	0.9742582907435365	0.09137672411751664	0.9756097529823357
74	0.0969229019645205	0.9764397896397177	0.08984607349081737	0.9756097529823357
75	0.10863504287044	0.9703315891728559	0.08881613682267558	0.9756097529823357
76	0.09299345575208023	0.9746945909180567	0.0880306204748486	0.9756097529823357
77	0.0970343854310833	0.9720767884146273	0.08682081375907107	0.9756097529823357
78	0.10050980500993928	0.977312391965177	0.08690704877783613	0.9756097529823357
79	0.10116235403438305	0.9733856903944964	0.0861513321044553	0.9756097529823357
80	0.09374297656001845	0.9742582887671173	0.08512070525814017	0.9756097529823357
81	0.09590665596889991	0.9760034889450873	0.08409103218998228	0.9773519132610813
82	0.09105550562784102	0.9746945894617477	0.08464387388906412	0.9808362338185725
83	0.09473425102457535	0.9760034904013961	0.08713907421362109	0.97386759270359
84	0.0913267810853364	0.9768760917906569	0.0830656951131098	0.9825783940973182
85	0.08981205208347313	0.9781849923142172	0.08226272359957679	0.9773519132610813
86	0.09126837608805918	0.9768760903343481	0.08166121468207561	0.9808362338185725
87	0.08928074702022379	0.9777486921396971	0.08115731491236737	0.9808362338185725
88	0.08893353118842393	0.9786212899922077	0.0805069966702511	0.9790940735398269
89	0.09254020713854835	0.9738219905690165	0.0799411358993228	0.9825783940973182
90	0.090250708221297	0.9751308905724664	0.081318841942096	0.9756097529823357
91	0.08668319195717002	0.9812390935358577	0.07953978984094248	0.9808362338185725
92	0.08427140829242753	0.9790575926632573	0.0793553867769989	0.9825783940973182
93	0.08209182857738948	0.9781849918981289	0.07893380328026382	0.9808362338185725
94	0.08441497265876484	0.9794938928377774	0.07897374306510134	0.9808362338185725
95	0.07972516482257094	0.9808027908648079	0.07856047638928848	0.9808362338185725
96	0.0812676309121945	0.9825479935393076	0.0775917505890858	0.9825783940973182
97	0.0752915122642151	0.9838568945829781	0.07810549531456486	0.9808362338185725
98	0.07380428762023986	0.9821116929486992	0.0766668446777382	0.9825783940973182
99	0.07572505252523572	0.9816753931902674	0.0769121885455444	0.9808362338185725

The optimal condition:
	epoch: 98
	train_acc: 0.9821116929486992
	val_acc: 0.982578394097
	using time: 182.857040882
